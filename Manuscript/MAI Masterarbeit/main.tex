%%%%%%%%%%%%%%%%%%%
%% imports
%%%%%%%%%%%%%%%%%%%
\documentclass[12pt,twoside,a4paper,parskip]{scrbook} % oneside for writing, twoside for submission (space for comments on the print)
\setcounter{tocdepth}{2} % depth of table of contents, for debugging purposes
\usepackage[utf8]{inputenc} % define the encoding type for LateX, may be obsolete in newer versions of LateX
\usepackage{csquotes} % helper package for quotes
\usepackage[english]{babel} % language support, multiple languages can also be listed
\usepackage{mathptmx} % Sets text and math to Times-like font
\usepackage{floatflt} % wrap text around tables and figures, useful for some templates
\usepackage[pdftex]{graphicx} % /includegraphics command with more options
\usepackage[hidelinks]{hyperref} % used for cross-referencing in LateX, hidelinks is an option to better format links
\usepackage{xcolor} % color management
\usepackage{amssymb} % symbol support
\usepackage{textcomp} % text symbol support
\usepackage{nicefrac} % better formatting for fractions
\usepackage{pdfpages} % include pdf pages in LaTeX
\usepackage{float} % floating objects (i.e. figures, tables)
\usepackage{pdflscape} % better pdf support with more options
\usepackage[verbose]{placeins} % checks that floats are within bounds - verbose adds extra logs
\usepackage[markcase=ignoreuppercase,headsepline,plainfootsepline]{scrlayer-scrpage} % manage page styles, markcase: automatic typesetting in heads, headsepline: line underneath the headerm, plainfootsepline: rule above the footer
\usepackage[ruled,vlined]{algorithm2e} % algorithm environment, ruled: algorithm with line at the top and bottom. Caption is not centered but at the beginning of the algorithm, vlined: vertical line followed by a small horizontal line between the start and the end of each block
\usepackage{caption} % adds captions to figures, tables, equations... with correct number assignments
\usepackage{subcaption} % adds subcaptions to subfigures, useful for more complex figures, has to be imported after the caption package
\usepackage{epstopdf} % needed to use .eps 
\usepackage{longtable} % enables long tables over page boundaries
\usepackage{setspace} % sets line spacing
\usepackage{booktabs} % better line management and line separation within tables
\usepackage[sortcites,style=numeric,backend=biber,doi=false,isbn=false,url=false,eprint=false]{biblatex} % good package for bibliography support in LaTeX with biber backend, sortcites: sorting bibliography (name, title, year), style=numeric: standard numeric citation style (recommended!), doi/isbn/url/eprint=false: hide links in bibliography (recommended for clean bibliography!)
\usepackage{makecell} % tabular column heads and multilined cells
\usepackage{amsmath} % math support 
\usepackage{scrhack}

\bibliography{bibliography} % included biblatex formatted citations from the file bibliography.bib

\usepackage{lipsum} % only used for the template generation, remove this usepackage command and all \lipsum calls

\usepackage{booktabs} % For professional looking tables
\usepackage{tabularx} % For auto-adjusting column widths
\usepackage{geometry} % Adjust page margins if necessary
\geometry{margin=1in}

\usepackage{graphicx} % Add this in the preamble if not already included
\usepackage{booktabs}
\usepackage{multirow}
\usepackage{float}



%%%%%%%%%%%%%%%%%%%
%% definitions
%%%%%%%%%%%%%%%%%%%
\def\BaAuthor{Bibin Babu}
\def\BaAuthorStudyProgram{MAI} 
\def\BaType{Master Thesis}
\def\BaTitle{Determination of  Drug Efficacy  
on Pancreatic Tumor 3D Spheroidal Tissues}
\def\BaSupervisorOne{Prof. Dr. Magda Gregorová}
\def\BaSupervisorTwo{Prof. Dr. Jan Hansmann}
\def\BaDeadline{\SubmitDate}
\def\SubmitDate{January 15th 2025}
\def\git{https://github.com/.../...}
\def\iswithfullname{}  % Define this to indicate that the full name should be shown

% option to generate anonymous submission for plagiarism scan!
\ifdefined\iswithfullname
\def\ShowBaAuthor{\BaAuthor}
\else
\def\ShowBaAuthor{N.~N.}
\fi

\hypersetup{
pdfauthor={\ShowBaAuthor},
pdftitle={\BaTitle},
pdfsubject={Subject},
pdfkeywords={Keywords}
}

%%%%%%%%%%%%%%%%%%%
%% configs to include
%%%%%%%%%%%%%%%%%%%
\colorlet{punct}{red!60!black}
\definecolor{background}{HTML}{EEEEEE}
\definecolor{delim}{RGB}{20,105,176}
\colorlet{numb}{magenta!60!black}

\definecolor{gray}{rgb}{0.4,0.4,0.4}
\definecolor{darkblue}{rgb}{0.0,0.0,0.6}
\definecolor{cyan}{rgb}{0.0,0.6,0.6}

\definecolor{pblue}{rgb}{0.13,0.13,1}
\definecolor{pgreen}{rgb}{0,0.5,0}
\definecolor{pred}{rgb}{0.9,0,0}
\definecolor{pgrey}{rgb}{0.46,0.45,0.48}

\newcommand*{\forcetwoside}[1][1]{%
 \begingroup
   \cleardoubleoddpage
   \KOMAoptions{titlepage=true}% useful e.g. for scrartcl
   \csname @twosidetrue\endcsname
   \maketitle[{#1}]
 \endgroup
}
\def\c#1{\mathcal{#1}}
\DeclareUnicodeCharacter{2212}{-}

\begin{document}

%%%%%%%%%%%%%%%%%%%
%% Title page
%%%%%%%%%%%%%%%%%%%
\ifdefined\print
\newgeometry{centering}    %%% make the page centered on paper
\begin{titlepage}
	\newcommand{\HRule}{\rule{\linewidth}{0.5mm}}
	\centering
	\begin{center}
		\vspace*{.06\textheight}	
		\HRule \\[0.4cm] % Horizontal line
		{\huge \bfseries \BaTitle \par}\vspace{0.4cm} % Thesis title
		\HRule \\[1.5cm] % Horizontal line
		\vspace{4.5cm}
		\begin{minipage}[t]{0.4\textwidth}

		\centering
		{\large \BaAuthor} 

		\end{minipage}
		\vfill
		\vspace*{.1\textheight}
		{\large \BaType}\\[0.5cm] % Thesis type
		{\large University of Applied Sciences Würzburg-Schweinfurt}\\[0.5cm]
		{\large \SubmitDate}\\[4cm] % Date
		\vfill
	\end{center}
\end{titlepage}
\restoregeometry
\fi

\frontmatter
\titlehead{%  {\centering side head}
  {Technical University of Applied Sciences Würzburg-Schweinfurt (THWS)\\
   Faculty of Computer Science and Business Information Systems\\\\
	}}
\subject{\BaType}
\title{\BaTitle\\[15mm]}
\subtitle{\normalsize{submitted to the Technical University of Applied Sciences W\"{u}rzburg-Schweinfurt in the Faculty of Computer Science and Business Information Systems to complete a course of studies in \BaAuthorStudyProgram}}
\author{\ShowBaAuthor}
\date{\normalsize{Submitted on: \BaDeadline}}
\publishers{
  \normalsize{Initial examiner: \BaSupervisorOne}\\
  \normalsize{Secondary examiner: \BaSupervisorTwo}\\
}
\lowertitleback{
\centering\includegraphics[width=4cm]{figures/qrcode-thesis.png}
}
\forcetwoside

%%%%%%%%%%%%%%%%%%%
%% abstract
%%%%%%%%%%%%%%%%%%%
\section*{Abstract (en)}
Pancreatic tumor treatment is hindered by the intricate nature of tumors and their diverse microenvironments. This complexity necessitates an exploration into identifying optimal drug combinations and concentrations tailored to each patient's specific tumor characteristics. This thesis aims to assess drug efficacy by ranking these various drug combinations and concentrations. The ranking is based on features extracted from bright-field microscopy images of three-dimensional tumor tissue models using representation learning. The core challenge is to learn robust features that accurately characterize alterations in these tumor tissue models induced by drug application over time. This research seeks to develop a standardized and effective approach for evaluating drug efficacy, potentially improving treatment outcomes for pancreatic tumor patients.

% cSpell:disable
\section*{Abstract (de)}
Die Behandlung von Bauchspeicheldrüsentumoren wird durch die komplexe Natur der Tumore und ihre vielfältigen Mikroumgebungen behindert. Diese Komplexität erfordert eine Untersuchung zur Identifizierung optimaler Medikamentenkombinationen und -konzentrationen, die auf die spezifischen Tumoreigenschaften jedes Patienten zugeschnitten sind. Diese Masterarbeit zielt darauf ab, die Wirksamkeit von Medikamenten zu bewerten, indem sie diese verschiedenen Medikamentenkombinationen und -konzentrationen einstuft. Die Bewertung basiert auf Merkmalen, die aus Helligkeitsmikroskopiebildern dreidimensionaler Tumorgewebsmodelle mittels Repräsentationslernen extrahiert werden. Die zentrale Herausforderung besteht darin, robuste Merkmale zu erlernen, die Veränderungen in diesen Tumorgewebsmodellen genau charakterisieren, die durch die Anwendung von Medikamenten über Zeit induziert werden. Diese Forschung zielt darauf ab, einen standardisierten und effektiven Ansatz zur Bewertung der Medikamenteneffizienz zu entwickeln, der möglicherweise die Behandlungsergebnisse für Patienten mit Bauchspeicheldrüsentumoren verbessert.

\newpage
\chapter*{Acknowledgment}
\vspace{1em}

\setstretch{1.5}
Thank all who believed in me.

Thank Prof. Magda for guiding me to how to think scientifically and also for the SimCLR and autoencoder prediction ranking startegy.

Thank Prof. Jan for the softmax approach idea.

Thank Dalia for the code for sharp layer calculation and thanks for the biological stuff explanation and the once in a time opportunity.

Thank Phillip for the cell viability test idea.

Thank stefan for the microscope focal length explanation.

Thank Philipp for the resize and crop augmentationc idea and general explanation for th edata augemnetation.

Thank Dad and Mom for this life. Without you guys I won't be able to write this.

Danke.
\vspace{2em}

\hfill Würzburg, on 15.01.2025

\vspace{2em}

\noindent\rule{6cm}{0.4pt}

\vspace{0.5em}

\noindent Bibin Babu
%%%%%%%%%%%%%%%%%%%
%% toc
%%%%%%%%%%%%%%%%%%%
\tableofcontents

%%%%%%%%%%%%%%%%%%%
%% List of Figures and Tables
%%%%%%%%%%%%%%%%%%%
\listoffigures
\addcontentsline{toc}{chapter}{List of Figures}

\listoftables
\addcontentsline{toc}{chapter}{List of Tables}

%%%%%%%%%%%%%%%%%%%
%% Main part of the thesis
%%%%%%%%%%%%%%%%%%%
\mainmatter

% Include chapters
\include{chapters/introduction}
\include{chapters/Motivation}
\include{chapters/Research questions}
\include{chapters/literature_review}
\include{chapters/Data Description}
\include{chapters/Structure of the Thesis}

\include{chapters/Methodology for SimCLR}
\include{chapters/Methodology for Intermediate evaluation of SimCLR model}
\include{chapters/Methodology for Ranking}

\include{chapters/conclusions}



\backmatter
%%%%%%%%%%%%%%%%%%%
%% Appendices
%%%%%%%%%%%%%%%%%%%
\appendix
\chapter{Appendix}\label{appendix}
% Add appendix content here

Derivation of K-Means Clustering using Euclidean Distance and Mean

Objective Function
The k-means algorithm aims to minimize the total squared Euclidean distance between data points and their assigned cluster centroids. The objective function is:

\[
J = \sum_{i=1}^{n} \sum_{k=1}^{K} r_{ik} \| \mathbf{x}_i - \boldsymbol{\mu}_k \|^2
\]

where:
\begin{itemize}
    \item \( n \): Number of data points,
    \item \( K \): Number of clusters,
    \item \( \mathbf{x}_i \): The \( i \)-th data point,
    \item \( \boldsymbol{\mu}_k \): The centroid of the \( k \)-th cluster,
    \item \( r_{ik} \): Binary indicator; \( r_{ik} = 1 \) if \( \mathbf{x}_i \) belongs to cluster \( k \), otherwise \( r_{ik} = 0 \).
\end{itemize}

\subsection*{Cluster Assignment Step}
For a fixed set of centroids \( \{ \boldsymbol{\mu}_k \}_{k=1}^K \), assign each data point \( \mathbf{x}_i \) to the nearest centroid. This minimizes:

\[
r_{ik} =
\begin{cases} 
1, & \text{if } k = \arg\min_{j} \| \mathbf{x}_i - \boldsymbol{\mu}_j \|^2, \\
0, & \text{otherwise.}
\end{cases}
\]

\subsection*{Centroid Update Step}
For a fixed cluster assignment \( \{ r_{ik} \} \), minimize \( J \) with respect to the centroids \( \{ \boldsymbol{\mu}_k \} \):

\[
J = \sum_{i=1}^{n} \sum_{k=1}^{K} r_{ik} \| \mathbf{x}_i - \boldsymbol{\mu}_k \|^2
\]

Focus on a single cluster \( k \). The term involving \( \boldsymbol{\mu}_k \) is:

\[
\sum_{i=1}^{n} r_{ik} \| \mathbf{x}_i - \boldsymbol{\mu}_k \|^2
= \sum_{i=1}^{n} r_{ik} \left( \mathbf{x}_i^\top \mathbf{x}_i - 2 \mathbf{x}_i^\top \boldsymbol{\mu}_k + \boldsymbol{\mu}_k^\top \boldsymbol{\mu}_k \right)
\]

Take the derivative with respect to \( \boldsymbol{\mu}_k \) and set it to zero:

\[
\frac{\partial}{\partial \boldsymbol{\mu}_k} \sum_{i=1}^{n} r_{ik} \| \mathbf{x}_i - \boldsymbol{\mu}_k \|^2 =
-2 \sum_{i=1}^{n} r_{ik} \mathbf{x}_i + 2 \sum_{i=1}^{n} r_{ik} \boldsymbol{\mu}_k = 0
\]

Simplify:

\[
\sum_{i=1}^{n} r_{ik} \mathbf{x}_i = \sum_{i=1}^{n} r_{ik} \boldsymbol{\mu}_k
\]

Factor out \( \boldsymbol{\mu}_k \):

\[
\boldsymbol{\mu}_k = \frac{\sum_{i=1}^{n} r_{ik} \mathbf{x}_i}{\sum_{i=1}^{n} r_{ik}}
\]

This is the mean of the points in cluster \( k \).

\subsection*{Algorithm Summary}
The k-means algorithm alternates between the following two steps until convergence:

\begin{enumerate}
    \item \textbf{Cluster Assignment Step}: Assign each point \( \mathbf{x}_i \) to the nearest cluster:
    \[
    r_{ik} =
    \begin{cases} 
    1, & \text{if } k = \arg\min_{j} \| \mathbf{x}_i - \boldsymbol{\mu}_j \|^2, \\
    0, & \text{otherwise.}
    \end{cases}
    \]
    \item \textbf{Centroid Update Step}: Update the centroid of each cluster as the mean of its assigned points:
    \[
    \boldsymbol{\mu}_k = \frac{\sum_{i=1}^{n} r_{ik} \mathbf{x}_i}{\sum_{i=1}^{n} r_{ik}}
    \]
\end{enumerate}

This iterative process continues until the assignments \( r_{ik} \) and centroids \( \boldsymbol{\mu}_k \) no longer change or the change is below a threshold.

\subsection*{Cosine distance}

\section*{Normalization}

To calculate the cosine distance, we first \textbf{normalize} all data points and centroids. Suppose the normalized data points and centroids are \( \mathbf{x}_i \) and \( \mathbf{c}_k \), respectively, then:

\[
\|\mathbf{x}_i\| = 1 \quad \text{and} \quad \|\mathbf{c}_k\| = 1.
\]

This ensures all vectors are on the unit sphere. The cosine similarity between two vectors \( \mathbf{x}_i \) and \( \mathbf{c}_k \) is defined as:

\[
\text{cosine similarity} = \frac{\mathbf{x}_i^\top \mathbf{c}_k}{\|\mathbf{x}_i\| \|\mathbf{c}_k\|}
\]

Since \( \|\mathbf{x}_i\| = 1 \) and \( \|\mathbf{c}_k\| = 1 \), we substitute these values into the equation:

\[
\text{cosine similarity} = \frac{\mathbf{x}_i^\top \mathbf{c}_k}{1 \times 1}
\]

This simplifies to:

\[
\text{cosine similarity} = \mathbf{x}_i^\top \mathbf{c}_k.
\]

Thus, the \textbf{cosine distance} becomes:
\[
\text{cosine distance} = 1 - \mathbf{x}_i^\top \mathbf{c}_k.
\]



\section*{Relating Cosine Distance to Euclidean Distance}

For normalized vectors, we derive the relationship between \textbf{Euclidean distance} and \textbf{cosine distance}. The squared Euclidean distance between a data point \( \mathbf{x}_i \) and a centroid \( \mathbf{c}_k \) is:
\[
\|\mathbf{x}_i - \mathbf{c}_k\|^2 = \sum_{j} (x_{ij} - c_{kj})^2.
\]
Expanding this:
\[
\|\mathbf{x}_i - \mathbf{c}_k\|^2 = \|\mathbf{x}_i\|^2 + \|\mathbf{c}_k\|^2 - 2 \mathbf{x}_i^\top \mathbf{c}_k.
\]
Since \( \|\mathbf{x}_i\| = 1 \) and \( \|\mathbf{c}_k\| = 1 \), we get:
\[
\|\mathbf{x}_i - \mathbf{c}_k\|^2 = 1 + 1 - 2 \mathbf{x}_i^\top \mathbf{c}_k.
\]
Simplify:
\[
\|\mathbf{x}_i - \mathbf{c}_k\|^2 = 2(1 - \mathbf{x}_i^\top \mathbf{c}_k).
\]
Thus, for normalized vectors, the Euclidean distance is proportional to the cosine distance:
\[
\|\mathbf{x}_i - \mathbf{c}_k\|^2 = 2 \cdot \text{cosine distance}.
\]
Rearranging to express the cosine distance:
\[
\text{cosine distance} = \frac{\|\mathbf{x}_i - \mathbf{c}_k\|^2}{2}.
\]




\section*{Objective Function}

The k-means algorithm with cosine distance aims to minimize the cosine distance between data points \( \mathbf{x}_i \) and their assigned cluster centroids \( \mathbf{c}_k \). The objective function is:

\[
J = \sum_{i=1}^{n} \sum_{k=1}^{K} r_{ik} \left( 1 - \frac{\mathbf{x}_i^\top \mathbf{c}_k}{\|\mathbf{x}_i\| \|\mathbf{c}_k\|} \right),
\]
where:
\begin{itemize}
    \item \( n \): Number of data points,
    \item \( K \): Number of clusters,
    \item \( \mathbf{x}_i \): \( i \)-th data point,
    \item \( \mathbf{c}_k \): Centroid of cluster \( k \) (normalized to unit length),
    \item \( r_{ik} \): Binary indicator; \( r_{ik} = 1 \) if \( \mathbf{x}_i \) belongs to cluster \( k \), otherwise \( r_{ik} = 0 \).
\end{itemize}

\section*{Objective Function in Terms of Euclidean Distance}

Using the above result, the k-means objective function with cosine distance:
\[
J = \sum_{i=1}^{n} \sum_{k=1}^{K} r_{ik} \left( 1 - \mathbf{x}_i^\top \mathbf{c}_k \right)
\]
can be rewritten in terms of Euclidean distance:
\[
J = \sum_{i=1}^{n} \sum_{k=1}^{K} r_{ik} \frac{\|\mathbf{x}_i - \mathbf{c}_k\|^2}{2}.
\]
Here, the factor \( \frac{1}{2} \) accounts for the scaling difference.

\section*{Cluster Assignment Step}

For a fixed set of centroids \( \{ \mathbf{c}_k \}_{k=1}^K \), assign each data point \( \mathbf{x}_i \) to the nearest cluster based on the \textbf{cosine similarity} (or equivalently, minimize cosine distance):
\[
r_{ik} =
\begin{cases}
1, & \text{if } k = \arg\max_{j} \mathbf{x}_i^\top \mathbf{c}_j, \\
0, & \text{otherwise.}
\end{cases}
\]
\subsection*{Centroid Update Step for Cosine Distance}
For a fixed cluster assignment \( \{ r_{ik} \} \), minimize \( J \) with respect to the centroids \( \{ \mathbf{c}_k \} \):

\[
J = \sum_{i=1}^{n} \sum_{k=1}^{K} r_{ik} \frac{\|\mathbf{x}_i - \mathbf{c}_k\|^2}{2}
\]

Focus on a single cluster \( k \). The term involving \( \mathbf{c}_k \) is:

\[
\sum_{i=1}^{n} r_{ik} \frac{\|\mathbf{x}_i - \mathbf{c}_k\|^2}{2}
= \sum_{i=1}^{n} r_{ik} \frac{1}{2} \left( \|\mathbf{x}_i\|^2 + \|\mathbf{c}_k\|^2 - 2 \mathbf{x}_i^\top \mathbf{c}_k \right)
\]

Since the vectors are normalized, \( \|\mathbf{x}_i\| = 1 \) and \( \|\mathbf{c}_k\| = 1 \), we have:

\[
\sum_{i=1}^{n} r_{ik} \frac{1}{2} \left( 1 + 1 - 2 \mathbf{x}_i^\top \mathbf{c}_k \right)
= \sum_{i=1}^{n} r_{ik} \left( 1 - \mathbf{x}_i^\top \mathbf{c}_k \right)
\]

Now, take the derivative of the above with respect to \( \mathbf{c}_k \) and set it to zero:

\[
\frac{\partial}{\partial \mathbf{c}_k} \sum_{i=1}^{n} r_{ik} \left( 1 - \mathbf{x}_i^\top \mathbf{c}_k \right)
= \sum_{i=1}^{n} r_{ik} \mathbf{x}_i = \sum_{i=1}^{n} r_{ik} \mathbf{c}_k
\]

Simplify:

\[
\sum_{i=1}^{n} r_{ik} \mathbf{x}_i = \sum_{i=1}^{n} r_{ik} \mathbf{c}_k
\]

Factor out \( \mathbf{c}_k \):

\[
\mathbf{c}_k = \frac{\sum_{i=1}^{n} r_{ik} \mathbf{x}_i}{\sum_{i=1}^{n} r_{ik}}
\]

This is the mean of the normalized points in cluster \( k \).

\section*{Centroid Update Step}

For a fixed cluster assignment \( \{ r_{ik} \} \), update the centroids \( \{ \mathbf{c}_k \} \) as the \textbf{normalized mean} of all data points assigned to cluster \( k \):

\[
\mathbf{c}_k = \frac{\sum_{i=1}^{n} r_{ik} \mathbf{x}_i}{\left\| \sum_{i=1}^{n} r_{ik} \mathbf{x}_i \right\|}.
\]

\section*{Algorithm Summary}

The k-means algorithm with cosine distance alternates between two steps until convergence:

\begin{enumerate}
    \item \textbf{Cluster Assignment Step}: Assign each point \( \mathbf{x}_i \) to the cluster with the highest cosine similarity:
    \[
    r_{ik} =
    \begin{cases}
    1, & \text{if } k = \arg\max_{j} \mathbf{x}_i^\top \mathbf{c}_j, \\
    0, & \text{otherwise.}
    \end{cases}
    \]

    \item \textbf{Centroid Update Step}: Update the centroid of each cluster as the normalized mean of its assigned points:
    \[
    \mathbf{c}_k = \frac{\sum_{i=1}^{n} r_{ik} \mathbf{x}_i}{\left\| \sum_{i=1}^{n} r_{ik} \mathbf{x}_i \right\|}.
    \]
\end{enumerate}

\section*{Conclusion}

By normalizing the data points and centroids, the k-means clustering objective can be expressed in terms of both cosine distance and Euclidean distance. The equivalence:
\[
\|\mathbf{x}_i - \mathbf{c}_k\|^2 = 2(1 - \mathbf{x}_i^\top \mathbf{c}_k)
\]
enables seamless interpretation and implementation in the algorithm.

%%%%%%%%%%%%%%%%%%%
%% create bibliography
%%%%%%%%%%%%%%%%%%%
\cleardoublepage
\phantomsection
\addcontentsline{toc}{chapter}{Literature}
\printbibliography

%%%%%%%%%%%%%%%%%%%
%% declaration on oath
%%%%%%%%%%%%%%%%%%%
\addchap{Declaration on oath}

I hereby certify that I have written my master thesis independently and have not yet submitted it for examination purposes elsewhere. All sources and aids used are listed, literal and meaningful quotations have been marked as such.

\vspace{20pt}
\begin{flushright}
$\overline{~~~~~~~~~~~~~~~~~\mbox{\ShowBaAuthor, \SubmitDate}~~~~~~~~~~~~~~~~~}$
\end{flushright}

\addchap{Consent to plagiarism check}

I hereby agree that my submitted work may be sent to PlagScan (www.plagscan.com) in digital form for the purpose of checking for plagiarism and that it may be temporarily (max. 5~years) stored in the database maintained by PlagScan as well as personal data which are part of this work may be stored there.

\begin{small}
Consent is voluntary. Without this consent, the plagiarism check cannot be prevented by removing all personal data and protecting the copyright requirements. Consent to the storage and use of personal data may be revoked at any time by notifying the faculty.
\end{small}

\vspace{20pt}
\begin{flushright}
$\overline{~~~~~~~~~~~~~~~~~\mbox{\ShowBaAuthor, \SubmitDate}~~~~~~~~~~~~~~~~~}$
\end{flushright}
\end{document}
