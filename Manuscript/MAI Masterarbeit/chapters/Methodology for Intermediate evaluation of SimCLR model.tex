\chapter{Methodology for Intermediate evaluation of SimCLR model}\label{ch:Methodology for Intermediate evaluation of SimCLR model}

\textcolor{red}{change the name to evaluatoin to check whether simclr learned something? instead of intermediate evaluatoin?}  

If we do kmeans with cosine distance distance then it only compare direction of the vector thats why we need to do normal kmeans with euclidean dist to show 
the magnitude similarity

Final evaluation of the SimCLR model depends on the  Ranking task, neverthless we can use other evaluation metrics, such as downstream task 
like classification, clusetring, distance measurement approach to check if simclr atleast learned to differentiate between untreated , single dose and exploded images.

\section{Classification using Logistic Regression on the SimCLR features}
1. A common approach to verify whether the SSL model has learned generalized representations is to perform Logistic Regression on the learned features.
 In other words, we use a single, linear layer that maps these representations to class predictions, where the three categories, 'untreated' and 'single dose', 'explod'  
 serve as our classes. The Logistic Regression model can only perform well if the learned representations capture all the relevant features necessary for the task. 
 Moreover, we don't need to worry much about overfitting since only a few parameters are trained. Therefore, we expect the model to perform well even with limited data.
 

2. Baseline comparison to original images. We classify the original images to see if simclr feature vectors are better or worse than original image to classify.


3 classes trained for 250 epochs.
1.untreated dataset: total no of images: 472
2. single dose dataset :  total no of images: 103
3. exploded dataset from drug screening experiments:  total no of images:  40

i didn't add any other comibnation of drug screening experiments since we are not sure whether they belong to which gp. ( some of them have medium resemblence of the
 above dataset images but we can't be sure.)


\subsection{Comparison of Classification Accuracy and Epochs for Different Data Augmentations}

\textcolor{red}{Table 8.1.1 - are you saying that you classification accuracy is 100?
 That seems far too good to be true. Why do the train runs have different number of epochs? And what do you mean by "Test Epoch"?!}


 \textcolor{red}{general comment to tables with result - after giving the tables you need to write a text which helps us to interpret it. What are the most important 
 number we shall look at? What shall we take out from the table as a message. For example something like (please do not use this directly. I have no clue 
 if this is the message you want us to take away from the table) "In Table 8.1. we show that when using the features Before Projection Head all 
 augmentation methods reached 100 train and test accuracy. The Resize approach needed the fewest epochs."}
    
    \begin{table}[h!]
        \centering
        \resizebox{\textwidth}{!}{%
        \begin{tabular}{llcccccc}
        \toprule
        \textbf{Augmentation Type}      & \textbf{Metric} & \textbf{Strong} & \textbf{Sweet} & \textbf{Resize} & \textbf{Resize No Contrast} & \textbf{Sweet No Contrast} \\ \midrule
        \multirow{4}{*}{\textbf{After Projection Head}}  
            & Train Accuracy (\%) & 88 & 59.76 & 97.15 & 58.74 & 56.30 \\
            & Train Epoch         & 249   & 248   & 236   & 239   & 249   \\
            & Test Accuracy (\%)  & 86.18 & 62.60 & 96.75 & 53.66 & 51.22 \\
            & Test Epoch          & 240   & 235   & 239   & 248   & 237   \\ \midrule
        \multirow{4}{*}{\textbf{Before Projection Head}} 
            & Train Accuracy (\%) & 100 & 100 & 100 & 100 & 100 \\
            & Train Epoch         & 148    & 18     & 62     & 14     & 44     \\
            & Test Accuracy (\%)  & 100 & 100 & 100 & 100 & 100 \\
            & Test Epoch          & 1      & 1      & 2      & 2      & 2      \\ 
        \bottomrule
        \end{tabular}%
        }
        \caption{Performance metrics for different augmentation strategies before and after the projection head.}
        \label{tab:augmentation_metric}
        \end{table}
        

        \begin{table}[h!]
            \centering
            \caption{Original Image Results}
            \label{tab:original_image_results}
            \begin{tabular}{lcccc}
            \toprule
            \textbf{Metric}         & \textbf{Train Accuracy (\%)} & \textbf{Train Epoch} & \textbf{Test Accuracy (\%)} & \textbf{Test Epoch} \\ \midrule
            \textbf{Original Image} & 95.12                        & 18                   & 94.31                        & 15                  \\ 
            \bottomrule
            \end{tabular}
        \end{table}
            




\textcolor{red}{table 8.2 can you somehow bring this into table 8.1 e.g. as another column? Would be easier to read. The first column 
"Augmentation Type" could be made smaller if you wrap the text so that it is on multiple lines.} 






\section{kmeans clustering}

Idea is whether the learned representation from simlcr outperforms the original images in clustering the images (unsupervised manner) For that we use simple kmeans 
clusetring. We will cluster them based on both euclidean distance as well as cosine distance.





\subsection{Evaluation}

Full dataset (unbalanced): contains all control(untreated): 472, all single dose: 103, all exploded: 40 images, all drug screen visualy similar/closer to single dose.

40 subset (Balanced to the minimum nof set in the group which is exploded. ie there is only total 40 of exploded): contains random but make sure it have exploded like 
controls total 40, and all exploded which is basically 40, 10 ds close to sd, 30 single dose.

Curated Full dataset (unbalanced): contains all control except controls have debris: 280, all single dose: 103, all exploded: 40 images, all drug screen visualy 
similar/closer to single dose: 22.

Curated 40 subset  (Balanced to the minimum nof set in the group which is exploded. ie there is only total 40 of exploded but excluded explod look alike from control):
contains random but make sure it doesn't have exploded like controls total 40, and all exploded which is basically 40, 10 ds close to sd, 30 single dose.

run 100 times for different random initilisation.

\begin{table}[htbp]
    \centering
    \caption{Dataset Composition Overview}
    \begin{tabular}{lccccl}
    \toprule
    Dataset Type & Control & Single Dose & Exploded & Drug Screen & Notes \\
    \midrule
    \multicolumn{6}{l}{\textbf{Raw Datasets}} \\
    \midrule
    Full & 472 & 103 & 40 & -- & Unbalanced \\
    Balanced-40 & 40 & 30 & 40 & 10 & Minimum set balanced \\
    \midrule
    \multicolumn{6}{l}{\textbf{Curated Datasets}} \\
    \midrule
    Full & 280 & 103 & 40 & 22 & Debris-free controls \\
    Balanced-40 & 40 & 30 & 40 & 10 & No exploded-like controls \\
    \bottomrule
    \end{tabular}
    \begin{flushleft}
    \small
    Note: Drug screen images are visually similar to single dose treatment. All balanced datasets are normalized to the exploded group size (n=40).
    \end{flushleft}
    \end{table}

\begin{table}[H]
    \centering
    \caption{Evaluation Results on Different Datasets and Augmentations with cosine distance}
    \label{tab:evaluation_results_cosine_distance}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}llcccc@{}}
        \toprule
        \textbf{Projection Head} & \textbf{Augmentation Type} & \textbf{Full Dataset (Unbalanced)} & \textbf{40 Subset (Balanced)} & \textbf{Curated Full Dataset} & \textbf{Curated 40 Subset} \\ \midrule
        \multirow{5}{*}{\textbf{Before}} 
        & Strong                & 93.56 & 95.83 & 98.43 & 100 \\
        & Sweet                 & 93.72 & 100 & 100 & 100 \\
        & Resize                & 93.56 & 98.33 & 98.20 & 100 \\
        & Resize No Contrast    & 92.62 & 99.17 & 91.01 & 99.17 \\
        & Sweet No Contrast     & 97.65 & 98.33 & 99.55 & 99.17 \\ \midrule
        \multirow{5}{*}{\textbf{After}} 
        & Strong                & 86.19 & 94.17 & 89.89 & 95.83 \\
        & Sweet                 & 74.10 & 72.50 & 75.96 & 69.17 \\
        & Resize                & 90.27 & 94.17 & 88.99 & 94.17 \\
        & Resize No Contrast    & 74.1 & 56.67 & 68.31 & 60.83 \\
        & Sweet No Contrast     & 74.10 & 75.83 & 75.28 & 76.67 \\ \bottomrule
    \end{tabular}%
    }
\end{table}

\begin{table}[H]
    \centering
    \caption{Evaluation Results on Different Datasets and Augmentations with euclidean distance}
    \label{tab:evaluation_results_euclidean}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}llcccc@{}}
        \toprule
        \textbf{Projection Head} & \textbf{Augmentation Type} & \textbf{Full Dataset (Unbalanced)} & \textbf{40 Subset (Balanced)} & \textbf{Curated Full Dataset} & \textbf{Curated 40 Subset} \\ \midrule
        \multirow{5}{*}{\textbf{Before}} 
        & Strong                & 93.72 & 99.17 & 99.1 & 100 \\
        & Sweet                 & 98.12 & 93.33 & 99.30 & 100 \\
        & Resize                & 90.27 & 85 & 89.89 & 82.50 \\
        & Resize No Contrast    & 93.56 & 98.33 & 91.01 & 99.17 \\
        & Sweet No Contrast     & 99.06 & 99.17 & 99.78 & 99.17 \\ \midrule
        \multirow{5}{*}{\textbf{After}} 
        & Strong                & 92.15 & 95 & 89.89 & 95.83 \\
        & Sweet                 & 74.10 & 71.67 & 73.71 & 68.33 \\
        & Resize                & 74.10 & 84.17 & 75.73 & 84.17 \\
        & Resize No Contrast    & 74.10 & 56.67 & 68.76 & 57.50 \\
        & Sweet No Contrast     & 74.10 & 70.83 & 78.88 & 72.50 \\ \bottomrule
    \end{tabular}%
    }
\end{table}




\begin{table}[H]
    \centering
    \caption{Evaluation Results Using Different Distance Metrics}
    \label{tab:distance_metrics}
    \resizebox{\textwidth}{!}{%
    \begin{tabular}{@{}llcccc@{}}
        \toprule
        & \textbf{Metric} & \textbf{Full Dataset (Unbalanced)} & \textbf{40 Subset (Balanced)} & \textbf{Curated Full Dataset (Unbalanced)} & \textbf{Curated 40 Subset (Balanced)} \\ \midrule
        \multirow{2}{*}{\textbf{Original Images}} 
        & Cosine Distance    & 93.09 & 65.83   & 82.25   & 65.83   \\ 
        & Euclidean Distance & 82.26     & 67.5   & 72.81   & 68.33   \\ \bottomrule
    \end{tabular}%
    }
\end{table}



\textcolor{red}{Include PCA 1 here? maybe in ranking. but we can add PCA 2 fugures}

\textcolor{red}{do sd VS others all?}





\section{Direct day 7 to day 10 distance evaluation}
calculate distance between day 7 untreated and its corresponding day 10 treated one.
Idea is:
1. it should give same distance between day 7 and its corresponding day 10
 even its changed in position/flipped. ie checking whether simlcr learned to 
 be invariant to position error in microscope error because of manual 
 handling/transporting.
2. it sould give same distance even if its blured/sharpened
3. it should give sma edistance even if its changed in brightness
4. main test for k means centroid approach. it should give different distance to single dose and exploded.


basic evaluations for ranking:
1.
whether it learned to be invariant the position change:
do flipps and calculate the cosine distance from control to treated flipped versions. ( i don't expect it learn to the change in center of position, 
if it learns good we can say center crop have some effect maybe? but not for the edge one?)
2. 
shape invariant:control to all single dose should be almost same cosine distance.

it also applicable to time prediction and reconstruction ranking evaluation and also from kmeans centriod approach.


\textcolor{red}{We will start with cosine distance and euclidean distance. other distcances based on time if we have}


\textcolor{red}{we are trying to find whether simclr learns something, from simclr side cond 7 to same cond7 augs should have high cosine similarity and within all
 gps foe example within sd higher cosine similarity since its gping this is what we have to check but we will do this only after ranking strategy depend on time}


 \textcolor{red}{then if have time we will do cond7 to cond10, sd stuuf}

 \begin{table}
 \centering
 \begin{tabular}{ll*{5}{l}}
 \toprule
 \multicolumn{2}{l}{Augmentation type} & Strong & Sweet & Resize & No contrast Resize & No contrast sweet \\ 
 \midrule
 & Flip and rotation & 0.1932 & 0.0109 & 0.134 & 0.0120 & 0.0108 \\
 Before & Blur and sharpness & 0.0061 & 0.0185 & 0.171 & 0.0024 & 0.0058 \\
 & Brightness change & 0.0003 & 0.0037 & 0.184 & 0.0013 & 0.0043 \\
 \midrule
 & Flip and rotation & 0.3435 & 0.0204 & 0.0747 & 0.0113 & 0.0212 \\
 After & Blur and sharpness & 0.0108 & 0.0388 & 0.2087 & 0.0047 & 0.0133 \\
 & Brightness change & 0.0005 & 0.0067 & 0.2864 & 0.0024 & 0.0078 \\
 \bottomrule
 \end{tabular}
 \end{table}
 ```
    

 \begin{table}[H]
    \centering
    \begin{tabular}{@{}lll@{}}
    \toprule
    \textbf{Flip and Rotation} & \textbf{Blur and Sharpness} & \textbf{Brightness Change} \\ \midrule
    0.0291                     & 0.0001                     & $5.73 \times 10^{-8}$      \\ \bottomrule
    \end{tabular}
    \caption{Metrics for different augmentation types.}
    \label{tab:augmentation_metrics}
\end{table}
    



  