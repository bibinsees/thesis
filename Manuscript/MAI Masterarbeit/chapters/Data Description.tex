\chapter{Data Description}\label{ch: DataDescription}
\section{Data set}
\label{sec:Data set}
As explained in the chapter \ref{ch:intro}, the dataset consists of images taken by bright-field microscopy, which operate as follows: 

The tumor 3D spheroidal tissue model is illuminated by transmitted white light (i.e, light is projected from below and observed from above).
 The contrast in the image is created due to the reduction in light intensity as it passes through denser regions of the sample, where more light is
  absorbed or scattered. This results in a typical bright-field microscopy image where the sample appears darker against a bright background, giving 
the technique its name. In our case, the 3D tumor model appears as a dark grayish structure on a bright background. 
For simplicity, bright-field microscopy images will be referred to as 'images'.

 Since the tissue models are cultivated using robotic arms, the process sometimes fails to replicate the natural shapes and patterns that typically occur when laboratory personnel manually cultivate the samples. To ensure the 
 dataset's quality and consistency, Dalia Mahdy, Phd student who works in the lab, pre-processed the images through a machine learning model to filter out invalid ones. By 'invalid images' , we mean
  those that variates from the expected morphology of the tumor tissues as cultivated by lab personnel. These images are typically elongated either in height or width as shown in second image 
 of figure \ref{fig:valid}. I collected these filtered images via USB and Google Drive in their original TIFF format. 

  \begin{figure}[H]
    \centering
    \includegraphics[scale=0.25]{figures/finevalid.png} 
    \caption{Examples of bright-field microscopy images with valid and invalid (unexpectedly elongated) morphology of tumor tissue models.}
    \label{fig:valid}
  \end{figure}

  The original images are 2456x2054 pixels in size, in 16-bit grayscale, and consist of multiple layers. These layers are obtained by capturing images
   at different focal planes in brightfield microscopy. The number of layers can vary, as images can be taken at any number of focal planes. The sharpness 
   of each layer of an image depends on how well the focal plane of the microscope aligns with the depth of the tumor tissue model. Only one layer of this 3D tumor tissue model will 
   be perfectly in focus, while others may appear blurry because they are slightly above or below the focal point as you can see in figure \ref{fig:blur}. Combining these focal planes later in 
   computational analysis can provide richer data, even if some layers are blurry individually. This is one of the reasons why I decided to use multiple
    layers. The images I received from the lab mostly have three layers, while a few have one or five layers.

    \begin{figure}[H]
      \centering
      \includegraphics[scale=0.4]{figures/blur.png} 
      \caption{Different layers of the same image reveal that, from A to C, the region above the white dotted line becomes sharper, while the region below becomes blurry }
      \label{fig:blur}
    \end{figure}

    Within the same experiment, images are 
    captured using consistent acquisition settings. that means each image in the same experiment consists of different layers captured at same focal lengths. For example, if image 1 has layers corresponding to focal
 lengths A, B, and C, Image 2 will also have layers corresponding to the same focal lengths A, B, and C.  However, for images from different experiments, the focal lengths may differ. For instance, images from 
 experiment 1 (single dose) may have slightly different acquisition settings compared to images from experiment 2 (drug screening), leading to variations 
 in the focal lengths and corresponding layers. 
 Secondly, the layers in each image are slightly misaligned when stacked, as shown in the figure  \ref{fig:Misalignment}. This misalignment of layers within the image and variation in focal length inbetween the images may or may not affect the performance of ranking.

 \begin{figure}[H]
  \centering
  \includegraphics[scale=0.25]{figures/posi.png} 
  \caption{A small section of the image was zoomed in and separated to show the misalignment of the three stacked layers.}
  \label{fig:Misalignment}
\end{figure}
\begin{figure}[H]
  \centering
  \includegraphics[scale=0.2]{figures/noise.png} 
  \caption{Noise}
  \label{fig:noise}
\end{figure}
We observed some temporal noise/artifacts, as shown in figure  \ref{fig:noise} in images. The presence of artifacts in the well-plates could be attributed to environmental factors such
as temperature, humidity, or CO\textsubscript{2}, or by some inconsistencies in sample handling. Such factors are likely to cause variations in cell behavior and
inconsistency in the  acquired images. These images were included as-is for SimCLR training, providing an opportunity for the model to learn from realistic conditions. 
However, I didn't artificially introduce additional noise or artifacts through data augmentation. This approach highlights a potential area for further exploration in future work. 

Figure \ref{fig:drug_eff} illustrates that, even with the same drug concentration applied to the spheroid tissue models under controlled conditions, occasional variations in 
effects were observed across different experiments. These variations could result from slight differences in spheroid composition or undetected microenvironmental influences 
that affect drug absorption by the spheroid and cellular response. Initially, I thought I would be able to evaluate the effect by drug combination, but because of this 
difference, we need to make the ranking relative assessment based on the day 10 images nevertheless it is applied by the same drug combo.


\begin{figure}[H]
  \centering
  \includegraphics[scale=0.5]{figures/drug_eff.png} 
  \caption{gp 8 drug applied}
  \label{fig:drug_eff}
\end{figure}


The table below shows the division of different types of image datasets we have, as  explained in the section ~\ref{sec:lab-setup}.
\begin{table}[ht!]
  \centering
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{|l|c|c|c|c|c|c|}
  \hline
  \textbf{Class} & \textbf{Drug Screened} & \textbf{Single Dose} & \textbf{Cond 10} & \textbf{Untreated} & \textbf{Day 8 \& 9} & \textbf{Total} \\ \hline
  \textbf{No. of Images (\%)}  & 200 (16.05\%) & 103 (8.26\%) & 231 (18.54\%) & 472 (37.89\%) & 240 (19.26\%) & 1246 \\ \hline
  \end{tabular}%
  }
  \caption{Dataset Class Overview}
  \label{tab:dataset}
\end{table}



An 8-bit image encompasses 256 color tones (ranging from 0 to 255) per channel, whereas a 16-bit image accommodates 65,536 color tones 
(ranging from 0 to 65,535) per channel, in our case 65,536 shades of gray. Retaining the original 16-bit depth is crucial because
 Converting it to an 8-bit image for faster and more efficient computation can lead to significant information loss in intensity details.
Since 8-bit images only allow 256 possible values, the finer variations in intensity that are present in 16-bit images become compressed as illusstrated in \ref{fig:8bitvs16bit}.
For example, two distinct values in 16-bit (from 30,000 to 30,048 ) could map to the same 8-bit value (for instance, both might be mapped to 117).
This results in the loss of subtle intensity differences, which can be crucial in our image task, where minute variations in intensity can be indicative
 of important features such as gradual trasnsition of dark color frfom center to border or amount of debris surrounded to the tumor cell.


 \begin{figure}[H]
  \centering
  \includegraphics[scale=0.5]{figures/8bitvs16bit.png} 
  \caption{8-bit vs 16 bit data lose comparison}
  \label{fig:8bitvs16bit}
\end{figure}

\section{Challenges}
\begin{enumerate}
    \item \textbf{Limited Dataset for Day 7 to Day 10 ranking prediction Model:} The dataset for predicting outcomes between Day 7 and Day 10 is limited, which poses a challenge for training and evaluation.

    \item \textbf{Issues with Day 10 Images:}
    \begin{enumerate}
        \item \textbf{Image Variations:} Day 10 images can exhibit variations such as flipping, blurring, brightness changes, and position changes from the original position of tumot tissue 
        cell in the image. 
        The position change occurs because, when the well plate is brought outside and then placed back under the microscope for taking day 10 image, 
        the position often shifts. This relative position of the tumor cell in the image can shift from the center to other directions.
         While a 'center crop' explained in in Section~\ref{sec:data preprocessing} approach can address this issue to some extent, it fails when the tumor cell 
         is located at the edge of the image. To deal this issue for some extend, Applying horizontal and vertical flips, rotations by $90^\circ$ and $270^\circ$, as 
        well as combinations like horizontal flip + rotation $90^\circ$ and horizontal flip + rotation $270^\circ$, can help make the model invariant to position changes.
    \end{enumerate}

    \item \textbf{Variability in Drug Effects on Day 10:}
    \begin{enumerate}
        \item \textbf{Effect Differences:} The same drug can have different effects on Day 10. For instance, there is a huge variation between DS 61 G6 and 
        41 GP6, while less variation is observed between RBTDS 4.1 and 4.2 GP3. Hence we can't assess the drug efficacy based on the drug combination instead we need to make the ranking relative 
        assessment based on the day 10 images.
        \item \textbf{Debris Amount:} Images from different groups with significant debris were visually selected. Since the number of such images was small, no specific code was implemented for this selection process.
    \end{enumerate}
\end{enumerate}


 










I choosed images from different gps which have huge debris amount visually. it was few so I didn't code my self.
