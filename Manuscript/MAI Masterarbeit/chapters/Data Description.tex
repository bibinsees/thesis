\chapter{Data Description}\label{ch: DataDescription}
\section{Data set}
\label{sec:Data set}
As explained in the chapter \ref{ch:intro}, the dataset consists of images taken by bright-field microscopy, which operate as follows: 

The tumor 3D spheroidal tissue model is illuminated by transmitted white light (i.e, light is projected from below and observed from above).
 The contrast in the image is created due to the reduction in light intensity as it passes through denser regions of the sample, where more light is
  absorbed or scattered. This results in a typical bright-field microscopy image where the sample appears darker against a bright background, giving 
the technique its name. In our case, the 3D tumor model appears as a dark grayish structure on a bright background. 
For simplicity, bright-field microscopy images will be referred to as 'images'.

 Since the tissue models are cultivated using robotic arms, the process sometimes fails to replicate the natural shapes and patterns that typically occur when laboratory personnel manually cultivate the samples. To ensure the 
 dataset's quality and consistency, Dalia Mahdy, Phd student who works in the lab, pre-processed the images through a machine learning model to filter out invalid ones. By 'invalid images' , we mean
  those that variates from the expected morphology of the tumor tissues as cultivated by lab personnel. These images are typically elongated either in height or width as shown in second image 
 of figure \ref{fig:valid}. I collected these filtered images via USB and Google Drive in their original TIFF format. 

  \begin{figure}[H]
    \centering
    \includegraphics[scale=0.25]{figures/finevalid.png} 
    \caption{Examples of bright-field microscopy images with valid and invalid (unexpectedly elongated) morphology of tumor tissue models.}
    \label{fig:valid}
  \end{figure}

  The original images are 2456x2054 pixels in size, in 16-bit grayscale, and consist of multiple layers. These layers are obtained by capturing images
   at different focal planes in brightfield microscopy. The number of layers can vary, as images can be taken at any number of focal planes. The sharpness 
   of each layer of an image depends on how well the focal plane of the microscope aligns with the depth of the tumor tissue model. Only one layer of this 3D tumor tissue model will 
   be perfectly in focus, while others may appear blurry because they are slightly above or below the focal point as you can see in figure \ref{fig:blur}. Combining these focal planes later in 
   computational analysis can provide richer data, even if some layers are blurry individually. This is one of the reasons why I decided to use multiple
    layers. The images I received from the lab mostly have three layers, while a few have one or five layers.

    \begin{figure}[H]
      \centering
      \includegraphics[scale=0.4]{figures/blur.png} 
      \caption{Different layers of the same image reveal that, from A to C, the region above the white dotted line becomes sharper, while the region below becomes blurry }
      \label{fig:blur}
    \end{figure}

    Within the same experiment, images are 
    captured using consistent acquisition settings. that means each image in the same experiment consists of different layers captured at same focal lengths. For example, if image 1 has layers corresponding to focal
 lengths A, B, and C, Image 2 will also have layers corresponding to the same focal lengths A, B, and C.  However, for images from different experiments, the focal lengths may differ. For instance, images from 
 experiment 1 (single dose) may have slightly different acquisition settings compared to images from experiment 2 (drug screening), leading to variations 
 in the focal lengths and corresponding layers. 
 Secondly, the layers in each image are slightly misaligned when stacked, as shown in the figure  \ref{fig:Misalignment}. This misalignment of layers within the image and variation in focal length inbetween the images may or may not affect the performance of ranking.

 \begin{figure}[H]
  \centering
  \includegraphics[scale=0.25]{figures/posi.png} 
  \caption{A small section of the image was zoomed in and separated to show the misalignment of the three stacked layers.}
  \label{fig:Misalignment}
\end{figure}
\begin{figure}[H]
  \centering
  \includegraphics[scale=0.2]{figures/noise.png} 
  \caption{Noise}
  \label{fig:noise}
\end{figure}
We observed some temporal noise/artifacts, as shown in figure  \ref{fig:noise} in images. The presence of artifacts in the well-plates could be attributed to environmental factors such
as temperature, humidity, or CO\textsubscript{2}, or by some inconsistencies in sample handling. Such factors are likely to cause variations in cell behavior and
inconsistency in the  acquired images. These images were included as-is for SimCLR training, providing an opportunity for the model to learn from realistic conditions. 
However, I didn't artificially introduce additional noise or artifacts through data augmentation. This approach highlights a potential area for further exploration in future work. 

Figure \ref{fig:drug_eff} illustrates that, even with the same drug concentration applied to the spheroid tissue models under controlled conditions, occasional variations in effects were observed across different experiments. These variations could be attributed to slight differences in spheroid composition or undetected microenvironmental influences that affected drug absorption by the spheroid and cellular response. Initiall idea was to evaluate the relative effect of images using the same drug concentration combination as a group, but due to these differences, the ranking assessment needs to be made relative, based on the individual day 10 images, even though the same drug combination was applied.

\begin{figure}[H]
  \centering
  \includegraphics[scale=0.3]{figures/drug_eff.png} 
  \caption{Different morphological changes were observed even when the same specific combination of drugs was applied in two different experiments. The same combination of 40 µM JQ1 and 40 µM GANT61 was applied in two different experiments, named DS61 and DS41}
  \label{fig:drug_eff}
\end{figure}


The table below \ref{tab:dataset} shows the division of different types of image datasets, as explained in Section~\ref{sec:lab-setup}. In this table, Day 8 and Day 9 represent the images obtained during different single-dose and drug-screen experiments. These images are included for SimCLR training. From the table, it is evident that there is a class imbalance.
\begin{table}[H]
  \centering
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{lcccccc}
    \toprule
    \textbf{Class} & \textbf{Drug Screen} & \textbf{Single Dose} & \textbf{Control day 10} & \textbf{Control} & \textbf{Day 8 \& 9} & \textbf{Total} \\ 
    \midrule
    \textbf{No. of Images (\%)} & 200 (16.05\%) & 103 (8.26\%) & 231 (18.54\%) & 472 (37.89\%) & 240 (19.26\%) & 1246 \\
    \bottomrule
  \end{tabular}%
  }
  \caption{Dataset Class Overview}
  \label{tab:dataset}
\end{table}
An 8-bit image encompasses 256 color tones (ranging from 0 to 255) per channel, while a 16-bit image accommodates 65,536 color tones (ranging from 0 to 65,535) per channel, specifically allowing for 65,536 shades of gray. Retaining the original 16-bit depth is crucial because converting it to an 8-bit image for faster and more efficient computation can lead to significant information loss in intensity details. Since 8-bit images permit only 256 possible values, the finer intensity variations present in 16-bit images become compressed, as illustrated in \ref{fig:8bitvs16bit}. For instance, two distinct 16-bit values (ranging from 30,000 to 30,048) could map to the same 8-bit value (for example, both might be mapped to 117). This results in the loss of subtle intensity differences, which can be vital in our image task, where minute variations in intensity can indicate important features, such as the gradual transition of dark color from the center to the border or the amount of debris surrounding the tumor cell.


 \begin{figure}[H]
  \centering
  \includegraphics[scale=0.4]{figures/8bitvs16bit.png} 
  \caption{8-bit vs 16 bit data lose comparison. Although the images visually appear similar, 16-bit data has pixel values ranging from 0 to 65535, while 8-bit data has pixel values ranging from 0 to 255}
  \label{fig:8bitvs16bit}
\end{figure}

\section{Challenges}
\begin{enumerate}
    \item \textbf{Limited Dataset for Day 7 to Day 10 ranking prediction Model:} The dataset for predicting outcomes between Day 7 and Day 10 is limited, which poses a challenge for training and evaluation.

    \item \textbf{Issues with Day 10 Images:}
     Day 10 images can exhibit variations such as flipping, blurring, brightness changes, and position changes from the original position of tumor tissue 
        model in the image. 
        The position change occurs because, when the well plate is brought outside and then placed back under the microscope for taking day 10 image, 
        the position often shifts. This relative position of the tumor cell in the image can shift from the center to other directions.
         While a 'center crop' explained in in Section~\ref{sec:data preprocessing} approach can address this issue to some extent, it fails when the tumor tissue model 
         is located at the edge of the image. To deal this issue for some extend, Applying horizontal and vertical flips, rotations by $90^\circ$ and $270^\circ$, as 
        well as combinations like horizontal flip + rotation $90^\circ$ and horizontal flip + rotation $270^\circ$, can help make the model invariant to position changes.
   

    \item \textbf{Variability in Drug Effects on Day 10:}
   The same drug can have different effects on Day 10. Hence we can't assess the drug efficacy based on the group of images applied by same drug combination instead we need to make the ranking relative 
        assessment based on each individual the day 10 images as illustrated in \ref{fig:drug_eff}.
 
\end{enumerate}

A total of 40 images from the drug screen with significant debris were manually selected for intermediate evaluation of SimCLR, as explained in Chapter \ref{ch:Methodology for Intermediate evaluation of SimCLR model}, and ranking strategies, as explained in Chapter \ref{ch:Methodology for Ranking}.



