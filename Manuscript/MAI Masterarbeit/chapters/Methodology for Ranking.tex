\chapter{Methodology for Ranking}\label{ch:Methodology for Ranking}
 
since we don't have ground truth labels to rank the images except control images.
My strategy was to simplify the current ranking problem to only scale/order/rank images 
using only control, single dose and exploded images.
The reason to pick these groups is that controls we know that there is no drug applied which means that there is no effect of drug at all. 
single dose images are the category which is clinically recommended at the moment (eventhough we don't know how much drug effected or how 
much it killed the cancer) 
and exploded are visually exploded from the original cancer cell meansing we can visually see debris around the cancer cell potentially which
 may potentially harm the surrounding goof cells.
once if we can order those small subset of entire images, we can add the other image as inference to see where they plotted relative to 
control 
or single dose or exloded in this scale.

\section{Ranking strategy 1: Using CAE}

\subsection{Day7 to day7 reconstruction}
Original images: Unfortunately, the inference loss/metric will ve same beacuse control day 10 and treatd looks same . I was dumb enough to do that.
 thats why i need  day 7 to day 7 reconstruction model.



I start with classical anomaly detection approach that we train a model to 
reconstruct/predict day 10 image from day 10 image exclusively on the untreated images. Since the day 10 prediction model is trained solely on untreated images,
 we expect the the inference loss/metric (i.e., the difference between the predicted and actual Day 10 image) will be very small for untreated images.
Conversely, the inference loss/metric will increase for treated images as their predictions deviate from those of untreated images.
 This inference loss/metric will be used as the feature for the ranking/order scale, where the initial images will start 
 with untreated images that have very small inference loss/metric, and the scale will end with images having high inference loss/metric in ascending order.


\subsection{Day7 to day10 predcition} \label{subsec:day7-to-day10}
\subsubsection{day10 predcition}
\begin{enumerate}
    \item \textbf{Step 1:} Create a latent space representation of all images, including untreated, clinically recommended, 
    and drug screening images, using SimCLR. 
    The idea is that SimCLR effectively learns efficient features of similar images that are not captured by 
    human-interpretable metrics. We expect the SimCLR feature vectors of similar images will be closer in the latent space. 
    In other words, feature vectors of similar images will be more linearly separable.
  
  \item \textbf{Step 2:} Train a prediction model exclusively on the representations of 
  untreated images from Day 7 to Day 10. ( Input: Day 7 feature vector and target: Day 10 feature vector )

  
  \item \textbf{Step 3:} Perform inference on the representations of test images, which include untreated, clinically recommended, and drug screening images.
  \item \textbf{Step 4:} Perform step 2 and step 3 on images instead of simclr feature vectors for comparitive study.
\end{enumerate}

Since the day 10 prediction model is trained solely on the representations of untreated images, the inference loss/metric 
(i.e., the difference between the predicted and actual Day 10 image representations) will be very small for untreated images.
 Conversely, the inference loss/metric will increase for treated images as their representations deviate from those of untreated images.
This inference loss/metric will be used as the feature for the ranking/order scale, where the initial images will start 
with untreated images that have very small inference loss/metric, and the scale will end with images having high inference loss/metric in ascending order. 
Determining a reasonable inference loss/metric will be one of the research problems to tackle.


\section{Ranking strategy 2: K means centroid approach}

This strategy utilizes the after projection head vectors since simclr loss function designed that after projection head vectors have cosine similarity between similar 
group.

\begin{enumerate}
  \item \textbf{Step 1:} Feed control images into k means and find the centriod of control (untreated) cluster based on both cosine distance and the euclidean distance. 
  ( we can choose the distacne metric if we have time)
  
  \item \textbf{Step 2:} calculate the euclidean/cosine distance from this centroid to every images.
  
  \item \textbf{Step 3:} Perform the same operation for simlcr features and on original images.
\end{enumerate}


\subsection*{Group-Wise Ranking Accuracy: Mathematical Definition and Process}

\textcolor{red}{below maybe wrong because I didN't added that gp order determine by calculating mean of cosine distance}

\subsubsection*{Definitions}

Let \( G_1, G_2, G_3, \dots, G_n \) represent \( n \) different groups of distances.  
The distances in each group \( G_i \) are denoted as:
\[
D_i = \{d_{i1}, d_{i2}, \dots, d_{im_i}\},
\]
where \( m_i \) is the number of elements in group \( G_i \).  

Let:
\[
\{D_1, D_2, \dots, D_n\}
\]
represent the collection of all groups.

After sorting all the distances across the groups into a single list, we check if the order of groups is maintained, i.e., whether all distances in \( G_1 \) are less than those in \( G_2 \), all in \( G_2 \) are less than those in \( G_3 \), and so on.

\subsubsection*{Mathematical Formula for Group-Wise Ranking Accuracy}

\paragraph{Correct Transitions}
A correct transition between two groups \( G_i \) and \( G_j \) (with \( i < j \)) occurs if all elements of \( G_i \) are less than all elements of \( G_j \) after sorting.  

This can be expressed mathematically as:
\[
\text{Correct Transition}(G_i \to G_j) = 
\left[
\forall d_{ik} \in G_i, \forall d_{jl} \in G_j : d_{ik} < d_{jl}
\right], \quad \text{for } i < j.
\]

\paragraph{Total Possible Transitions}
The total number of possible transitions is the number of adjacent group pairs:
\[
T_{\text{total}} = n - 1.
\]

\paragraph{Group-Wise Ranking Accuracy}
The ranking accuracy is the ratio of correct transitions (\( T_{\text{correct}} \)) to total possible transitions (\( T_{\text{total}} \)):
\[
\text{Accuracy} = \frac{T_{\text{correct}}}{T_{\text{total}}}.
\]

\subsubsection*{Step-by-Step Process}

1. \textbf{Sort the Distances:} Sort all the distances from all groups into a single list while keeping track of the group each distance belongs to.

2. \textbf{Check for Correct Transitions:} For each adjacent group pair \( (G_i, G_j) \), check if the condition:
\[
\forall d_{ik} \in G_i, \forall d_{jl} \in G_j : d_{ik} < d_{jl}
\]
holds true.

3. \textbf{Count Correct Transitions:} If the condition holds for a group pair, increment \( T_{\text{correct}} \).

4. \textbf{Compute Accuracy:} Finally, compute the group-wise ranking accuracy as:
\[
\text{Accuracy} = \frac{T_{\text{correct}}}{T_{\text{total}}}.
\]






Curated control dataset: 280
sd: full: 103
exploded full: 40

ds close to sd 10

\begin{table}[H]
  \centering
  \begin{tabular}{@{}llccccc@{}}
  \toprule
  Projection Head & Distance From      & Strong & Sweet & Resize & No Contrast Resize & No Contrast Sweet \\ \midrule
                  & Single Dose Mean   & 92.42      & 91.71     & 92.42      & 91.47                  & 92.42                 \\
  Before          & Control Mean       & 94.55      & 92.65     & 93.84      & \textbf{95.73}                  & 94.55                 \\
                  & Explod Mean        & 82.23      & 82.23     & 92.65     & 83.65                  & 81.52                \\ \midrule
                  & Single Dose Mean   & \textbf{97.39}  & 87.68     & 92.89     & 82.94                  & 83.65                 \\
  After           & Control Mean       & 86.97      & 76.78    & 90.76      & 76.30                 & 82.70                 \\
                  & Explod Mean        & 92.18      & 79.62    & 88.86      & 77.96                  & 82.23                 \\ \bottomrule
  \end{tabular}
  \caption{Cosine distance}
  \label{tab:your_table_label}
\end{table}


\begin{table}[H]
  \centering
  \begin{tabular}{@{}llccccc@{}}
  \toprule
  Projection Head & Distance From      & Strong & Sweet & Resize & No Contrast Resize & No Contrast Sweet \\ \midrule
                  & Single Dose Mean   & 91      & 89.10     & 91.23      & 86.49                  & 90.52                 \\
  Before          & Control Mean       & 87.68      & 86.73     & 88.15      & 82.94                  & 86.73                 \\
                  & Explod Mean        & 81.99      & 81.52     & 92.65      & 83.18                  &   81.52               \\ \midrule
                  & Single Dose Mean   & 90.05      & 81.28     & 91.94      & 77.25                  & 78.67                 \\
  After           & Control Mean       & 82.23      & 76.07     & 84.12      & 76.54                  & 74.17                 \\
                  & Explod Mean        & 90.52      & 78.20    & 94.79      & 75.83                  & 81.75                 \\ \bottomrule
  \end{tabular}
  \caption{Euclidean distance}
  \label{tab:your_table}
\end{table}


\textcolor{red}{check for any pattern in the 97.39 . do other distances depend on time later }

With this costumized metric, we get around 95 if there is slightest seperation for 3 gps.

after projection head: strong seperates perfectly but the problem is since the control is seperated at the middle ordering. Hence we can find the less effective in the middle,

\textcolor{red}{clear seperation between sd and ex ( 2 gp) and max mean difference between them table:}


\begin{table}[H]
  \centering
  \begin{tabular}{@{}llll@{}}
  \toprule
  Distance From & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Single Dose\\ Mean\end{tabular}} & \multicolumn{1}{c}{Control Mean} & \multicolumn{1}{c}{Explod Mean} \\ \midrule
  Cosine        & 81.28                                                                           & 86.02                            & 76.78                           \\
  Euclidean     & 83.18                                                                           & 78.44                            & 80.81                           \\ \bottomrule
  \end{tabular}
  \caption{Your table caption here}
  \label{tab:you_label}
\end{table}


\section{Ranking strategy 3: Softmax approach}

This strategy utilizes the before projection head vectors since its linearly seperable for downstream task classification as suggested in original simclr paper.

We will use simclr features since original images are not able to classify 100 percentage as we seen in intermediate evaluation.
1. Train classification model to classify cond7 and sd. 
2. Then do inference on them and take softmax probability as metric for ranking.
below table used 750 epochs, batch:8: all of these value can improve by performing regularizytion and more layers or less layers basically hyper parameter tuning. 
i didn't do it, since i was focused on methodolgy.
Below trained for 750 epochs:batch:8
\begin{table}[H]
  \centering
  \begin{tabular}{@{}lccccc@{}}
  \toprule
  \textbf{Classification} & \textbf{Strong} & \textbf{Sweet} & \textbf{Resize} & \textbf{No Contrast Resize} & \textbf{No Contrast Sweet} \\ \midrule
  Cond7 vs SD             & 97.89           & 99.29          & 98.59           & 98.25                       & 100                        \\
  Cond7 vs Ex             & 97.54               & 96.49              & 98.94               & 100                           &   97.54                        \\
  Ex vs SD             & 95.78               & 98.94              & 95.08               & 92.98                           & 97.54                         \\ \bottomrule
  \end{tabular}
  \caption{Table description goes here.}
  \label{tab:ranking softmax}
\end{table}

\textcolor{red}{Depend on time do ex twenty nine}
  
\textcolor{red}{this questions if strong or No contrast sweet is betterr? because previously strong was better. Now sweet performed well for this task. 
to understand why sweet performs better we need to see crop change and brghtness, contrast change seperatly.}

When we used curated dataset percentage of gp wise accuracy went down where when we used control as the same number of images of sd accuracy is 100. 
it worked maybe because of class balancing.

How do we check which data aug is working?
it should seperate cond7, ex, sd: 100 percentage. because if get 100 that means it is able to make gp of control and sd for sure, from ex mixing.

why are we doing this because every aug can  seperate cond 7 and sd. thats obivious. because there is no other gps. so we have to add new gp as inference to see if 
cond7 and sd still gp together. same principle in kmeans approach.

so, with this approach from cond7 to sd classsification softmax probability score we get mixture of exploded and gray from drug screen.

if we want to avoid that we can train supervised classification to filter out the exploded from there then put them on right side of sd so that we get clean scale.
for that training we can use simclr feature vectors because it gave more accuracy than the original image accuracy.

\textcolor{red}{put the below table in classification and also do classification of ex fourty others because we are usign it for softmax approach} 

\begin{table}[H]
  \centering
  \resizebox{\textwidth}{!}{%
  \begin{tabular}{llccccc}
  \toprule
  \textbf{Augmentation Type}      & \textbf{Metric} & \textbf{Strong} & \textbf{Sweet} & \textbf{Resize} & \textbf{Resize No Contrast} & \textbf{Sweet No Contrast} \\ \midrule
  \multirow{4}{*}{\textbf{Before Projection Head}} 
      & Train Accuracy (\%) & 97.07 & 96.23 & 96.23 & 97.91 & 97.07 \\
      & Train Epoch         & 30 & 41 & 128 & 465 & 485 \\
      & Test Accuracy (\%)  & 95 & 91.67 & 93.33 & 93.33 & 95 \\
      & Test Epoch          & 5 & 5 & 21 & 12 & 17 \\ 
  \bottomrule
  \end{tabular}%
  }
  \caption{Performance metrics for different augmentation strategies before the projection head.}
  \label{tab:augmentation_metrics}
\end{table}

\textcolor{red}{include other classification combinations in table}

Why its not giving 100 because now the problem is harder. we had 2 classes, explod vs all other drug screen,where drug screen look intermediate to explod and sigle dose.
Also we can improve this result by adding more hidden layers instead of just one linear layer and so more. at the moment i didn't since we want to know which data aug works for harder problem.
because in the intermediate evaluation  most of them gave 100 percenatage making it not  evaluator for evaluating inbetween data augs. there we get that orig vs data augs.

\begin{table}[h!]
  \centering
  \caption{Original Image Results}
  \label{tab:original_image_results}
  \begin{tabular}{lcccc}
  \toprule
  \textbf{Metric}         & \textbf{Train Accuracy (\%)} & \textbf{Train Epoch} & \textbf{Test Accuracy (\%)} & \textbf{Test Epoch} \\ \midrule
  \textbf{Original Image} & 84.94                        & 434                   & 78.33                        & 19                  \\ 
  \bottomrule
  \end{tabular}
\end{table}


ordered images can found in the below gdrive links for both mixed and cleaned order for ds and ex.
show them ordered images for 80 percentage gp wise accuracy ie only seperated 2 gps, show them its worse.

\textcolor{red}{its better to not use exploded and harm people sentence from intro and data intro just say debris, because cond10 and exploded have debris. cond10 
have debris even without drug so debris can happen without drug.it is probabliy because its cultivated in lab where these things happen.} 