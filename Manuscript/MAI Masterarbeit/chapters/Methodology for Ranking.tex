\chapter{Methodology for Ranking}\label{ch:Methodology for Ranking}
 
since we don't have ground truth labels to rank the images except control images.
My strategy was to simplify the current ranking problem to only scale/order/rank images 
using only control, single dose and exploded images.
The reason to pick these groups is that controls we know that there is no drug applied which means that there is no effect of drug at all. 
single dose images are the category which is clinically recommended at the moment (eventhough we don't know how much drug effected or how 
much it killed the cancer) 
and exploded are visually exploded from the original cancer cell meansing we can visually see debris around the cancer cell potentially which
 may potentially harm the surrounding goof cells.
once if we can order those small subset of entire images, we can add the other image as inference to see where they plotted relative to 
control 
or single dose or exloded in this scale.

\section{Ranking strategy 1: Using CAE}

\subsection{Day7 to day7 reconstruction}
Original images: Unfortunately, the inference loss/metric will ve same beacuse control day 10 and treatd looks same . I was dumb enough to do that.
 thats why i need  day 7 to day 7 reconstruction model.



I start with classical anomaly detection approach that we train a model to 
reconstruct/predict day 10 image from day 10 image exclusively on the untreated images. Since the day 10 prediction model is trained solely on untreated images,
 we expect the the inference loss/metric (i.e., the difference between the predicted and actual Day 10 image) will be very small for untreated images.
Conversely, the inference loss/metric will increase for treated images as their predictions deviate from those of untreated images.
 This inference loss/metric will be used as the feature for the ranking/order scale, where the initial images will start 
 with untreated images that have very small inference loss/metric, and the scale will end with images having high inference loss/metric in ascending order.


\subsection{Day7 to day10 predcition} \label{subsec:day7-to-day10}
\subsubsection{day10 predcition}
\begin{enumerate}
    \item \textbf{Step 1:} Create a latent space representation of all images, including untreated, clinically recommended, 
    and drug screening images, using SimCLR. 
    The idea is that SimCLR effectively learns efficient features of similar images that are not captured by 
    human-interpretable metrics. We expect the SimCLR feature vectors of similar images will be closer in the latent space. 
    In other words, feature vectors of similar images will be more linearly separable.
  
  \item \textbf{Step 2:} Train a prediction model exclusively on the representations of 
  untreated images from Day 7 to Day 10. ( Input: Day 7 feature vector and target: Day 10 feature vector )

  
  \item \textbf{Step 3:} Perform inference on the representations of test images, which include untreated, clinically recommended, and drug screening images.
  \item \textbf{Step 4:} Perform step 2 and step 3 on images instead of simclr feature vectors for comparitive study.
\end{enumerate}

Since the day 10 prediction model is trained solely on the representations of untreated images, the inference loss/metric 
(i.e., the difference between the predicted and actual Day 10 image representations) will be very small for untreated images.
 Conversely, the inference loss/metric will increase for treated images as their representations deviate from those of untreated images.
This inference loss/metric will be used as the feature for the ranking/order scale, where the initial images will start 
with untreated images that have very small inference loss/metric, and the scale will end with images having high inference loss/metric in ascending order. 
Determining a reasonable inference loss/metric will be one of the research problems to tackle.

\subsubsection{Delta predcition}
\begin{enumerate}
  \item \textbf{Step 1:} Calculate the difference/delta between the day 7 and day 10 simclr 
  feature vectors  exclusively on the untreated images.
  \item \textbf{Step 2:} Train a prediction model where input is day 7 feature vector 
  and target will be Delta.


  \item \textbf{Step 3:} Perform inference on the test set where input will be day 7 feature vector of all images which include untreated, 
  clinically recommended, and drug screening images to predict the delta between the day 7 feature vector  and day 10 feature vector.
\end{enumerate}

Since the delta prediction model is trained solely on the representations of day 
7 untreated  images to predict the delta between the day 7 feature vector 
and day 10 feature vector of untreated images,
 the inference loss/metric (i.e., the difference between the predicted delta and actual
  delta) will be very small for untreated images. Conversely,
   the inference loss/metric will increase for treated images as their representations 
   deviate from those of untreated images. This inference loss/metric will be used as 
   the feature for the ranking/order scale, where the initial images will start with 
   untreated images that have very small inference loss/metric, and the scale will end 
   with images having high inference loss/metric in ascending order. 
   Determining a reasonable inference loss/metric will be one of the research problems 
   to tackle.



\section{Ranking strategy 2: K means centroid approach}

This strategy utilizes the after projection head vectors since simclr loss function designed that after projection head vectors have cosine similarity between similar 
group.

\begin{enumerate}
  \item \textbf{Step 1:} Feed control images into k means and find the centriod of control (untreated) cluster based on both cosine distance and the euclidean distance. 
  ( we can choose the distacne metric if we have time)
  
  \item \textbf{Step 2:} calculate the euclidean/cosine distance from this centroid to every images.
  
  \item \textbf{Step 3:} Perform the same operation for simlcr features and on original images.
\end{enumerate}


\subsection*{Group-Wise Ranking Accuracy: Mathematical Definition and Process}

\textcolor{red}{below maybe wrong because I didN't added that gp order determine by calculating mean of cosine distance}

\subsubsection*{Definitions}

Let \( G_1, G_2, G_3, \dots, G_n \) represent \( n \) different groups of distances.  
The distances in each group \( G_i \) are denoted as:
\[
D_i = \{d_{i1}, d_{i2}, \dots, d_{im_i}\},
\]
where \( m_i \) is the number of elements in group \( G_i \).  

Let:
\[
\{D_1, D_2, \dots, D_n\}
\]
represent the collection of all groups.

After sorting all the distances across the groups into a single list, we check if the order of groups is maintained, i.e., whether all distances in \( G_1 \) are less than those in \( G_2 \), all in \( G_2 \) are less than those in \( G_3 \), and so on.

\subsubsection*{Mathematical Formula for Group-Wise Ranking Accuracy}

\paragraph{Correct Transitions}
A correct transition between two groups \( G_i \) and \( G_j \) (with \( i < j \)) occurs if all elements of \( G_i \) are less than all elements of \( G_j \) after sorting.  

This can be expressed mathematically as:
\[
\text{Correct Transition}(G_i \to G_j) = 
\left[
\forall d_{ik} \in G_i, \forall d_{jl} \in G_j : d_{ik} < d_{jl}
\right], \quad \text{for } i < j.
\]

\paragraph{Total Possible Transitions}
The total number of possible transitions is the number of adjacent group pairs:
\[
T_{\text{total}} = n - 1.
\]

\paragraph{Group-Wise Ranking Accuracy}
The ranking accuracy is the ratio of correct transitions (\( T_{\text{correct}} \)) to total possible transitions (\( T_{\text{total}} \)):
\[
\text{Accuracy} = \frac{T_{\text{correct}}}{T_{\text{total}}}.
\]

\subsubsection*{Step-by-Step Process}

1. \textbf{Sort the Distances:} Sort all the distances from all groups into a single list while keeping track of the group each distance belongs to.

2. \textbf{Check for Correct Transitions:} For each adjacent group pair \( (G_i, G_j) \), check if the condition:
\[
\forall d_{ik} \in G_i, \forall d_{jl} \in G_j : d_{ik} < d_{jl}
\]
holds true.

3. \textbf{Count Correct Transitions:} If the condition holds for a group pair, increment \( T_{\text{correct}} \).

4. \textbf{Compute Accuracy:} Finally, compute the group-wise ranking accuracy as:
\[
\text{Accuracy} = \frac{T_{\text{correct}}}{T_{\text{total}}}.
\]






Curated control dataset: 280
sd: full: 103
exploded full: 40

ds close to sd 10

\begin{table}[H]
  \centering
  \begin{tabular}{@{}llccccc@{}}
  \toprule
  Projection Head & Distance From      & Strong & Sweet & Resize & No Contrast Resize & No Contrast Sweet \\ \midrule
                  & Single Dose Mean   & 92.42      & 91.71     & 92.42      & 91.47                  & 92.42                 \\
  Before          & Control Mean       & 94.55      & 92.65     & 93.84      & \textbf{95.73}                  & 94.55                 \\
                  & Explod Mean        & 82.23      & 82.23     & 92.65     & 83.65                  & 81.52                \\ \midrule
                  & Single Dose Mean   & \textbf{97.39}  & 87.68     & 92.89     & 82.94                  & 83.65                 \\
  After           & Control Mean       & 86.97      & 76.78    & 90.76      & 76.30                 & 82.70                 \\
                  & Explod Mean        & 92.18      & 79.62    & 88.86      & 77.96                  & 82.23                 \\ \bottomrule
  \end{tabular}
  \caption{Cosine distance}
  \label{tab:your_table_label}
\end{table}


\begin{table}[H]
  \centering
  \begin{tabular}{@{}llccccc@{}}
  \toprule
  Projection Head & Distance From      & Strong & Sweet & Resize & No Contrast Resize & No Contrast Sweet \\ \midrule
                  & Single Dose Mean   & 91      & 89.10     & 91.23      & 86.49                  & 90.52                 \\
  Before          & Control Mean       & 87.68      & 86.73     & 88.15      & 82.94                  & 86.73                 \\
                  & Explod Mean        & 81.99      & 81.52     & 92.65      & 83.18                  &   81.52               \\ \midrule
                  & Single Dose Mean   & 90.05      & 81.28     & 91.94      & 77.25                  & 78.67                 \\
  After           & Control Mean       & 82.23      & 76.07     & 84.12      & 76.54                  & 74.17                 \\
                  & Explod Mean        & 90.52      & 78.20    & 94.79      & 75.83                  & 81.75                 \\ \bottomrule
  \end{tabular}
  \caption{Euclidean distance}
  \label{tab:your_table}
\end{table}


\textcolor{red}{check for any pattern in the 97.39 . do other distances depend on time later }

we get above 95 if there is seperation for 3 gps.


\begin{table}[H]
  \centering
  \begin{tabular}{@{}llll@{}}
  \toprule
  Distance From & \multicolumn{1}{c}{\begin{tabular}[c]{@{}c@{}}Single Dose\\ Mean\end{tabular}} & \multicolumn{1}{c}{Control Mean} & \multicolumn{1}{c}{Explod Mean} \\ \midrule
  Cosine        & 81.28                                                                           & 86.02                            & 76.78                           \\
  Euclidean     & 83.18                                                                           & 78.44                            & 80.81                           \\ \bottomrule
  \end{tabular}
  \caption{Your table caption here}
  \label{tab:you_label}
\end{table}


\section{Ranking strategy 3: Softmax approach}

This strategy utilizes the before projection head vectors since its linearly seperable for downstream task classification as suggested in original simclr paper.
1. Train classification model to classify untreated and treated. 
2. Then do inference on them and take softmax probability as metric for ranking.