\chapter{Literature Review}\label{ch:Literature Review}

\textbf{Base neural network architecture for representation learning.} Learning visual representations of medical images, such as X-rays (radiographic images) and bright-field microscopy images, is crucial for medical image understanding. However, progress in this area has been hindered by the heterogeneity and complexity of subtle features in these images, especially when they don't have labels. Existing work often relies on fine-tuning weights transferred from ImageNet pretraining (Wang et al., 2017 \cite{8099852} ; Esteva et al., 2017 \cite{Esteva2017Dermatologist} ; Irvin et al., 2019 \cite{irvin2019chexpert} ), which is suboptimal due to the drastically different characteristics of medical images. 

To address these challenges, researchers have proposed various innovative approaches. ConVIRT \cite{zhang2022contrastive} offers an alternative unsupervised strategy for learning medical visual representations by exploiting naturally occurring paired descriptive text. This method introduces a new approach to pretraining medical image encoders using paired text data via a bidirectional contrastive objective between the two modalities. It is domain-agnostic and requires no additional expert input.  However, given the absence of specific paired text data for our image dataset, ConVIRT does not offer a solution tailored to our specific problem.

The contrastive loss used in ConVIRT is derived from the SimCLR \cite{chen2020simple} self supervised learning framework. SimCLR learns representations by maximizing agreement between differently augmented views of the same data example via a contrastive loss in the latent space. The framework consists of a neural network base encoder that extracts representation vectors from augmented data examples. The framework allows for various choices of network architecture without any constraints. The authors opt for simplicity and adopt ResNet \cite{he2015deepresiduallearningimage}, introducing a learnable nonlinear transformation between the representation and the contrastive loss to substantially improve the quality of the learned representations. However, these methods require careful treatment of negative pairs, typically relying on large batch sizes to retrieve them. Additionally, their performance is highly dependent on the choice of image augmentations. 

convolutional autoencoder 
kmeasns clustering


Cosine distance
Euclidean distacne 
L1 distance
MSE
Pearson correlation
Dot product
Jaccard similarity
Hamming distance

Since lack of data is a problem one of the most important problem, we need to explore rannking srategy that doesn't need specific training, which is why we choosed dimenstionaily reduction technics like PCA, t-SNE, UMAP. \cite{keyes2020cancerprimer} paper applied PCA, t-SNE, UMAP to high-dimensional cytometry datasets in the study of human cancer, specifically to analyze bone marrow aspirates from acute myeloid leukemia patients to reduce it to two or three dimensions for analyzing and interpreting cytometry data. 

In another study \cite{edwoodland_2024_13881989}, researchers applied PCA, UMAP, and t-SNE to reduce the dimensionality of bottleneck features from a Swin UNETR trained for liver segmentation on T1-weighted MRIs. They found that either PCA or UMAP improved performance over average pooling for all models test. Since there is studies that shows PCA; Tsne and umap works well for medical images, we further explore hem to reduce the higher dimensionality of our image data to single dimension and use them for ranking.