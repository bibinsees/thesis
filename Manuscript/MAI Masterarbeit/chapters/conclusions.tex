\chapter{Conclusion}

\section{Final Evaluation}
Now out of the 4 methodologies which methodology is more reliable and consistant in terms of relative positioning? This is the question we try to answer below.
We will evaluate the performance of the specific method out of each main 4 methodologies that performed well in ranking accuracy.
I picked 22 sinle dose  similar images from drug screening images (Note: This final Evaluation is not relaible in the sense that the picked images are not verified by any biology expert that those are the most visually similar images to single dose images from drug screening. so eventhough this final evaluation is not scientificly right, its better than nothing). Idea is that we will pick the best performed data augmentation type/category from each methodology and check whether these 22 images are still positioned in the range of the single dose image range. Limitation is that we are not sure whether the picked images are the most similar images to single dose images from drug screening interms of visual similartiy or drug efficay since I'm not expert in biology.

\begin{table}[H]
	\centering
	\small
	\begin{tabular}{@{}lcc@{}}
	\toprule
	\textbf{Ranking Strategy}                                                                       & \textbf{Out of Single Dose Range} & \textbf{Ranking Accuracy} \\ \midrule
	Prediction model Euclidean distance Before                                                     & 0                   & 76.93                   \\  
	tsne: before sweet                                                                              & 0                   & 100                     \\ 
	tsne: resize before                                                                             & 0                   & 100                     \\ 
	tsne: before no contrast resize                                                                 & 0                   & 100                     \\ 
	Softmax: cond7 vs Ex Resize                                                                     & 1                   & 97.33                   \\ 
	Softmax: Ex vs sd Strong                                                                        & 7                   & 92.46                   \\ 
	\begin{tabular}[c]{@{}l@{}}K-means: After cosine strong\\ using single dose mean\end{tabular}   & 12                  & 93.17                   \\ 
	\bottomrule
	\end{tabular}
	\caption{Performance metrics across different strategies.}
	\label{tab:ranking_strategies}
\end{table}

From above table that sone of the selected out of 22 are out of the single dose image ranking metric for Softmax and K means strategy. that makes these strategies least reliable comparing to other approaches. Infact K means approach the 12 images which are out of single dose image ranking metric range positioned amoung the control class that makes K means strategy most unreliable. 

	  Or they actually seem to perform randomly and are not reliable. This may be due to not enough data.  Or 
	  they do something but you are not actually sure, how to use for the final objective or ranking. This is also ok and you shall explain why you are 
	  not convinced.
	  
	  Perhaps the ranking is simply a badly formulated problem and it should not be approached this way at all. This is also ok to say and 
	  be open about it. Simply, even if it "does not work" it is still VERY useful if we understand what you have done and why you think it does not work.	
say classfication and clustering using unsupervised performed well 

Despite your best efforts the methods do not seem to deliver useful results.

References - clean these. Correct references shall have not only the names and year but also the publication venue (journal, conference, arxiv... etc.)

\section{Things that doesn't work}
manhatton distance 
pca weighted 
prediction with day 10 to 10 classical anamoly detection methodologies
predict directly the mse change, predicting diectly cosine change

\section{Future research direction}

\begin{enumerate}
    \item Hybrid: Include human-interpretable features in the unsupervised learning features combined effect.
    \item Weakly supervised DINO transformer-based approach. Future work: Later, other models such as masked autoencoders and DINO will be explored, depending on the available time.
	Why we would like to try other models? Because SimCLR demands larger batch size and more data for better performance which we don't have.
    \item Weakly supervised SimCLR approach.
    \item Other distance-based approaches.
    \item kl density estimation probability
    \item Image size for simclr 96 vs 256 vs 512 as well as original images 96 vs 256 vs 512 vs even original size 2054?
    \item other architectures. Resnet vs unet in Simclr
    \item 3 channel vs 1 channel (mis alignment probelm or compuatoinal faster?)
    \item Batch size 16 vs 64 vs 128 vs 256
    \item \textcolor{red}{after projectoin add l2 norm so that it will exactly like the loss fn gives good cosine sim} 
    \item new paper about simclr in linkedin magda

\end{enumerate}