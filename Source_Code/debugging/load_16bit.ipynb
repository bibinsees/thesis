{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "from torchvision.transforms import ToTensor\n",
    "image = Image.open(r'C:\\Users\\k54739\\OneDrive\\Thesis\\.tiff_experiment_unsupervised_data\\combined\\1.tiff')\n",
    "image = ToTensor()(image)\n",
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "import os\n",
    "\n",
    "# Correct file path with image name\n",
    "file_path = r'C:\\Users\\k54739\\OneDrive\\Thesis\\.tiff_experiment_unsupervised_data\\combined\\1.tiff'\n",
    "\n",
    "# Ensure the path points to an existing file\n",
    "if os.path.isfile(file_path):\n",
    "    image = Image.open(file_path)\n",
    "    \n",
    "    # Print image mode (e.g., \"L\" for 8-bit grayscale, \"I;16\" for 16-bit grayscale, \"RGB\" for RGB)\n",
    "    print(f\"Image mode: {image.mode}\")\n",
    "    \n",
    "    # If the image is in grayscale mode, check the bit depth\n",
    "    if image.mode == \"I;16\":\n",
    "        print(\"The image is a 16-bit grayscale image.\")\n",
    "    elif image.mode == \"L\":\n",
    "        print(\"The image is an 8-bit grayscale image.\")\n",
    "    elif image.mode == \"RGB\":\n",
    "        print(\"The image is an RGB image.\")\n",
    "    else:\n",
    "        print(f\"The image has an unsupported mode: {image.mode}\")\n",
    "    \n",
    "    # Additional image properties\n",
    "    print(f\"Image size: {image.size}\")\n",
    "    print(f\"Image format: {image.format}\")\n",
    "else:\n",
    "    print(f\"File not found: {file_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tifffile import imread\n",
    "from torchvision.transforms import ToTensor\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "image= imread((r'C:\\Users\\k54739\\OneDrive\\Thesis\\.tiff_experiment_unsupervised_data\\combined\\1.tiff'))\n",
    "image = ToTensor()(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[[30519, 29847, 29351,  ..., 29447, 30071, 29399],\n",
      "         [30967, 29607, 30119,  ..., 30647, 30903, 29479],\n",
      "         [29351, 30455, 30215,  ..., 31063, 30199, 30711]],\n",
      "\n",
      "        [[30535, 29975, 29911,  ..., 31175, 29991, 30119],\n",
      "         [29431, 30439, 29271,  ..., 30023, 29911, 29767],\n",
      "         [29863, 30807, 29543,  ..., 30727, 30487, 30759]],\n",
      "\n",
      "        [[30151, 30311, 30439,  ..., 30615, 30167, 30839],\n",
      "         [30199, 30183, 30039,  ..., 30103, 29831, 30311],\n",
      "         [30503, 30823, 31255,  ..., 31335, 30263, 29991]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[31479, 31239, 30359,  ..., 30167, 30887, 29943],\n",
      "         [30631, 31383, 29847,  ..., 30631, 30119, 30151],\n",
      "         [31543, 30807, 30407,  ..., 30615, 30663, 30519]],\n",
      "\n",
      "        [[31095, 31063, 30247,  ..., 30727, 29271, 30711],\n",
      "         [31495, 30695, 30871,  ..., 29895, 30087, 29671],\n",
      "         [31639, 30503, 30567,  ..., 29687, 30231, 30135]],\n",
      "\n",
      "        [[30871, 30759, 30135,  ..., 30103, 30647, 30583],\n",
      "         [30503, 29879, 29751,  ..., 30775, 30663, 29959],\n",
      "         [30455, 30215, 31127,  ..., 30919, 28935, 30535]]],\n",
      "       dtype=torch.uint16)\n"
     ]
    }
   ],
   "source": [
    "print(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Maximum pixel value: 39417.0\n"
     ]
    }
   ],
   "source": [
    "image_tensor = image.to(torch.float32)\n",
    "\n",
    "# Print the maximum pixel value\n",
    "max_pixel_value = torch.max(image_tensor)\n",
    "print(f\"Maximum pixel value: {max_pixel_value.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[30519 30535 30151 ... 31479 31095 30871]\n",
      " [29847 29975 30311 ... 31239 31063 30759]\n",
      " [29351 29911 30439 ... 30359 30247 30135]\n",
      " ...\n",
      " [29447 31175 30615 ... 30167 30727 30103]\n",
      " [30071 29991 30167 ... 30887 29271 30647]\n",
      " [29399 30119 30839 ... 29943 30711 30583]]\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "\n",
    "image = cv2.imread(r'C:\\Users\\k54739\\OneDrive\\Thesis\\.tiff_experiment_unsupervised_data\\combined\\1.tiff',cv2.IMREAD_UNCHANGED)\n",
    "print(image)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_tensor = tf.convert_to_tensor(image, dtype=float32)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (testenv)",
   "language": "python",
   "name": "testenv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
