{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import functional as Func\n",
    "\n",
    "import tifffile as tiff\n",
    "import os\n",
    "import time\n",
    "\n",
    "from torchvision.transforms import RandomResizedCrop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huge change from previous implementations since we are using target day10 images,we need to give same transform to day10 image as same as day7. hence we removed transform.compose instead we used from torchvision.transforms import functional as Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, day7_dir, day10_dir): \n",
    "        self.day7_files = {os.path.basename(file): os.path.join(day7_dir, file) for file in os.listdir(day7_dir) if file.endswith('.tiff')}\n",
    "        self.day10_files = {os.path.basename(file): os.path.join(day10_dir, file) for file in os.listdir(day10_dir) if file.endswith('.tiff')}\n",
    "      \n",
    "\n",
    "        # Ensure all day7 files have a corresponding day10 file\n",
    "        self.common_files = list(self.day7_files.keys())\n",
    "        assert set(self.common_files) <= set(self.day10_files.keys()), \"Mismatch between day7 and day10 filenames.\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.common_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.common_files[idx]\n",
    "        day7_img_path = self.day7_files[filename]\n",
    "        day10_img_path = self.day10_files[filename]\n",
    "\n",
    "        # Load the images\n",
    "        day7_img = tiff.imread(day7_img_path)\n",
    "        day10_img = tiff.imread(day10_img_path)\n",
    "\n",
    "         # Ensure the images have 3 layers (channels)\n",
    "        if day7_img.shape[0] != 3:\n",
    "            raise ValueError(f\"Day7 image at {day7_img_path} does not have exactly 3 layers. Found shape: {day7_img.shape}.\")\n",
    "        if day10_img.shape[0] != 3:\n",
    "            raise ValueError(f\"Day10 image at {day10_img_path} does not have exactly 3 layers. Found shape: {day10_img.shape}.\")\n",
    "        \n",
    "        # Normalize and convert both images\n",
    "        day7_img = day7_img.astype(np.float32) / 65535.0\n",
    "        day10_img = day10_img.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Convert to tensors\n",
    "        day7_img = torch.tensor(day7_img, dtype=torch.float32)\n",
    "        day10_img = torch.tensor(day10_img, dtype=torch.float32)\n",
    "\n",
    "        # Apply transforms \n",
    "\n",
    "        # RandomHorizontalFlip\n",
    "        if torch.rand(1) < 0.5:\n",
    "            day7_img = Func.hflip(day7_img)\n",
    "            day10_img = Func.hflip(day10_img)\n",
    "        # RandomVerticalFlip\n",
    "        if torch.rand(1) < 0.5:\n",
    "            day7_img = Func.vflip(day7_img)\n",
    "            day10_img = Func.vflip(day10_img)\n",
    "\n",
    "        # RandomRotation\n",
    "        angle = torch.randint(-10, 10, (1,)).item()  # Generate a random angle\n",
    "        day7_img = Func.rotate(day7_img, angle)\n",
    "        day10_img = Func.rotate(day10_img, angle)\n",
    "\n",
    "        # RandomResizedCrop\n",
    "        crop_transform = RandomResizedCrop(size=256)\n",
    "        i, j, h, w = crop_transform.get_params(day7_img, scale=(0.08, 1.0), ratio=(3 / 4, 4 / 3))\n",
    "        day7_img = Func.resized_crop(day7_img, i, j, h, w, size=(256, 256))\n",
    "        day10_img = Func.resized_crop(day10_img, i, j, h, w, size=(256, 256))\n",
    "\n",
    "        return day7_img, day10_img\n",
    "    \n",
    "# Specify paths for both day7 and day10 folders\n",
    "day7_dir = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7'\n",
    "day10_dir = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10'\n",
    "\n",
    "# Create the dataset\n",
    "dataset = ImageDataset(day7_dir=day7_dir, day10_dir=day10_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Image Shape: torch.Size([3, 256, 256]), Day 10 Image Shape: torch.Size([3, 256, 256])\n",
      "Day 7 Image Shape: torch.Size([3, 256, 256]), Day 10 Image Shape: torch.Size([3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for i, (day7_img, day10_img) in enumerate(dataset):\n",
    "    print(f\"Day 7 Image Shape: {day7_img.shape}, Day 10 Image Shape: {day10_img.shape}\")\n",
    "    if i == 1:  # Check just a couple of samples\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split dataset with explicit percentage\n",
    "def split_dataset(dataset, val_percentage):\n",
    "    val_size = int(len(dataset) * val_percentage)\n",
    "    train_size = len(dataset) - val_size\n",
    "    return random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Split the dataset with 20% for validation\n",
    "val_percentage = 0.2\n",
    "train_dataset, val_dataset = split_dataset(dataset, val_percentage)\n",
    "\n",
    "batch_size = 16\n",
    "# Define DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=0) #num_workers=os.cpu count() using cluster gpu\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 104\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of images in the training dataset\n",
    "total_images_in_train = len(train_loader.dataset)\n",
    "print(f\"Total number of images: {total_images_in_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 26\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of images in the training dataset\n",
    "total_images_in_val = len(val_loader.dataset)\n",
    "print(f\"Total number of images: {total_images_in_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "  Input image (day7): torch.Size([16, 3, 256, 256])\n",
      "  Target image (day10): torch.Size([16, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of both pairs and total number of images in one epoch\n",
    "for i, (input_image, target_image) in enumerate(train_loader):\n",
    "    print(f\"Batch {i}:\")\n",
    "    print(f\"  Input image (day7): {input_image.shape}\")\n",
    "    print(f\"  Target image (day10): {target_image.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencod_fituning(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencod_fituning, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding='same'),  # Input: (3, 96, 96) Output: (64, 96, 96)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, padding=1),        # Output: (64, 48, 48)\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding='same'), # Output: (32, 48, 48)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, padding=1),        # Output: (32, 24, 24)\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding='same'), # Output: (16, 24, 24)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, padding=0)         # Output: (16, 12, 12)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding='same'), # Output: (32, 12, 12)\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),      # Output: (32, 24, 24)\n",
    "    \n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding='same'), # Output: (16, 24, 24)\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),      # Output: (16, 48, 48)\n",
    "    \n",
    "            nn.Conv2d(16, 3, kernel_size=3, padding='same'),  # Output: (3, 48, 48)\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),      # Output: (3, 96, 96)\n",
    "            nn.Sigmoid()                                      # Ensures output values are in [0, 1] range\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(\"Input:\", x.shape)\n",
    "        \n",
    "        # Encoder\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "            #print(f\"After {layer}: {x.shape}\")\n",
    "        \n",
    "        # Decoder\n",
    "        for layer in self.decoder:\n",
    "            x = layer(x)\n",
    "            #print(f\"After {layer}: {x.shape}\")\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "modi = Autoencod_fituning()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(modi.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(modi, train_loader, val_loader, optimizer, criterion, num_epochs=1):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()  # Start time for the epoch\n",
    "        \n",
    "        # Training phase\n",
    "        modi.train()\n",
    "        train_loss = 0\n",
    "        for input_images, target_images in train_loader:\n",
    "            optimizer.zero_grad()\n",
    "            outputs = modi(input_images)\n",
    "            loss = criterion(outputs, target_images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation phase\n",
    "        modi.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for input_images, target_images in val_loader:\n",
    "                outputs = modi(input_images)\n",
    "                loss = criterion(outputs, target_images)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        end_time = time.time()  # End time for the epoch\n",
    "        epoch_time = end_time - start_time  # Calculate epoch duration\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Time: {epoch_time:.2f} seconds')\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Train Loss: 0.0424, Validation Loss: 0.0419, Time: 21.49 seconds\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train_and_validate(modi, train_loader, val_loader, optimizer, criterion, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.0389, Validation Loss: 0.0273, Time: 21.56 seconds\n",
      "Epoch [2/10], Train Loss: 0.0290, Validation Loss: 0.0251, Time: 22.33 seconds\n",
      "Epoch [3/10], Train Loss: 0.0256, Validation Loss: 0.0231, Time: 22.50 seconds\n",
      "Epoch [4/10], Train Loss: 0.0238, Validation Loss: 0.0233, Time: 22.85 seconds\n",
      "Epoch [5/10], Train Loss: 0.0266, Validation Loss: 0.0216, Time: 22.47 seconds\n",
      "Epoch [6/10], Train Loss: 0.0240, Validation Loss: 0.0204, Time: 23.15 seconds\n",
      "Epoch [7/10], Train Loss: 0.0233, Validation Loss: 0.0200, Time: 23.13 seconds\n",
      "Epoch [8/10], Train Loss: 0.0239, Validation Loss: 0.0192, Time: 22.91 seconds\n",
      "Epoch [9/10], Train Loss: 0.0243, Validation Loss: 0.0217, Time: 21.73 seconds\n",
      "Epoch [10/10], Train Loss: 0.0246, Validation Loss: 0.0214, Time: 21.83 seconds\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train_and_validate(modi, train_loader, val_loader, optimizer, criterion, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.0222, Validation Loss: 0.0182, Time: 22.77 seconds\n",
      "Epoch [2/100], Train Loss: 0.0233, Validation Loss: 0.0247, Time: 22.28 seconds\n",
      "Epoch [3/100], Train Loss: 0.0237, Validation Loss: 0.0205, Time: 21.37 seconds\n",
      "Epoch [4/100], Train Loss: 0.0232, Validation Loss: 0.0218, Time: 21.61 seconds\n",
      "Epoch [5/100], Train Loss: 0.0226, Validation Loss: 0.0193, Time: 21.93 seconds\n",
      "Epoch [6/100], Train Loss: 0.0229, Validation Loss: 0.0205, Time: 22.19 seconds\n",
      "Epoch [7/100], Train Loss: 0.0239, Validation Loss: 0.0222, Time: 31.80 seconds\n",
      "Epoch [8/100], Train Loss: 0.0230, Validation Loss: 0.0186, Time: 40.98 seconds\n",
      "Epoch [9/100], Train Loss: 0.0223, Validation Loss: 0.0192, Time: 28.48 seconds\n",
      "Epoch [10/100], Train Loss: 0.0223, Validation Loss: 0.0219, Time: 22.52 seconds\n",
      "Epoch [11/100], Train Loss: 0.0220, Validation Loss: 0.0178, Time: 21.92 seconds\n",
      "Epoch [12/100], Train Loss: 0.0221, Validation Loss: 0.0185, Time: 21.85 seconds\n",
      "Epoch [13/100], Train Loss: 0.0229, Validation Loss: 0.0200, Time: 22.05 seconds\n",
      "Epoch [14/100], Train Loss: 0.0223, Validation Loss: 0.0196, Time: 22.21 seconds\n",
      "Epoch [15/100], Train Loss: 0.0222, Validation Loss: 0.0200, Time: 22.69 seconds\n",
      "Epoch [16/100], Train Loss: 0.0230, Validation Loss: 0.0197, Time: 27.97 seconds\n",
      "Epoch [17/100], Train Loss: 0.0219, Validation Loss: 0.0199, Time: 40.18 seconds\n",
      "Epoch [18/100], Train Loss: 0.0213, Validation Loss: 0.0209, Time: 34.47 seconds\n",
      "Epoch [19/100], Train Loss: 0.0225, Validation Loss: 0.0206, Time: 22.46 seconds\n",
      "Epoch [20/100], Train Loss: 0.0244, Validation Loss: 0.0196, Time: 22.07 seconds\n",
      "Epoch [21/100], Train Loss: 0.0231, Validation Loss: 0.0211, Time: 21.88 seconds\n",
      "Epoch [22/100], Train Loss: 0.0218, Validation Loss: 0.0196, Time: 24.95 seconds\n",
      "Epoch [23/100], Train Loss: 0.0227, Validation Loss: 0.0184, Time: 30.44 seconds\n",
      "Epoch [24/100], Train Loss: 0.0221, Validation Loss: 0.0204, Time: 22.44 seconds\n",
      "Epoch [25/100], Train Loss: 0.0216, Validation Loss: 0.0201, Time: 22.47 seconds\n",
      "Epoch [26/100], Train Loss: 0.0222, Validation Loss: 0.0192, Time: 22.40 seconds\n",
      "Epoch [27/100], Train Loss: 0.0226, Validation Loss: 0.0197, Time: 22.35 seconds\n",
      "Epoch [28/100], Train Loss: 0.0216, Validation Loss: 0.0224, Time: 22.49 seconds\n",
      "Epoch [29/100], Train Loss: 0.0223, Validation Loss: 0.0195, Time: 22.91 seconds\n",
      "Epoch [30/100], Train Loss: 0.0226, Validation Loss: 0.0206, Time: 22.26 seconds\n",
      "Epoch [31/100], Train Loss: 0.0222, Validation Loss: 0.0182, Time: 22.47 seconds\n",
      "Epoch [32/100], Train Loss: 0.0222, Validation Loss: 0.0199, Time: 22.65 seconds\n",
      "Epoch [33/100], Train Loss: 0.0211, Validation Loss: 0.0187, Time: 22.61 seconds\n",
      "Epoch [34/100], Train Loss: 0.0211, Validation Loss: 0.0177, Time: 22.85 seconds\n",
      "Epoch [35/100], Train Loss: 0.0208, Validation Loss: 0.0181, Time: 30.34 seconds\n",
      "Epoch [36/100], Train Loss: 0.0218, Validation Loss: 0.0217, Time: 20.15 seconds\n",
      "Epoch [37/100], Train Loss: 0.0208, Validation Loss: 0.0193, Time: 20.21 seconds\n",
      "Epoch [38/100], Train Loss: 0.0206, Validation Loss: 0.0170, Time: 20.42 seconds\n",
      "Epoch [39/100], Train Loss: 0.0213, Validation Loss: 0.0171, Time: 20.42 seconds\n",
      "Epoch [40/100], Train Loss: 0.0222, Validation Loss: 0.0184, Time: 19.83 seconds\n",
      "Epoch [41/100], Train Loss: 0.0213, Validation Loss: 0.0199, Time: 20.41 seconds\n",
      "Epoch [42/100], Train Loss: 0.0213, Validation Loss: 0.0200, Time: 20.40 seconds\n",
      "Epoch [43/100], Train Loss: 0.0212, Validation Loss: 0.0188, Time: 20.78 seconds\n",
      "Epoch [44/100], Train Loss: 0.0209, Validation Loss: 0.0170, Time: 20.49 seconds\n",
      "Epoch [45/100], Train Loss: 0.0215, Validation Loss: 0.0187, Time: 20.27 seconds\n",
      "Epoch [46/100], Train Loss: 0.0215, Validation Loss: 0.0185, Time: 21.19 seconds\n",
      "Epoch [47/100], Train Loss: 0.0220, Validation Loss: 0.0172, Time: 20.25 seconds\n",
      "Epoch [48/100], Train Loss: 0.0233, Validation Loss: 0.0200, Time: 20.22 seconds\n",
      "Epoch [49/100], Train Loss: 0.0215, Validation Loss: 0.0190, Time: 20.41 seconds\n",
      "Epoch [50/100], Train Loss: 0.0207, Validation Loss: 0.0176, Time: 21.28 seconds\n",
      "Epoch [51/100], Train Loss: 0.0207, Validation Loss: 0.0186, Time: 21.00 seconds\n",
      "Epoch [52/100], Train Loss: 0.0221, Validation Loss: 0.0195, Time: 20.11 seconds\n",
      "Epoch [53/100], Train Loss: 0.0201, Validation Loss: 0.0192, Time: 20.29 seconds\n",
      "Epoch [54/100], Train Loss: 0.0216, Validation Loss: 0.0163, Time: 20.25 seconds\n",
      "Epoch [55/100], Train Loss: 0.0202, Validation Loss: 0.0184, Time: 20.31 seconds\n",
      "Epoch [56/100], Train Loss: 0.0226, Validation Loss: 0.0200, Time: 21.69 seconds\n",
      "Epoch [57/100], Train Loss: 0.0204, Validation Loss: 0.0200, Time: 20.54 seconds\n",
      "Epoch [58/100], Train Loss: 0.0212, Validation Loss: 0.0188, Time: 20.44 seconds\n",
      "Epoch [59/100], Train Loss: 0.0209, Validation Loss: 0.0178, Time: 20.26 seconds\n",
      "Epoch [60/100], Train Loss: 0.0215, Validation Loss: 0.0210, Time: 20.46 seconds\n",
      "Epoch [61/100], Train Loss: 0.0207, Validation Loss: 0.0198, Time: 20.64 seconds\n",
      "Epoch [62/100], Train Loss: 0.0202, Validation Loss: 0.0193, Time: 20.27 seconds\n",
      "Epoch [63/100], Train Loss: 0.0215, Validation Loss: 0.0215, Time: 20.04 seconds\n",
      "Epoch [64/100], Train Loss: 0.0202, Validation Loss: 0.0191, Time: 20.39 seconds\n",
      "Epoch [65/100], Train Loss: 0.0206, Validation Loss: 0.0176, Time: 21.33 seconds\n",
      "Epoch [66/100], Train Loss: 0.0199, Validation Loss: 0.0170, Time: 21.21 seconds\n",
      "Epoch [67/100], Train Loss: 0.0217, Validation Loss: 0.0176, Time: 20.46 seconds\n",
      "Epoch [68/100], Train Loss: 0.0203, Validation Loss: 0.0216, Time: 20.53 seconds\n",
      "Epoch [69/100], Train Loss: 0.0203, Validation Loss: 0.0192, Time: 20.70 seconds\n",
      "Epoch [70/100], Train Loss: 0.0212, Validation Loss: 0.0194, Time: 20.50 seconds\n",
      "Epoch [71/100], Train Loss: 0.0220, Validation Loss: 0.0182, Time: 21.46 seconds\n",
      "Epoch [72/100], Train Loss: 0.0214, Validation Loss: 0.0190, Time: 20.99 seconds\n",
      "Epoch [73/100], Train Loss: 0.0221, Validation Loss: 0.0200, Time: 21.56 seconds\n",
      "Epoch [74/100], Train Loss: 0.0216, Validation Loss: 0.0216, Time: 21.74 seconds\n",
      "Epoch [75/100], Train Loss: 0.0214, Validation Loss: 0.0187, Time: 20.77 seconds\n",
      "Epoch [76/100], Train Loss: 0.0212, Validation Loss: 0.0204, Time: 20.26 seconds\n",
      "Epoch [77/100], Train Loss: 0.0222, Validation Loss: 0.0190, Time: 20.53 seconds\n",
      "Epoch [78/100], Train Loss: 0.0202, Validation Loss: 0.0165, Time: 20.38 seconds\n",
      "Epoch [79/100], Train Loss: 0.0208, Validation Loss: 0.0188, Time: 21.01 seconds\n",
      "Epoch [80/100], Train Loss: 0.0194, Validation Loss: 0.0193, Time: 20.59 seconds\n",
      "Epoch [81/100], Train Loss: 0.0218, Validation Loss: 0.0186, Time: 21.19 seconds\n",
      "Epoch [82/100], Train Loss: 0.0211, Validation Loss: 0.0164, Time: 21.99 seconds\n",
      "Epoch [83/100], Train Loss: 0.0214, Validation Loss: 0.0201, Time: 22.26 seconds\n",
      "Epoch [84/100], Train Loss: 0.0213, Validation Loss: 0.0189, Time: 21.62 seconds\n",
      "Epoch [85/100], Train Loss: 0.0215, Validation Loss: 0.0195, Time: 21.72 seconds\n",
      "Epoch [86/100], Train Loss: 0.0221, Validation Loss: 0.0200, Time: 21.81 seconds\n",
      "Epoch [87/100], Train Loss: 0.0244, Validation Loss: 0.0186, Time: 21.06 seconds\n",
      "Epoch [88/100], Train Loss: 0.0206, Validation Loss: 0.0203, Time: 21.31 seconds\n",
      "Epoch [89/100], Train Loss: 0.0209, Validation Loss: 0.0200, Time: 21.41 seconds\n",
      "Epoch [90/100], Train Loss: 0.0208, Validation Loss: 0.0170, Time: 21.82 seconds\n",
      "Epoch [91/100], Train Loss: 0.0214, Validation Loss: 0.0211, Time: 21.90 seconds\n",
      "Epoch [92/100], Train Loss: 0.0199, Validation Loss: 0.0213, Time: 21.80 seconds\n",
      "Epoch [93/100], Train Loss: 0.0205, Validation Loss: 0.0180, Time: 21.73 seconds\n",
      "Epoch [94/100], Train Loss: 0.0213, Validation Loss: 0.0182, Time: 21.67 seconds\n",
      "Epoch [95/100], Train Loss: 0.0207, Validation Loss: 0.0182, Time: 22.35 seconds\n",
      "Epoch [96/100], Train Loss: 0.0205, Validation Loss: 0.0182, Time: 20.84 seconds\n",
      "Epoch [97/100], Train Loss: 0.0209, Validation Loss: 0.0180, Time: 20.98 seconds\n",
      "Epoch [98/100], Train Loss: 0.0212, Validation Loss: 0.0184, Time: 21.07 seconds\n",
      "Epoch [99/100], Train Loss: 0.0217, Validation Loss: 0.0230, Time: 21.81 seconds\n",
      "Epoch [100/100], Train Loss: 0.0227, Validation Loss: 0.0170, Time: 21.13 seconds\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train_and_validate(modi, train_loader, val_loader, optimizer, criterion, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 0.0214, Validation Loss: 0.0178, Time: 21.51 seconds\n",
      "Epoch [2/500], Train Loss: 0.0200, Validation Loss: 0.0215, Time: 21.13 seconds\n",
      "Epoch [3/500], Train Loss: 0.0204, Validation Loss: 0.0216, Time: 20.85 seconds\n",
      "Epoch [4/500], Train Loss: 0.0206, Validation Loss: 0.0194, Time: 21.62 seconds\n",
      "Epoch [5/500], Train Loss: 0.0211, Validation Loss: 0.0173, Time: 22.07 seconds\n",
      "Epoch [6/500], Train Loss: 0.0204, Validation Loss: 0.0140, Time: 22.86 seconds\n",
      "Epoch [7/500], Train Loss: 0.0205, Validation Loss: 0.0192, Time: 22.10 seconds\n",
      "Epoch [8/500], Train Loss: 0.0216, Validation Loss: 0.0190, Time: 21.60 seconds\n",
      "Epoch [9/500], Train Loss: 0.0220, Validation Loss: 0.0177, Time: 21.56 seconds\n",
      "Epoch [10/500], Train Loss: 0.0208, Validation Loss: 0.0177, Time: 21.82 seconds\n",
      "Epoch [11/500], Train Loss: 0.0200, Validation Loss: 0.0174, Time: 22.25 seconds\n",
      "Epoch [12/500], Train Loss: 0.0210, Validation Loss: 0.0195, Time: 22.11 seconds\n",
      "Epoch [13/500], Train Loss: 0.0216, Validation Loss: 0.0160, Time: 22.02 seconds\n",
      "Epoch [14/500], Train Loss: 0.0210, Validation Loss: 0.0179, Time: 21.83 seconds\n",
      "Epoch [15/500], Train Loss: 0.0204, Validation Loss: 0.0168, Time: 20.38 seconds\n",
      "Epoch [16/500], Train Loss: 0.0231, Validation Loss: 0.0198, Time: 20.74 seconds\n",
      "Epoch [17/500], Train Loss: 0.0207, Validation Loss: 0.0177, Time: 21.28 seconds\n",
      "Epoch [18/500], Train Loss: 0.0203, Validation Loss: 0.0173, Time: 21.54 seconds\n",
      "Epoch [19/500], Train Loss: 0.0212, Validation Loss: 0.0192, Time: 22.29 seconds\n",
      "Epoch [20/500], Train Loss: 0.0209, Validation Loss: 0.0176, Time: 22.61 seconds\n",
      "Epoch [21/500], Train Loss: 0.0203, Validation Loss: 0.0178, Time: 22.48 seconds\n",
      "Epoch [22/500], Train Loss: 0.0200, Validation Loss: 0.0146, Time: 22.40 seconds\n",
      "Epoch [23/500], Train Loss: 0.0205, Validation Loss: 0.0206, Time: 22.24 seconds\n",
      "Epoch [24/500], Train Loss: 0.0217, Validation Loss: 0.0191, Time: 21.39 seconds\n",
      "Epoch [25/500], Train Loss: 0.0197, Validation Loss: 0.0192, Time: 21.74 seconds\n",
      "Epoch [26/500], Train Loss: 0.0211, Validation Loss: 0.0186, Time: 22.15 seconds\n",
      "Epoch [27/500], Train Loss: 0.0216, Validation Loss: 0.0200, Time: 21.88 seconds\n",
      "Epoch [28/500], Train Loss: 0.0213, Validation Loss: 0.0207, Time: 21.99 seconds\n",
      "Epoch [29/500], Train Loss: 0.0194, Validation Loss: 0.0195, Time: 21.55 seconds\n",
      "Epoch [30/500], Train Loss: 0.0185, Validation Loss: 0.0178, Time: 21.60 seconds\n",
      "Epoch [31/500], Train Loss: 0.0202, Validation Loss: 0.0175, Time: 22.00 seconds\n",
      "Epoch [32/500], Train Loss: 0.0206, Validation Loss: 0.0172, Time: 21.59 seconds\n",
      "Epoch [33/500], Train Loss: 0.0197, Validation Loss: 0.0175, Time: 21.68 seconds\n",
      "Epoch [34/500], Train Loss: 0.0209, Validation Loss: 0.0184, Time: 22.59 seconds\n",
      "Epoch [35/500], Train Loss: 0.0214, Validation Loss: 0.0163, Time: 22.25 seconds\n",
      "Epoch [36/500], Train Loss: 0.0197, Validation Loss: 0.0198, Time: 21.94 seconds\n",
      "Epoch [37/500], Train Loss: 0.0205, Validation Loss: 0.0193, Time: 22.17 seconds\n",
      "Epoch [38/500], Train Loss: 0.0216, Validation Loss: 0.0186, Time: 21.89 seconds\n",
      "Epoch [39/500], Train Loss: 0.0215, Validation Loss: 0.0177, Time: 22.79 seconds\n",
      "Epoch [40/500], Train Loss: 0.0208, Validation Loss: 0.0191, Time: 22.37 seconds\n",
      "Epoch [41/500], Train Loss: 0.0188, Validation Loss: 0.0181, Time: 21.76 seconds\n",
      "Epoch [42/500], Train Loss: 0.0201, Validation Loss: 0.0176, Time: 22.01 seconds\n",
      "Epoch [43/500], Train Loss: 0.0220, Validation Loss: 0.0163, Time: 22.41 seconds\n",
      "Epoch [44/500], Train Loss: 0.0194, Validation Loss: 0.0177, Time: 22.77 seconds\n",
      "Epoch [45/500], Train Loss: 0.0220, Validation Loss: 0.0161, Time: 21.62 seconds\n",
      "Epoch [46/500], Train Loss: 0.0197, Validation Loss: 0.0204, Time: 21.72 seconds\n",
      "Epoch [47/500], Train Loss: 0.0201, Validation Loss: 0.0193, Time: 22.15 seconds\n",
      "Epoch [48/500], Train Loss: 0.0211, Validation Loss: 0.0168, Time: 22.07 seconds\n",
      "Epoch [49/500], Train Loss: 0.0198, Validation Loss: 0.0183, Time: 22.16 seconds\n",
      "Epoch [50/500], Train Loss: 0.0190, Validation Loss: 0.0167, Time: 22.57 seconds\n",
      "Epoch [51/500], Train Loss: 0.0191, Validation Loss: 0.0199, Time: 22.34 seconds\n",
      "Epoch [52/500], Train Loss: 0.0212, Validation Loss: 0.0185, Time: 22.44 seconds\n",
      "Epoch [53/500], Train Loss: 0.0210, Validation Loss: 0.0178, Time: 22.57 seconds\n",
      "Epoch [54/500], Train Loss: 0.0192, Validation Loss: 0.0188, Time: 22.58 seconds\n",
      "Epoch [55/500], Train Loss: 0.0209, Validation Loss: 0.0183, Time: 21.81 seconds\n",
      "Epoch [56/500], Train Loss: 0.0205, Validation Loss: 0.0191, Time: 21.40 seconds\n",
      "Epoch [57/500], Train Loss: 0.0193, Validation Loss: 0.0182, Time: 21.60 seconds\n",
      "Epoch [58/500], Train Loss: 0.0199, Validation Loss: 0.0210, Time: 21.62 seconds\n",
      "Epoch [59/500], Train Loss: 0.0207, Validation Loss: 0.0170, Time: 21.80 seconds\n",
      "Epoch [60/500], Train Loss: 0.0205, Validation Loss: 0.0192, Time: 22.31 seconds\n",
      "Epoch [61/500], Train Loss: 0.0197, Validation Loss: 0.0188, Time: 22.10 seconds\n",
      "Epoch [62/500], Train Loss: 0.0224, Validation Loss: 0.0174, Time: 21.61 seconds\n",
      "Epoch [63/500], Train Loss: 0.0205, Validation Loss: 0.0193, Time: 21.85 seconds\n",
      "Epoch [64/500], Train Loss: 0.0198, Validation Loss: 0.0174, Time: 22.33 seconds\n",
      "Epoch [65/500], Train Loss: 0.0203, Validation Loss: 0.0182, Time: 22.31 seconds\n",
      "Epoch [66/500], Train Loss: 0.0190, Validation Loss: 0.0159, Time: 22.18 seconds\n",
      "Epoch [67/500], Train Loss: 0.0199, Validation Loss: 0.0167, Time: 22.13 seconds\n",
      "Epoch [68/500], Train Loss: 0.0206, Validation Loss: 0.0168, Time: 21.84 seconds\n",
      "Epoch [69/500], Train Loss: 0.0210, Validation Loss: 0.0180, Time: 22.10 seconds\n",
      "Epoch [70/500], Train Loss: 0.0229, Validation Loss: 0.0205, Time: 22.00 seconds\n",
      "Epoch [71/500], Train Loss: 0.0206, Validation Loss: 0.0155, Time: 21.76 seconds\n",
      "Epoch [72/500], Train Loss: 0.0197, Validation Loss: 0.0168, Time: 21.88 seconds\n",
      "Epoch [73/500], Train Loss: 0.0208, Validation Loss: 0.0165, Time: 21.59 seconds\n",
      "Epoch [74/500], Train Loss: 0.0207, Validation Loss: 0.0179, Time: 22.27 seconds\n",
      "Epoch [75/500], Train Loss: 0.0202, Validation Loss: 0.0209, Time: 22.19 seconds\n",
      "Epoch [76/500], Train Loss: 0.0202, Validation Loss: 0.0169, Time: 22.68 seconds\n",
      "Epoch [77/500], Train Loss: 0.0198, Validation Loss: 0.0200, Time: 22.55 seconds\n",
      "Epoch [78/500], Train Loss: 0.0215, Validation Loss: 0.0188, Time: 22.42 seconds\n",
      "Epoch [79/500], Train Loss: 0.0218, Validation Loss: 0.0197, Time: 21.91 seconds\n",
      "Epoch [80/500], Train Loss: 0.0213, Validation Loss: 0.0187, Time: 22.16 seconds\n",
      "Epoch [81/500], Train Loss: 0.0210, Validation Loss: 0.0180, Time: 22.52 seconds\n",
      "Epoch [82/500], Train Loss: 0.0208, Validation Loss: 0.0172, Time: 22.72 seconds\n",
      "Epoch [83/500], Train Loss: 0.0195, Validation Loss: 0.0183, Time: 21.77 seconds\n",
      "Epoch [84/500], Train Loss: 0.0198, Validation Loss: 0.0185, Time: 21.92 seconds\n",
      "Epoch [85/500], Train Loss: 0.0195, Validation Loss: 0.0187, Time: 21.91 seconds\n",
      "Epoch [86/500], Train Loss: 0.0214, Validation Loss: 0.0173, Time: 22.08 seconds\n",
      "Epoch [87/500], Train Loss: 0.0205, Validation Loss: 0.0191, Time: 22.08 seconds\n",
      "Epoch [88/500], Train Loss: 0.0207, Validation Loss: 0.0203, Time: 22.38 seconds\n",
      "Epoch [89/500], Train Loss: 0.0210, Validation Loss: 0.0168, Time: 22.27 seconds\n",
      "Epoch [90/500], Train Loss: 0.0201, Validation Loss: 0.0181, Time: 22.62 seconds\n",
      "Epoch [91/500], Train Loss: 0.0212, Validation Loss: 0.0205, Time: 22.24 seconds\n",
      "Epoch [92/500], Train Loss: 0.0199, Validation Loss: 0.0158, Time: 22.70 seconds\n",
      "Epoch [93/500], Train Loss: 0.0191, Validation Loss: 0.0176, Time: 21.65 seconds\n",
      "Epoch [94/500], Train Loss: 0.0204, Validation Loss: 0.0180, Time: 21.69 seconds\n",
      "Epoch [95/500], Train Loss: 0.0209, Validation Loss: 0.0178, Time: 22.55 seconds\n",
      "Epoch [96/500], Train Loss: 0.0213, Validation Loss: 0.0209, Time: 21.74 seconds\n",
      "Epoch [97/500], Train Loss: 0.0205, Validation Loss: 0.0173, Time: 21.77 seconds\n",
      "Epoch [98/500], Train Loss: 0.0187, Validation Loss: 0.0193, Time: 21.54 seconds\n",
      "Epoch [99/500], Train Loss: 0.0199, Validation Loss: 0.0189, Time: 21.84 seconds\n",
      "Epoch [100/500], Train Loss: 0.0201, Validation Loss: 0.0199, Time: 21.76 seconds\n",
      "Epoch [101/500], Train Loss: 0.0208, Validation Loss: 0.0202, Time: 22.36 seconds\n",
      "Epoch [102/500], Train Loss: 0.0201, Validation Loss: 0.0180, Time: 22.32 seconds\n",
      "Epoch [103/500], Train Loss: 0.0207, Validation Loss: 0.0176, Time: 21.69 seconds\n",
      "Epoch [104/500], Train Loss: 0.0206, Validation Loss: 0.0174, Time: 21.84 seconds\n",
      "Epoch [105/500], Train Loss: 0.0214, Validation Loss: 0.0215, Time: 22.00 seconds\n",
      "Epoch [106/500], Train Loss: 0.0196, Validation Loss: 0.0173, Time: 21.96 seconds\n",
      "Epoch [107/500], Train Loss: 0.0215, Validation Loss: 0.0185, Time: 21.83 seconds\n",
      "Epoch [108/500], Train Loss: 0.0196, Validation Loss: 0.0178, Time: 22.33 seconds\n",
      "Epoch [109/500], Train Loss: 0.0208, Validation Loss: 0.0174, Time: 21.76 seconds\n",
      "Epoch [110/500], Train Loss: 0.0202, Validation Loss: 0.0163, Time: 21.65 seconds\n",
      "Epoch [111/500], Train Loss: 0.0196, Validation Loss: 0.0142, Time: 22.08 seconds\n",
      "Epoch [112/500], Train Loss: 0.0191, Validation Loss: 0.0178, Time: 21.94 seconds\n",
      "Epoch [113/500], Train Loss: 0.0226, Validation Loss: 0.0174, Time: 21.67 seconds\n",
      "Epoch [114/500], Train Loss: 0.0199, Validation Loss: 0.0193, Time: 22.33 seconds\n",
      "Epoch [115/500], Train Loss: 0.0190, Validation Loss: 0.0184, Time: 21.82 seconds\n",
      "Epoch [116/500], Train Loss: 0.0207, Validation Loss: 0.0169, Time: 21.93 seconds\n",
      "Epoch [117/500], Train Loss: 0.0195, Validation Loss: 0.0189, Time: 21.67 seconds\n",
      "Epoch [118/500], Train Loss: 0.0212, Validation Loss: 0.0179, Time: 21.95 seconds\n",
      "Epoch [119/500], Train Loss: 0.0211, Validation Loss: 0.0161, Time: 21.77 seconds\n",
      "Epoch [120/500], Train Loss: 0.0223, Validation Loss: 0.0167, Time: 22.52 seconds\n",
      "Epoch [121/500], Train Loss: 0.0198, Validation Loss: 0.0180, Time: 21.77 seconds\n",
      "Epoch [122/500], Train Loss: 0.0204, Validation Loss: 0.0185, Time: 21.51 seconds\n",
      "Epoch [123/500], Train Loss: 0.0204, Validation Loss: 0.0167, Time: 22.08 seconds\n",
      "Epoch [124/500], Train Loss: 0.0201, Validation Loss: 0.0168, Time: 21.55 seconds\n",
      "Epoch [125/500], Train Loss: 0.0200, Validation Loss: 0.0207, Time: 22.11 seconds\n",
      "Epoch [126/500], Train Loss: 0.0179, Validation Loss: 0.0170, Time: 21.31 seconds\n",
      "Epoch [127/500], Train Loss: 0.0201, Validation Loss: 0.0191, Time: 21.68 seconds\n",
      "Epoch [128/500], Train Loss: 0.0187, Validation Loss: 0.0175, Time: 22.67 seconds\n",
      "Epoch [129/500], Train Loss: 0.0219, Validation Loss: 0.0197, Time: 22.17 seconds\n",
      "Epoch [130/500], Train Loss: 0.0210, Validation Loss: 0.0178, Time: 22.39 seconds\n",
      "Epoch [131/500], Train Loss: 0.0204, Validation Loss: 0.0182, Time: 22.46 seconds\n",
      "Epoch [132/500], Train Loss: 0.0205, Validation Loss: 0.0194, Time: 21.49 seconds\n",
      "Epoch [133/500], Train Loss: 0.0200, Validation Loss: 0.0190, Time: 21.51 seconds\n",
      "Epoch [134/500], Train Loss: 0.0199, Validation Loss: 0.0188, Time: 22.16 seconds\n",
      "Epoch [135/500], Train Loss: 0.0189, Validation Loss: 0.0175, Time: 21.65 seconds\n",
      "Epoch [136/500], Train Loss: 0.0196, Validation Loss: 0.0178, Time: 22.38 seconds\n",
      "Epoch [137/500], Train Loss: 0.0207, Validation Loss: 0.0198, Time: 21.67 seconds\n",
      "Epoch [138/500], Train Loss: 0.0205, Validation Loss: 0.0176, Time: 21.67 seconds\n",
      "Epoch [139/500], Train Loss: 0.0210, Validation Loss: 0.0188, Time: 21.99 seconds\n",
      "Epoch [140/500], Train Loss: 0.0200, Validation Loss: 0.0180, Time: 21.54 seconds\n",
      "Epoch [141/500], Train Loss: 0.0201, Validation Loss: 0.0178, Time: 21.66 seconds\n",
      "Epoch [142/500], Train Loss: 0.0217, Validation Loss: 0.0181, Time: 22.31 seconds\n",
      "Epoch [143/500], Train Loss: 0.0205, Validation Loss: 0.0201, Time: 21.90 seconds\n",
      "Epoch [144/500], Train Loss: 0.0223, Validation Loss: 0.0176, Time: 21.83 seconds\n",
      "Epoch [145/500], Train Loss: 0.0203, Validation Loss: 0.0178, Time: 22.10 seconds\n",
      "Epoch [146/500], Train Loss: 0.0196, Validation Loss: 0.0169, Time: 22.78 seconds\n",
      "Epoch [147/500], Train Loss: 0.0211, Validation Loss: 0.0181, Time: 22.65 seconds\n",
      "Epoch [148/500], Train Loss: 0.0198, Validation Loss: 0.0180, Time: 21.70 seconds\n",
      "Epoch [149/500], Train Loss: 0.0215, Validation Loss: 0.0193, Time: 21.58 seconds\n",
      "Epoch [150/500], Train Loss: 0.0206, Validation Loss: 0.0166, Time: 22.16 seconds\n",
      "Epoch [151/500], Train Loss: 0.0195, Validation Loss: 0.0187, Time: 22.70 seconds\n",
      "Epoch [152/500], Train Loss: 0.0222, Validation Loss: 0.0186, Time: 22.69 seconds\n",
      "Epoch [153/500], Train Loss: 0.0196, Validation Loss: 0.0174, Time: 22.43 seconds\n",
      "Epoch [154/500], Train Loss: 0.0195, Validation Loss: 0.0178, Time: 22.39 seconds\n",
      "Epoch [155/500], Train Loss: 0.0193, Validation Loss: 0.0175, Time: 22.52 seconds\n",
      "Epoch [156/500], Train Loss: 0.0216, Validation Loss: 0.0182, Time: 21.89 seconds\n",
      "Epoch [157/500], Train Loss: 0.0212, Validation Loss: 0.0176, Time: 22.11 seconds\n",
      "Epoch [158/500], Train Loss: 0.0190, Validation Loss: 0.0218, Time: 22.48 seconds\n",
      "Epoch [159/500], Train Loss: 0.0190, Validation Loss: 0.0201, Time: 22.05 seconds\n",
      "Epoch [160/500], Train Loss: 0.0208, Validation Loss: 0.0184, Time: 21.64 seconds\n",
      "Epoch [161/500], Train Loss: 0.0202, Validation Loss: 0.0176, Time: 21.71 seconds\n",
      "Epoch [162/500], Train Loss: 0.0201, Validation Loss: 0.0181, Time: 21.83 seconds\n",
      "Epoch [163/500], Train Loss: 0.0206, Validation Loss: 0.0184, Time: 21.92 seconds\n",
      "Epoch [164/500], Train Loss: 0.0202, Validation Loss: 0.0175, Time: 22.02 seconds\n",
      "Epoch [165/500], Train Loss: 0.0213, Validation Loss: 0.0160, Time: 21.99 seconds\n",
      "Epoch [166/500], Train Loss: 0.0205, Validation Loss: 0.0190, Time: 22.47 seconds\n",
      "Epoch [167/500], Train Loss: 0.0208, Validation Loss: 0.0172, Time: 21.91 seconds\n",
      "Epoch [168/500], Train Loss: 0.0208, Validation Loss: 0.0176, Time: 22.86 seconds\n",
      "Epoch [169/500], Train Loss: 0.0200, Validation Loss: 0.0198, Time: 22.59 seconds\n",
      "Epoch [170/500], Train Loss: 0.0200, Validation Loss: 0.0173, Time: 21.86 seconds\n",
      "Epoch [171/500], Train Loss: 0.0205, Validation Loss: 0.0163, Time: 22.20 seconds\n",
      "Epoch [172/500], Train Loss: 0.0208, Validation Loss: 0.0185, Time: 22.14 seconds\n",
      "Epoch [173/500], Train Loss: 0.0207, Validation Loss: 0.0171, Time: 21.63 seconds\n",
      "Epoch [174/500], Train Loss: 0.0204, Validation Loss: 0.0176, Time: 22.15 seconds\n",
      "Epoch [175/500], Train Loss: 0.0200, Validation Loss: 0.0182, Time: 21.70 seconds\n",
      "Epoch [176/500], Train Loss: 0.0210, Validation Loss: 0.0187, Time: 22.01 seconds\n",
      "Epoch [177/500], Train Loss: 0.0196, Validation Loss: 0.0170, Time: 22.25 seconds\n",
      "Epoch [178/500], Train Loss: 0.0199, Validation Loss: 0.0181, Time: 22.58 seconds\n",
      "Epoch [179/500], Train Loss: 0.0186, Validation Loss: 0.0195, Time: 22.17 seconds\n",
      "Epoch [180/500], Train Loss: 0.0212, Validation Loss: 0.0175, Time: 22.33 seconds\n",
      "Epoch [181/500], Train Loss: 0.0209, Validation Loss: 0.0173, Time: 22.24 seconds\n",
      "Epoch [182/500], Train Loss: 0.0216, Validation Loss: 0.0166, Time: 22.30 seconds\n",
      "Epoch [183/500], Train Loss: 0.0203, Validation Loss: 0.0170, Time: 21.72 seconds\n",
      "Epoch [184/500], Train Loss: 0.0197, Validation Loss: 0.0198, Time: 21.68 seconds\n",
      "Epoch [185/500], Train Loss: 0.0208, Validation Loss: 0.0182, Time: 22.67 seconds\n",
      "Epoch [186/500], Train Loss: 0.0206, Validation Loss: 0.0181, Time: 22.36 seconds\n",
      "Epoch [187/500], Train Loss: 0.0205, Validation Loss: 0.0174, Time: 22.56 seconds\n",
      "Epoch [188/500], Train Loss: 0.0203, Validation Loss: 0.0191, Time: 21.86 seconds\n",
      "Epoch [189/500], Train Loss: 0.0209, Validation Loss: 0.0184, Time: 22.27 seconds\n",
      "Epoch [190/500], Train Loss: 0.0211, Validation Loss: 0.0185, Time: 22.78 seconds\n",
      "Epoch [191/500], Train Loss: 0.0199, Validation Loss: 0.0207, Time: 21.96 seconds\n",
      "Epoch [192/500], Train Loss: 0.0199, Validation Loss: 0.0208, Time: 21.93 seconds\n",
      "Epoch [193/500], Train Loss: 0.0208, Validation Loss: 0.0177, Time: 21.99 seconds\n",
      "Epoch [194/500], Train Loss: 0.0204, Validation Loss: 0.0197, Time: 22.27 seconds\n",
      "Epoch [195/500], Train Loss: 0.0188, Validation Loss: 0.0188, Time: 22.60 seconds\n",
      "Epoch [196/500], Train Loss: 0.0199, Validation Loss: 0.0184, Time: 22.67 seconds\n",
      "Epoch [197/500], Train Loss: 0.0197, Validation Loss: 0.0177, Time: 22.01 seconds\n",
      "Epoch [198/500], Train Loss: 0.0208, Validation Loss: 0.0203, Time: 22.65 seconds\n",
      "Epoch [199/500], Train Loss: 0.0193, Validation Loss: 0.0200, Time: 22.15 seconds\n",
      "Epoch [200/500], Train Loss: 0.0199, Validation Loss: 0.0181, Time: 21.88 seconds\n",
      "Epoch [201/500], Train Loss: 0.0202, Validation Loss: 0.0180, Time: 21.90 seconds\n",
      "Epoch [202/500], Train Loss: 0.0196, Validation Loss: 0.0183, Time: 21.66 seconds\n",
      "Epoch [203/500], Train Loss: 0.0196, Validation Loss: 0.0200, Time: 22.22 seconds\n",
      "Epoch [204/500], Train Loss: 0.0198, Validation Loss: 0.0177, Time: 21.79 seconds\n",
      "Epoch [205/500], Train Loss: 0.0189, Validation Loss: 0.0198, Time: 21.63 seconds\n",
      "Epoch [206/500], Train Loss: 0.0208, Validation Loss: 0.0176, Time: 22.54 seconds\n",
      "Epoch [207/500], Train Loss: 0.0184, Validation Loss: 0.0184, Time: 22.65 seconds\n",
      "Epoch [208/500], Train Loss: 0.0203, Validation Loss: 0.0177, Time: 22.97 seconds\n",
      "Epoch [209/500], Train Loss: 0.0199, Validation Loss: 0.0187, Time: 22.67 seconds\n",
      "Epoch [210/500], Train Loss: 0.0196, Validation Loss: 0.0164, Time: 21.77 seconds\n",
      "Epoch [211/500], Train Loss: 0.0198, Validation Loss: 0.0172, Time: 22.27 seconds\n",
      "Epoch [212/500], Train Loss: 0.0191, Validation Loss: 0.0191, Time: 22.47 seconds\n",
      "Epoch [213/500], Train Loss: 0.0214, Validation Loss: 0.0180, Time: 21.63 seconds\n",
      "Epoch [214/500], Train Loss: 0.0189, Validation Loss: 0.0182, Time: 22.19 seconds\n",
      "Epoch [215/500], Train Loss: 0.0209, Validation Loss: 0.0189, Time: 22.69 seconds\n",
      "Epoch [216/500], Train Loss: 0.0202, Validation Loss: 0.0151, Time: 22.12 seconds\n",
      "Epoch [217/500], Train Loss: 0.0192, Validation Loss: 0.0190, Time: 21.86 seconds\n",
      "Epoch [218/500], Train Loss: 0.0202, Validation Loss: 0.0185, Time: 21.91 seconds\n",
      "Epoch [219/500], Train Loss: 0.0182, Validation Loss: 0.0174, Time: 22.73 seconds\n",
      "Epoch [220/500], Train Loss: 0.0198, Validation Loss: 0.0178, Time: 21.98 seconds\n",
      "Epoch [221/500], Train Loss: 0.0201, Validation Loss: 0.0206, Time: 21.94 seconds\n",
      "Epoch [222/500], Train Loss: 0.0216, Validation Loss: 0.0171, Time: 22.06 seconds\n",
      "Epoch [223/500], Train Loss: 0.0191, Validation Loss: 0.0170, Time: 22.84 seconds\n",
      "Epoch [224/500], Train Loss: 0.0198, Validation Loss: 0.0181, Time: 21.87 seconds\n",
      "Epoch [225/500], Train Loss: 0.0197, Validation Loss: 0.0164, Time: 21.88 seconds\n",
      "Epoch [226/500], Train Loss: 0.0192, Validation Loss: 0.0180, Time: 22.08 seconds\n",
      "Epoch [227/500], Train Loss: 0.0207, Validation Loss: 0.0194, Time: 22.15 seconds\n",
      "Epoch [228/500], Train Loss: 0.0202, Validation Loss: 0.0202, Time: 21.86 seconds\n",
      "Epoch [229/500], Train Loss: 0.0195, Validation Loss: 0.0180, Time: 21.77 seconds\n",
      "Epoch [230/500], Train Loss: 0.0198, Validation Loss: 0.0170, Time: 22.26 seconds\n",
      "Epoch [231/500], Train Loss: 0.0196, Validation Loss: 0.0178, Time: 22.83 seconds\n",
      "Epoch [232/500], Train Loss: 0.0198, Validation Loss: 0.0163, Time: 22.02 seconds\n",
      "Epoch [233/500], Train Loss: 0.0192, Validation Loss: 0.0185, Time: 22.75 seconds\n",
      "Epoch [234/500], Train Loss: 0.0182, Validation Loss: 0.0202, Time: 23.10 seconds\n",
      "Epoch [235/500], Train Loss: 0.0202, Validation Loss: 0.0193, Time: 22.71 seconds\n",
      "Epoch [236/500], Train Loss: 0.0198, Validation Loss: 0.0181, Time: 22.49 seconds\n",
      "Epoch [237/500], Train Loss: 0.0187, Validation Loss: 0.0174, Time: 21.93 seconds\n",
      "Epoch [238/500], Train Loss: 0.0186, Validation Loss: 0.0143, Time: 22.22 seconds\n",
      "Epoch [239/500], Train Loss: 0.0188, Validation Loss: 0.0173, Time: 22.31 seconds\n",
      "Epoch [240/500], Train Loss: 0.0204, Validation Loss: 0.0174, Time: 22.14 seconds\n",
      "Epoch [241/500], Train Loss: 0.0194, Validation Loss: 0.0190, Time: 22.03 seconds\n",
      "Epoch [242/500], Train Loss: 0.0198, Validation Loss: 0.0182, Time: 22.63 seconds\n",
      "Epoch [243/500], Train Loss: 0.0191, Validation Loss: 0.0171, Time: 22.70 seconds\n",
      "Epoch [244/500], Train Loss: 0.0188, Validation Loss: 0.0180, Time: 22.59 seconds\n",
      "Epoch [245/500], Train Loss: 0.0194, Validation Loss: 0.0182, Time: 22.17 seconds\n",
      "Epoch [246/500], Train Loss: 0.0203, Validation Loss: 0.0184, Time: 22.52 seconds\n",
      "Epoch [247/500], Train Loss: 0.0200, Validation Loss: 0.0160, Time: 21.95 seconds\n",
      "Epoch [248/500], Train Loss: 0.0200, Validation Loss: 0.0196, Time: 22.16 seconds\n",
      "Epoch [249/500], Train Loss: 0.0198, Validation Loss: 0.0168, Time: 22.63 seconds\n",
      "Epoch [250/500], Train Loss: 0.0203, Validation Loss: 0.0198, Time: 22.46 seconds\n",
      "Epoch [251/500], Train Loss: 0.0195, Validation Loss: 0.0148, Time: 22.36 seconds\n",
      "Epoch [252/500], Train Loss: 0.0205, Validation Loss: 0.0192, Time: 22.60 seconds\n",
      "Epoch [253/500], Train Loss: 0.0195, Validation Loss: 0.0189, Time: 22.57 seconds\n",
      "Epoch [254/500], Train Loss: 0.0196, Validation Loss: 0.0197, Time: 22.28 seconds\n",
      "Epoch [255/500], Train Loss: 0.0208, Validation Loss: 0.0183, Time: 22.08 seconds\n",
      "Epoch [256/500], Train Loss: 0.0222, Validation Loss: 0.0199, Time: 21.96 seconds\n",
      "Epoch [257/500], Train Loss: 0.0196, Validation Loss: 0.0185, Time: 21.76 seconds\n",
      "Epoch [258/500], Train Loss: 0.0219, Validation Loss: 0.0175, Time: 22.17 seconds\n",
      "Epoch [259/500], Train Loss: 0.0201, Validation Loss: 0.0173, Time: 21.90 seconds\n",
      "Epoch [260/500], Train Loss: 0.0197, Validation Loss: 0.0194, Time: 22.14 seconds\n",
      "Epoch [261/500], Train Loss: 0.0204, Validation Loss: 0.0187, Time: 22.18 seconds\n",
      "Epoch [262/500], Train Loss: 0.0203, Validation Loss: 0.0160, Time: 22.66 seconds\n",
      "Epoch [263/500], Train Loss: 0.0201, Validation Loss: 0.0176, Time: 22.42 seconds\n",
      "Epoch [264/500], Train Loss: 0.0195, Validation Loss: 0.0189, Time: 22.44 seconds\n",
      "Epoch [265/500], Train Loss: 0.0191, Validation Loss: 0.0180, Time: 22.45 seconds\n",
      "Epoch [266/500], Train Loss: 0.0204, Validation Loss: 0.0175, Time: 22.34 seconds\n",
      "Epoch [267/500], Train Loss: 0.0194, Validation Loss: 0.0173, Time: 21.83 seconds\n",
      "Epoch [268/500], Train Loss: 0.0196, Validation Loss: 0.0178, Time: 22.19 seconds\n",
      "Epoch [269/500], Train Loss: 0.0198, Validation Loss: 0.0161, Time: 22.02 seconds\n",
      "Epoch [270/500], Train Loss: 0.0194, Validation Loss: 0.0174, Time: 22.43 seconds\n",
      "Epoch [271/500], Train Loss: 0.0192, Validation Loss: 0.0174, Time: 22.72 seconds\n",
      "Epoch [272/500], Train Loss: 0.0194, Validation Loss: 0.0166, Time: 22.44 seconds\n",
      "Epoch [273/500], Train Loss: 0.0200, Validation Loss: 0.0173, Time: 22.47 seconds\n",
      "Epoch [274/500], Train Loss: 0.0191, Validation Loss: 0.0181, Time: 22.35 seconds\n",
      "Epoch [275/500], Train Loss: 0.0223, Validation Loss: 0.0176, Time: 22.10 seconds\n",
      "Epoch [276/500], Train Loss: 0.0191, Validation Loss: 0.0168, Time: 22.07 seconds\n",
      "Epoch [277/500], Train Loss: 0.0217, Validation Loss: 0.0178, Time: 22.83 seconds\n",
      "Epoch [278/500], Train Loss: 0.0202, Validation Loss: 0.0167, Time: 21.87 seconds\n",
      "Epoch [279/500], Train Loss: 0.0195, Validation Loss: 0.0183, Time: 22.38 seconds\n",
      "Epoch [280/500], Train Loss: 0.0200, Validation Loss: 0.0186, Time: 22.01 seconds\n",
      "Epoch [281/500], Train Loss: 0.0201, Validation Loss: 0.0183, Time: 21.90 seconds\n",
      "Epoch [282/500], Train Loss: 0.0185, Validation Loss: 0.0178, Time: 22.48 seconds\n",
      "Epoch [283/500], Train Loss: 0.0209, Validation Loss: 0.0177, Time: 22.48 seconds\n",
      "Epoch [284/500], Train Loss: 0.0208, Validation Loss: 0.0164, Time: 22.26 seconds\n",
      "Epoch [285/500], Train Loss: 0.0196, Validation Loss: 0.0166, Time: 22.58 seconds\n",
      "Epoch [286/500], Train Loss: 0.0195, Validation Loss: 0.0189, Time: 22.61 seconds\n",
      "Epoch [287/500], Train Loss: 0.0190, Validation Loss: 0.0165, Time: 22.17 seconds\n",
      "Epoch [288/500], Train Loss: 0.0210, Validation Loss: 0.0183, Time: 22.81 seconds\n",
      "Epoch [289/500], Train Loss: 0.0209, Validation Loss: 0.0177, Time: 22.44 seconds\n",
      "Epoch [290/500], Train Loss: 0.0193, Validation Loss: 0.0161, Time: 21.87 seconds\n",
      "Epoch [291/500], Train Loss: 0.0210, Validation Loss: 0.0164, Time: 22.31 seconds\n",
      "Epoch [292/500], Train Loss: 0.0202, Validation Loss: 0.0173, Time: 21.99 seconds\n",
      "Epoch [293/500], Train Loss: 0.0186, Validation Loss: 0.0157, Time: 22.24 seconds\n",
      "Epoch [294/500], Train Loss: 0.0194, Validation Loss: 0.0184, Time: 21.78 seconds\n",
      "Epoch [295/500], Train Loss: 0.0204, Validation Loss: 0.0172, Time: 21.85 seconds\n",
      "Epoch [296/500], Train Loss: 0.0207, Validation Loss: 0.0180, Time: 22.51 seconds\n",
      "Epoch [297/500], Train Loss: 0.0192, Validation Loss: 0.0178, Time: 22.29 seconds\n",
      "Epoch [298/500], Train Loss: 0.0193, Validation Loss: 0.0184, Time: 22.20 seconds\n",
      "Epoch [299/500], Train Loss: 0.0201, Validation Loss: 0.0216, Time: 21.99 seconds\n",
      "Epoch [300/500], Train Loss: 0.0198, Validation Loss: 0.0193, Time: 22.54 seconds\n",
      "Epoch [301/500], Train Loss: 0.0195, Validation Loss: 0.0177, Time: 22.42 seconds\n",
      "Epoch [302/500], Train Loss: 0.0202, Validation Loss: 0.0180, Time: 23.02 seconds\n",
      "Epoch [303/500], Train Loss: 0.0185, Validation Loss: 0.0176, Time: 22.07 seconds\n",
      "Epoch [304/500], Train Loss: 0.0204, Validation Loss: 0.0175, Time: 22.25 seconds\n",
      "Epoch [305/500], Train Loss: 0.0194, Validation Loss: 0.0186, Time: 22.68 seconds\n",
      "Epoch [306/500], Train Loss: 0.0209, Validation Loss: 0.0164, Time: 22.36 seconds\n",
      "Epoch [307/500], Train Loss: 0.0209, Validation Loss: 0.0169, Time: 22.56 seconds\n",
      "Epoch [308/500], Train Loss: 0.0197, Validation Loss: 0.0176, Time: 22.76 seconds\n",
      "Epoch [309/500], Train Loss: 0.0206, Validation Loss: 0.0176, Time: 21.74 seconds\n",
      "Epoch [310/500], Train Loss: 0.0200, Validation Loss: 0.0180, Time: 22.25 seconds\n",
      "Epoch [311/500], Train Loss: 0.0199, Validation Loss: 0.0177, Time: 22.51 seconds\n",
      "Epoch [312/500], Train Loss: 0.0191, Validation Loss: 0.0176, Time: 22.00 seconds\n",
      "Epoch [313/500], Train Loss: 0.0198, Validation Loss: 0.0190, Time: 22.20 seconds\n",
      "Epoch [314/500], Train Loss: 0.0207, Validation Loss: 0.0195, Time: 22.25 seconds\n",
      "Epoch [315/500], Train Loss: 0.0197, Validation Loss: 0.0164, Time: 21.90 seconds\n",
      "Epoch [316/500], Train Loss: 0.0203, Validation Loss: 0.0155, Time: 22.23 seconds\n",
      "Epoch [317/500], Train Loss: 0.0200, Validation Loss: 0.0174, Time: 21.96 seconds\n",
      "Epoch [318/500], Train Loss: 0.0203, Validation Loss: 0.0173, Time: 22.02 seconds\n",
      "Epoch [319/500], Train Loss: 0.0194, Validation Loss: 0.0185, Time: 22.39 seconds\n",
      "Epoch [320/500], Train Loss: 0.0205, Validation Loss: 0.0178, Time: 21.97 seconds\n",
      "Epoch [321/500], Train Loss: 0.0208, Validation Loss: 0.0203, Time: 22.32 seconds\n",
      "Epoch [322/500], Train Loss: 0.0193, Validation Loss: 0.0156, Time: 21.72 seconds\n",
      "Epoch [323/500], Train Loss: 0.0196, Validation Loss: 0.0195, Time: 21.91 seconds\n",
      "Epoch [324/500], Train Loss: 0.0203, Validation Loss: 0.0162, Time: 21.90 seconds\n",
      "Epoch [325/500], Train Loss: 0.0204, Validation Loss: 0.0171, Time: 22.39 seconds\n",
      "Epoch [326/500], Train Loss: 0.0196, Validation Loss: 0.0169, Time: 22.14 seconds\n",
      "Epoch [327/500], Train Loss: 0.0196, Validation Loss: 0.0169, Time: 22.32 seconds\n",
      "Epoch [328/500], Train Loss: 0.0204, Validation Loss: 0.0186, Time: 21.89 seconds\n",
      "Epoch [329/500], Train Loss: 0.0194, Validation Loss: 0.0201, Time: 22.88 seconds\n",
      "Epoch [330/500], Train Loss: 0.0200, Validation Loss: 0.0166, Time: 22.13 seconds\n",
      "Epoch [331/500], Train Loss: 0.0201, Validation Loss: 0.0184, Time: 22.14 seconds\n",
      "Epoch [332/500], Train Loss: 0.0206, Validation Loss: 0.0183, Time: 21.86 seconds\n",
      "Epoch [333/500], Train Loss: 0.0215, Validation Loss: 0.0186, Time: 22.86 seconds\n",
      "Epoch [334/500], Train Loss: 0.0207, Validation Loss: 0.0155, Time: 22.55 seconds\n",
      "Epoch [335/500], Train Loss: 0.0193, Validation Loss: 0.0170, Time: 21.90 seconds\n",
      "Epoch [336/500], Train Loss: 0.0199, Validation Loss: 0.0207, Time: 22.35 seconds\n",
      "Epoch [337/500], Train Loss: 0.0209, Validation Loss: 0.0178, Time: 21.74 seconds\n",
      "Epoch [338/500], Train Loss: 0.0192, Validation Loss: 0.0183, Time: 22.06 seconds\n",
      "Epoch [339/500], Train Loss: 0.0198, Validation Loss: 0.0170, Time: 22.65 seconds\n",
      "Epoch [340/500], Train Loss: 0.0202, Validation Loss: 0.0168, Time: 22.20 seconds\n",
      "Epoch [341/500], Train Loss: 0.0197, Validation Loss: 0.0175, Time: 22.03 seconds\n",
      "Epoch [342/500], Train Loss: 0.0196, Validation Loss: 0.0184, Time: 21.87 seconds\n",
      "Epoch [343/500], Train Loss: 0.0195, Validation Loss: 0.0171, Time: 23.07 seconds\n",
      "Epoch [344/500], Train Loss: 0.0204, Validation Loss: 0.0160, Time: 22.20 seconds\n",
      "Epoch [345/500], Train Loss: 0.0189, Validation Loss: 0.0181, Time: 21.90 seconds\n",
      "Epoch [346/500], Train Loss: 0.0194, Validation Loss: 0.0156, Time: 22.62 seconds\n",
      "Epoch [347/500], Train Loss: 0.0214, Validation Loss: 0.0181, Time: 22.70 seconds\n",
      "Epoch [348/500], Train Loss: 0.0207, Validation Loss: 0.0197, Time: 22.74 seconds\n",
      "Epoch [349/500], Train Loss: 0.0209, Validation Loss: 0.0143, Time: 22.13 seconds\n",
      "Epoch [350/500], Train Loss: 0.0192, Validation Loss: 0.0178, Time: 22.47 seconds\n",
      "Epoch [351/500], Train Loss: 0.0191, Validation Loss: 0.0183, Time: 23.06 seconds\n",
      "Epoch [352/500], Train Loss: 0.0206, Validation Loss: 0.0179, Time: 23.12 seconds\n",
      "Epoch [353/500], Train Loss: 0.0195, Validation Loss: 0.0189, Time: 22.16 seconds\n",
      "Epoch [354/500], Train Loss: 0.0189, Validation Loss: 0.0186, Time: 22.56 seconds\n",
      "Epoch [355/500], Train Loss: 0.0200, Validation Loss: 0.0193, Time: 22.50 seconds\n",
      "Epoch [356/500], Train Loss: 0.0183, Validation Loss: 0.0183, Time: 22.49 seconds\n",
      "Epoch [357/500], Train Loss: 0.0191, Validation Loss: 0.0182, Time: 22.12 seconds\n",
      "Epoch [358/500], Train Loss: 0.0189, Validation Loss: 0.0178, Time: 22.75 seconds\n",
      "Epoch [359/500], Train Loss: 0.0190, Validation Loss: 0.0178, Time: 22.65 seconds\n",
      "Epoch [360/500], Train Loss: 0.0187, Validation Loss: 0.0153, Time: 22.42 seconds\n",
      "Epoch [361/500], Train Loss: 0.0206, Validation Loss: 0.0187, Time: 22.56 seconds\n",
      "Epoch [362/500], Train Loss: 0.0204, Validation Loss: 0.0169, Time: 22.54 seconds\n",
      "Epoch [363/500], Train Loss: 0.0196, Validation Loss: 0.0173, Time: 22.72 seconds\n",
      "Epoch [364/500], Train Loss: 0.0195, Validation Loss: 0.0184, Time: 22.49 seconds\n",
      "Epoch [365/500], Train Loss: 0.0193, Validation Loss: 0.0189, Time: 22.30 seconds\n",
      "Epoch [366/500], Train Loss: 0.0208, Validation Loss: 0.0183, Time: 22.02 seconds\n",
      "Epoch [367/500], Train Loss: 0.0209, Validation Loss: 0.0178, Time: 21.81 seconds\n",
      "Epoch [368/500], Train Loss: 0.0191, Validation Loss: 0.0167, Time: 22.08 seconds\n",
      "Epoch [369/500], Train Loss: 0.0195, Validation Loss: 0.0172, Time: 22.71 seconds\n",
      "Epoch [370/500], Train Loss: 0.0200, Validation Loss: 0.0163, Time: 22.40 seconds\n",
      "Epoch [371/500], Train Loss: 0.0190, Validation Loss: 0.0154, Time: 22.76 seconds\n",
      "Epoch [372/500], Train Loss: 0.0196, Validation Loss: 0.0176, Time: 21.88 seconds\n",
      "Epoch [373/500], Train Loss: 0.0200, Validation Loss: 0.0173, Time: 22.48 seconds\n",
      "Epoch [374/500], Train Loss: 0.0201, Validation Loss: 0.0168, Time: 22.26 seconds\n",
      "Epoch [375/500], Train Loss: 0.0194, Validation Loss: 0.0179, Time: 22.12 seconds\n",
      "Epoch [376/500], Train Loss: 0.0191, Validation Loss: 0.0177, Time: 22.31 seconds\n",
      "Epoch [377/500], Train Loss: 0.0217, Validation Loss: 0.0169, Time: 22.56 seconds\n",
      "Epoch [378/500], Train Loss: 0.0199, Validation Loss: 0.0179, Time: 21.72 seconds\n",
      "Epoch [379/500], Train Loss: 0.0205, Validation Loss: 0.0176, Time: 22.36 seconds\n",
      "Epoch [380/500], Train Loss: 0.0192, Validation Loss: 0.0170, Time: 22.41 seconds\n",
      "Epoch [381/500], Train Loss: 0.0204, Validation Loss: 0.0177, Time: 22.59 seconds\n",
      "Epoch [382/500], Train Loss: 0.0204, Validation Loss: 0.0197, Time: 21.88 seconds\n",
      "Epoch [383/500], Train Loss: 0.0197, Validation Loss: 0.0201, Time: 21.96 seconds\n",
      "Epoch [384/500], Train Loss: 0.0199, Validation Loss: 0.0189, Time: 22.10 seconds\n",
      "Epoch [385/500], Train Loss: 0.0204, Validation Loss: 0.0151, Time: 22.05 seconds\n",
      "Epoch [386/500], Train Loss: 0.0206, Validation Loss: 0.0169, Time: 21.92 seconds\n",
      "Epoch [387/500], Train Loss: 0.0208, Validation Loss: 0.0171, Time: 22.25 seconds\n",
      "Epoch [388/500], Train Loss: 0.0198, Validation Loss: 0.0175, Time: 22.20 seconds\n",
      "Epoch [389/500], Train Loss: 0.0222, Validation Loss: 0.0178, Time: 21.73 seconds\n",
      "Epoch [390/500], Train Loss: 0.0182, Validation Loss: 0.0171, Time: 21.84 seconds\n",
      "Epoch [391/500], Train Loss: 0.0210, Validation Loss: 0.0175, Time: 22.25 seconds\n",
      "Epoch [392/500], Train Loss: 0.0195, Validation Loss: 0.0165, Time: 22.18 seconds\n",
      "Epoch [393/500], Train Loss: 0.0197, Validation Loss: 0.0153, Time: 22.38 seconds\n",
      "Epoch [394/500], Train Loss: 0.0193, Validation Loss: 0.0171, Time: 21.88 seconds\n",
      "Epoch [395/500], Train Loss: 0.0199, Validation Loss: 0.0179, Time: 22.04 seconds\n",
      "Epoch [396/500], Train Loss: 0.0213, Validation Loss: 0.0180, Time: 22.77 seconds\n",
      "Epoch [397/500], Train Loss: 0.0183, Validation Loss: 0.0212, Time: 22.91 seconds\n",
      "Epoch [398/500], Train Loss: 0.0200, Validation Loss: 0.0168, Time: 23.53 seconds\n",
      "Epoch [399/500], Train Loss: 0.0195, Validation Loss: 0.0175, Time: 22.41 seconds\n",
      "Epoch [400/500], Train Loss: 0.0198, Validation Loss: 0.0155, Time: 21.92 seconds\n",
      "Epoch [401/500], Train Loss: 0.0197, Validation Loss: 0.0178, Time: 22.69 seconds\n",
      "Epoch [402/500], Train Loss: 0.0210, Validation Loss: 0.0181, Time: 21.76 seconds\n",
      "Epoch [403/500], Train Loss: 0.0188, Validation Loss: 0.0175, Time: 21.95 seconds\n",
      "Epoch [404/500], Train Loss: 0.0198, Validation Loss: 0.0152, Time: 22.58 seconds\n",
      "Epoch [405/500], Train Loss: 0.0206, Validation Loss: 0.0199, Time: 22.72 seconds\n",
      "Epoch [406/500], Train Loss: 0.0197, Validation Loss: 0.0170, Time: 22.26 seconds\n",
      "Epoch [407/500], Train Loss: 0.0202, Validation Loss: 0.0209, Time: 22.46 seconds\n",
      "Epoch [408/500], Train Loss: 0.0205, Validation Loss: 0.0168, Time: 22.68 seconds\n",
      "Epoch [409/500], Train Loss: 0.0189, Validation Loss: 0.0186, Time: 22.08 seconds\n",
      "Epoch [410/500], Train Loss: 0.0192, Validation Loss: 0.0176, Time: 22.43 seconds\n",
      "Epoch [411/500], Train Loss: 0.0193, Validation Loss: 0.0163, Time: 22.01 seconds\n",
      "Epoch [412/500], Train Loss: 0.0190, Validation Loss: 0.0174, Time: 21.96 seconds\n",
      "Epoch [413/500], Train Loss: 0.0195, Validation Loss: 0.0150, Time: 22.27 seconds\n",
      "Epoch [414/500], Train Loss: 0.0205, Validation Loss: 0.0178, Time: 21.93 seconds\n",
      "Epoch [415/500], Train Loss: 0.0193, Validation Loss: 0.0176, Time: 22.02 seconds\n",
      "Epoch [416/500], Train Loss: 0.0186, Validation Loss: 0.0163, Time: 22.39 seconds\n",
      "Epoch [417/500], Train Loss: 0.0212, Validation Loss: 0.0184, Time: 22.48 seconds\n",
      "Epoch [418/500], Train Loss: 0.0196, Validation Loss: 0.0196, Time: 22.26 seconds\n",
      "Epoch [419/500], Train Loss: 0.0201, Validation Loss: 0.0168, Time: 22.46 seconds\n",
      "Epoch [420/500], Train Loss: 0.0195, Validation Loss: 0.0177, Time: 22.35 seconds\n",
      "Epoch [421/500], Train Loss: 0.0202, Validation Loss: 0.0164, Time: 22.37 seconds\n",
      "Epoch [422/500], Train Loss: 0.0206, Validation Loss: 0.0171, Time: 22.47 seconds\n",
      "Epoch [423/500], Train Loss: 0.0192, Validation Loss: 0.0173, Time: 22.45 seconds\n",
      "Epoch [424/500], Train Loss: 0.0200, Validation Loss: 0.0151, Time: 22.98 seconds\n",
      "Epoch [425/500], Train Loss: 0.0202, Validation Loss: 0.0191, Time: 22.63 seconds\n",
      "Epoch [426/500], Train Loss: 0.0202, Validation Loss: 0.0164, Time: 22.05 seconds\n",
      "Epoch [427/500], Train Loss: 0.0202, Validation Loss: 0.0149, Time: 22.42 seconds\n",
      "Epoch [428/500], Train Loss: 0.0202, Validation Loss: 0.0193, Time: 22.65 seconds\n",
      "Epoch [429/500], Train Loss: 0.0199, Validation Loss: 0.0171, Time: 22.12 seconds\n",
      "Epoch [430/500], Train Loss: 0.0189, Validation Loss: 0.0173, Time: 22.34 seconds\n",
      "Epoch [431/500], Train Loss: 0.0197, Validation Loss: 0.0169, Time: 21.86 seconds\n",
      "Epoch [432/500], Train Loss: 0.0192, Validation Loss: 0.0229, Time: 22.63 seconds\n",
      "Epoch [433/500], Train Loss: 0.0203, Validation Loss: 0.0172, Time: 22.41 seconds\n",
      "Epoch [434/500], Train Loss: 0.0186, Validation Loss: 0.0172, Time: 21.82 seconds\n",
      "Epoch [435/500], Train Loss: 0.0215, Validation Loss: 0.0175, Time: 22.43 seconds\n",
      "Epoch [436/500], Train Loss: 0.0206, Validation Loss: 0.0157, Time: 22.10 seconds\n",
      "Epoch [437/500], Train Loss: 0.0207, Validation Loss: 0.0166, Time: 21.95 seconds\n",
      "Epoch [438/500], Train Loss: 0.0197, Validation Loss: 0.0170, Time: 21.92 seconds\n",
      "Epoch [439/500], Train Loss: 0.0203, Validation Loss: 0.0189, Time: 22.52 seconds\n",
      "Epoch [440/500], Train Loss: 0.0186, Validation Loss: 0.0161, Time: 22.34 seconds\n",
      "Epoch [441/500], Train Loss: 0.0213, Validation Loss: 0.0189, Time: 22.64 seconds\n",
      "Epoch [442/500], Train Loss: 0.0198, Validation Loss: 0.0196, Time: 22.38 seconds\n",
      "Epoch [443/500], Train Loss: 0.0195, Validation Loss: 0.0189, Time: 22.18 seconds\n",
      "Epoch [444/500], Train Loss: 0.0197, Validation Loss: 0.0175, Time: 22.33 seconds\n",
      "Epoch [445/500], Train Loss: 0.0195, Validation Loss: 0.0174, Time: 22.16 seconds\n",
      "Epoch [446/500], Train Loss: 0.0208, Validation Loss: 0.0170, Time: 22.09 seconds\n",
      "Epoch [447/500], Train Loss: 0.0198, Validation Loss: 0.0166, Time: 22.57 seconds\n",
      "Epoch [448/500], Train Loss: 0.0201, Validation Loss: 0.0174, Time: 22.03 seconds\n",
      "Epoch [449/500], Train Loss: 0.0195, Validation Loss: 0.0193, Time: 22.07 seconds\n",
      "Epoch [450/500], Train Loss: 0.0188, Validation Loss: 0.0187, Time: 22.35 seconds\n",
      "Epoch [451/500], Train Loss: 0.0186, Validation Loss: 0.0180, Time: 22.65 seconds\n",
      "Epoch [452/500], Train Loss: 0.0195, Validation Loss: 0.0170, Time: 22.37 seconds\n",
      "Epoch [453/500], Train Loss: 0.0195, Validation Loss: 0.0200, Time: 22.45 seconds\n",
      "Epoch [454/500], Train Loss: 0.0197, Validation Loss: 0.0187, Time: 22.57 seconds\n",
      "Epoch [455/500], Train Loss: 0.0193, Validation Loss: 0.0184, Time: 22.21 seconds\n",
      "Epoch [456/500], Train Loss: 0.0194, Validation Loss: 0.0159, Time: 21.83 seconds\n",
      "Epoch [457/500], Train Loss: 0.0196, Validation Loss: 0.0208, Time: 22.68 seconds\n",
      "Epoch [458/500], Train Loss: 0.0194, Validation Loss: 0.0164, Time: 22.79 seconds\n",
      "Epoch [459/500], Train Loss: 0.0199, Validation Loss: 0.0143, Time: 22.30 seconds\n",
      "Epoch [460/500], Train Loss: 0.0181, Validation Loss: 0.0193, Time: 21.85 seconds\n",
      "Epoch [461/500], Train Loss: 0.0178, Validation Loss: 0.0168, Time: 22.21 seconds\n",
      "Epoch [462/500], Train Loss: 0.0202, Validation Loss: 0.0176, Time: 22.50 seconds\n",
      "Epoch [463/500], Train Loss: 0.0194, Validation Loss: 0.0187, Time: 22.25 seconds\n",
      "Epoch [464/500], Train Loss: 0.0187, Validation Loss: 0.0169, Time: 22.16 seconds\n",
      "Epoch [465/500], Train Loss: 0.0199, Validation Loss: 0.0157, Time: 22.69 seconds\n",
      "Epoch [466/500], Train Loss: 0.0183, Validation Loss: 0.0172, Time: 22.20 seconds\n",
      "Epoch [467/500], Train Loss: 0.0193, Validation Loss: 0.0177, Time: 23.06 seconds\n",
      "Epoch [468/500], Train Loss: 0.0183, Validation Loss: 0.0167, Time: 22.21 seconds\n",
      "Epoch [469/500], Train Loss: 0.0196, Validation Loss: 0.0185, Time: 22.24 seconds\n",
      "Epoch [470/500], Train Loss: 0.0207, Validation Loss: 0.0196, Time: 22.01 seconds\n",
      "Epoch [471/500], Train Loss: 0.0202, Validation Loss: 0.0195, Time: 22.73 seconds\n",
      "Epoch [472/500], Train Loss: 0.0188, Validation Loss: 0.0196, Time: 22.32 seconds\n",
      "Epoch [473/500], Train Loss: 0.0193, Validation Loss: 0.0173, Time: 21.90 seconds\n",
      "Epoch [474/500], Train Loss: 0.0196, Validation Loss: 0.0178, Time: 21.90 seconds\n",
      "Epoch [475/500], Train Loss: 0.0191, Validation Loss: 0.0201, Time: 22.22 seconds\n",
      "Epoch [476/500], Train Loss: 0.0192, Validation Loss: 0.0164, Time: 22.29 seconds\n",
      "Epoch [477/500], Train Loss: 0.0201, Validation Loss: 0.0177, Time: 22.63 seconds\n",
      "Epoch [478/500], Train Loss: 0.0201, Validation Loss: 0.0151, Time: 22.38 seconds\n",
      "Epoch [479/500], Train Loss: 0.0199, Validation Loss: 0.0181, Time: 22.88 seconds\n",
      "Epoch [480/500], Train Loss: 0.0196, Validation Loss: 0.0198, Time: 22.52 seconds\n",
      "Epoch [481/500], Train Loss: 0.0216, Validation Loss: 0.0205, Time: 22.57 seconds\n",
      "Epoch [482/500], Train Loss: 0.0190, Validation Loss: 0.0173, Time: 22.50 seconds\n",
      "Epoch [483/500], Train Loss: 0.0196, Validation Loss: 0.0173, Time: 22.50 seconds\n",
      "Epoch [484/500], Train Loss: 0.0197, Validation Loss: 0.0184, Time: 22.59 seconds\n",
      "Epoch [485/500], Train Loss: 0.0196, Validation Loss: 0.0169, Time: 22.87 seconds\n",
      "Epoch [486/500], Train Loss: 0.0195, Validation Loss: 0.0165, Time: 22.30 seconds\n",
      "Epoch [487/500], Train Loss: 0.0188, Validation Loss: 0.0190, Time: 22.01 seconds\n",
      "Epoch [488/500], Train Loss: 0.0201, Validation Loss: 0.0196, Time: 21.89 seconds\n",
      "Epoch [489/500], Train Loss: 0.0189, Validation Loss: 0.0170, Time: 22.17 seconds\n",
      "Epoch [490/500], Train Loss: 0.0202, Validation Loss: 0.0165, Time: 22.59 seconds\n",
      "Epoch [491/500], Train Loss: 0.0206, Validation Loss: 0.0180, Time: 21.73 seconds\n",
      "Epoch [492/500], Train Loss: 0.0203, Validation Loss: 0.0166, Time: 22.10 seconds\n",
      "Epoch [493/500], Train Loss: 0.0197, Validation Loss: 0.0166, Time: 22.36 seconds\n",
      "Epoch [494/500], Train Loss: 0.0200, Validation Loss: 0.0177, Time: 22.52 seconds\n",
      "Epoch [495/500], Train Loss: 0.0186, Validation Loss: 0.0178, Time: 22.43 seconds\n",
      "Epoch [496/500], Train Loss: 0.0182, Validation Loss: 0.0153, Time: 21.76 seconds\n",
      "Epoch [497/500], Train Loss: 0.0202, Validation Loss: 0.0207, Time: 22.52 seconds\n",
      "Epoch [498/500], Train Loss: 0.0183, Validation Loss: 0.0172, Time: 22.79 seconds\n",
      "Epoch [499/500], Train Loss: 0.0193, Validation Loss: 0.0153, Time: 22.05 seconds\n",
      "Epoch [500/500], Train Loss: 0.0206, Validation Loss: 0.0167, Time: 21.87 seconds\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train_and_validate(modi, train_loader, val_loader, optimizer, criterion, num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model parameters after training\n",
    "torch.save(modi.state_dict(), 'modi_time_pred.pth')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#check for whether pairing day7 with day 10 is working properly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_D07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_D07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_D08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_D08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_D09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_D09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_D10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_D10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_D11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_D11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_E07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_E07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_E08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_E08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_E09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_E09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_E10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_E10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_E11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_E11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_F07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_F07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_F08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_F08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_F09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_F09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_F10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_F10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_F11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_F11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_G07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_G07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_G08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_G08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_G09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_G09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_G10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_G10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_G11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_G11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_D07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_D07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_D08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_D08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_D09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_D09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_D10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_D10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_D11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_D11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_E07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_E07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_E08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_E08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_E09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_E09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_E10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_E10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_E11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_E11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_F07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_F07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_F08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_F08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_F09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_F09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_F10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_F10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_F11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_F11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_G07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_G07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_G08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_G08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_G09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_G09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_G10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_G10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_G11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_G11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_D07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_D07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_D08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_D08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_D09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_D09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_D10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_D10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_D11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_D11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_E07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_E07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_E08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_E08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_E09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_E09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_E10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_E10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_E11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_E11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_F07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_F07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_F08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_F08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_F09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_F09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_F10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_F10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_F11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_F11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_G07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_G07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_G08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_G08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_G09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_G09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_G10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_G10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_G11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_G11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_D07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_D07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_D08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_D08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_D09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_D09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_D10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_D10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_D11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_D11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_E07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_E07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_E08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_E08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_E09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_E09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_E10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_E10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_E11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_E11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_F07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_F07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_F08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_F08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_F09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_F09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_F10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_F10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_F11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_F11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_G07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_G07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_G08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_G08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_G09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_G09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_G10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_G10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_G11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_G11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_B02-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_B02-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_B03-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_B03-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_B04-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_B04-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_B05-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_B05-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_B06-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_B06-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_C02-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_C02-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_C03-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_C03-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_C04-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_C04-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_C05-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_C05-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_C06-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_C06-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_D02-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_D02-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_D03-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_D03-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_D04-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_D04-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_D05-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_D05-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_D06-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_D06-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_E02-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_E02-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_E03-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_E03-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_E04-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_E04-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_E05-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_E05-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_E06-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_E06-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_F02-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_F02-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_F03-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_F03-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_F04-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_F04-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_F05-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_F05-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_F06-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_F06-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_G02-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_G02-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_G03-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_G03-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_G04-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_G04-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_G05-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_G05-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_G06-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_G06-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_D07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_D07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_D08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_D08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_D09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_D09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_D10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_D10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_D11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_D11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_E07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_E07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_E08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_E08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_E09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_E09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_E10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_E10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_E11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_E11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_F07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_F07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_F08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_F08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_F09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_F09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_F10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_F10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_F11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_F11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_G07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_G07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_G08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_G08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_G09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_G09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_G10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_G10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_G11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_G11-T01.tiff\n",
      "\n",
      "Total number of paired images: 130\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "class ImagePairingChecker:\n",
    "    def __init__(self, day7_dir, day10_dir):\n",
    "        self.day7_files = {os.path.basename(file): os.path.join(day7_dir, file) for file in os.listdir(day7_dir) if file.endswith('.tiff')}\n",
    "        self.day10_files = {os.path.basename(file): os.path.join(day10_dir, file) for file in os.listdir(day10_dir) if file.endswith('.tiff')}\n",
    "\n",
    "        # Ensure all day7 files have a corresponding day10 file\n",
    "        self.common_files = list(self.day7_files.keys())\n",
    "        assert set(self.common_files) <= set(self.day10_files.keys()), \"Mismatch between day7 and day10 filenames.\"\n",
    "\n",
    "    def print_paired_paths(self):\n",
    "        for filename in self.common_files:\n",
    "            day7_img_path = self.day7_files[filename]\n",
    "            day10_img_path = self.day10_files[filename]\n",
    "            print(f\"Day7: {day7_img_path} | Day10: {day10_img_path}\")\n",
    "        \n",
    "        # Print the total number of pairs\n",
    "        print(f\"\\nTotal number of paired images: {len(self.common_files)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "day7_dir = os.path.abspath(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7')\n",
    "day10_dir = os.path.abspath(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10')\n",
    "\n",
    "\n",
    "pairing_checker = ImagePairingChecker(day7_dir, day10_dir)\n",
    "pairing_checker.print_paired_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
