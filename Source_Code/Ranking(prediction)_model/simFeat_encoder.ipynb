{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_model_path =  r'C:\\Users\\k54739\\saved_model\\simclr_model_epoch_245.pth' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay,max_epochs):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        # Load the pretrained ResNet-18 model\n",
    "        self.convnet = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "        \n",
    "        # Modify the fully connected layer\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4 * hidden_dim),  # Linear layer with 4*hidden_dim output\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * hidden_dim, 20)  # Output layer with hidden_dim output\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.AdamW(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        self.lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=max_epochs, eta_min=lr / 50)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convnet(x)\n",
    "\n",
    "    def info_nce_loss(self, imgs1, imgs2, device):\n",
    "\n",
    "        imgs = torch.cat((imgs1, imgs2), dim=0)  # Concatenate along the batch dimension\n",
    "        imgs = imgs.to(device)  # Move images to the device\n",
    "\n",
    "        # Encode all images\n",
    "        feats = self.forward(imgs)\n",
    "    \n",
    "        # Calculate cosine similarity\n",
    "        cos_sim = nn.functional.cosine_similarity(feats[:, None, :], feats[None, :, :], dim=-1)\n",
    "    \n",
    "        # Mask out cosine similarity to itself\n",
    "        self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "        cos_sim.masked_fill_(self_mask, -9e15)\n",
    "    \n",
    "        # Find positive example -> batch_size//2 away from the original example\n",
    "        pos_mask = self_mask.roll(shifts=cos_sim.shape[0] // 2, dims=0)\n",
    "    \n",
    "        # Normalize similarity scores by temperature\n",
    "        cos_sim = cos_sim / self.temperature\n",
    "\n",
    "        # InfoNCE loss\n",
    "        nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "        nll = nll.mean()\n",
    "\n",
    "        # Accuracy calculations\n",
    "        # Create a combination of positive and negative similarities for ranking\n",
    "        comb_sim = torch.cat([cos_sim[pos_mask][:, None],  # Positive example in first position\n",
    "                          cos_sim.masked_fill(pos_mask, -9e15)], dim=-1)\n",
    "    \n",
    "        # Sort and get the ranking position of the positive example\n",
    "        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
    "    \n",
    "        # Compute accuracy metrics\n",
    "        top1_acc = (sim_argsort == 0).float().mean()  # Top-1 accuracy\n",
    "        top5_acc = (sim_argsort < 5).float().mean()   # Top-5 accuracy\n",
    "        mean_pos = 1 + sim_argsort.float().mean()     # Mean position of the positive example\n",
    "\n",
    "        return nll, top1_acc, top5_acc, mean_pos\n",
    "\n",
    "    def train_epoch(self, train_loader, device):\n",
    "        self.train()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            imgs1, imgs2, _ = batch\n",
    "            imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "        \n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Calculate loss and accuracy metrics\n",
    "            loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            #self.lr_scheduler.step()\n",
    "\n",
    "            # Accumulate metrics\n",
    "            total_loss += loss.item()\n",
    "            total_top1_acc += top1_acc.item()\n",
    "            total_top5_acc += top5_acc.item()\n",
    "            total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(train_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(train_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(train_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos\n",
    "\n",
    "    def validate_epoch(self, val_loader, device):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "                imgs1, imgs2, _ = batch\n",
    "                imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "\n",
    "                # Calculate loss and accuracy metrics\n",
    "                loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "                # Accumulate metrics\n",
    "                total_loss += loss.item()\n",
    "                total_top1_acc += top1_acc.item()\n",
    "                total_top5_acc += top5_acc.item()\n",
    "                total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(val_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(val_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(val_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(val_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos\n",
    "    \n",
    "\n",
    "    def inference_epoch(self, inference_loader, device):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(inference_loader, desc=\"Inferencing\", leave=False):\n",
    "                imgs1, imgs2, _ = batch\n",
    "                imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "\n",
    "                # Calculate loss and accuracy metrics\n",
    "                loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "                # Accumulate metrics\n",
    "                total_loss += loss.item()\n",
    "                total_top1_acc += top1_acc.item()\n",
    "                total_top5_acc += top5_acc.item()\n",
    "                total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(inference_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(inference_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(inference_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(inference_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup for inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_18812\\1467178467.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  simclr_model.load_state_dict(torch.load(full_model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (convnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=512, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simclr_model = SimCLR(hidden_dim=128, lr=5e-4, temperature=0.07, weight_decay=1e-4,max_epochs=245)\n",
    "simclr_model.load_state_dict(torch.load(full_model_path))\n",
    "simclr_model.to(device)\n",
    "simclr_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Simclr feature Encoder-decoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, day7_dir, day10_dir):\n",
    "        self.day7_files = {os.path.basename(file): os.path.join(day7_dir, file) for file in os.listdir(day7_dir) if file.endswith('.tiff')}\n",
    "        self.day10_files = {os.path.basename(file): os.path.join(day10_dir, file) for file in os.listdir(day10_dir) if file.endswith('.tiff')}\n",
    "      \n",
    "        # Ensure all day7 files have a corresponding day10 file\n",
    "        self.common_files = list(self.day7_files.keys())\n",
    "        assert set(self.common_files) <= set(self.day10_files.keys()), \"Mismatch between day7 and day10 filenames.\"\n",
    "        self.resize = Resize((96, 96))\n",
    "       \n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.common_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.common_files[idx]\n",
    "        day7_img_path = self.day7_files[filename]\n",
    "        day10_img_path = self.day10_files[filename]\n",
    "\n",
    "        # Load the images\n",
    "        day7_img = tiff.imread(day7_img_path)\n",
    "        day10_img = tiff.imread(day10_img_path)\n",
    "\n",
    "        # Ensure the images have 3 layers (channels)\n",
    "        if day7_img.shape[0] != 3:\n",
    "            raise ValueError(f\"Day7 image at {day7_img_path} does not have exactly 3 layers. Found shape: {day7_img.shape}.\")\n",
    "        if day10_img.shape[0] != 3:\n",
    "            raise ValueError(f\"Day10 image at {day10_img_path} does not have exactly 3 layers. Found shape: {day10_img.shape}.\")\n",
    "\n",
    "        # Normalize and convert both images\n",
    "        day7_img = day7_img.astype(np.float32) / 65535.0\n",
    "        day10_img = day10_img.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Convert to tensors\n",
    "        day7_img = torch.tensor(day7_img, dtype=torch.float32)\n",
    "        day10_img = torch.tensor(day10_img, dtype=torch.float32)\n",
    "\n",
    "        day7_img = self.resize(day7_img)\n",
    "        day10_img = self.resize(day10_img)\n",
    "\n",
    "        return day7_img, day10_img\n",
    "        #return day7_img, day10_img,day7_img_path,day10_img_path\n",
    "\n",
    "    \n",
    "# Specify paths for both day7 and day10 folders\n",
    "train_day7_dir = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\combined\\day7'\n",
    "train_day10_dir = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\combined\\day10'\n",
    "\n",
    "\n",
    "# Create the dataset\n",
    "train_dataset = ImageDataset(train_day7_dir, train_day10_dir) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 16\n",
    "# Define DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=0) #num_workers=os.cpu count() using cluster gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 130\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of images in the training dataset\n",
    "total_images_in_train = len(train_loader.dataset)\n",
    "print(f\"Total number of images: {total_images_in_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "  Input image (day7): torch.Size([16, 3, 96, 96])\n",
      "  Target image (day10): torch.Size([16, 3, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of both pairs and total number of images in one epoch\n",
    "for i, (input_image, target_image) in enumerate(train_loader):\n",
    "    print(f\"Batch {i}:\")\n",
    "    print(f\"  Input image (day7): {input_image.shape}\")\n",
    "    print(f\"  Target image (day10): {target_image.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve one dataset sample\n",
    "day7_img, day10_img, day7_img_path, day10_img_path = train_dataset[2]\n",
    "\n",
    "# Convert tensors to numpy arrays for visualization\n",
    "day7_img_np = day7_img.permute(1, 2, 0).numpy()\n",
    "day10_img_np = day10_img.permute(1, 2, 0).numpy()\n",
    "\n",
    "# Display images with paths\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Day7 Original\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(day7_img_np)\n",
    "plt.title(f\"Day7 Original\\n{day7_img_path}\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "# Day10 Original\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(day10_img_np)\n",
    "plt.title(f\"Day10 Original\\n{day10_img_path}\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Retrieve one dataset sample\n",
    "day7_img, day10_img, day7_img_path, day10_img_path = val_dataset[2]\n",
    "\n",
    "# Convert tensors to numpy arrays for visualization\n",
    "day7_img_np = day7_img.permute(1, 2, 0).numpy()\n",
    "day10_img_np = day10_img.permute(1, 2, 0).numpy()\n",
    "\n",
    "# Display images with paths\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Day7 Original\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.imshow(day7_img_np)\n",
    "plt.title(f\"Day7 Original\\n{day7_img_path}\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "# Day10 Original\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.imshow(day10_img_np)\n",
    "plt.title(f\"Day10 Original\\n{day10_img_path}\")\n",
    "plt.axis(\"off\")\n",
    "\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        \n",
    "        # Recursively find all .tiff and .tif files in subdirectories\n",
    "        self.image_files = []\n",
    "        for root, _, files in os.walk(image_dir):\n",
    "            for file in files:\n",
    "                if file.lower().endswith(('.tiff', '.tif')):\n",
    "                    self.image_files.append(os.path.join(root, file))\n",
    "        \n",
    "        # Debugging: Print the number of images found\n",
    "        print(f\"Found {len(self.image_files)} image files in directory: {image_dir}\")\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "        \n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        \n",
    "        # Convert to a torch tensor\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        \n",
    "        # Apply resize transform\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        return image\n",
    "\n",
    "\n",
    "# Directories for labeled data\n",
    "image_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\"\n",
    "dataset = ImageDataset(image_dir=image_dir)\n",
    "\n",
    "# Define DataLoaders\n",
    "batch_size = 16\n",
    "train_loader = DataLoader(dataset, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_data_features(model, dataloader):\n",
    "    # Prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    # Encode all paired images\n",
    "    day7_feats = []\n",
    "    day10_feats = []\n",
    "    \n",
    "    for batch_day7_imgs, batch_day10_imgs in tqdm(dataloader):\n",
    "        # Move images to the device\n",
    "        batch_day7_imgs = batch_day7_imgs.to(device)\n",
    "        batch_day10_imgs = batch_day10_imgs.to(device)\n",
    "\n",
    "        # Extract features for day7 and day10 images\n",
    "        batch_day7_feats = network(batch_day7_imgs)\n",
    "        batch_day10_feats = network(batch_day10_imgs)\n",
    "\n",
    "        print(f\"Day 7 Batch features shape: {batch_day7_feats.shape}\")\n",
    "        print(f\"Day 10 Batch features shape: {batch_day10_feats.shape}\")\n",
    "\n",
    "        # Collect features\n",
    "        day7_feats.append(batch_day7_feats.detach().cpu())\n",
    "        day10_feats.append(batch_day10_feats.detach().cpu())\n",
    "\n",
    "    # Concatenate features\n",
    "    day7_feats = torch.cat(day7_feats, dim=0)\n",
    "    day10_feats = torch.cat(day10_feats, dim=0)\n",
    "\n",
    "    print(f\"Day 7 Features shape after concatenation: {day7_feats.shape}\")\n",
    "    print(f\"Day 10 Features shape after concatenation: {day10_feats.shape}\")\n",
    "\n",
    "    return day7_feats, day10_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:01<00:12,  1.62s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:03<00:10,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:04<00:08,  1.45s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:05<00:07,  1.41s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:07<00:05,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [00:08<00:04,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [00:10<00:02,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [00:11<00:01,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([2, 512])\n",
      "Day 10 Batch features shape: torch.Size([2, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([130, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([130, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Assuming you have a pre-trained model and DataLoader\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "\n",
    "# Extract features from the training dataset\n",
    "train_day7_feats, train_day10_feats = prepare_data_features(simclr_model, train_loader)\n",
    "\n",
    "\n",
    "# Use the extracted features for your MLP model training\n",
    "# Example: MLP(input_dim=train_day7_feats.shape[1], output_dim=train_day10_feats.shape[1])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save training features\n",
    "torch.save(train_day7_feats, 'train_day7_feats.pt')\n",
    "torch.save(train_day10_feats, 'train_day10_feats.pt')\n",
    "\n",
    "print(\"Features saved successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import torchvision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_12176\\2277901324.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_day7_feats = torch.load('train_day7_feats.pt')\n",
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_12176\\2277901324.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  train_day10_feats = torch.load('train_day10_feats.pt')\n"
     ]
    }
   ],
   "source": [
    "# Load training features\n",
    "train_day7_feats = torch.load('train_day7_feats.pt')\n",
    "train_day10_feats = torch.load('train_day10_feats.pt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of training Day 7 features: 130\n",
      "Number of training Day 10 features: 130\n"
     ]
    }
   ],
   "source": [
    "# Print lengths of feature tensors\n",
    "print(f\"Number of training Day 7 features: {len(train_day7_feats)}\")\n",
    "print(f\"Number of training Day 10 features: {len(train_day10_feats)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of training Day 7 features: torch.Size([130, 512])\n",
      "Shape of training Day 10 features: torch.Size([130, 512])\n"
     ]
    }
   ],
   "source": [
    "# Print shapes of feature tensors\n",
    "print(f\"Shape of training Day 7 features: {train_day7_feats.shape}\")\n",
    "print(f\"Shape of training Day 10 features: {train_day10_feats.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeaturePredictor(nn.Module):\n",
    "    def __init__(self, input_size=512, output_size=512):\n",
    "        super(FeaturePredictor, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeaturePredictor()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "optimizer_class = torch.optim.Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait after the last validation loss improvement.\n",
    "            delta (float): Minimum change in the validation loss to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.no_improvement_epochs = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.no_improvement_epochs = 0\n",
    "        else:\n",
    "            self.no_improvement_epochs += 1\n",
    "            if self.no_improvement_epochs >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "\n",
    "def cross_validate_with_early_stopping(\n",
    "    model_class, dataset, criterion, optimizer_class, num_epochs=50, n_splits=5, patience=10, device='cuda'\n",
    "):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    histories = []\n",
    "    best_models = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "        # Create subsets for this fold\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "        # Initialize the model, optimizer, and early stopping for this fold\n",
    "        model = model_class().to(device)\n",
    "        optimizer = optimizer_class(model.parameters(), lr=1e-4)\n",
    "        early_stopping = EarlyStopping(patience=patience)\n",
    "\n",
    "        # Training and validation loop\n",
    "        history = {'train_loss': [], 'val_loss': []}\n",
    "        for epoch in range(num_epochs):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            for batch_inputs, batch_targets in train_loader:\n",
    "                batch_inputs, batch_targets = batch_inputs.to(device), batch_targets.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(batch_inputs)\n",
    "                loss = criterion(outputs, batch_targets)\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                # Backward pass and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            history['train_loss'].append(train_loss)\n",
    "\n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for batch_inputs, batch_targets in val_loader:\n",
    "                    batch_inputs, batch_targets = batch_inputs.to(device), batch_targets.to(device)\n",
    "                    outputs = model(batch_inputs)\n",
    "                    loss = criterion(outputs, batch_targets)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            history['val_loss'].append(val_loss)\n",
    "\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}] Fold {fold + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "            # Check early stopping\n",
    "            early_stopping(val_loss)\n",
    "            if early_stopping.early_stop:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} for fold {fold + 1}\")\n",
    "                break\n",
    "\n",
    "        # Save the best model for this fold\n",
    "        best_models.append(model.state_dict())\n",
    "        histories.append(history)\n",
    "\n",
    "    return histories, best_models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch [1/100] Fold 1, Train Loss: 2.4670, Val Loss: 2.4445\n",
      "Epoch [2/100] Fold 1, Train Loss: 2.4049, Val Loss: 2.4387\n",
      "Epoch [3/100] Fold 1, Train Loss: 2.4142, Val Loss: 2.4329\n",
      "Epoch [4/100] Fold 1, Train Loss: 2.4031, Val Loss: 2.4270\n",
      "Epoch [5/100] Fold 1, Train Loss: 2.4178, Val Loss: 2.4209\n",
      "Epoch [6/100] Fold 1, Train Loss: 2.3656, Val Loss: 2.4144\n",
      "Epoch [7/100] Fold 1, Train Loss: 2.3861, Val Loss: 2.4074\n",
      "Epoch [8/100] Fold 1, Train Loss: 2.4429, Val Loss: 2.4000\n",
      "Epoch [9/100] Fold 1, Train Loss: 2.3115, Val Loss: 2.3919\n",
      "Epoch [10/100] Fold 1, Train Loss: 2.3640, Val Loss: 2.3830\n",
      "Epoch [11/100] Fold 1, Train Loss: 2.3051, Val Loss: 2.3733\n",
      "Epoch [12/100] Fold 1, Train Loss: 2.3076, Val Loss: 2.3627\n",
      "Epoch [13/100] Fold 1, Train Loss: 2.4299, Val Loss: 2.3510\n",
      "Epoch [14/100] Fold 1, Train Loss: 2.3437, Val Loss: 2.3378\n",
      "Epoch [15/100] Fold 1, Train Loss: 2.2752, Val Loss: 2.3230\n",
      "Epoch [16/100] Fold 1, Train Loss: 2.3303, Val Loss: 2.3057\n",
      "Epoch [17/100] Fold 1, Train Loss: 2.2707, Val Loss: 2.2848\n",
      "Epoch [18/100] Fold 1, Train Loss: 2.3047, Val Loss: 2.2582\n",
      "Epoch [19/100] Fold 1, Train Loss: 2.1716, Val Loss: 2.2230\n",
      "Epoch [20/100] Fold 1, Train Loss: 2.1715, Val Loss: 2.1737\n",
      "Epoch [21/100] Fold 1, Train Loss: 2.1669, Val Loss: 2.1049\n",
      "Epoch [22/100] Fold 1, Train Loss: 2.0703, Val Loss: 2.0091\n",
      "Epoch [23/100] Fold 1, Train Loss: 1.9112, Val Loss: 1.8810\n",
      "Epoch [24/100] Fold 1, Train Loss: 1.7966, Val Loss: 1.7244\n",
      "Epoch [25/100] Fold 1, Train Loss: 1.6637, Val Loss: 1.5658\n",
      "Epoch [26/100] Fold 1, Train Loss: 1.4902, Val Loss: 1.4738\n",
      "Epoch [27/100] Fold 1, Train Loss: 1.4715, Val Loss: 1.4617\n",
      "Epoch [28/100] Fold 1, Train Loss: 1.4571, Val Loss: 1.4034\n",
      "Epoch [29/100] Fold 1, Train Loss: 1.3690, Val Loss: 1.3487\n",
      "Epoch [30/100] Fold 1, Train Loss: 1.3508, Val Loss: 1.3295\n",
      "Epoch [31/100] Fold 1, Train Loss: 1.3078, Val Loss: 1.3089\n",
      "Epoch [32/100] Fold 1, Train Loss: 1.2393, Val Loss: 1.2840\n",
      "Epoch [33/100] Fold 1, Train Loss: 1.2749, Val Loss: 1.2699\n",
      "Epoch [34/100] Fold 1, Train Loss: 1.2636, Val Loss: 1.2610\n",
      "Epoch [35/100] Fold 1, Train Loss: 1.2460, Val Loss: 1.2532\n",
      "Epoch [36/100] Fold 1, Train Loss: 1.2579, Val Loss: 1.2480\n",
      "Epoch [37/100] Fold 1, Train Loss: 1.1946, Val Loss: 1.2436\n",
      "Epoch [38/100] Fold 1, Train Loss: 1.2136, Val Loss: 1.2406\n",
      "Epoch [39/100] Fold 1, Train Loss: 1.2465, Val Loss: 1.2384\n",
      "Epoch [40/100] Fold 1, Train Loss: 1.2190, Val Loss: 1.2366\n",
      "Epoch [41/100] Fold 1, Train Loss: 1.2161, Val Loss: 1.2356\n",
      "Epoch [42/100] Fold 1, Train Loss: 1.2189, Val Loss: 1.2353\n",
      "Epoch [43/100] Fold 1, Train Loss: 1.2038, Val Loss: 1.2347\n",
      "Epoch [44/100] Fold 1, Train Loss: 1.1742, Val Loss: 1.2351\n",
      "Epoch [45/100] Fold 1, Train Loss: 1.2057, Val Loss: 1.2352\n",
      "Epoch [46/100] Fold 1, Train Loss: 1.1710, Val Loss: 1.2343\n",
      "Epoch [47/100] Fold 1, Train Loss: 1.2050, Val Loss: 1.2340\n",
      "Epoch [48/100] Fold 1, Train Loss: 1.2643, Val Loss: 1.2337\n",
      "Epoch [49/100] Fold 1, Train Loss: 1.2124, Val Loss: 1.2324\n",
      "Epoch [50/100] Fold 1, Train Loss: 1.2425, Val Loss: 1.2312\n",
      "Epoch [51/100] Fold 1, Train Loss: 1.1802, Val Loss: 1.2301\n",
      "Epoch [52/100] Fold 1, Train Loss: 1.2372, Val Loss: 1.2289\n",
      "Epoch [53/100] Fold 1, Train Loss: 1.2177, Val Loss: 1.2278\n",
      "Epoch [54/100] Fold 1, Train Loss: 1.1970, Val Loss: 1.2276\n",
      "Epoch [55/100] Fold 1, Train Loss: 1.2099, Val Loss: 1.2270\n",
      "Epoch [56/100] Fold 1, Train Loss: 1.2001, Val Loss: 1.2268\n",
      "Epoch [57/100] Fold 1, Train Loss: 1.2361, Val Loss: 1.2266\n",
      "Epoch [58/100] Fold 1, Train Loss: 1.1883, Val Loss: 1.2262\n",
      "Epoch [59/100] Fold 1, Train Loss: 1.1677, Val Loss: 1.2265\n",
      "Epoch [60/100] Fold 1, Train Loss: 1.1823, Val Loss: 1.2268\n",
      "Epoch [61/100] Fold 1, Train Loss: 1.2122, Val Loss: 1.2264\n",
      "Epoch [62/100] Fold 1, Train Loss: 1.2051, Val Loss: 1.2259\n",
      "Epoch [63/100] Fold 1, Train Loss: 1.2280, Val Loss: 1.2262\n",
      "Epoch [64/100] Fold 1, Train Loss: 1.1963, Val Loss: 1.2268\n",
      "Epoch [65/100] Fold 1, Train Loss: 1.1919, Val Loss: 1.2270\n",
      "Epoch [66/100] Fold 1, Train Loss: 1.1810, Val Loss: 1.2272\n",
      "Epoch [67/100] Fold 1, Train Loss: 1.2081, Val Loss: 1.2263\n",
      "Epoch [68/100] Fold 1, Train Loss: 1.1783, Val Loss: 1.2247\n",
      "Epoch [69/100] Fold 1, Train Loss: 1.1986, Val Loss: 1.2236\n",
      "Epoch [70/100] Fold 1, Train Loss: 1.1715, Val Loss: 1.2228\n",
      "Epoch [71/100] Fold 1, Train Loss: 1.2197, Val Loss: 1.2225\n",
      "Epoch [72/100] Fold 1, Train Loss: 1.1984, Val Loss: 1.2221\n",
      "Epoch [73/100] Fold 1, Train Loss: 1.1842, Val Loss: 1.2219\n",
      "Epoch [74/100] Fold 1, Train Loss: 1.1947, Val Loss: 1.2217\n",
      "Epoch [75/100] Fold 1, Train Loss: 1.2420, Val Loss: 1.2218\n",
      "Epoch [76/100] Fold 1, Train Loss: 1.1789, Val Loss: 1.2216\n",
      "Epoch [77/100] Fold 1, Train Loss: 1.1727, Val Loss: 1.2215\n",
      "Epoch [78/100] Fold 1, Train Loss: 1.2350, Val Loss: 1.2213\n",
      "Epoch [79/100] Fold 1, Train Loss: 1.2056, Val Loss: 1.2211\n",
      "Epoch [80/100] Fold 1, Train Loss: 1.1777, Val Loss: 1.2206\n",
      "Epoch [81/100] Fold 1, Train Loss: 1.2179, Val Loss: 1.2200\n",
      "Epoch [82/100] Fold 1, Train Loss: 1.2211, Val Loss: 1.2194\n",
      "Epoch [83/100] Fold 1, Train Loss: 1.2017, Val Loss: 1.2190\n",
      "Epoch [84/100] Fold 1, Train Loss: 1.2048, Val Loss: 1.2185\n",
      "Epoch [85/100] Fold 1, Train Loss: 1.1958, Val Loss: 1.2187\n",
      "Epoch [86/100] Fold 1, Train Loss: 1.2200, Val Loss: 1.2188\n",
      "Epoch [87/100] Fold 1, Train Loss: 1.2132, Val Loss: 1.2193\n",
      "Epoch [88/100] Fold 1, Train Loss: 1.2224, Val Loss: 1.2198\n",
      "Epoch [89/100] Fold 1, Train Loss: 1.1541, Val Loss: 1.2193\n",
      "Epoch [90/100] Fold 1, Train Loss: 1.1621, Val Loss: 1.2190\n",
      "Epoch [91/100] Fold 1, Train Loss: 1.1999, Val Loss: 1.2193\n",
      "Epoch [92/100] Fold 1, Train Loss: 1.1906, Val Loss: 1.2192\n",
      "Epoch [93/100] Fold 1, Train Loss: 1.2139, Val Loss: 1.2188\n",
      "Epoch [94/100] Fold 1, Train Loss: 1.2622, Val Loss: 1.2193\n",
      "Early stopping at epoch 94 for fold 1\n",
      "Fold 2/5\n",
      "Epoch [1/100] Fold 2, Train Loss: 2.3907, Val Loss: 2.5420\n",
      "Epoch [2/100] Fold 2, Train Loss: 2.3474, Val Loss: 2.5357\n",
      "Epoch [3/100] Fold 2, Train Loss: 2.3661, Val Loss: 2.5293\n",
      "Epoch [4/100] Fold 2, Train Loss: 2.4065, Val Loss: 2.5227\n",
      "Epoch [5/100] Fold 2, Train Loss: 2.3063, Val Loss: 2.5157\n",
      "Epoch [6/100] Fold 2, Train Loss: 2.3680, Val Loss: 2.5083\n",
      "Epoch [7/100] Fold 2, Train Loss: 2.2944, Val Loss: 2.5003\n",
      "Epoch [8/100] Fold 2, Train Loss: 2.3561, Val Loss: 2.4917\n",
      "Epoch [9/100] Fold 2, Train Loss: 2.3581, Val Loss: 2.4823\n",
      "Epoch [10/100] Fold 2, Train Loss: 2.3492, Val Loss: 2.4720\n",
      "Epoch [11/100] Fold 2, Train Loss: 2.4053, Val Loss: 2.4607\n",
      "Epoch [12/100] Fold 2, Train Loss: 2.4321, Val Loss: 2.4481\n",
      "Epoch [13/100] Fold 2, Train Loss: 2.2653, Val Loss: 2.4342\n",
      "Epoch [14/100] Fold 2, Train Loss: 2.3319, Val Loss: 2.4185\n",
      "Epoch [15/100] Fold 2, Train Loss: 2.3186, Val Loss: 2.4009\n",
      "Epoch [16/100] Fold 2, Train Loss: 2.2605, Val Loss: 2.3808\n",
      "Epoch [17/100] Fold 2, Train Loss: 2.3378, Val Loss: 2.3577\n",
      "Epoch [18/100] Fold 2, Train Loss: 2.2269, Val Loss: 2.3308\n",
      "Epoch [19/100] Fold 2, Train Loss: 2.1181, Val Loss: 2.2992\n",
      "Epoch [20/100] Fold 2, Train Loss: 2.0998, Val Loss: 2.2617\n",
      "Epoch [21/100] Fold 2, Train Loss: 2.1851, Val Loss: 2.2152\n",
      "Epoch [22/100] Fold 2, Train Loss: 2.0381, Val Loss: 2.1559\n",
      "Epoch [23/100] Fold 2, Train Loss: 2.0041, Val Loss: 2.0798\n",
      "Epoch [24/100] Fold 2, Train Loss: 1.9440, Val Loss: 1.9826\n",
      "Epoch [25/100] Fold 2, Train Loss: 1.7902, Val Loss: 1.8627\n",
      "Epoch [26/100] Fold 2, Train Loss: 1.6643, Val Loss: 1.7264\n",
      "Epoch [27/100] Fold 2, Train Loss: 1.5465, Val Loss: 1.5964\n",
      "Epoch [28/100] Fold 2, Train Loss: 1.3972, Val Loss: 1.5153\n",
      "Epoch [29/100] Fold 2, Train Loss: 1.3642, Val Loss: 1.4880\n",
      "Epoch [30/100] Fold 2, Train Loss: 1.4644, Val Loss: 1.4469\n",
      "Epoch [31/100] Fold 2, Train Loss: 1.3502, Val Loss: 1.4063\n",
      "Epoch [32/100] Fold 2, Train Loss: 1.2895, Val Loss: 1.3827\n",
      "Epoch [33/100] Fold 2, Train Loss: 1.2509, Val Loss: 1.3653\n",
      "Epoch [34/100] Fold 2, Train Loss: 1.2516, Val Loss: 1.3468\n",
      "Epoch [35/100] Fold 2, Train Loss: 1.2785, Val Loss: 1.3302\n",
      "Epoch [36/100] Fold 2, Train Loss: 1.2424, Val Loss: 1.3177\n",
      "Epoch [37/100] Fold 2, Train Loss: 1.2934, Val Loss: 1.3097\n",
      "Epoch [38/100] Fold 2, Train Loss: 1.2131, Val Loss: 1.3038\n",
      "Epoch [39/100] Fold 2, Train Loss: 1.2163, Val Loss: 1.2991\n",
      "Epoch [40/100] Fold 2, Train Loss: 1.2557, Val Loss: 1.2961\n",
      "Epoch [41/100] Fold 2, Train Loss: 1.2080, Val Loss: 1.2936\n",
      "Epoch [42/100] Fold 2, Train Loss: 1.2002, Val Loss: 1.2906\n",
      "Epoch [43/100] Fold 2, Train Loss: 1.1880, Val Loss: 1.2882\n",
      "Epoch [44/100] Fold 2, Train Loss: 1.2484, Val Loss: 1.2867\n",
      "Epoch [45/100] Fold 2, Train Loss: 1.2473, Val Loss: 1.2846\n",
      "Epoch [46/100] Fold 2, Train Loss: 1.1953, Val Loss: 1.2833\n",
      "Epoch [47/100] Fold 2, Train Loss: 1.2159, Val Loss: 1.2827\n",
      "Epoch [48/100] Fold 2, Train Loss: 1.1878, Val Loss: 1.2816\n",
      "Epoch [49/100] Fold 2, Train Loss: 1.1774, Val Loss: 1.2803\n",
      "Epoch [50/100] Fold 2, Train Loss: 1.2238, Val Loss: 1.2782\n",
      "Epoch [51/100] Fold 2, Train Loss: 1.1858, Val Loss: 1.2763\n",
      "Epoch [52/100] Fold 2, Train Loss: 1.1810, Val Loss: 1.2748\n",
      "Epoch [53/100] Fold 2, Train Loss: 1.2212, Val Loss: 1.2742\n",
      "Epoch [54/100] Fold 2, Train Loss: 1.2073, Val Loss: 1.2743\n",
      "Epoch [55/100] Fold 2, Train Loss: 1.1628, Val Loss: 1.2735\n",
      "Epoch [56/100] Fold 2, Train Loss: 1.1948, Val Loss: 1.2730\n",
      "Epoch [57/100] Fold 2, Train Loss: 1.2076, Val Loss: 1.2726\n",
      "Epoch [58/100] Fold 2, Train Loss: 1.1730, Val Loss: 1.2727\n",
      "Epoch [59/100] Fold 2, Train Loss: 1.2358, Val Loss: 1.2722\n",
      "Epoch [60/100] Fold 2, Train Loss: 1.2312, Val Loss: 1.2712\n",
      "Epoch [61/100] Fold 2, Train Loss: 1.1686, Val Loss: 1.2694\n",
      "Epoch [62/100] Fold 2, Train Loss: 1.2023, Val Loss: 1.2691\n",
      "Epoch [63/100] Fold 2, Train Loss: 1.1584, Val Loss: 1.2701\n",
      "Epoch [64/100] Fold 2, Train Loss: 1.2326, Val Loss: 1.2715\n",
      "Epoch [65/100] Fold 2, Train Loss: 1.1877, Val Loss: 1.2710\n",
      "Epoch [66/100] Fold 2, Train Loss: 1.1841, Val Loss: 1.2695\n",
      "Epoch [67/100] Fold 2, Train Loss: 1.1899, Val Loss: 1.2684\n",
      "Epoch [68/100] Fold 2, Train Loss: 1.2136, Val Loss: 1.2682\n",
      "Epoch [69/100] Fold 2, Train Loss: 1.2138, Val Loss: 1.2682\n",
      "Epoch [70/100] Fold 2, Train Loss: 1.1715, Val Loss: 1.2681\n",
      "Epoch [71/100] Fold 2, Train Loss: 1.1513, Val Loss: 1.2698\n",
      "Epoch [72/100] Fold 2, Train Loss: 1.2096, Val Loss: 1.2692\n",
      "Epoch [73/100] Fold 2, Train Loss: 1.1437, Val Loss: 1.2674\n",
      "Epoch [74/100] Fold 2, Train Loss: 1.1773, Val Loss: 1.2662\n",
      "Epoch [75/100] Fold 2, Train Loss: 1.1692, Val Loss: 1.2662\n",
      "Epoch [76/100] Fold 2, Train Loss: 1.2063, Val Loss: 1.2663\n",
      "Epoch [77/100] Fold 2, Train Loss: 1.1954, Val Loss: 1.2651\n",
      "Epoch [78/100] Fold 2, Train Loss: 1.1635, Val Loss: 1.2639\n",
      "Epoch [79/100] Fold 2, Train Loss: 1.1689, Val Loss: 1.2637\n",
      "Epoch [80/100] Fold 2, Train Loss: 1.1667, Val Loss: 1.2648\n",
      "Epoch [81/100] Fold 2, Train Loss: 1.2342, Val Loss: 1.2652\n",
      "Epoch [82/100] Fold 2, Train Loss: 1.1875, Val Loss: 1.2636\n",
      "Epoch [83/100] Fold 2, Train Loss: 1.1956, Val Loss: 1.2624\n",
      "Epoch [84/100] Fold 2, Train Loss: 1.1608, Val Loss: 1.2623\n",
      "Epoch [85/100] Fold 2, Train Loss: 1.2077, Val Loss: 1.2638\n",
      "Epoch [86/100] Fold 2, Train Loss: 1.2651, Val Loss: 1.2653\n",
      "Epoch [87/100] Fold 2, Train Loss: 1.1761, Val Loss: 1.2646\n",
      "Epoch [88/100] Fold 2, Train Loss: 1.2539, Val Loss: 1.2634\n",
      "Epoch [89/100] Fold 2, Train Loss: 1.1448, Val Loss: 1.2626\n",
      "Epoch [90/100] Fold 2, Train Loss: 1.1679, Val Loss: 1.2639\n",
      "Epoch [91/100] Fold 2, Train Loss: 1.2036, Val Loss: 1.2671\n",
      "Epoch [92/100] Fold 2, Train Loss: 1.2135, Val Loss: 1.2690\n",
      "Epoch [93/100] Fold 2, Train Loss: 1.1591, Val Loss: 1.2681\n",
      "Epoch [94/100] Fold 2, Train Loss: 1.2141, Val Loss: 1.2660\n",
      "Early stopping at epoch 94 for fold 2\n",
      "Fold 3/5\n",
      "Epoch [1/100] Fold 3, Train Loss: 2.3933, Val Loss: 2.4435\n",
      "Epoch [2/100] Fold 3, Train Loss: 2.4066, Val Loss: 2.4372\n",
      "Epoch [3/100] Fold 3, Train Loss: 2.3656, Val Loss: 2.4307\n",
      "Epoch [4/100] Fold 3, Train Loss: 2.4009, Val Loss: 2.4239\n",
      "Epoch [5/100] Fold 3, Train Loss: 2.3882, Val Loss: 2.4168\n",
      "Epoch [6/100] Fold 3, Train Loss: 2.3285, Val Loss: 2.4091\n",
      "Epoch [7/100] Fold 3, Train Loss: 2.3142, Val Loss: 2.4008\n",
      "Epoch [8/100] Fold 3, Train Loss: 2.3705, Val Loss: 2.3918\n",
      "Epoch [9/100] Fold 3, Train Loss: 2.4002, Val Loss: 2.3818\n",
      "Epoch [10/100] Fold 3, Train Loss: 2.4419, Val Loss: 2.3707\n",
      "Epoch [11/100] Fold 3, Train Loss: 2.3906, Val Loss: 2.3583\n",
      "Epoch [12/100] Fold 3, Train Loss: 2.3076, Val Loss: 2.3444\n",
      "Epoch [13/100] Fold 3, Train Loss: 2.2962, Val Loss: 2.3288\n",
      "Epoch [14/100] Fold 3, Train Loss: 2.2550, Val Loss: 2.3106\n",
      "Epoch [15/100] Fold 3, Train Loss: 2.2066, Val Loss: 2.2885\n",
      "Epoch [16/100] Fold 3, Train Loss: 2.2234, Val Loss: 2.2609\n",
      "Epoch [17/100] Fold 3, Train Loss: 2.1936, Val Loss: 2.2252\n",
      "Epoch [18/100] Fold 3, Train Loss: 2.1533, Val Loss: 2.1770\n",
      "Epoch [19/100] Fold 3, Train Loss: 2.1083, Val Loss: 2.1093\n",
      "Epoch [20/100] Fold 3, Train Loss: 1.9924, Val Loss: 2.0137\n",
      "Epoch [21/100] Fold 3, Train Loss: 1.9197, Val Loss: 1.8848\n",
      "Epoch [22/100] Fold 3, Train Loss: 1.8501, Val Loss: 1.7254\n",
      "Epoch [23/100] Fold 3, Train Loss: 1.6638, Val Loss: 1.5622\n",
      "Epoch [24/100] Fold 3, Train Loss: 1.4923, Val Loss: 1.4592\n",
      "Epoch [25/100] Fold 3, Train Loss: 1.4514, Val Loss: 1.4327\n",
      "Epoch [26/100] Fold 3, Train Loss: 1.4006, Val Loss: 1.3843\n",
      "Epoch [27/100] Fold 3, Train Loss: 1.3766, Val Loss: 1.3404\n",
      "Epoch [28/100] Fold 3, Train Loss: 1.3773, Val Loss: 1.3254\n",
      "Epoch [29/100] Fold 3, Train Loss: 1.2843, Val Loss: 1.3066\n",
      "Epoch [30/100] Fold 3, Train Loss: 1.2962, Val Loss: 1.2864\n",
      "Epoch [31/100] Fold 3, Train Loss: 1.2233, Val Loss: 1.2716\n",
      "Epoch [32/100] Fold 3, Train Loss: 1.2486, Val Loss: 1.2652\n",
      "Epoch [33/100] Fold 3, Train Loss: 1.2036, Val Loss: 1.2602\n",
      "Epoch [34/100] Fold 3, Train Loss: 1.2649, Val Loss: 1.2598\n",
      "Epoch [35/100] Fold 3, Train Loss: 1.2641, Val Loss: 1.2580\n",
      "Epoch [36/100] Fold 3, Train Loss: 1.1940, Val Loss: 1.2542\n",
      "Epoch [37/100] Fold 3, Train Loss: 1.2337, Val Loss: 1.2519\n",
      "Epoch [38/100] Fold 3, Train Loss: 1.1860, Val Loss: 1.2519\n",
      "Epoch [39/100] Fold 3, Train Loss: 1.1803, Val Loss: 1.2507\n",
      "Epoch [40/100] Fold 3, Train Loss: 1.1962, Val Loss: 1.2512\n",
      "Epoch [41/100] Fold 3, Train Loss: 1.2048, Val Loss: 1.2523\n",
      "Epoch [42/100] Fold 3, Train Loss: 1.1961, Val Loss: 1.2516\n",
      "Epoch [43/100] Fold 3, Train Loss: 1.1936, Val Loss: 1.2507\n",
      "Epoch [44/100] Fold 3, Train Loss: 1.2676, Val Loss: 1.2498\n",
      "Epoch [45/100] Fold 3, Train Loss: 1.2020, Val Loss: 1.2492\n",
      "Epoch [46/100] Fold 3, Train Loss: 1.2524, Val Loss: 1.2485\n",
      "Epoch [47/100] Fold 3, Train Loss: 1.1648, Val Loss: 1.2484\n",
      "Epoch [48/100] Fold 3, Train Loss: 1.2269, Val Loss: 1.2480\n",
      "Epoch [49/100] Fold 3, Train Loss: 1.2140, Val Loss: 1.2474\n",
      "Epoch [50/100] Fold 3, Train Loss: 1.2293, Val Loss: 1.2483\n",
      "Epoch [51/100] Fold 3, Train Loss: 1.1752, Val Loss: 1.2496\n",
      "Epoch [52/100] Fold 3, Train Loss: 1.2186, Val Loss: 1.2501\n",
      "Epoch [53/100] Fold 3, Train Loss: 1.2001, Val Loss: 1.2502\n",
      "Epoch [54/100] Fold 3, Train Loss: 1.2088, Val Loss: 1.2504\n",
      "Epoch [55/100] Fold 3, Train Loss: 1.1628, Val Loss: 1.2499\n",
      "Epoch [56/100] Fold 3, Train Loss: 1.2048, Val Loss: 1.2501\n",
      "Epoch [57/100] Fold 3, Train Loss: 1.2514, Val Loss: 1.2502\n",
      "Epoch [58/100] Fold 3, Train Loss: 1.1435, Val Loss: 1.2492\n",
      "Epoch [59/100] Fold 3, Train Loss: 1.1613, Val Loss: 1.2501\n",
      "Early stopping at epoch 59 for fold 3\n",
      "Fold 4/5\n",
      "Epoch [1/100] Fold 4, Train Loss: 2.4979, Val Loss: 2.4394\n",
      "Epoch [2/100] Fold 4, Train Loss: 2.4292, Val Loss: 2.4327\n",
      "Epoch [3/100] Fold 4, Train Loss: 2.4976, Val Loss: 2.4257\n",
      "Epoch [4/100] Fold 4, Train Loss: 2.4452, Val Loss: 2.4183\n",
      "Epoch [5/100] Fold 4, Train Loss: 2.3810, Val Loss: 2.4105\n",
      "Epoch [6/100] Fold 4, Train Loss: 2.4326, Val Loss: 2.4023\n",
      "Epoch [7/100] Fold 4, Train Loss: 2.3126, Val Loss: 2.3933\n",
      "Epoch [8/100] Fold 4, Train Loss: 2.2833, Val Loss: 2.3837\n",
      "Epoch [9/100] Fold 4, Train Loss: 2.3359, Val Loss: 2.3732\n",
      "Epoch [10/100] Fold 4, Train Loss: 2.2992, Val Loss: 2.3616\n",
      "Epoch [11/100] Fold 4, Train Loss: 2.3079, Val Loss: 2.3490\n",
      "Epoch [12/100] Fold 4, Train Loss: 2.4012, Val Loss: 2.3349\n",
      "Epoch [13/100] Fold 4, Train Loss: 2.2813, Val Loss: 2.3193\n",
      "Epoch [14/100] Fold 4, Train Loss: 2.2385, Val Loss: 2.3019\n",
      "Epoch [15/100] Fold 4, Train Loss: 2.2570, Val Loss: 2.2826\n",
      "Epoch [16/100] Fold 4, Train Loss: 2.1836, Val Loss: 2.2609\n",
      "Epoch [17/100] Fold 4, Train Loss: 2.1532, Val Loss: 2.2363\n",
      "Epoch [18/100] Fold 4, Train Loss: 2.1816, Val Loss: 2.2085\n",
      "Epoch [19/100] Fold 4, Train Loss: 2.1264, Val Loss: 2.1756\n",
      "Epoch [20/100] Fold 4, Train Loss: 2.0410, Val Loss: 2.1357\n",
      "Epoch [21/100] Fold 4, Train Loss: 2.0328, Val Loss: 2.0861\n",
      "Epoch [22/100] Fold 4, Train Loss: 2.0318, Val Loss: 2.0239\n",
      "Epoch [23/100] Fold 4, Train Loss: 1.9838, Val Loss: 1.9455\n",
      "Epoch [24/100] Fold 4, Train Loss: 1.9042, Val Loss: 1.8470\n",
      "Epoch [25/100] Fold 4, Train Loss: 1.7101, Val Loss: 1.7293\n",
      "Epoch [26/100] Fold 4, Train Loss: 1.6063, Val Loss: 1.6029\n",
      "Epoch [27/100] Fold 4, Train Loss: 1.5540, Val Loss: 1.4909\n",
      "Epoch [28/100] Fold 4, Train Loss: 1.4231, Val Loss: 1.4357\n",
      "Epoch [29/100] Fold 4, Train Loss: 1.3961, Val Loss: 1.4179\n",
      "Epoch [30/100] Fold 4, Train Loss: 1.4415, Val Loss: 1.3766\n",
      "Epoch [31/100] Fold 4, Train Loss: 1.3400, Val Loss: 1.3391\n",
      "Epoch [32/100] Fold 4, Train Loss: 1.2776, Val Loss: 1.3208\n",
      "Epoch [33/100] Fold 4, Train Loss: 1.3537, Val Loss: 1.3050\n",
      "Epoch [34/100] Fold 4, Train Loss: 1.3057, Val Loss: 1.2860\n",
      "Epoch [35/100] Fold 4, Train Loss: 1.2709, Val Loss: 1.2737\n",
      "Epoch [36/100] Fold 4, Train Loss: 1.2761, Val Loss: 1.2669\n",
      "Epoch [37/100] Fold 4, Train Loss: 1.2714, Val Loss: 1.2610\n",
      "Epoch [38/100] Fold 4, Train Loss: 1.2396, Val Loss: 1.2557\n",
      "Epoch [39/100] Fold 4, Train Loss: 1.2244, Val Loss: 1.2514\n",
      "Epoch [40/100] Fold 4, Train Loss: 1.2434, Val Loss: 1.2485\n",
      "Epoch [41/100] Fold 4, Train Loss: 1.2377, Val Loss: 1.2456\n",
      "Epoch [42/100] Fold 4, Train Loss: 1.2179, Val Loss: 1.2433\n",
      "Epoch [43/100] Fold 4, Train Loss: 1.2641, Val Loss: 1.2418\n",
      "Epoch [44/100] Fold 4, Train Loss: 1.2264, Val Loss: 1.2411\n",
      "Epoch [45/100] Fold 4, Train Loss: 1.2104, Val Loss: 1.2399\n",
      "Epoch [46/100] Fold 4, Train Loss: 1.2058, Val Loss: 1.2386\n",
      "Epoch [47/100] Fold 4, Train Loss: 1.2080, Val Loss: 1.2387\n",
      "Epoch [48/100] Fold 4, Train Loss: 1.2229, Val Loss: 1.2385\n",
      "Epoch [49/100] Fold 4, Train Loss: 1.1983, Val Loss: 1.2393\n",
      "Epoch [50/100] Fold 4, Train Loss: 1.2222, Val Loss: 1.2397\n",
      "Epoch [51/100] Fold 4, Train Loss: 1.1870, Val Loss: 1.2381\n",
      "Epoch [52/100] Fold 4, Train Loss: 1.2627, Val Loss: 1.2378\n",
      "Epoch [53/100] Fold 4, Train Loss: 1.1688, Val Loss: 1.2375\n",
      "Epoch [54/100] Fold 4, Train Loss: 1.2509, Val Loss: 1.2371\n",
      "Epoch [55/100] Fold 4, Train Loss: 1.2065, Val Loss: 1.2365\n",
      "Epoch [56/100] Fold 4, Train Loss: 1.1763, Val Loss: 1.2360\n",
      "Epoch [57/100] Fold 4, Train Loss: 1.1871, Val Loss: 1.2359\n",
      "Epoch [58/100] Fold 4, Train Loss: 1.2218, Val Loss: 1.2357\n",
      "Epoch [59/100] Fold 4, Train Loss: 1.1636, Val Loss: 1.2365\n",
      "Epoch [60/100] Fold 4, Train Loss: 1.2106, Val Loss: 1.2370\n",
      "Epoch [61/100] Fold 4, Train Loss: 1.2385, Val Loss: 1.2365\n",
      "Epoch [62/100] Fold 4, Train Loss: 1.2034, Val Loss: 1.2359\n",
      "Epoch [63/100] Fold 4, Train Loss: 1.1580, Val Loss: 1.2343\n",
      "Epoch [64/100] Fold 4, Train Loss: 1.2651, Val Loss: 1.2339\n",
      "Epoch [65/100] Fold 4, Train Loss: 1.2208, Val Loss: 1.2327\n",
      "Epoch [66/100] Fold 4, Train Loss: 1.1802, Val Loss: 1.2319\n",
      "Epoch [67/100] Fold 4, Train Loss: 1.1926, Val Loss: 1.2316\n",
      "Epoch [68/100] Fold 4, Train Loss: 1.1698, Val Loss: 1.2304\n",
      "Epoch [69/100] Fold 4, Train Loss: 1.2508, Val Loss: 1.2300\n",
      "Epoch [70/100] Fold 4, Train Loss: 1.1759, Val Loss: 1.2304\n",
      "Epoch [71/100] Fold 4, Train Loss: 1.2061, Val Loss: 1.2299\n",
      "Epoch [72/100] Fold 4, Train Loss: 1.2225, Val Loss: 1.2299\n",
      "Epoch [73/100] Fold 4, Train Loss: 1.2010, Val Loss: 1.2300\n",
      "Epoch [74/100] Fold 4, Train Loss: 1.2206, Val Loss: 1.2300\n",
      "Epoch [75/100] Fold 4, Train Loss: 1.2081, Val Loss: 1.2291\n",
      "Epoch [76/100] Fold 4, Train Loss: 1.2100, Val Loss: 1.2291\n",
      "Epoch [77/100] Fold 4, Train Loss: 1.1995, Val Loss: 1.2294\n",
      "Epoch [78/100] Fold 4, Train Loss: 1.2562, Val Loss: 1.2296\n",
      "Epoch [79/100] Fold 4, Train Loss: 1.1413, Val Loss: 1.2305\n",
      "Epoch [80/100] Fold 4, Train Loss: 1.1754, Val Loss: 1.2304\n",
      "Epoch [81/100] Fold 4, Train Loss: 1.1818, Val Loss: 1.2309\n",
      "Epoch [82/100] Fold 4, Train Loss: 1.1800, Val Loss: 1.2312\n",
      "Epoch [83/100] Fold 4, Train Loss: 1.2128, Val Loss: 1.2328\n",
      "Epoch [84/100] Fold 4, Train Loss: 1.2486, Val Loss: 1.2347\n",
      "Epoch [85/100] Fold 4, Train Loss: 1.1828, Val Loss: 1.2362\n",
      "Epoch [86/100] Fold 4, Train Loss: 1.2286, Val Loss: 1.2363\n",
      "Early stopping at epoch 86 for fold 4\n",
      "Fold 5/5\n",
      "Epoch [1/100] Fold 5, Train Loss: 2.5782, Val Loss: 2.2503\n",
      "Epoch [2/100] Fold 5, Train Loss: 2.4475, Val Loss: 2.2444\n",
      "Epoch [3/100] Fold 5, Train Loss: 2.3662, Val Loss: 2.2385\n",
      "Epoch [4/100] Fold 5, Train Loss: 2.5636, Val Loss: 2.2324\n",
      "Epoch [5/100] Fold 5, Train Loss: 2.4254, Val Loss: 2.2260\n",
      "Epoch [6/100] Fold 5, Train Loss: 2.4609, Val Loss: 2.2192\n",
      "Epoch [7/100] Fold 5, Train Loss: 2.4832, Val Loss: 2.2118\n",
      "Epoch [8/100] Fold 5, Train Loss: 2.4303, Val Loss: 2.2038\n",
      "Epoch [9/100] Fold 5, Train Loss: 2.4694, Val Loss: 2.1950\n",
      "Epoch [10/100] Fold 5, Train Loss: 2.3923, Val Loss: 2.1853\n",
      "Epoch [11/100] Fold 5, Train Loss: 2.4047, Val Loss: 2.1746\n",
      "Epoch [12/100] Fold 5, Train Loss: 2.3922, Val Loss: 2.1628\n",
      "Epoch [13/100] Fold 5, Train Loss: 2.2657, Val Loss: 2.1496\n",
      "Epoch [14/100] Fold 5, Train Loss: 2.3049, Val Loss: 2.1350\n",
      "Epoch [15/100] Fold 5, Train Loss: 2.3708, Val Loss: 2.1186\n",
      "Epoch [16/100] Fold 5, Train Loss: 2.2834, Val Loss: 2.0998\n",
      "Epoch [17/100] Fold 5, Train Loss: 2.2504, Val Loss: 2.0780\n",
      "Epoch [18/100] Fold 5, Train Loss: 2.2154, Val Loss: 2.0519\n",
      "Epoch [19/100] Fold 5, Train Loss: 2.1961, Val Loss: 2.0199\n",
      "Epoch [20/100] Fold 5, Train Loss: 2.1633, Val Loss: 1.9796\n",
      "Epoch [21/100] Fold 5, Train Loss: 2.1267, Val Loss: 1.9279\n",
      "Epoch [22/100] Fold 5, Train Loss: 2.0602, Val Loss: 1.8598\n",
      "Epoch [23/100] Fold 5, Train Loss: 1.9857, Val Loss: 1.7698\n",
      "Epoch [24/100] Fold 5, Train Loss: 1.9372, Val Loss: 1.6560\n",
      "Epoch [25/100] Fold 5, Train Loss: 1.8137, Val Loss: 1.5279\n",
      "Epoch [26/100] Fold 5, Train Loss: 1.6048, Val Loss: 1.4198\n",
      "Epoch [27/100] Fold 5, Train Loss: 1.5106, Val Loss: 1.3886\n",
      "Epoch [28/100] Fold 5, Train Loss: 1.4286, Val Loss: 1.4079\n",
      "Epoch [29/100] Fold 5, Train Loss: 1.4301, Val Loss: 1.3462\n",
      "Epoch [30/100] Fold 5, Train Loss: 1.3607, Val Loss: 1.2768\n",
      "Epoch [31/100] Fold 5, Train Loss: 1.3536, Val Loss: 1.2409\n",
      "Epoch [32/100] Fold 5, Train Loss: 1.3153, Val Loss: 1.2202\n",
      "Epoch [33/100] Fold 5, Train Loss: 1.2820, Val Loss: 1.2050\n",
      "Epoch [34/100] Fold 5, Train Loss: 1.2960, Val Loss: 1.1991\n",
      "Epoch [35/100] Fold 5, Train Loss: 1.3083, Val Loss: 1.1981\n",
      "Epoch [36/100] Fold 5, Train Loss: 1.3159, Val Loss: 1.1929\n",
      "Epoch [37/100] Fold 5, Train Loss: 1.2363, Val Loss: 1.1845\n",
      "Epoch [38/100] Fold 5, Train Loss: 1.2312, Val Loss: 1.1746\n",
      "Epoch [39/100] Fold 5, Train Loss: 1.2822, Val Loss: 1.1688\n",
      "Epoch [40/100] Fold 5, Train Loss: 1.2418, Val Loss: 1.1673\n",
      "Epoch [41/100] Fold 5, Train Loss: 1.2775, Val Loss: 1.1673\n",
      "Epoch [42/100] Fold 5, Train Loss: 1.2622, Val Loss: 1.1693\n",
      "Epoch [43/100] Fold 5, Train Loss: 1.2118, Val Loss: 1.1721\n",
      "Epoch [44/100] Fold 5, Train Loss: 1.2062, Val Loss: 1.1711\n",
      "Epoch [45/100] Fold 5, Train Loss: 1.2126, Val Loss: 1.1681\n",
      "Epoch [46/100] Fold 5, Train Loss: 1.2413, Val Loss: 1.1652\n",
      "Epoch [47/100] Fold 5, Train Loss: 1.2350, Val Loss: 1.1634\n",
      "Epoch [48/100] Fold 5, Train Loss: 1.2394, Val Loss: 1.1637\n",
      "Epoch [49/100] Fold 5, Train Loss: 1.2355, Val Loss: 1.1639\n",
      "Epoch [50/100] Fold 5, Train Loss: 1.2433, Val Loss: 1.1606\n",
      "Epoch [51/100] Fold 5, Train Loss: 1.2283, Val Loss: 1.1594\n",
      "Epoch [52/100] Fold 5, Train Loss: 1.2614, Val Loss: 1.1618\n",
      "Epoch [53/100] Fold 5, Train Loss: 1.2166, Val Loss: 1.1655\n",
      "Epoch [54/100] Fold 5, Train Loss: 1.1844, Val Loss: 1.1667\n",
      "Epoch [55/100] Fold 5, Train Loss: 1.2932, Val Loss: 1.1634\n",
      "Epoch [56/100] Fold 5, Train Loss: 1.2107, Val Loss: 1.1638\n",
      "Epoch [57/100] Fold 5, Train Loss: 1.2366, Val Loss: 1.1649\n",
      "Epoch [58/100] Fold 5, Train Loss: 1.1742, Val Loss: 1.1627\n",
      "Epoch [59/100] Fold 5, Train Loss: 1.2099, Val Loss: 1.1612\n",
      "Epoch [60/100] Fold 5, Train Loss: 1.2215, Val Loss: 1.1614\n",
      "Epoch [61/100] Fold 5, Train Loss: 1.2413, Val Loss: 1.1627\n",
      "Early stopping at epoch 61 for fold 5\n"
     ]
    }
   ],
   "source": [
    "# Example usage\n",
    "dataset = TensorDataset(train_day7_feats, train_day10_feats)\n",
    "\n",
    "cv_histories, best_models = cross_validate_with_early_stopping(\n",
    "    model_class=FeaturePredictor,\n",
    "    dataset=dataset,\n",
    "    criterion=nn.MSELoss(),\n",
    "    optimizer_class=torch.optim.Adam,\n",
    "    num_epochs=100,\n",
    "    patience=10\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def train_and_evaluate(\n",
    "    model, \n",
    "    train_loader, \n",
    "    val_loader, \n",
    "    criterion, \n",
    "    optimizer, \n",
    "    num_epochs=50, \n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "):\n",
    "\n",
    "    model = model.to(device)\n",
    "    history = {'train_loss': [], 'val_loss': []}\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        # Training phase\n",
    "        model.train()\n",
    "        train_loss = 0.0\n",
    "        for batch_inputs, batch_targets in train_loader:\n",
    "            # Move data to the appropriate device\n",
    "            batch_inputs, batch_targets = batch_inputs.to(device), batch_targets.to(device)\n",
    "            \n",
    "            # Forward pass\n",
    "            outputs = model(batch_inputs)\n",
    "            loss = criterion(outputs, batch_targets)\n",
    "            train_loss += loss.item()\n",
    "            \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        \n",
    "        train_loss /= len(train_loader)\n",
    "        history['train_loss'].append(train_loss)\n",
    "        \n",
    "        # Validation phase\n",
    "        model.eval()\n",
    "        val_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            for batch_inputs, batch_targets in val_loader:\n",
    "                # Move data to the appropriate device\n",
    "                batch_inputs, batch_targets = batch_inputs.to(device), batch_targets.to(device)\n",
    "                \n",
    "                # Forward pass\n",
    "                outputs = model(batch_inputs)\n",
    "                loss = criterion(outputs, batch_targets)\n",
    "                val_loss += loss.item()\n",
    "        \n",
    "        val_loss /= len(val_loader)\n",
    "        history['val_loss'].append(val_loss)\n",
    "        \n",
    "        # Print epoch stats\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n",
    "    \n",
    "    return history\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "def cross_validate_and_train(\n",
    "    model_class,  # Pass the class, not an instance\n",
    "    dataset,\n",
    "    criterion,\n",
    "    optimizer_class,\n",
    "    num_epochs=50,\n",
    "    n_splits=5,\n",
    "    device='cuda' if torch.cuda.is_available() else 'cpu'\n",
    "):\n",
    "    \"\"\"\n",
    "    Perform cross-validation and train the model on each fold.\n",
    "    \n",
    "    Args:\n",
    "        model_class: The class of the model to train (not an instance).\n",
    "        dataset: The dataset containing features and targets.\n",
    "        criterion: The loss function.\n",
    "        optimizer_class: The optimizer class (e.g., torch.optim.Adam).\n",
    "        num_epochs: Number of epochs for each fold.\n",
    "        n_splits: Number of cross-validation splits.\n",
    "        device: Device to use for training ('cuda' or 'cpu').\n",
    "        \n",
    "    Returns:\n",
    "        list: A list containing the history (losses) for each fold.\n",
    "    \"\"\"\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    histories = []\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "        \n",
    "        # Create subsets for this fold\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "        \n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "        \n",
    "        # Initialize the model and optimizer for this fold\n",
    "        model = model_class().to(device)\n",
    "        optimizer = optimizer_class(model.parameters(), lr=1e-4)\n",
    "        \n",
    "        # Train and evaluate for this fold\n",
    "        history = train_and_evaluate(\n",
    "            model=model,\n",
    "            train_loader=train_loader,\n",
    "            val_loader=val_loader,\n",
    "            criterion=criterion,\n",
    "            optimizer=optimizer,\n",
    "            num_epochs=num_epochs,\n",
    "            device=device\n",
    "        )\n",
    "        \n",
    "        histories.append(history)\n",
    "    \n",
    "    return histories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset = TensorDataset(train_day7_feats, train_day10_feats)\n",
    "\n",
    "# Perform cross-validation\n",
    "cv_histories = cross_validate_and_train(\n",
    "    model_class=FeaturePredictor,  # Pass the model class\n",
    "    dataset=dataset,\n",
    "    criterion=criterion,\n",
    "    optimizer_class=torch.optim.Adam,\n",
    "    num_epochs=1000,\n",
    "    n_splits=5\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_curves(cv_histories, num_epochs):\n",
    "    \"\"\"\n",
    "    Plot training and validation loss curves for each fold.\n",
    "    \n",
    "    Args:\n",
    "        cv_histories (list): List of loss histories for each fold.\n",
    "        num_epochs (int): Number of epochs.\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 6))\n",
    "\n",
    "    for fold, history in enumerate(cv_histories):\n",
    "        epochs = range(1, num_epochs + 1)\n",
    "        plt.plot(epochs, history['train_loss'], label=f'Fold {fold + 1} Train Loss')\n",
    "        plt.plot(epochs, history['val_loss'], label=f'Fold {fold + 1} Val Loss', linestyle='--')\n",
    "\n",
    "    plt.title('Training and Validation Loss per Fold')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_loss_curves(cv_histories, num_epochs=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_loss_curves_separately(cv_histories, num_epochs):\n",
    "    \"\"\"\n",
    "    Plot training and validation loss curves for each fold in separate figures.\n",
    "    \n",
    "    Args:\n",
    "        cv_histories (list): List of loss histories for each fold.\n",
    "        num_epochs (int): Number of epochs.\n",
    "    \"\"\"\n",
    "    # Plot Training Loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for fold, history in enumerate(cv_histories):\n",
    "        epochs = range(1, num_epochs + 1)\n",
    "        plt.plot(epochs, history['train_loss'], label=f'Fold {fold + 1} Train Loss')\n",
    "    plt.title('Training Loss per Fold')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Validation Loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for fold, history in enumerate(cv_histories):\n",
    "        epochs = range(1, num_epochs + 1)\n",
    "        plt.plot(epochs, history['val_loss'], label=f'Fold {fold + 1} Val Loss', linestyle='--')\n",
    "    plt.title('Validation Loss per Fold')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "# Example usage\n",
    "plot_loss_curves_separately(cv_histories, num_epochs=1000)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Average the training and validation losses across folds\n",
    "avg_train_loss = np.mean([history['train_loss'][-1] for history in cv_histories])\n",
    "avg_val_loss = np.mean([history['val_loss'][-1] for history in cv_histories])\n",
    "\n",
    "print(f\"Average Training Loss: {avg_train_loss:.4f}\")\n",
    "print(f\"Average Validation Loss: {avg_val_loss:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
