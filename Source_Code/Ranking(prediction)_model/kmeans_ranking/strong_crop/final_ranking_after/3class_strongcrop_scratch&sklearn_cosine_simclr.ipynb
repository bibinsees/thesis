{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from collections import Counter\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#torch.save(simclr_model.state_dict(), 'model_weights.pth')\n",
    "full_model_path =  r'C:\\Users\\k54739\\saved_model\\simclr_strongcrop_245.pth'\n",
    "#torch.save(simclr_model, full_model_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay,max_epochs):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        # Load the pretrained ResNet-18 model\n",
    "        self.convnet = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "        \n",
    "        # Modify the fully connected layer\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4 * hidden_dim),  # Linear layer with 4*hidden_dim output\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * hidden_dim, 20)  # Output layer with hidden_dim output\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.AdamW(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        self.lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=max_epochs, eta_min=lr / 50)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convnet(x)\n",
    "\n",
    "    def info_nce_loss(self, imgs1, imgs2, device):\n",
    "\n",
    "        imgs = torch.cat((imgs1, imgs2), dim=0)  # Concatenate along the batch dimension\n",
    "        imgs = imgs.to(device)  # Move images to the device\n",
    "\n",
    "        # Encode all images\n",
    "        feats = self.forward(imgs)\n",
    "    \n",
    "        # Calculate cosine similarity\n",
    "        cos_sim = nn.functional.cosine_similarity(feats[:, None, :], feats[None, :, :], dim=-1)\n",
    "    \n",
    "        # Mask out cosine similarity to itself\n",
    "        self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "        cos_sim.masked_fill_(self_mask, -9e15)\n",
    "    \n",
    "        # Find positive example -> batch_size//2 away from the original example\n",
    "        pos_mask = self_mask.roll(shifts=cos_sim.shape[0] // 2, dims=0)\n",
    "    \n",
    "        # Normalize similarity scores by temperature\n",
    "        cos_sim = cos_sim / self.temperature\n",
    "\n",
    "        # InfoNCE loss\n",
    "        nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "        nll = nll.mean()\n",
    "\n",
    "        # Accuracy calculations\n",
    "        # Create a combination of positive and negative similarities for ranking\n",
    "        comb_sim = torch.cat([cos_sim[pos_mask][:, None],  # Positive example in first position\n",
    "                          cos_sim.masked_fill(pos_mask, -9e15)], dim=-1)\n",
    "    \n",
    "        # Sort and get the ranking position of the positive example\n",
    "        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
    "    \n",
    "        # Compute accuracy metrics\n",
    "        top1_acc = (sim_argsort == 0).float().mean()  # Top-1 accuracy\n",
    "        top5_acc = (sim_argsort < 5).float().mean()   # Top-5 accuracy\n",
    "        mean_pos = 1 + sim_argsort.float().mean()     # Mean position of the positive example\n",
    "\n",
    "        return nll, top1_acc, top5_acc, mean_pos\n",
    "\n",
    "    def train_epoch(self, train_loader, device):\n",
    "        self.train()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            imgs1, imgs2, _ = batch\n",
    "            imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "        \n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Calculate loss and accuracy metrics\n",
    "            loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            #self.lr_scheduler.step()\n",
    "\n",
    "            # Accumulate metrics\n",
    "            total_loss += loss.item()\n",
    "            total_top1_acc += top1_acc.item()\n",
    "            total_top5_acc += top5_acc.item()\n",
    "            total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(train_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(train_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(train_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos\n",
    "\n",
    "    def validate_epoch(self, val_loader, device):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "                imgs1, imgs2, _ = batch\n",
    "                imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "\n",
    "                # Calculate loss and accuracy metrics\n",
    "                loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "                # Accumulate metrics\n",
    "                total_loss += loss.item()\n",
    "                total_top1_acc += top1_acc.item()\n",
    "                total_top5_acc += top5_acc.item()\n",
    "                total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(val_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(val_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(val_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(val_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos\n",
    "    \n",
    "\n",
    "    def inference_epoch(self, inference_loader, device):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(inference_loader, desc=\"Inferencing\", leave=False):\n",
    "                imgs1, imgs2, _ = batch\n",
    "                imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "\n",
    "                # Calculate loss and accuracy metrics\n",
    "                loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "                # Accumulate metrics\n",
    "                total_loss += loss.item()\n",
    "                total_top1_acc += top1_acc.item()\n",
    "                total_top5_acc += top5_acc.item()\n",
    "                total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(inference_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(inference_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(inference_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(inference_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_200344\\1467178467.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  simclr_model.load_state_dict(torch.load(full_model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (convnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=512, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simclr_model = SimCLR(hidden_dim=128, lr=5e-4, temperature=0.07, weight_decay=1e-4,max_epochs=245)\n",
    "simclr_model.load_state_dict(torch.load(full_model_path))\n",
    "simclr_model.to(device)\n",
    "simclr_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution: {'cond7_all': 472}\n"
     ]
    }
   ],
   "source": [
    "class LabeledImageDataset(Dataset):\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        #self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "\n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Convert to a torch tensor and add channel dimension\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        \n",
    "        # Apply resize transform\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "        #return image, label, img_path\n",
    "\n",
    "def load_data(root_dir):\n",
    "    classes = ['cond7_all']\n",
    "    #classes = ['sd']\n",
    "    \n",
    "    #classes = ['ds_ohne_cond10']\n",
    "\n",
    "\n",
    "    image_files = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(root_dir, class_name)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir) if file.endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        labels.extend([idx] * len(files))\n",
    "    \n",
    "    # Check if the labels correctly reflect the classes\n",
    "    print(\"Label distribution:\", {classes[i]: labels.count(i) for i in range(len(classes))})\n",
    "\n",
    "    return image_files, labels\n",
    "\n",
    "\n",
    "# Directories for labeled data\n",
    "#image_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_ds_ohne_cond10\"\n",
    "image_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\classification\"\n",
    "\n",
    "# Load data\n",
    "image_files, labels = load_data(image_dir)\n",
    "\n",
    "# Create the labeled datasets\n",
    "labeled_dataset = LabeledImageDataset(image_files, labels)\n",
    "\n",
    "# Define DataLoaders\n",
    "batch_size = 16\n",
    "loader_labeled = DataLoader(labeled_dataset, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#for anchor,label, path in loader_labeled:\n",
    "for anchor,label in loader_labeled:\n",
    "    print(anchor.shape, label.shape, anchor.dtype)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_data_features(model, dataloader):\n",
    "    # Prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    #network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    # Encode all images\n",
    "    feats, labels = [], []\n",
    "    for batch_imgs, batch_labels in tqdm(dataloader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        print(f\"Batch features shape: {batch_feats.shape}\")\n",
    "        print(f\"Batch labels shape: {batch_labels.shape}\")\n",
    "        \n",
    "        feats.append(batch_feats.detach().cpu())\n",
    "        labels.append(batch_labels)\n",
    "\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    \n",
    "    print(f\"Features shape after concatenation: {feats.shape}\")\n",
    "    print(f\"Labels shape after concatenation: {labels.shape}\")\n",
    "\n",
    "    return torch.utils.data.TensorDataset(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:00<00:28,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:01<00:22,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:02<00:20,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:03<00:18,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:03<00:18,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:04<00:17,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:05<00:16,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:05<00:15,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:06<00:14,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:07<00:13,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:07<00:13,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [00:08<00:12,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [00:09<00:11,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [00:10<00:11,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [00:10<00:11,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [00:11<00:10,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [00:12<00:09,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [00:12<00:08,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [00:13<00:07,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [00:14<00:06,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [00:14<00:06,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [00:15<00:05,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [00:16<00:04,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [00:16<00:04,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [00:17<00:03,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [00:18<00:02,  1.39it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [00:19<00:02,  1.41it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [00:19<00:01,  1.43it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [00:20<00:00,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:20<00:00,  1.44it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([8, 20])\n",
      "Batch labels shape: torch.Size([8])\n",
      "Features shape after concatenation: torch.Size([472, 20])\n",
      "Labels shape after concatenation: torch.Size([472])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract features for train and test datasets\n",
    "feats_simclr = prepare_data_features(simclr_model, loader_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.utils.data.dataset.TensorDataset"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feats_simclr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_data_features(model, dataloader):\n",
    "    # Prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    #network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    # Encode all images\n",
    "    feats, labels, paths = [], [], []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        print(f\"Batch features shape: {batch_feats.shape}\")\n",
    "        print(f\"Batch labels shape: {batch_labels.shape}\")\n",
    "        print(f\"Batch labels shape: {batch_paths}\")\n",
    "        \n",
    "        feats.append(batch_feats.detach().cpu())\n",
    "        labels.append(batch_labels)\n",
    "        paths.extend(batch_paths) \n",
    "\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    \n",
    "    \n",
    "    print(f\"Features shape after concatenation: {feats.shape}\")\n",
    "    print(f\"Labels shape after concatenation: {labels.shape}\")\n",
    "    print(f\"Number of paths after concatenation: {len(paths)}\")\n",
    "\n",
    "    return feats, labels, paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/30 [00:01<00:29,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_B02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_B03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_B04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_B05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_B06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_B07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_B08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_B09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_B10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_B11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_C02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_C03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_C04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_C05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_C06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_C07-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 2/30 [00:01<00:23,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_C08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_C09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_C10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_C11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_D02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_D03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_D04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_D05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_D06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_D07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_D08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_D09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_D10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_D11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_E02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_E03-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 3/30 [00:02<00:20,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_E04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_E05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_E06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_E07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_E08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_E09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_E10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_E11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_F02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_F03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_F04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_F05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_F06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_F07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_F08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_F09-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 4/30 [00:03<00:20,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_F10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_F11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_G02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_G03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_G04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_G05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_G06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_G07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_G08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_G09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_G10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_1B_G11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_B03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_B04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_B05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_B06-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 17%|█▋        | 5/30 [00:03<00:18,  1.36it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_B07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_B08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_B09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_B10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_B11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_C02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_C03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_C04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_C05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_C06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_C07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_C08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_C09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_C10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_C11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_D02-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 20%|██        | 6/30 [00:04<00:16,  1.42it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_D03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_D04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_D05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_D06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_D07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_D08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_D09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_D10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_D11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_E02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_E03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_E04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_E05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_E06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_E07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_E08-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 7/30 [00:05<00:15,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_E09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_E10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_E11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_F02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_F03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_F04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_F05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_F06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_F07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_F08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_F09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_F10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_F11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_G02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_G04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_G05-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 27%|██▋       | 8/30 [00:05<00:14,  1.48it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_G06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_G07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_G08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_G09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_G10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_41_G11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_B02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_B03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_B04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_B05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_B06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_B07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_B08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_B09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_B10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_B11-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 9/30 [00:06<00:13,  1.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_C02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_C03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_C04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_C05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_C06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_C07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_C08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_C09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_C10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_C11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_D02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_D03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_D04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_D05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_D06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_D07-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 10/30 [00:07<00:13,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_D08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_D09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_D10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_D11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_E02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_E03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_E04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_E05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_E06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_E07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_E08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_E09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_E10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_E11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_F02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_F03-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 37%|███▋      | 11/30 [00:07<00:12,  1.52it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_F04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_F05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_F06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_F07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_F08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_F09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_F10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_F11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_G02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_G04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_G05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_G06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_G07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_G08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_G09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_G10-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 40%|████      | 12/30 [00:08<00:12,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_42_G11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_B02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_B03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_B05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_B06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_B07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_B08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_B09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_B10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_B11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_C02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_C03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_C04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_C05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_C06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_C07-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 43%|████▎     | 13/30 [00:09<00:11,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_C08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_C09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_C10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_C11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_D02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_D03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_D04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_D05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_D06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_D07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_D08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_D09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_D10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_D11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_E02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_E03-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 14/30 [00:09<00:11,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_E04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_E05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_E06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_E07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_E08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_E09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_E10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_E11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_F02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_F03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_F04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_F05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_F06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_F07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_F08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_F09-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 15/30 [00:10<00:10,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_F10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_F11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_G02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_G03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_G04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_G05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_G06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_G07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_G08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_G09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_G10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_51_G11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_B02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_B03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_B04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_B05-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 53%|█████▎    | 16/30 [00:11<00:10,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_B06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_B07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_B08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_B09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_B10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_B11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_C02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_C03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_C04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_C05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_C06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_C07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_C08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_C09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_C10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_C11-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 57%|█████▋    | 17/30 [00:12<00:10,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_D02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_D03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_D04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_D05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_D06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_D07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_D08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_D09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_D10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_D11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_E02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_E03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_E04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_E05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_E06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_E07-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 60%|██████    | 18/30 [00:13<00:09,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_E08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_E09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_E10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_E11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_F02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_F03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_F04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_F05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_F06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_F07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_F08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_F09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_F10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_F11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_G02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_G03-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 63%|██████▎   | 19/30 [00:14<00:09,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_G04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_G05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_G06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_G07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_G08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_G09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_G10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_52_G11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_B02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_B03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_B05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_B06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_B07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_B09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_B10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_B11-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 20/30 [00:14<00:08,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_C02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_C03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_C04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_C05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_C06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_C07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_C08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_C09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_C10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_C11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_D02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_D03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_D04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_D05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_D06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_D07-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 70%|███████   | 21/30 [00:15<00:07,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_D08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_D09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_D10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_D11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_E02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_E03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_E04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_E05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_E06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_E07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_E08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_E09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_E10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_E11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_F02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_F03-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 73%|███████▎  | 22/30 [00:16<00:06,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_F04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_F05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_F06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_F07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_F08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_F09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_F10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_F11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_G02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_G03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_G04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_G05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_G06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_G07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_G08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_G09-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 23/30 [00:17<00:05,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_G10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_61_G11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_B02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_B03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_B04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_B05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_B06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_B07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_B08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_B09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_B10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_B11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_C02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_C03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_C04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_C05-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 80%|████████  | 24/30 [00:18<00:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_C06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_C07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_C08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_C09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_C10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_C11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_D02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_D03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_D04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_D05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_D06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_D07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_D08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_D09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_D10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_D11-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 83%|████████▎ | 25/30 [00:18<00:03,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_E02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_E03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_E04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_E05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_E06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_E07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_E08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_E09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_E10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_E11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_F02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_F04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_F05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_F06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_F07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_F08-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 26/30 [00:19<00:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_F09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_F10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_F11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_G02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_G03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_G04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_G05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_G06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_G07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_G08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_G09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_G10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\ds_62_G11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_B02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_B03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_B04-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|█████████ | 27/30 [00:20<00:02,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_B05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_B06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_B07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_B08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_B09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_B10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_B11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_C02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_C03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_C04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_C05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_C06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_C07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_C08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_C09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_C10-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 93%|█████████▎| 28/30 [00:21<00:01,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_C11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_D02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_D03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_D04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_D05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_D06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_D07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_D08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_D09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_D10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_D11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_E02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_E03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_E04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_E05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_E06-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 29/30 [00:22<00:00,  1.18it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_E07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_E08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_E09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_E10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_E11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_F02-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_F03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_F04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_F05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_F06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_F07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_F08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_F09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_F10-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_F11-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_G02-T01.tiff']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:22<00:00,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([8, 20])\n",
      "Batch labels shape: torch.Size([8])\n",
      "Batch labels shape: ['C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_G03-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_G04-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_G05-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_G06-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_G07-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_G08-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_G09-T01.tiff', 'C:\\\\Users\\\\k54739\\\\Bibi_new_thesis\\\\thesis\\\\classification\\\\cond7_all\\\\sd_04_G11-T01.tiff']\n",
      "Features shape after concatenation: torch.Size([472, 20])\n",
      "Labels shape after concatenation: torch.Size([472])\n",
      "Number of paths after concatenation: 472\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract features for train and test datasets\n",
    "feats, labels, paths = prepare_data_features(simclr_model, loader_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Couple features with their corresponding paths\n",
    "data = list(zip(feats.tolist(), paths))  # Convert tensor to list for compatibility\n",
    "\n",
    "# Save to a .pkl file\n",
    "with open(\"sd.pkl\", \"wb\") as f:\n",
    "    pickle.dump(data, f)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Extract features for train and test datasets\n",
    "feats_simclr = prepare_data_features(simclr_model, loader_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features (for K-Means): (472, 20)\n",
      "Shape of labels: (472,)\n"
     ]
    }
   ],
   "source": [
    "# Convert features and labels to NumPy arrays\n",
    "feats_np = feats_simclr.tensors[0].numpy()  # Features in shape (60, 512)\n",
    "feats_np_norm = normalize(feats_np, axis=1)\n",
    "labels_np = feats_simclr.tensors[1].numpy()  # Corresponding labels\n",
    "\n",
    "# Check the shapes\n",
    "print(\"Shape of features (for K-Means):\", feats_np.shape)\n",
    "print(\"Shape of labels:\", labels_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_dsclose = feats_simclr.tensors[0]\n",
    "sd_dsclose.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in the current folder\n",
    "save_path = \"sd_dsclose.pt\"  # File name only\n",
    "\n",
    "# Save the tensor\n",
    "torch.save(sd_dsclose, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in the current folder\n",
    "save_path = \"sd.pt\"  # File name only\n",
    "\n",
    "# Save the tensor\n",
    "torch.save(sd, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ex = feats_simclr.tensors[0]\n",
    "ex.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save in the current folder\n",
    "save_path = \"ex.pt\"  # File name only\n",
    "\n",
    "# Save the tensor\n",
    "torch.save(ex, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sd = feats_simclr.tensors[0]\n",
    "sd.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save in the current folder\n",
    "save_path = \"sd.pt\"  # File name only\n",
    "\n",
    "# Save the tensor\n",
    "torch.save(sd, save_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cond7 = feats_simclr.tensors[0]\n",
    "cond7.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save in the current folder\n",
    "save_path = \"cond7.pt\"  # File name only\n",
    "\n",
    "# Save the tensor\n",
    "torch.save(cond7, save_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert features and labels to NumPy arrays\n",
    "feats_np = feats_simclr.tensors[0].numpy()  # Features in shape (60, 512)\n",
    "feats_np_norm = normalize(feats_np, axis=1)\n",
    "labels_np = feats_simclr.tensors[1].numpy()  # Corresponding labels\n",
    "\n",
    "# Check the shapes\n",
    "print(\"Shape of features (for K-Means):\", feats_np.shape)\n",
    "print(\"Shape of labels:\", labels_np.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define KMeansCosine class\n",
    "class KMeansCosine:\n",
    "    def __init__(self, n_clusters=2, max_iter=300, random_state=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Normalize the data to unit vectors\n",
    "        X_normalized = X / np.linalg.norm(X, axis=1)[:, np.newaxis]\n",
    "\n",
    "        # Initialize centroids randomly from the data points\n",
    "        np.random.seed(self.random_state)\n",
    "        initial_indices = np.random.choice(X_normalized.shape[0], self.n_clusters, replace=False)\n",
    "        centroids = X_normalized[initial_indices]\n",
    "\n",
    "        # Track the minimum cost and corresponding labels/centroids\n",
    "        best_cost = float('inf')\n",
    "        best_labels = None\n",
    "        best_centroids = None\n",
    "\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            # Compute the cosine similarity and distance\n",
    "            similarities = cosine_similarity(X_normalized, centroids)\n",
    "            cosine_dist = 1 - similarities\n",
    "            cost = np.sum(cosine_dist)\n",
    "            print(f\"Iteration cost: {cost}\")\n",
    "\n",
    "            # Update best cost and corresponding labels/centroids if the current cost is lower\n",
    "            if cost < best_cost:\n",
    "                best_cost = cost\n",
    "                best_labels = np.argmax(similarities, axis=1)\n",
    "                best_centroids = centroids.copy()\n",
    "\n",
    "            # Assign clusters based on the highest similarity (lowest distance)\n",
    "            labels = np.argmax(similarities, axis=1)\n",
    "\n",
    "            # Update centroids by taking the mean of the points in each cluster\n",
    "            new_centroids = np.array([X_normalized[labels == i].mean(axis=0) for i in range(self.n_clusters)])\n",
    "            new_centroids /= np.linalg.norm(new_centroids, axis=1)[:, np.newaxis]\n",
    "\n",
    "            # Check for convergence (if centroids do not change)\n",
    "            if np.allclose(centroids, new_centroids, atol=1e-6):  # Use np.allclose for numerical stability\n",
    "                break\n",
    "\n",
    "            centroids = new_centroids\n",
    "\n",
    "        # Store final centroids and labels\n",
    "        self.labels_ = labels\n",
    "        self.centroids_ = centroids\n",
    "        self.best_labels_ = best_labels\n",
    "        self.best_centroids_ = best_centroids\n",
    "        self.best_cost_ = best_cost"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Define KMeansCosine class\n",
    "class KMeansCosine:\n",
    "    def __init__(self, n_clusters=2, max_iter=300, random_state=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X):\n",
    "        X_normalized = X / np.linalg.norm(X, axis=1)[:, np.newaxis]\n",
    "        np.random.seed(self.random_state)\n",
    "        initial_indices = np.random.choice(X_normalized.shape[0], self.n_clusters, replace=False)\n",
    "        centroids = X_normalized[initial_indices]\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            similarities = cosine_similarity(X_normalized, centroids)\n",
    "            labels = np.argmax(similarities, axis=1)\n",
    "            new_centroids = np.array([X_normalized[labels == i].mean(axis=0) for i in range(self.n_clusters)])\n",
    "            new_centroids /= np.linalg.norm(new_centroids, axis=1)[:, np.newaxis]\n",
    "\n",
    "            if np.all(centroids == new_centroids):\n",
    "                break\n",
    "\n",
    "            centroids = new_centroids\n",
    "\n",
    "        self.labels_ = labels\n",
    "        self.centroids_ = centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_cosine = KMeansCosine(n_clusters=3, max_iter=100, random_state=30)\n",
    "kmeans_cosine.fit(feats_np)\n",
    "\n",
    "print(\"Final Cluster Labels:\", kmeans_cosine.labels_)\n",
    "print(\"Final Centroids:\", kmeans_cosine.centroids_)\n",
    "#print(\"Best Cluster Labels with Lowest Cost:\", kmeans_cosine.best_labels_)\n",
    "print(\"Best Centroids with Lowest Cost:\", kmeans_cosine.best_centroids_)\n",
    "print(\"Lowest Cost:\", kmeans_cosine.best_cost_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = kmeans_cosine.labels_\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cluster assignments:\", idx)\n",
    "print(\"True labels:\", labels_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx = kmeans_cosine.best_labels_\n",
    "best_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cluster assignments:\", best_idx)\n",
    "print(\"True labels:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `idx` contains the cluster assignments from KMeans\n",
    "#  `labels` contains the true labels\n",
    "\n",
    "K = len(np.unique(idx))  # Number of clusters\n",
    "\n",
    "# Iterate over each cluster and count the true labels in that cluster\n",
    "for cluster in range(K):\n",
    "    # Find the indices of images assigned to the current cluster\n",
    "    cluster_indices = np.where(idx == cluster)[0]\n",
    "    \n",
    "    # Get the true labels for the images in this cluster\n",
    "    cluster_labels = labels_np[cluster_indices]\n",
    "    \n",
    "    # Use Counter to count occurrences of each label in the cluster\n",
    "    label_counts = Counter(cluster_labels)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Cluster {cluster} has true labels: {label_counts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = len(np.unique(best_idx))  # Number of clusters\n",
    "\n",
    "# Iterate over each cluster and count the true labels in that cluster\n",
    "for cluster in range(K):\n",
    "    # Find the indices of images assigned to the current cluster\n",
    "    cluster_indices = np.where(best_idx == cluster)[0]\n",
    "    \n",
    "    # Get the true labels for the images in this cluster\n",
    "    cluster_labels = labels_np[cluster_indices]\n",
    "    \n",
    "    # Use Counter to count occurrences of each label in the cluster\n",
    "    label_counts = Counter(cluster_labels)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Cluster {cluster} has true labels: {label_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reorder K-Means labels to match true labels\n",
    "def reorder_labels(true_labels, predicted_labels):\n",
    "    reordered_labels = np.zeros_like(predicted_labels)\n",
    "\n",
    "    for cluster in np.unique(predicted_labels):\n",
    "        mask = (predicted_labels == cluster)\n",
    "        # Use mode and handle cases where mode() returns a scalar\n",
    "        most_common_label = mode(true_labels[mask], axis=None).mode  # Get the mode for the current cluster\n",
    "        if isinstance(most_common_label, np.ndarray):\n",
    "            most_common_label = most_common_label[0]  # Safely extract the mode value if it's an array\n",
    "        \n",
    "        reordered_labels[mask] = most_common_label\n",
    "\n",
    "    return reordered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this after running K-Means\n",
    "reordered_idx = reorder_labels(labels_np, idx)\n",
    "\n",
    "# Now you can compare `reordered_idx` with `labels` to evaluate accuracy\n",
    "accuracy = np.sum(reordered_idx == labels_np) / len(labels_np) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this after running K-Means\n",
    "reordered_idx = reorder_labels(labels_np, best_idx)\n",
    "\n",
    "# Now you can compare `reordered_idx` with `labels` to evaluate accuracy\n",
    "accuracy = np.sum(reordered_idx == labels_np) / len(labels) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means initialization function\n",
    "def kMeans_init_centroids(X, K):\n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    centroids = X[randidx[:K]]\n",
    "    return centroids\n",
    "\n",
    "# Function to find the closest centroids using Cosine Similarity\n",
    "def find_closest_centroids(X, centroids):\n",
    "    # Normalize both the data points and centroids to ensure we compute cosine similarity\n",
    "    #X_norm = normalize(X, axis=1)\n",
    "    #centroids_norm = normalize(centroids, axis=1)\n",
    "    \n",
    "    # Assign data points to closest centroids based on cosine similarity\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        # Compute cosine similarity\n",
    "        similarities = np.dot(centroids, X[i])  # Dot product gives cosine similarity\n",
    "        idx[i] = np.argmax(similarities)  # We want the most similar (highest value)\n",
    "    return idx\n",
    "\n",
    "# Function to compute new centroids\n",
    "def compute_centroids(X, idx, K):\n",
    "    centroids = np.zeros((K, X.shape[1]))  # Use shape[1] for features\n",
    "    for k in range(K):\n",
    "        points = X[idx == k]\n",
    "        if len(points) > 0:\n",
    "            centroids[k] = np.mean(points, axis=0)   # noralised vectors mean maynot be normalised. hence we normalise before calculating mean.https://chatgpt.com/share/671b97a7-ec2c-8010-af33-af106df0a25c\n",
    "            centroids_norm = normalize(centroids, axis=1)\n",
    "    return centroids_norm\n",
    "\n",
    "# Function to run K-Means algorithm with cost tracking (using Cosine Similarity)\n",
    "def run_kMeans(X, initial_centroids, max_iters=10):\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    idx = np.zeros(X.shape[0])\n",
    "    \n",
    "    best_centroids = centroids\n",
    "    lowest_cost = float('inf')\n",
    "    final_iteration = 0  # To keep track of the iteration where the best centroids were found\n",
    "    best_idx = idx  # Track the best index assignment\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        print(f\"K-Means iteration {i}/{max_iters - 1}\")\n",
    "        \n",
    "        # Assign each data point to the closest centroid using cosine similarity\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        \n",
    "        # Compute new centroids\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "\n",
    "        # Calculate cost function for the current centroids using cosine distance\n",
    "\n",
    "        # 1. Compute cosine similarity\n",
    "        sim = np.dot(X, centroids.T)\n",
    "        #print(sim.shape)\n",
    "        #print(sim)\n",
    "        # 2. Calculate cosine distance\n",
    "        cosine_dist = 1 - sim\n",
    "        #print(cosine_dist.shape)\n",
    "        #print(cosine_dist)\n",
    "        # 3. Find maximum cosine distance for each data point\n",
    "        #max_cosine_dist = cosine_dist.max(axis=1)\n",
    "        #print(max_cosine_dist.shape)\n",
    "        #print(max_cosine_dist)\n",
    "        cost = np.sum(cosine_dist)\n",
    "\n",
    "        # 4. Sum of all maximum distances\n",
    "        #cost = np.sum(max_cosine_dist)\n",
    "\n",
    "        #cost = np.sum(1 - np.dot(X_norm, centroids_norm.T).max(axis=1))  # Cosine distance = 1 - cosine similarity  \n",
    "        print(f\"Cost function value: {cost}\")  # Print the cost function value\n",
    "\n",
    "        # Check if this is the best cost so far\n",
    "        if cost < lowest_cost:\n",
    "            lowest_cost = cost\n",
    "            best_centroids = centroids\n",
    "            best_idx = idx.copy()\n",
    "            final_iteration = i  # Update the iteration where best centroids were found\n",
    "\n",
    "    print(f\"Final centroids selected from iteration: {final_iteration}\")  # Indicate which iteration was chosen\n",
    "    return best_centroids, best_idx, centroids,idx  # Return the best centroids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# K-Means initialization function\n",
    "def kMeans_init_centroids(X, K):\n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    centroids = X[randidx[:K]]\n",
    "    return centroids\n",
    "\n",
    "# Function to find the closest centroids using Cosine Similarity\n",
    "def find_closest_centroids(X, centroids):\n",
    "    # Normalize both the data points and centroids to ensure we compute cosine similarity\n",
    "    X_norm = normalize(X, axis=1)\n",
    "    centroids_norm = normalize(centroids, axis=1)\n",
    "    \n",
    "    # Assign data points to closest centroids based on cosine similarity\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        # Compute cosine similarity\n",
    "        similarities = np.dot(centroids_norm, X_norm[i])  # Dot product gives cosine similarity\n",
    "        idx[i] = np.argmax(similarities)  # We want the most similar (highest value)\n",
    "    return idx\n",
    "\n",
    "# Function to compute new centroids\n",
    "def compute_centroids(X, idx, K):\n",
    "    centroids = np.zeros((K, X.shape[1]))  # Use shape[1] for features\n",
    "    for k in range(K):\n",
    "        points = X[idx == k]\n",
    "        if len(points) > 0:\n",
    "            # Normalize the points within the cluster along each feature axis\n",
    "            normalized_points = normalize(points, axis=1)   # noralised vectors mean maynot be normalised. hence we normalise before calculating mean.https://chatgpt.com/share/671b97a7-ec2c-8010-af33-af106df0a25c\n",
    "            # Compute the mean of the normalized points to get the new centroid\n",
    "            centroids[k] = np.mean(normalized_points, axis=0)\n",
    "    return centroids\n",
    "\n",
    "# Function to run K-Means algorithm with cost tracking (using Cosine Similarity)\n",
    "def run_kMeans(X, initial_centroids, max_iters=10):\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    idx = np.zeros(X.shape[0])\n",
    "    \n",
    "    best_centroids = centroids\n",
    "    lowest_cost = float('inf')\n",
    "    final_iteration = 0  # To keep track of the iteration where the best centroids were found\n",
    "    best_idx = idx  # Track the best index assignment\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        print(f\"K-Means iteration {i}/{max_iters - 1}\")\n",
    "        \n",
    "        # Assign each data point to the closest centroid using cosine similarity\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        \n",
    "        # Compute new centroids\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "\n",
    "        # Calculate cost function for the current centroids using cosine distance\n",
    "        X_norm = normalize(X, axis=1)\n",
    "        centroids_norm = normalize(centroids, axis=1)\n",
    "\n",
    "        # 1. Compute cosine similarity\n",
    "        sim = np.dot(X_norm, centroids_norm.T)\n",
    "        #print(sim.shape)\n",
    "        #print(sim)\n",
    "        # 2. Calculate cosine distance\n",
    "        cosine_dist = 1 - sim\n",
    "        #print(cosine_dist.shape)\n",
    "        #print(cosine_dist)\n",
    "        # 3. Find maximum cosine distance for each data point\n",
    "        #max_cosine_dist = cosine_dist.max(axis=1)\n",
    "        #print(max_cosine_dist.shape)\n",
    "        #print(max_cosine_dist)\n",
    "        cost = np.sum(cosine_dist)\n",
    "\n",
    "        # 4. Sum of all maximum distances\n",
    "        #cost = np.sum(max_cosine_dist)\n",
    "\n",
    "        #cost = np.sum(1 - np.dot(X_norm, centroids_norm.T).max(axis=1))  # Cosine distance = 1 - cosine similarity  \n",
    "        print(f\"Cost function value: {cost}\")  # Print the cost function value\n",
    "\n",
    "        # Check if this is the best cost so far\n",
    "        if cost < lowest_cost:\n",
    "            lowest_cost = cost\n",
    "            best_centroids = centroids\n",
    "            best_idx = idx.copy()\n",
    "            final_iteration = i  # Update the iteration where best centroids were found\n",
    "\n",
    "    print(f\"Final centroids selected from iteration: {final_iteration}\")  # Indicate which iteration was chosen\n",
    "    return best_centroids, best_idx, centroids,idx  # Return the best centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to run the K-Means algorithm\n",
    "\n",
    "K = 1                     # Set number of clusters\n",
    "initial_centroids = kMeans_init_centroids(feats_np_norm, K)  # Step 3: Initialize centroids\n",
    "max_iters = 100                # Step 4: Number of iterations\n",
    "best_centroids, best_idx, centroids, idx = run_kMeans(feats_np_norm, initial_centroids, max_iters)  # Step 5: Run K-Means\n",
    "print(\"Final centroids:\", centroids)  # Output the final centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('ex40_centroid.npy', centroids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "three_class_cosine_centroid = centroids[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "control_centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to run the K-Means algorithm\n",
    "\n",
    "K = 3                     # Set number of clusters\n",
    "initial_centroids = kMeans_init_centroids(feats_np_norm, K)  # Step 3: Initialize centroids\n",
    "max_iters = 50                # Step 4: Number of iterations\n",
    "best_centroids, best_idx, centroids, idx = run_kMeans(feats_np_norm, initial_centroids, max_iters)  # Step 5: Run K-Means\n",
    "print(\"Final centroids:\", centroids)  # Output the final centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids[1].dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the L2 norm of the centroid\n",
    "norm = np.linalg.norm(centroids[1])\n",
    "\n",
    "# Check if the norm is close to 1\n",
    "if np.isclose(norm, 1.0, atol=1e-6):\n",
    "    print(\"The centroid is already normalized.\")\n",
    "else:\n",
    "    print(f\"The centroid is not normalized. Norm: {norm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Convert the centroid to a PyTorch tensor\n",
    "three_class_cosine_centroid = torch.tensor(three_class_cosine_centroid)\n",
    "\n",
    "# Define the specific path\n",
    "save_path_torch = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Source_Code\\Ranking(prediction)_model\\kmeans_ranking\\cosine\\three_class_cosine_centroid.pt\"\n",
    "\n",
    "# Save the centroid tensor\n",
    "torch.save(three_class_cosine_centroid, save_path_torch)\n",
    "print(f\"Centroid saved to {save_path_torch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cluster assignments:\", idx)\n",
    "print(\"True labels:\", labels_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cluster assignments:\", best_idx)\n",
    "print(\"True labels:\", labels_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `idx` contains the cluster assignments from KMeans\n",
    "# and `labels` contains the true labels\n",
    "\n",
    "K = len(np.unique(idx))  # Number of clusters\n",
    "\n",
    "# Iterate over each cluster and count the true labels in that cluster\n",
    "for cluster in range(K):\n",
    "    # Find the indices of images assigned to the current cluster\n",
    "    cluster_indices = np.where(idx == cluster)[0]\n",
    "    \n",
    "    # Get the true labels for the images in this cluster\n",
    "    cluster_labels = labels_np[cluster_indices]\n",
    "    \n",
    "    # Use Counter to count occurrences of each label in the cluster\n",
    "    label_counts = Counter(cluster_labels)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Cluster {cluster} has true labels: {label_counts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = len(np.unique(best_idx))  # Number of clusters\n",
    "\n",
    "# Iterate over each cluster and count the true labels in that cluster\n",
    "for cluster in range(K):\n",
    "    # Find the indices of images assigned to the current cluster\n",
    "    cluster_indices = np.where(best_idx == cluster)[0]\n",
    "    \n",
    "    # Get the true labels for the images in this cluster\n",
    "    cluster_labels = labels_np[cluster_indices]\n",
    "    \n",
    "    # Use Counter to count occurrences of each label in the cluster\n",
    "    label_counts = Counter(cluster_labels)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Cluster {cluster} has true labels: {label_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "\n",
    "# Function to reorder K-Means labels to match true labels\n",
    "def reorder_labels(true_labels, predicted_labels):\n",
    "    reordered_labels = np.zeros_like(predicted_labels)\n",
    "\n",
    "    for cluster in np.unique(predicted_labels):\n",
    "        mask = (predicted_labels == cluster)\n",
    "        # Use mode and handle cases where mode() returns a scalar\n",
    "        most_common_label = mode(true_labels[mask], axis=None).mode  # Get the mode for the current cluster\n",
    "        if isinstance(most_common_label, np.ndarray):\n",
    "            most_common_label = most_common_label[0]  # Safely extract the mode value if it's an array\n",
    "        \n",
    "        reordered_labels[mask] = most_common_label\n",
    "\n",
    "    return reordered_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this after running K-Means\n",
    "reordered_idx = reorder_labels(labels_np, idx)\n",
    "\n",
    "# Now you can compare `reordered_idx` with `labels` to evaluate accuracy\n",
    "accuracy = np.sum(reordered_idx == labels_np) / len(labels_np) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this after running K-Means\n",
    "reordered_idx = reorder_labels(labels_np, best_idx)\n",
    "\n",
    "# Now you can compare `reordered_idx` with `labels` to evaluate accuracy\n",
    "accuracy = np.sum(reordered_idx == labels_np) / len(labels_np) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "iteration 1: 90%\n",
    "\n",
    "iteration 2: 96.67%\n",
    "\n",
    "iteration 3: 95%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reduce the dimensionality of data points and centroids to 2D using PCA\n",
    "def reduce_to_2D_pca(X, centroids):\n",
    "    # Initialize PCA with 2 components\n",
    "    pca = PCA(n_components=2)\n",
    "    \n",
    "    # Apply PCA to the data points (X) and centroids\n",
    "    X_2D = pca.fit_transform(X)  # Reducing original data points\n",
    "    centroids_2D = pca.transform(centroids)  # Reducing centroids\n",
    "\n",
    "    return X_2D, centroids_2D\n",
    "\n",
    "# Function to plot 2D visualization of clustered data points and centroids with true labels\n",
    "def plot_2D_clusters_with_labels(X_2D, centroids_2D, idx, labels, K):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    # Define color map for clusters\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, K))\n",
    "    \n",
    "    # Plot data points colored by their cluster assignment\n",
    "    for k in range(K):\n",
    "        cluster_points = X_2D[idx == k]\n",
    "        cluster_labels = labels[idx == k]  # Get true labels for the current cluster\n",
    "        \n",
    "        # Scatter plot for each cluster\n",
    "        plt.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "                    c=[colors[k]], label=f\"Cluster {k+1}\", alpha=0.6)\n",
    "        \n",
    "        # Annotate each point with its true label\n",
    "        for i in range(cluster_points.shape[0]):\n",
    "            plt.annotate(str(cluster_labels[i]), \n",
    "                         (cluster_points[i, 0], cluster_points[i, 1]), \n",
    "                         fontsize=8, alpha=0.75)\n",
    "\n",
    "    # Plot centroids as larger markers\n",
    "    plt.scatter(centroids_2D[:, 0], centroids_2D[:, 1], \n",
    "                c='k', marker='x', s=200, label='Centroids')\n",
    "\n",
    "    plt.title(\"2D Visualization of Clusters using PCA with True Labels\")\n",
    "    plt.xlabel(\"Component 1\")\n",
    "    plt.ylabel(\"Component 2\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA after K-Means clustering for 2D visualization\n",
    "X_2D_pca, centroids_2D_pca = reduce_to_2D_pca(feats_np_norm, centroids)\n",
    "\n",
    "# Plot the 2D clusters with centroids and true labels\n",
    "plot_2D_clusters_with_labels(X_2D_pca, centroids_2D_pca, idx, labels_np, K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA after K-Means clustering for 2D visualization\n",
    "X_2D_pca, centroids_2D_pca = reduce_to_2D_pca(feats_np_norm, best_centroids)\n",
    "\n",
    "# Plot the 2D clusters with centroids and true labels\n",
    "plot_2D_clusters_with_labels(X_2D_pca, centroids_2D_pca, best_idx, labels_np, K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "zero = centroids[0]\n",
    "zero"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"zero.npy\", zero)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "one = centroids[1]\n",
    "one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"one.npy\", one)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "two = centroids[2]\n",
    "two"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"two.npy\", two)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
