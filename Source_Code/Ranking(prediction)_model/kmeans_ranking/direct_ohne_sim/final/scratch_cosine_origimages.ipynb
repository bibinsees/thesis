{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Labels and Counts:\n",
      "Class 'cond7_curated' (Index 0): 280 images\n"
     ]
    }
   ],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = []\n",
    "        self.labels = []\n",
    "        self.class_names = []  # To store class (folder) names\n",
    "        self.class_to_idx = {}  # To map class names to indices\n",
    "        self.class_counts = {}  # To store count of images per class\n",
    "\n",
    "        # Define a transformation to resize the images\n",
    "        self.transform = transforms.Compose([transforms.Resize((96, 96))])\n",
    "\n",
    "        # Get all subdirectories (classes)\n",
    "        self.class_names = [d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))]\n",
    "        self.class_names.sort()  # Ensure consistent ordering\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.class_names)}\n",
    "\n",
    "        # Load images and assign labels based on folder name\n",
    "        for class_name in self.class_names:\n",
    "            class_dir = os.path.join(image_dir, class_name)\n",
    "            class_images = [os.path.join(class_dir, file) for file in os.listdir(class_dir) if file.endswith(('.tiff', '.tif'))]\n",
    "            self.image_files.extend(class_images)\n",
    "            self.labels.extend([self.class_to_idx[class_name]] * len(class_images))  # Assign class index as label\n",
    "            \n",
    "            # Store the count of images per class\n",
    "            self.class_counts[class_name] = len(class_images)\n",
    "\n",
    "        # Print labels and counts\n",
    "        self.print_labels_and_counts()\n",
    "     \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "        \n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        original_image = image.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Convert to a torch tensor \n",
    "        image = torch.tensor(original_image, dtype=torch.float32)\n",
    "        #print(image.shape)\n",
    "        # Apply the resizing transform (resize)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        flattened_image = image.view(-1).numpy()  # Reshape to (96*96*3, )\n",
    "        \n",
    "        return flattened_image, label\n",
    "\n",
    "    def print_labels_and_counts(self):\n",
    "        print(\"Class Labels and Counts:\")\n",
    "        for class_name, class_index in self.class_to_idx.items():\n",
    "            print(f\"Class '{class_name}' (Index {class_index}): {self.class_counts[class_name]} images\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "image_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\classification\"  # Replace with your image directory\n",
    "dataset = ImageDataset(image_dir)  # Initialize dataset, it will automatically print labels and counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "280"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27648,)\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset)):\n",
    "    falttened_image,l = dataset[i]\n",
    "    print(falttened_image.shape)  # This will print the shape of each image\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Create a list to store all flattened vectors and labels\n",
    "flattened_images = []\n",
    "\n",
    "\n",
    "# Iterate through the dataset and collect flattened images and labels\n",
    "for i in range(len(dataset)):\n",
    "    flattened_image, label = dataset[i]\n",
    "    flattened_images.append(flattened_image)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_10148\\3505366632.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\cb\\pytorch_1000000000000\\work\\torch\\csrc\\utils\\tensor_new.cpp:281.)\n",
      "  ex_flattened_images_tensor = torch.tensor(flattened_images, dtype=torch.float32)  # Shape: [120, Flattened_Size]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Convert to PyTorch tensors\n",
    "ex_flattened_images_tensor = torch.tensor(flattened_images, dtype=torch.float32)  # Shape: [120, Flattened_Size]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([280, 27648])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ex_flattened_images_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Replace with your actual tensor\n",
    "\n",
    "# Save in the current folder\n",
    "save_path_images = \"cond7.pt\"  # File name only\n",
    "\n",
    "# Save the tensor\n",
    "torch.save(ex_flattened_images_tensor, save_path_images)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the tensors\n",
    "loaded_flattened_images = torch.load('ex_flattened_images.pt')\n",
    "\n",
    "\n",
    "print(f\"Loaded flattened images shape: {loaded_flattened_images.shape}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the centroid\n",
    "centroid_tensor = torch.load('centroid.pt')\n",
    "print(\"Centroid loaded with shape:\", centroid_tensor.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.tiff')] \n",
    "        \n",
    "        # Define a transformation to resize the images\n",
    "        self.transform = transforms.Compose([transforms.Resize((96, 96))])\n",
    "     \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Print the shape of the loaded image\n",
    "        #print(f\"Image {img_path} loaded with shape: {image.shape}\")\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "        \n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        original_image = image.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Convert to a torch tensor \n",
    "        image = torch.tensor(original_image, dtype=torch.float32)\n",
    "\n",
    "        # Apply the resizing transform (first convert to tensor, then resize)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        flattened_image = image.view(-1).numpy()  # Reshape to (96*96*3, )\n",
    "        #print(flattened_image.shape)\n",
    "        return flattened_image\n",
    "\n",
    "\n",
    "  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset = ImageDataset(r\"../../tiff_experiment_unsupervised_data/combined\")\n",
    "for i in range(len(dataset)):\n",
    "    falttened_image = dataset[i]  # This will print the shape of each image\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combine all images into a single dataset for K-Means input\n",
    "def load_image_data(dataset):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        flattened_image, label = dataset[i]  # Unpack the image and label\n",
    "        all_images.append(flattened_image)\n",
    "        all_labels.append(label)\n",
    "    \n",
    "    # Stack all the flattened images to create a large dataset\n",
    "    # Convert to numpy arrays for K-Means input\n",
    "    return np.vstack(all_images), np.array(all_labels)\n",
    "\n",
    "# K-Means initialization function\n",
    "def kMeans_init_centroids(X, K):\n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    centroids = X[randidx[:K]]\n",
    "    return centroids\n",
    "\n",
    "# Function to find the closest centroids\n",
    "def find_closest_centroids(X, centroids):\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        distances = np.linalg.norm(X[i] - centroids, axis=1)\n",
    "        idx[i] = np.argmin(distances)\n",
    "    return idx\n",
    "\n",
    "# Function to compute new centroids\n",
    "def compute_centroids(X, idx, K):\n",
    "    centroids = np.zeros((K, X.shape[1]))  # Use shape[1] for features\n",
    "    for k in range(K):\n",
    "        points = X[idx == k]\n",
    "        centroids[k] = np.mean(points, axis=0) if len(points) > 0 else centroids[k]\n",
    "    return centroids\n",
    "\n",
    "# Function to run K-Means algorithm with cost tracking\n",
    "def run_kMeans(X, initial_centroids, max_iters=10):\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    idx = np.zeros(X.shape[0])\n",
    "    \n",
    "    best_centroids = centroids\n",
    "    lowest_cost = float('inf')\n",
    "    final_iteration = 0  # To keep track of the iteration where the best centroids were found\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        print(f\"K-Means iteration {i}/{max_iters - 1}\")\n",
    "        \n",
    "        # Assign each data point to the closest centroid\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        \n",
    "        # Compute new centroids\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "\n",
    "        # Calculate cost function for the current centroids\n",
    "        cost = np.sum(np.linalg.norm(X - centroids[idx], axis=1)**2)\n",
    "        print(f\"Cost function value: {cost:.4f}\")  # Print the cost function value\n",
    "\n",
    "        # Check if this is the best cost so far\n",
    "        if cost < lowest_cost:\n",
    "            lowest_cost = cost\n",
    "            best_centroids = centroids\n",
    "            final_iteration = i  # Update the iteration where best centroids were found\n",
    "\n",
    "    print(f\"Final centroids selected from iteration: {final_iteration}\")  # Indicate which iteration was chosen\n",
    "    return best_centroids, idx  # Return the best centroids\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Combine all images into a single dataset for K-Means input\n",
    "def load_image_data(dataset):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        flattened_image, label = dataset[i]  # Unpack the image and label\n",
    "        all_images.append(flattened_image)\n",
    "        all_labels.append(label)\n",
    "    \n",
    "    # Stack all the flattened images to create a large dataset\n",
    "    # Convert to numpy arrays for K-Means input\n",
    "    return np.vstack(all_images), np.array(all_labels)\n",
    "\n",
    "# K-Means initialization function\n",
    "def kMeans_init_centroids(X, K):\n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    centroids = X[randidx[:K]]\n",
    "    return centroids\n",
    "\n",
    "# Function to find the closest centroids using Cosine Similarity\n",
    "def find_closest_centroids(X, centroids):\n",
    "    # Normalize both the data points and centroids to ensure we compute cosine similarity\n",
    "    X_norm = normalize(X, axis=1)\n",
    "    centroids_norm = normalize(centroids, axis=1)\n",
    "    #print(X_norm.shape)              #(60, 27648)\n",
    "    #print(centroids_norm.shape)  #(2, 27648)\n",
    "    #print(X_norm[0].shape) #(27648,)\n",
    "    \n",
    "    # Assign data points to closest centroids based on cosine similarity\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        # Compute cosine similarity\n",
    "        similarities = np.dot(centroids_norm, X_norm[i])  # Dot product gives cosine similarity\n",
    "        #print(similarities.shape)\n",
    "        idx[i] = np.argmax(similarities)  # We want the most similar (highest value)\n",
    "    return idx  #idx = [1, 0, 1, 1, 0,...]\n",
    "\n",
    "\n",
    "def compute_centroids(X, idx, K):\n",
    "    centroids = np.zeros((K, X.shape[1]))  # Use shape[1] for features\n",
    "    for k in range(K):\n",
    "        points = X[idx == k]\n",
    "        if len(points) > 0:\n",
    "            # Normalize the points within the cluster along each feature axis\n",
    "            normalized_points = normalize(points, axis=1)\n",
    "            # Compute the mean of the normalized points to get the new centroid\n",
    "            centroids[k] = np.mean(normalized_points, axis=0)\n",
    "    return centroids\n",
    "\n",
    "# Function to run K-Means algorithm with cost tracking (using Cosine Similarity)\n",
    "def run_kMeans(X, initial_centroids, max_iters=10):\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    idx = np.zeros(X.shape[0])\n",
    "    \n",
    "    best_centroids = centroids\n",
    "    lowest_cost = float('inf')\n",
    "    final_iteration = 0  # To keep track of the iteration where the best centroids were found\n",
    "    best_idx = idx  # Track the best index assignment\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        print(f\"K-Means iteration {i}/{max_iters - 1}\")\n",
    "        \n",
    "        # Assign each data point to the closest centroid using cosine similarity\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        \n",
    "        \n",
    "        # Compute new centroids\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "\n",
    "        #Range of cosine distance is from 0 to 2, 0 — identical vectors, 1 — no correlation, 2 — absolutely different.\n",
    "\n",
    "        # Calculate cost function for the current centroids using cosine distance\n",
    "        X_norm = normalize(X, axis=1)\n",
    "        centroids_norm = normalize(centroids, axis=1)\n",
    "\n",
    "        # 1. Compute cosine similarity\n",
    "        sim = np.dot(X_norm, centroids_norm.T)\n",
    "        #print(sim.shape)\n",
    "        #print(sim)\n",
    "        # 2. Calculate cosine distance\n",
    "        cosine_dist = 1 - sim\n",
    "        #print(cosine_dist.shape)\n",
    "        #print(cosine_dist)\n",
    "        # 3. Find maximum cosine distance for each data point\n",
    "        max_cosine_dist = cosine_dist.max(axis=1)\n",
    "        #print(max_cosine_dist.shape)\n",
    "        #print(max_cosine_dist)\n",
    "        \n",
    "\n",
    "        # 4. Sum of all maximum distances\n",
    "        cost = np.sum(max_cosine_dist)\n",
    "\n",
    "        #cost = np.sum(1 - np.dot(X_norm, centroids_norm.T).max(axis=1))  # Cosine distance = (1 - cosine similarity)  #this code calcs cosine sim to all images? wwhy max? inspect both code each value and then total value\n",
    "        print(f\"Cost function value: {cost:.4f}\")  # Print the cost function value\n",
    "\n",
    "        # Check if this is the best cost so far\n",
    "        if cost < lowest_cost:\n",
    "            lowest_cost = cost\n",
    "            best_centroids = centroids\n",
    "            best_idx = idx.copy()\n",
    "            final_iteration = i  # Update the iteration where best centroids were found\n",
    "\n",
    "    print(f\"Final centroids selected from iteration: {final_iteration}\")  # Indicate which iteration was chosen\n",
    "    return best_centroids, best_idx, idx  # Return the best centroids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# from scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Combine all images into a single dataset for K-Means input\n",
    "def load_image_data(dataset):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        flattened_image, label = dataset[i]  # Unpack the image and label\n",
    "        all_images.append(flattened_image)\n",
    "        all_labels.append(label)\n",
    "    \n",
    "    # Stack all the flattened images to create a large dataset\n",
    "    X = np.vstack(all_images)  # Combine all images into a single dataset\n",
    "\n",
    "    # Normalize the combined dataset along the features axis (axis=1)\n",
    "    X_normalized = normalize(X, axis=1)\n",
    "    return X_normalized, np.array(all_labels)\n",
    "\n",
    "# K-Means initialization function\n",
    "def kMeans_init_centroids(X, K):\n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    centroids = X[randidx[:K]]  # Randomly select K centroids from normalized X\n",
    "    return centroids\n",
    "\n",
    "# Function to find the closest centroids using Cosine Similarity\n",
    "def find_closest_centroids(X, centroids):\n",
    "    # No need to normalize X and centroids here as they are already normalized\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        similarities = np.dot(centroids, X[i])  # Dot product gives cosine similarity\n",
    "        idx[i] = np.argmax(similarities)  # We want the most similar (highest value)\n",
    "    return idx\n",
    "\n",
    "# Function to compute new centroids\n",
    "def compute_centroids(X, idx, K):\n",
    "    centroids = np.zeros((K, X.shape[1]))\n",
    "    for k in range(K):\n",
    "        points = X[idx == k]\n",
    "        if len(points) > 0:\n",
    "            centroids[k] = np.mean(points, axis=0)  #why axs =0 ans:https://chatgpt.com/share/671b97a7-ec2c-8010-af33-af106df0a25c\n",
    "            centroids_norm = normalize(centroids, axis=1)\n",
    "    return centroids_norm\n",
    "\n",
    "# Function to run K-Means algorithm with cost tracking (using Cosine Similarity)\n",
    "def run_kMeans(X, initial_centroids, max_iters=10):\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    idx = np.zeros(X.shape[0])\n",
    "\n",
    "    best_centroids = centroids\n",
    "    lowest_cost = float('inf')\n",
    "    final_iteration = 0\n",
    "    best_idx = idx  # Track the best index assignment\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        print(f\"K-Means iteration {i}/{max_iters - 1}\")\n",
    "        \n",
    "        # Assign each data point to the closest centroid\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        \n",
    "        # Compute new centroids\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "\n",
    "        # Calculate cost function\n",
    "        sim = np.dot(X, centroids.T)\n",
    "        cosine_dist = 1 - sim\n",
    "        #max_cosine_dist = cosine_dist.max(axis=1)\n",
    "        #cost = np.sum(max_cosine_dist)\n",
    "\n",
    "        cost = np.sum(cosine_dist)\n",
    "        \n",
    "\n",
    "        print(f\"Cost function value: {cost}\")\n",
    "\n",
    "        if cost < lowest_cost:\n",
    "            lowest_cost = cost\n",
    "            best_centroids = centroids\n",
    "            best_idx = idx.copy()\n",
    "            final_iteration = i\n",
    "\n",
    "    print(f\"Final centroids selected from iteration: {final_iteration}\")\n",
    "    return best_centroids, best_idx, centroids, idx  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of stacked images (X): (280, 27648)\n",
      "Shape of labels: (280,)\n",
      "K-Means iteration 0/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 1/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 2/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 3/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 4/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 5/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 6/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 7/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 8/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 9/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 10/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 11/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 12/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 13/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 14/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 15/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 16/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 17/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 18/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 19/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 20/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 21/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 22/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 23/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 24/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 25/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 26/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 27/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 28/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 29/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 30/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 31/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 32/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 33/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 34/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 35/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 36/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 37/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 38/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 39/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 40/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 41/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 42/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 43/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 44/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 45/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 46/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 47/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 48/49\n",
      "Cost function value: 3.974089667911575\n",
      "K-Means iteration 49/49\n",
      "Cost function value: 3.974089667911575\n",
      "Final centroids selected from iteration: 0\n",
      "Final centroids: [[0.00688797 0.00688642 0.0068877  ... 0.00686604 0.00686017 0.00685573]]\n"
     ]
    }
   ],
   "source": [
    "# Main function to run the K-Means algorithm\n",
    "X, labels = load_image_data(dataset)  # Load data and labels \n",
    "\n",
    "# To check and print the dimensions:\n",
    "print(\"Shape of stacked images (X):\", X.shape)\n",
    "print(\"Shape of labels:\", labels.shape)       \n",
    "\n",
    "K = 1                          # Step 2: Set number of clusters\n",
    "initial_centroids = kMeans_init_centroids(X, K)  # Step 3: Initialize centroids \n",
    "max_iters = 50                # Step 4: Number of iterations\n",
    "\n",
    "best_centroids, best_idx, centroids, idx = run_kMeans(X, initial_centroids, max_iters)  # Step 5: Run K-Means\n",
    "print(\"Final centroids:\", best_centroids)  # Output the final centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 27648)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Centroid saved as 'cosine_centroid_tensor.pt'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import os\n",
    "\n",
    "# Example NumPy array converted to PyTorch tensor\n",
    "cosine_centroid_tensor = torch.tensor(centroids)\n",
    "\n",
    "# Save as .pt file\n",
    "torch.save(cosine_centroid_tensor, 'cond7_cosin_centroid.pt')\n",
    "print(\"Centroid saved as 'cosine_centroid_tensor.pt'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_centroid_tensor.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testtwo= centroids\n",
    "testtwo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testone = centroids\n",
    "testone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testtwo==centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cluster assignments:\", idx)\n",
    "print(\"True labels:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cluster assignments:\", best_idx)\n",
    "print(\"True labels:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `idx` contains the cluster assignments from KMeans\n",
    "#  `labels` contains the true labels\n",
    "\n",
    "K = len(np.unique(idx))  # Number of clusters\n",
    "\n",
    "# Iterate over each cluster and count the true labels in that cluster\n",
    "for cluster in range(K):\n",
    "    # Find the indices of images assigned to the current cluster\n",
    "    cluster_indices = np.where(idx == cluster)[0]\n",
    "    \n",
    "    # Get the true labels for the images in this cluster\n",
    "    cluster_labels = labels[cluster_indices]\n",
    "    \n",
    "    # Use Counter to count occurrences of each label in the cluster\n",
    "    label_counts = Counter(cluster_labels)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Cluster {cluster} has true labels: {label_counts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = len(np.unique(best_idx))  # Number of clusters\n",
    "\n",
    "# Iterate over each cluster and count the true labels in that cluster\n",
    "for cluster in range(K):\n",
    "    # Find the indices of images assigned to the current cluster\n",
    "    cluster_indices = np.where(best_idx == cluster)[0]\n",
    "    \n",
    "    # Get the true labels for the images in this cluster\n",
    "    cluster_labels = labels[cluster_indices]\n",
    "    \n",
    "    # Use Counter to count occurrences of each label in the cluster\n",
    "    label_counts = Counter(cluster_labels)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Cluster {cluster} has true labels: {label_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reorder K-Means labels to match true labels\n",
    "def reorder_labels(true_labels, predicted_labels):\n",
    "    reordered_labels = np.zeros_like(predicted_labels)\n",
    "\n",
    "    for cluster in np.unique(predicted_labels):\n",
    "        mask = (predicted_labels == cluster)\n",
    "        # Use mode and handle cases where mode() returns a scalar\n",
    "        most_common_label = mode(true_labels[mask], axis=None).mode  # Get the mode for the current cluster\n",
    "        if isinstance(most_common_label, np.ndarray):\n",
    "            most_common_label = most_common_label[0]  # Safely extract the mode value if it's an array\n",
    "        \n",
    "        reordered_labels[mask] = most_common_label\n",
    "\n",
    "    return reordered_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#top score: 82.14"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this after running K-Means\n",
    "reordered_idx = reorder_labels(labels, idx)\n",
    "\n",
    "# Now you can compare `reordered_idx` with `labels` to evaluate accuracy\n",
    "accuracy = np.sum(reordered_idx == labels) / len(labels) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this after running K-Means\n",
    "reordered_idx = reorder_labels(labels, best_idx)\n",
    "\n",
    "# Now you can compare `reordered_idx` with `labels` to evaluate accuracy\n",
    "accuracy = np.sum(reordered_idx == labels) / len(labels) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reduce the dimensionality of data points and centroids to 2D using PCA\n",
    "def reduce_to_2D_pca(X, centroids):\n",
    "    # Initialize PCA with 2 components\n",
    "    pca = PCA(n_components=2)\n",
    "    \n",
    "    # Apply PCA to the data points (X) and centroids\n",
    "    X_2D = pca.fit_transform(X)  # Reducing original data points\n",
    "    centroids_2D = pca.transform(centroids)  # Reducing centroids\n",
    "\n",
    "    return X_2D, centroids_2D\n",
    "\n",
    "# Function to plot 2D visualization of clustered data points and centroids with true labels\n",
    "def plot_2D_clusters_with_labels(X_2D, centroids_2D, idx, labels, K):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    # Define color map for clusters\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, K))\n",
    "    \n",
    "    # Plot data points colored by their cluster assignment\n",
    "    for k in range(K):\n",
    "        cluster_points = X_2D[idx == k]\n",
    "        cluster_labels = labels[idx == k]  # Get true labels for the current cluster\n",
    "        \n",
    "        # Scatter plot for each cluster\n",
    "        plt.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "                    c=[colors[k]], label=f\"Cluster {k+1}\", alpha=0.6)\n",
    "        \n",
    "        # Annotate each point with its true label\n",
    "        for i in range(cluster_points.shape[0]):\n",
    "            plt.annotate(str(cluster_labels[i]), \n",
    "                         (cluster_points[i, 0], cluster_points[i, 1]), \n",
    "                         fontsize=8, alpha=0.75)\n",
    "\n",
    "    # Plot centroids as larger markers\n",
    "    plt.scatter(centroids_2D[:, 0], centroids_2D[:, 1], \n",
    "                c='k', marker='x', s=200, label='Centroids')\n",
    "\n",
    "    plt.title(\"2D Visualization of Clusters using PCA with True Labels\")\n",
    "    plt.xlabel(\"Component 1\")\n",
    "    plt.ylabel(\"Component 2\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA after K-Means clustering for 2D visualization\n",
    "X_2D_pca, centroids_2D_pca = reduce_to_2D_pca(X, centroids)\n",
    "\n",
    "# Plot the 2D clusters with centroids and true labels\n",
    "plot_2D_clusters_with_labels(X_2D_pca, centroids_2D_pca, idx, labels, K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA after K-Means clustering for 2D visualization\n",
    "X_2D_pca, centroids_2D_pca = reduce_to_2D_pca(X, best_centroids)\n",
    "\n",
    "# Plot the 2D clusters with centroids and true labels\n",
    "plot_2D_clusters_with_labels(X_2D_pca, centroids_2D_pca, best_idx, labels, K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_points = 30+30+12\n",
    "wrong = 3 \n",
    "predicted_corrected = total_data_points - wrong\n",
    "accuracy = (predicted_corrected/total_data_points)*100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibi = np.array([\n",
    "    [0.6394, 0.64353806, 0.64770716, 0.68035775, 0.68076485, 0.68122697],\n",
    "    [0.6434593, 0.64427465, 0.6459859, 0.6629785, 0.6606025, 0.65433437],\n",
    "    [0.6341258, 0.63328487, 0.62688166, 0.6681404, 0.66825783, 0.6676554],\n",
    "    [0.627638, 0.6284246, 0.6292516, 0.61081785, 0.6114242, 0.6106233],\n",
    "    [0.63396144, 0.63511825, 0.6288564, 0.6226765, 0.6219877, 0.62269145],\n",
    "    [0.6106442, 0.61703616, 0.6183802, 0.616232, 0.6164079, 0.6152731],\n",
    "    [0.6106442, 0.61703616, 0.6183802, 0.616232, 0.6164079, 0.6152731]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibi.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.tiff')] \n",
    "        \n",
    "        # Define a transformation to resize the images\n",
    "        self.transform = transforms.Compose([transforms.Resize((256, 256))])\n",
    "     \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "        \n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        original_image = image.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Convert to a torch tensor \n",
    "        image = torch.tensor(original_image, dtype=torch.float32)\n",
    "\n",
    "        # Apply the resizing transform\n",
    "        image = self.transform(image)\n",
    "\n",
    "        image_numpy = image.numpy()\n",
    "\n",
    "        return image_numpy, original_image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and visualize images\n",
    "dataset = ImageDataset(r\"../../tiff_experiment_unsupervised_data/combined\")\n",
    "for i in range(len(dataset)):\n",
    "    image_numpy, original_image = dataset[i]  # This will get the resized and original images\n",
    "\n",
    "    # Plot the original and resized images side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Display original image\n",
    "    axes[0].imshow(original_image.transpose(1, 2, 0))  # Change shape for imshow (H, W, C)\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')  # Turn off axis\n",
    "\n",
    "    # Display resized image\n",
    "    axes[1].imshow(image_numpy.transpose(1, 2, 0))  # Change shape for imshow (H, W, C)\n",
    "    axes[1].set_title('Resized Image')\n",
    "    axes[1].axis('off')  # Turn off axis\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageData(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.tiff')] \n",
    "        \n",
    "        # Define a transformation to resize the images (Note: Resize expects a PIL image or torchvision tensor)\n",
    "        self.transform = transforms.Resize((256, 256))\n",
    "     \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Print the shape of the loaded image\n",
    "        print(f\"Image {img_path} loaded with shape: {image.shape}\")\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "        \n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        original_image = image.astype(np.float32) / 65535.0\n",
    "        print(original_image.shape)\n",
    "        # Convert to a torch tensor \n",
    "        image = torch.tensor(original_image, dtype=torch.float32)\n",
    "        print(f\"tensor image {image.shape}\")\n",
    "        # Apply resizing using torch.nn.functional.interpolate\n",
    "        image = F.interpolate(image.unsqueeze(0), size=(256, 256), mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "        image_numpy = image.numpy()\n",
    "\n",
    "        # Flatten the resized image for K-Means input (reshape into (3, 256*256))\n",
    "        #reshaped_image = image.view(3, -1).T  # Reshape to (256*256, 3)\n",
    "        #print(f\"Reshaped image shape: {reshaped_image.shape}\")\n",
    "\n",
    "        return original_image, image_numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create dataset and visualize images\n",
    "dataset = ImageData(r\"../../tiff_experiment_unsupervised_data/combined\")\n",
    "for i in range(len(dataset)):\n",
    "    orig_image, image_np = dataset[i]  # This will get the resized and original images\n",
    "\n",
    "    # Plot the original and resized images side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Display original image\n",
    "    axes[0].imshow(orig_image.transpose(1, 2, 0))  # Change shape for imshow (H, W, C)\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')  # Turn off axis\n",
    "\n",
    "    # Display resized image\n",
    "    axes[1].imshow(image_np.transpose(1, 2, 0))  # Change shape for imshow (H, W, C)\n",
    "    axes[1].set_title('Resized Image')\n",
    "    axes[1].axis('off')  # Turn off axis\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    break  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = tiff.imread(r'C:\\Users\\k54739\\Bibin Babu\\thesis\\Data_supervised\\drug_screened\\B02-T01.tiff')\n",
    "\n",
    "# Print the shape of the loaded image\n",
    "print(f\"Image shape {image.shape}\")\n",
    "\n",
    "# Ensure the image has 3 layers (channels)\n",
    "if image.shape[0] != 3:\n",
    "    raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "        \n",
    "# Normalize the 16-bit image to [0, 1]\n",
    "original_image = image.astype(np.float32) / 65535.0\n",
    "print(original_image.shape)\n",
    "# Convert to a torch tensor \n",
    "image = torch.tensor(original_image, dtype=torch.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_with_aspect_ratio(image, target_size):\n",
    "    # Calculate the target size maintaining aspect ratio\n",
    "    h, w = image.shape[1], image.shape[2]\n",
    "    aspect_ratio = w / h\n",
    "    \n",
    "    if aspect_ratio > 1:  # Wider than tall\n",
    "        new_width = target_size\n",
    "        new_height = int(target_size / aspect_ratio)\n",
    "    else:  # Taller than wide\n",
    "        new_height = target_size\n",
    "        new_width = int(target_size * aspect_ratio)\n",
    "\n",
    "    resized_image = F.interpolate(image.unsqueeze(0), size=(new_height, new_width), mode='bilinear', align_corners=False).squeeze(0)\n",
    "    \n",
    "    # Pad to the target size if necessary\n",
    "    padded_image = F.pad(resized_image, (0, target_size - new_width, 0, target_size - new_height), mode='constant', value=0)\n",
    "    return padded_image\n",
    "padded_image = resize_with_aspect_ratio(image,256)\n",
    "print(padded_image.shape)\n",
    "np_image = padded_image.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tifffile as tiff  # Import tifffile for reading TIFF images\n",
    "\n",
    "# Function to resize with aspect ratio while padding\n",
    "def resize_with_aspect_ratio(image, target_size):\n",
    "    # Get original dimensions\n",
    "    h, w = image.shape[1], image.shape[2]  # Assuming image shape is (C, H, W)\n",
    "    aspect_ratio = w / h\n",
    "    \n",
    "    if aspect_ratio > 1:  # Wider than tall\n",
    "        new_w = target_size\n",
    "        new_h = int(target_size / aspect_ratio)\n",
    "    else:  # Taller than wide or square\n",
    "        new_h = target_size\n",
    "        new_w = int(target_size * aspect_ratio)\n",
    "\n",
    "    # Resize using F.interpolate\n",
    "    resized_image = torch.nn.functional.interpolate(\n",
    "        image.unsqueeze(0), size=(new_h, new_w), mode='bilinear', align_corners=False\n",
    "    ).squeeze(0)\n",
    "\n",
    "    # Create a padded image\n",
    "    padded_image = torch.zeros((3, target_size, target_size))  # Create an empty image of target size\n",
    "    padded_image[:, :new_h, :new_w] = resized_image  # Place resized image in the top-left corner\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "# Load the image\n",
    "img_path = r'C:\\Users\\k54739\\Bibin Babu\\thesis\\Data_supervised\\drug_screened\\B02-T01.tiff'\n",
    "image = tiff.imread(img_path)\n",
    "\n",
    "# Print the shape of the loaded image\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "\n",
    "# Ensure the image has 3 layers (channels)\n",
    "if image.shape[0] != 3:\n",
    "    raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "        \n",
    "# Normalize the 16-bit image to [0, 1]\n",
    "original_image = image.astype(np.float32) / 65535.0\n",
    "print(f\"Normalized image shape: {original_image.shape}\")\n",
    "\n",
    "# Convert to a torch tensor \n",
    "image_tensor = torch.tensor(original_image, dtype=torch.float32)\n",
    "\n",
    "# Resize with aspect ratio and pad\n",
    "padded_image = resize_with_aspect_ratio(image_tensor, 256)\n",
    "print(f\"Padded image shape: {padded_image.shape}\")\n",
    "\n",
    "# Convert padded tensor back to numpy array for visualization\n",
    "np_image = padded_image.numpy()\n",
    "\n",
    "# Plot the original and padded images side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Display original image\n",
    "axes[0].imshow(np.transpose(original_image, (1, 2, 0)))  # Transpose for matplotlib\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Display padded image\n",
    "axes[1].imshow(np.transpose(np_image, (1, 2, 0)))  # Transpose for matplotlib\n",
    "axes[1].set_title('Padded Image')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = ImageDataset(r\"../../tiff_experiment_unsupervised_data/combined\")\n",
    "for i in range(len(dataset)):\n",
    "    falttened_image = dataset[i]  # This will print the shape of each image\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an example dataset that we will be using\n",
    "def load_data():\n",
    "    return np.random.rand(300, 2) * 10  # 300 data points with 2 features\n",
    "\n",
    "# Function for random initialization of centroids\n",
    "def kMeans_init_centroids(X, K):\n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    centroids = X[randidx[:K]]\n",
    "    return centroids\n",
    "\n",
    "# Function to find the closest centroids\n",
    "def find_closest_centroids(X, centroids):\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        distances = np.linalg.norm(X[i] - centroids, axis=1)\n",
    "        idx[i] = np.argmin(distances)\n",
    "    return idx\n",
    "\n",
    "# Function to compute new centroids\n",
    "def compute_centroids(X, idx, K):\n",
    "    centroids = np.zeros((K, X.shape[1]))  # Use shape[1] for features\n",
    "    for k in range(K):\n",
    "        points = X[idx == k]\n",
    "        centroids[k] = np.mean(points, axis=0) if len(points) > 0 else centroids[k]\n",
    "    return centroids\n",
    "\n",
    "# Function to run K-Means algorithm\n",
    "def run_kMeans(X, initial_centroids, max_iters=10):\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    idx = np.zeros(X.shape[0])\n",
    "    centroids_history = []\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        print(f\"K-Means iteration {i}/{max_iters - 1}\")\n",
    "        # Assign each data point to the closest centroid\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        # Store the current centroids\n",
    "        centroids_history.append(centroids.copy())\n",
    "        # Compute new centroids\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "\n",
    "    # Final plot after all iterations\n",
    "    plot_progress_kMeans(X, centroids_history, idx, K)\n",
    "    return centroids, idx\n",
    "\n",
    "# Updated plotting function\n",
    "def plot_progress_kMeans(X, centroids_history, idx, K):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Get colors for each cluster\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, K))\n",
    "    \n",
    "    # Plot data points with colors based on their final assignments\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=colors[idx], alpha=0.6)\n",
    "\n",
    "    # Plot all centroid movements\n",
    "    for k in range(K):\n",
    "        for i in range(len(centroids_history) - 1):\n",
    "            plt.plot([centroids_history[i][k, 0], centroids_history[i + 1][k, 0]], \n",
    "                     [centroids_history[i][k, 1], centroids_history[i + 1][k, 1]], \n",
    "                     'k--')  # Draw dashed lines\n",
    "\n",
    "        # Plot the last centroid position\n",
    "        plt.scatter(centroids_history[-1][k, 0], centroids_history[-1][k, 1], marker='x', s=200, c='k', label='Final Centroids' if k == 0 else \"\")\n",
    "\n",
    "    plt.title(\"K-Means Clustering Progress\")\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlim(X[:, 0].min() - 1, X[:, 0].max() + 1)\n",
    "    plt.ylim(X[:, 1].min() - 1, X[:, 1].max() + 1)\n",
    "    plt.show()\n",
    "\n",
    "# Main function to run the K-Means algorithm\n",
    "X = load_data()                 # Step 1: Load dataset\n",
    "K = 3                           # Step 2: Set number of clusters\n",
    "initial_centroids = kMeans_init_centroids(X, K)  # Step 3: Initialize centroids\n",
    "max_iters = 10                  # Step 4: Number of iterations\n",
    "centroids, idx = run_kMeans(X, initial_centroids, max_iters)  # Step 5: Run K-Means\n",
    "print(\"Final centroids:\", centroids)  # Output the final centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
