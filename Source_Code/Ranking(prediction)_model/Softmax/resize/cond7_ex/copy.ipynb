{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "#from helper import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Now you can use the `device` variable\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay,max_epochs):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        # Load the pretrained ResNet-18 model\n",
    "        self.convnet = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "        \n",
    "        # Modify the fully connected layer\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4 * hidden_dim),  # Linear layer with 4*hidden_dim output\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * hidden_dim, 20)  # Output layer with hidden_dim output\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.AdamW(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        self.lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=max_epochs, eta_min=lr / 50)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convnet(x)\n",
    "\n",
    "    def info_nce_loss(self, imgs1, imgs2, device):\n",
    "\n",
    "        imgs = torch.cat((imgs1, imgs2), dim=0)  # Concatenate along the batch dimension\n",
    "        imgs = imgs.to(device)  # Move images to the device\n",
    "\n",
    "        # Encode all images\n",
    "        feats = self.forward(imgs)\n",
    "    \n",
    "        # Calculate cosine similarity\n",
    "        cos_sim = nn.functional.cosine_similarity(feats[:, None, :], feats[None, :, :], dim=-1)\n",
    "    \n",
    "        # Mask out cosine similarity to itself\n",
    "        self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "        cos_sim.masked_fill_(self_mask, -9e15)\n",
    "    \n",
    "        # Find positive example -> batch_size//2 away from the original example\n",
    "        pos_mask = self_mask.roll(shifts=cos_sim.shape[0] // 2, dims=0)\n",
    "    \n",
    "        # Normalize similarity scores by temperature\n",
    "        cos_sim = cos_sim / self.temperature\n",
    "\n",
    "        # InfoNCE loss\n",
    "        nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "        nll = nll.mean()\n",
    "\n",
    "        # Accuracy calculations\n",
    "        # Create a combination of positive and negative similarities for ranking\n",
    "        comb_sim = torch.cat([cos_sim[pos_mask][:, None],  # Positive example in first position\n",
    "                          cos_sim.masked_fill(pos_mask, -9e15)], dim=-1)\n",
    "    \n",
    "        # Sort and get the ranking position of the positive example\n",
    "        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
    "    \n",
    "        # Compute accuracy metrics\n",
    "        top1_acc = (sim_argsort == 0).float().mean()  # Top-1 accuracy\n",
    "        top5_acc = (sim_argsort < 5).float().mean()   # Top-5 accuracy\n",
    "        mean_pos = 1 + sim_argsort.float().mean()     # Mean position of the positive example\n",
    "\n",
    "        return nll, top1_acc, top5_acc, mean_pos\n",
    "\n",
    "    def train_epoch(self, train_loader, device):\n",
    "        self.train()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            imgs1, imgs2, _ = batch\n",
    "            imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "        \n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Calculate loss and accuracy metrics\n",
    "            loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            #self.lr_scheduler.step()\n",
    "\n",
    "            # Accumulate metrics\n",
    "            total_loss += loss.item()\n",
    "            total_top1_acc += top1_acc.item()\n",
    "            total_top5_acc += top5_acc.item()\n",
    "            total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(train_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(train_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(train_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos\n",
    "\n",
    "    def validate_epoch(self, val_loader, device):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "                imgs1, imgs2, _ = batch\n",
    "                imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "\n",
    "                # Calculate loss and accuracy metrics\n",
    "                loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "                # Accumulate metrics\n",
    "                total_loss += loss.item()\n",
    "                total_top1_acc += top1_acc.item()\n",
    "                total_top5_acc += top5_acc.item()\n",
    "                total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(val_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(val_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(val_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(val_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos\n",
    "    \n",
    "\n",
    "    def inference_epoch(self, inference_loader, device):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(inference_loader, desc=\"Inferencing\", leave=False):\n",
    "                imgs1, imgs2, _ = batch\n",
    "                imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "\n",
    "                # Calculate loss and accuracy metrics\n",
    "                loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "                # Accumulate metrics\n",
    "                total_loss += loss.item()\n",
    "                total_top1_acc += top1_acc.item()\n",
    "                total_top5_acc += top5_acc.item()\n",
    "                total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(inference_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(inference_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(inference_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(inference_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "model_path = r'C:\\Users\\k54739\\Bibi_new_thesis\\saved_model\\resize_simclr_modelepoch250.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_17784\\1145718020.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  simclr_model = torch.load(model_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (convnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=512, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simclr_model = torch.load(model_path)\n",
    "simclr_model.to(device)\n",
    "simclr_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference before projection head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledImageDataset(Dataset):\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "\n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Convert to a torch tensor and add channel dimension\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        \n",
    "        # Apply resize transform\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def load_and_split_data(root_dir, test_size=0.2):\n",
    "    #classes = ['untreated', 'single_dose', 'drug_screened']\n",
    "    classes = ['control', 'ex_40']\n",
    "    image_files = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(root_dir, class_name)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir) if file.endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        labels.extend([idx] * len(files))\n",
    "    \n",
    "    # Check if the labels correctly reflect the classes\n",
    "    #print(\"Label distribution:\", {classes[i]: labels.count(i) for i in range(len(classes))})\n",
    "    \n",
    "    # Split data into training and test sets\n",
    "    train_files, test_files, train_labels, test_labels = train_test_split(\n",
    "        image_files, labels, test_size=test_size, stratify=labels, random_state=42)\n",
    "\n",
    "    return train_files, test_files, train_labels, test_labels\n",
    "\n",
    "\n",
    "# Directories for labeled data\n",
    "image_dir = r\"G:\\train_ex\"\n",
    "\n",
    "# Load and split the data\n",
    "train_files, test_files, train_labels, test_labels = load_and_split_data(image_dir, test_size=0.2)\n",
    "\n",
    "# Create the labeled datasets\n",
    "train_labeled_dataset = LabeledImageDataset(train_files, train_labels)\n",
    "test_labeled_dataset = LabeledImageDataset(test_files, test_labels)\n",
    "\n",
    "# Define DataLoaders\n",
    "batch_size = 16\n",
    "train_loader_labeled = DataLoader(train_labeled_dataset, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=0)\n",
    "test_loader_labeled = DataLoader(test_labeled_dataset, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 96, 96]) torch.Size([16]) torch.float32\n",
      "tensor([1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "for anchor,label in train_loader_labeled:\n",
    "    print(anchor.shape, label.shape, anchor.dtype)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize a counter\n",
    "total_images = 0\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for anchor, label in train_loader_labeled:\n",
    "    total_images += anchor.size(0)  # Increment by the batch size (number of images in the current batch)\n",
    "\n",
    "# Print the total number of images\n",
    "print(f\"Total number of images in train_loader_labeled: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize a counter\n",
    "total_images = 0\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for anchor, label in test_loader_labeled:\n",
    "    total_images += anchor.size(0)  # Increment by the batch size (number of images in the current batch)\n",
    "\n",
    "# Print the total number of images\n",
    "print(f\"Total number of images in test_loader_labeled: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_data_features(model, dataloader):\n",
    "    # Prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    # Encode all images\n",
    "    feats, labels = [], []\n",
    "    for batch_imgs, batch_labels in tqdm(dataloader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        print(f\"Batch features shape: {batch_feats.shape}\")\n",
    "        print(f\"Batch labels shape: {batch_labels.shape}\")\n",
    "        \n",
    "        feats.append(batch_feats.detach().cpu())\n",
    "        labels.append(batch_labels)\n",
    "\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    \n",
    "    print(f\"Features shape after concatenation: {feats.shape}\")\n",
    "    print(f\"Labels shape after concatenation: {labels.shape}\")\n",
    "\n",
    "    return torch.utils.data.TensorDataset(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:05<00:39,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:11<00:35,  5.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:17<00:29,  5.98s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:23<00:23,  5.86s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [00:28<00:16,  5.52s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [00:34<00:11,  5.58s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [00:40<00:05,  5.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:45<00:00,  5.74s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Features shape after concatenation: torch.Size([128, 512])\n",
      "Labels shape after concatenation: torch.Size([128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:06<00:06,  6.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:12<00:00,  6.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Features shape after concatenation: torch.Size([32, 512])\n",
      "Labels shape after concatenation: torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract features for train and test datasets\n",
    "train_feats_simclr = prepare_data_features(simclr_model, train_loader_labeled)\n",
    "test_feats_simclr = prepare_data_features(simclr_model, test_loader_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model definition\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, feature_dim, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_logistic_regression(model, train_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch_feats, batch_labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        batch_feats, batch_labels = batch_feats.to(device), batch_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_feats)\n",
    "        loss = nn.functional.cross_entropy(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_logistic_regression(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_feats, batch_labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            batch_feats, batch_labels = batch_feats.to(device), batch_labels.to(device)\n",
    "            \n",
    "            outputs = model(batch_feats)\n",
    "            loss = nn.functional.cross_entropy(outputs, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logreg_simplified(batch_size, train_feats_data, test_feats_data, feature_dim, num_classes, lr=5e-4, weight_decay=1e-4, max_epochs=50):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_feats_data, batch_size=batch_size, shuffle=True,\n",
    "                              drop_last=False, pin_memory=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_feats_data, batch_size=batch_size, shuffle=False,\n",
    "                             drop_last=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "    # Model, loss, and optimizer\n",
    "    model = LogisticRegression(feature_dim, num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                               milestones=[int(max_epochs * 0.6), int(max_epochs * 0.8)],\n",
    "                                               gamma=0.1)\n",
    "\n",
    "    # Store metrics for plotting\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    # Track best by accuracy\n",
    "    best_test_acc = -1.0\n",
    "    best_model_state_acc = None\n",
    "\n",
    "    # Track best by loss (with accuracy as a tiebreaker)\n",
    "    best_test_loss = float('inf')\n",
    "    best_test_loss_acc = -1.0\n",
    "    best_model_state_loss = None\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{max_epochs}\")\n",
    "\n",
    "        train_loss, train_acc = train_logistic_regression(model, train_loader, optimizer, scheduler, device)\n",
    "        test_loss, test_acc = evaluate_logistic_regression(model, test_loader, criterion, device)\n",
    "\n",
    "        print(f\"Training loss: {train_loss:.4f}, Training accuracy: {train_acc:.4f}\")\n",
    "        print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        test_accuracies.append(test_acc)\n",
    "\n",
    "        # Check for best accuracy model\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            best_model_state_acc = model.state_dict()\n",
    "\n",
    "        # Check for best loss model\n",
    "        # Condition: strictly lower loss OR equal loss but higher accuracy\n",
    "        if (test_loss < best_test_loss) or (test_loss == best_test_loss and test_acc > best_test_loss_acc):\n",
    "            best_test_loss = test_loss\n",
    "            best_test_loss_acc = test_acc\n",
    "            best_model_state_loss = model.state_dict()\n",
    "\n",
    "    # Now we have two best states: best_model_state_acc and best_model_state_loss\n",
    "    # Create two separate model instances for them\n",
    "    best_acc_model = LogisticRegression(feature_dim, num_classes).to(device)\n",
    "    best_acc_model.load_state_dict(best_model_state_acc)\n",
    "    best_acc_model.eval()\n",
    "\n",
    "    best_loss_model = LogisticRegression(feature_dim, num_classes).to(device)\n",
    "    best_loss_model.load_state_dict(best_model_state_loss)\n",
    "    best_loss_model.eval()\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Loss curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(max_epochs), train_losses, label='Train Loss')\n",
    "    plt.plot(range(max_epochs), test_losses, label='Test Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(max_epochs), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(max_epochs), test_accuracies, label='Test Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Return both models and the final results (e.g., last train_acc and test_acc recorded)\n",
    "    return best_acc_model, best_loss_model, {\"train_acc\": train_acc, \"test_acc\": test_acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 655.27it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1000.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2569, Training accuracy: 0.9297\n",
      "Test loss: 0.1022, Test accuracy: 1.0000\n",
      "Epoch 2/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 727.20it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 999.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0876, Training accuracy: 0.9922\n",
      "Test loss: 0.0517, Test accuracy: 1.0000\n",
      "Epoch 3/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 888.95it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1998.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0416, Training accuracy: 0.9922\n",
      "Test loss: 0.0306, Test accuracy: 1.0000\n",
      "Epoch 4/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1331.95it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1000.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0227, Training accuracy: 1.0000\n",
      "Test loss: 0.0237, Test accuracy: 1.0000\n",
      "Epoch 5/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1141.93it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2000.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0170, Training accuracy: 1.0000\n",
      "Test loss: 0.0210, Test accuracy: 1.0000\n",
      "Epoch 6/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1334.49it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2007.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0138, Training accuracy: 1.0000\n",
      "Test loss: 0.0189, Test accuracy: 1.0000\n",
      "Epoch 7/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1333.64it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1994.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0115, Training accuracy: 1.0000\n",
      "Test loss: 0.0170, Test accuracy: 1.0000\n",
      "Epoch 8/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1331.84it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1977.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0100, Training accuracy: 1.0000\n",
      "Test loss: 0.0153, Test accuracy: 1.0000\n",
      "Epoch 9/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1333.43it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2023.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0090, Training accuracy: 1.0000\n",
      "Test loss: 0.0141, Test accuracy: 1.0000\n",
      "Epoch 10/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1119.38it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2001.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0081, Training accuracy: 1.0000\n",
      "Test loss: 0.0128, Test accuracy: 1.0000\n",
      "Epoch 11/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1141.19it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1984.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0074, Training accuracy: 1.0000\n",
      "Test loss: 0.0119, Test accuracy: 1.0000\n",
      "Epoch 12/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1530.42it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1999.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0067, Training accuracy: 1.0000\n",
      "Test loss: 0.0111, Test accuracy: 1.0000\n",
      "Epoch 13/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1114.73it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1999.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0062, Training accuracy: 1.0000\n",
      "Test loss: 0.0105, Test accuracy: 1.0000\n",
      "Epoch 14/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 734.36it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 936.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0058, Training accuracy: 1.0000\n",
      "Test loss: 0.0100, Test accuracy: 1.0000\n",
      "Epoch 15/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 666.69it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1977.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0096, Test accuracy: 1.0000\n",
      "Epoch 16/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 789.24it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2015.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0050, Training accuracy: 1.0000\n",
      "Test loss: 0.0090, Test accuracy: 1.0000\n",
      "Epoch 17/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1308.98it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2000.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0046, Training accuracy: 1.0000\n",
      "Test loss: 0.0086, Test accuracy: 1.0000\n",
      "Epoch 18/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1307.40it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1998.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0044, Training accuracy: 1.0000\n",
      "Test loss: 0.0082, Test accuracy: 1.0000\n",
      "Epoch 19/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1118.82it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1998.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0041, Training accuracy: 1.0000\n",
      "Test loss: 0.0078, Test accuracy: 1.0000\n",
      "Epoch 20/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1291.85it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2011.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0039, Training accuracy: 1.0000\n",
      "Test loss: 0.0075, Test accuracy: 1.0000\n",
      "Epoch 21/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1287.68it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2014.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0036, Training accuracy: 1.0000\n",
      "Test loss: 0.0073, Test accuracy: 1.0000\n",
      "Epoch 22/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1309.29it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2000.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0070, Test accuracy: 1.0000\n",
      "Epoch 23/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1333.22it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1999.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0033, Training accuracy: 1.0000\n",
      "Test loss: 0.0067, Test accuracy: 1.0000\n",
      "Epoch 24/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1331.84it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1739.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0031, Training accuracy: 1.0000\n",
      "Test loss: 0.0065, Test accuracy: 1.0000\n",
      "Epoch 25/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1333.59it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1999.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0029, Training accuracy: 1.0000\n",
      "Test loss: 0.0063, Test accuracy: 1.0000\n",
      "Epoch 26/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1332.05it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1998.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0028, Training accuracy: 1.0000\n",
      "Test loss: 0.0061, Test accuracy: 1.0000\n",
      "Epoch 27/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1141.85it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1998.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0027, Training accuracy: 1.0000\n",
      "Test loss: 0.0059, Test accuracy: 1.0000\n",
      "Epoch 28/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1302.38it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2000.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0026, Training accuracy: 1.0000\n",
      "Test loss: 0.0056, Test accuracy: 1.0000\n",
      "Epoch 29/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1304.86it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2013.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0024, Training accuracy: 1.0000\n",
      "Test loss: 0.0055, Test accuracy: 1.0000\n",
      "Epoch 30/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1304.05it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0024, Training accuracy: 1.0000\n",
      "Test loss: 0.0053, Test accuracy: 1.0000\n",
      "Epoch 31/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1305.52it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2001.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0022, Training accuracy: 1.0000\n",
      "Test loss: 0.0052, Test accuracy: 1.0000\n",
      "Epoch 32/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1309.08it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2015.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0022, Training accuracy: 1.0000\n",
      "Test loss: 0.0050, Test accuracy: 1.0000\n",
      "Epoch 33/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1141.27it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1996.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0049, Test accuracy: 1.0000\n",
      "Epoch 34/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1312.93it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2002.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0020, Training accuracy: 1.0000\n",
      "Test loss: 0.0047, Test accuracy: 1.0000\n",
      "Epoch 35/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1141.70it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2011.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0046, Test accuracy: 1.0000\n",
      "Epoch 36/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1129.97it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1698.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0045, Test accuracy: 1.0000\n",
      "Epoch 37/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1141.19it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2001.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0044, Test accuracy: 1.0000\n",
      "Epoch 38/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1123.54it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2019.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0043, Test accuracy: 1.0000\n",
      "Epoch 39/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1120.16it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2000.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0042, Test accuracy: 1.0000\n",
      "Epoch 40/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1120.05it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2001.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0041, Test accuracy: 1.0000\n",
      "Epoch 41/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1302.07it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2035.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0040, Test accuracy: 1.0000\n",
      "Epoch 42/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 637.92it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 999.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0040, Test accuracy: 1.0000\n",
      "Epoch 43/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 658.02it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2006.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0039, Test accuracy: 1.0000\n",
      "Epoch 44/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 788.25it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2001.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0038, Test accuracy: 1.0000\n",
      "Epoch 45/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1301.67it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1999.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0037, Test accuracy: 1.0000\n",
      "Epoch 46/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1331.63it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2001.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0036, Test accuracy: 1.0000\n",
      "Epoch 47/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1333.43it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2000.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0035, Test accuracy: 1.0000\n",
      "Epoch 48/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1141.81it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1622.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0035, Test accuracy: 1.0000\n",
      "Epoch 49/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1600.65it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1767.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0034, Test accuracy: 1.0000\n",
      "Epoch 50/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1141.93it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 34952.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0033, Test accuracy: 1.0000\n",
      "Epoch 51/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1141.81it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1983.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0033, Test accuracy: 1.0000\n",
      "Epoch 52/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1142.94it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1975.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0032, Test accuracy: 1.0000\n",
      "Epoch 53/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1123.27it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2001.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0031, Test accuracy: 1.0000\n",
      "Epoch 54/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 571.67it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 941.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0031, Test accuracy: 1.0000\n",
      "Epoch 55/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 982.24it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2023.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0030, Test accuracy: 1.0000\n",
      "Epoch 56/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1308.32it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2005.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0030, Test accuracy: 1.0000\n",
      "Epoch 57/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1118.29it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2016.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0030, Test accuracy: 1.0000\n",
      "Epoch 58/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1143.06it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2019.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 59/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1305.72it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 999.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 60/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1119.97it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1003.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 61/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1313.54it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1000.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 62/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1306.43it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2010.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 63/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1331.79it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2013.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 64/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1331.90it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2003.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 65/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1332.05it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2014.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 66/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1142.08it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2014.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 67/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1332.00it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1002.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 68/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1332.11it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1999.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 69/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1132.75it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2006.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 70/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 561.47it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 666.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 71/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 999.24it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2001.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 72/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 982.33it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2002.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 73/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1563.80it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1984.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 74/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1287.68it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1998.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 75/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1108.21it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2000.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 76/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1281.29it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 999.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 77/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1283.25it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1999.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 78/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1279.68it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2000.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 79/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1334.49it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1999.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 80/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1331.95it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1582.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 81/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 799.49it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1999.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 82/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1119.34it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1985.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 83/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1283.05it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2010.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 84/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1331.84it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2014.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 85/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1333.11it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1608.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 86/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1346.32it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1985.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 87/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1331.84it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1701.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 88/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1333.48it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1999.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0029, Test accuracy: 1.0000\n",
      "Epoch 89/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1295.59it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2013.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 90/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1304.35it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1999.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 91/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1305.01it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2000.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 92/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1307.60it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2014.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 93/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1141.38it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2014.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 94/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1304.81it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1003.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 95/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1124.29it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2014.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 96/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1125.72it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1753.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 97/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 657.43it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 629.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 98/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 615.40it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 2016.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 99/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 873.59it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1817.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 100/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 1141.89it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1780.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 101/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 376.12it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 667.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 102/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 412.00it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 103/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 414.79it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 666.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 104/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 437.29it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 105/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 395.96it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 501.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 106/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 380.95it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 478.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 107/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 343.19it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 108/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 379.02it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 109/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 361.96it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 110/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 361.26it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 111/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 413.20it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 112/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 417.48it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 666.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 113/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 435.06it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 114/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 421.07it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 115/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 421.05it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 484.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 116/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 467.89it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 117/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 397.26it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 664.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 118/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 419.24it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 483.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 119/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 418.85it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 285.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 120/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 345.82it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 121/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 417.87it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 122/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 419.03it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 389.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 123/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 380.06it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 124/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 395.28it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 125/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 418.34it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 126/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 380.85it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 127/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 418.17it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 486.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 128/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 419.01it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 129/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 378.36it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 666.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 130/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 271.52it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 482.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 131/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 399.87it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 383.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 132/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 440.70it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 133/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 400.00it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 667.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 134/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 416.39it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 485.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 135/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 418.89it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 333.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 136/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 378.94it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 137/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 346.27it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 138/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 397.55it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 139/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 418.42it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 140/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 416.56it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 141/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 397.43it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 142/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 380.93it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 481.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 143/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 419.02it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 484.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 144/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 306.82it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 145/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 378.64it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 146/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 397.64it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 147/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 415.60it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 498.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 148/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 421.05it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 149/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 437.52it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 150/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 378.24it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 151/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 376.72it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 666.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 152/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 500.06it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 153/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 441.34it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 154/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 417.42it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 155/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 368.42it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 285.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 156/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 292.83it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 386.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 157/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 444.61it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 667.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 158/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 392.28it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 159/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 444.38it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 497.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 160/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 392.28it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 161/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 378.52it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 162/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 397.58it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 163/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 361.80it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 497.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 164/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 378.26it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 165/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 377.13it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 166/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 417.97it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 167/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 376.04it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 667.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 168/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 420.91it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 169/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 398.12it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 170/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 379.21it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 171/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 375.61it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 480.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 172/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 318.70it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 173/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 359.86it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 174/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 395.61it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 175/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 380.89it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 480.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 176/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 377.95it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 177/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 318.55it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 398.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 178/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 318.55it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 179/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 292.69it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 180/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 395.47it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 181/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 415.19it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 471.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 182/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 410.40it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 183/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 444.44it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 184/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 361.48it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 185/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 345.85it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 186/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 416.92it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 187/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 397.40it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 188/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 318.27it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 189/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 360.69it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 327.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 190/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 396.42it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 191/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 358.91it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 192/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 331.89it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 193/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 318.29it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 481.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 194/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 362.15it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 195/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 397.12it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 332.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 196/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 306.12it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 197/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 378.28it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 198/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 396.63it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 199/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 329.89it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 666.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 200/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 377.44it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 201/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 360.46it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 202/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 239.88it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 203/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 285.74it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 204/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 328.45it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 205/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 323.57it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 666.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 206/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 347.80it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 207/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 357.12it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 485.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 208/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 306.06it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 485.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 209/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 344.07it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 210/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 376.35it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 211/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 318.46it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 212/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 377.17it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 213/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 293.99it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 214/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 305.08it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 487.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 215/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 317.16it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 665.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 216/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 331.14it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 217/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 306.28it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 218/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 283.04it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 219/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 362.08it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 482.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 220/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 360.49it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 221/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 344.82it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 222/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 360.23it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 650.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 223/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 329.01it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 498.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 224/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 283.69it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 488.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 225/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 318.40it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 640.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 226/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 360.10it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 490.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 227/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 280.84it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 333.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 228/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 281.81it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 229/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 344.58it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 333.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 230/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 341.40it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 470.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 231/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 311.25it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 501.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 232/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 313.82it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 233/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 316.98it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 483.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 234/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 331.71it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 501.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 235/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 339.44it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 236/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 379.07it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 237/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 305.43it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 238/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 374.76it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 239/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 345.70it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 240/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 343.44it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 241/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 293.79it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 391.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 242/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 345.99it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 488.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 243/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 315.64it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 244/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 317.56it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 245/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 295.39it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 478.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 246/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 345.14it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 247/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 295.09it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 248/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 318.64it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 498.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 249/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 319.98it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 250/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 192.79it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 251/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 261.71it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 387.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 252/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 344.78it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 253/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 305.62it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 254/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 220.33it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 255/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 281.82it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 256/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 372.33it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 257/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 374.70it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 258/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 347.83it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 259/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 330.68it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 260/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 346.40it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 261/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 331.61it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 333.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 262/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 241.53it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 462.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 263/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 265.89it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 264/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 306.36it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 328.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 265/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 345.02it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 266/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 303.90it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 390.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 267/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 329.80it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 268/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 307.77it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 326.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 269/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 282.67it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 388.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 270/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 302.03it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 271/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 343.57it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 272/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 328.66it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 475.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 273/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 314.40it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 627.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 274/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 318.05it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 275/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 396.63it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 385.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 276/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 413.95it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 665.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 277/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 373.23it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 666.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 278/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 372.38it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 279/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 394.53it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1998.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 280/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 328.48it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 483.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 281/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 394.58it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 327.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 282/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 394.90it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 665.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 283/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 376.12it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 284/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 341.25it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 285/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 391.81it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 479.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 286/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 372.80it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 480.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 287/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 342.20it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 486.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 288/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 346.86it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 327.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 289/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 318.81it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 290/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 363.52it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 329.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 291/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 330.27it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 292/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 363.35it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 293/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 347.81it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 473.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 294/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 342.15it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 621.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 295/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 288.90it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 296/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 374.81it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 297/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 419.05it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 298/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 374.65it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 643.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 299/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 345.90it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 485.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 300/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 346.09it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 484.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 301/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 361.64it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 484.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 302/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 417.97it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 498.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 303/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 395.31it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 304/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 439.29it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 305/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 377.09it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 306/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 396.72it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 307/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 394.97it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 308/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 377.24it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 485.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 309/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 394.70it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 388.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 310/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 374.97it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 311/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 361.20it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 665.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 312/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 318.82it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 381.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 313/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 304.60it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1003.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 314/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 295.32it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 502.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 315/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 305.10it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 316/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 330.89it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 475.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 317/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 375.12it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 393.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 318/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 358.12it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 319/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 392.16it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 498.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 320/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 317.47it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 398.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 321/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 317.56it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 487.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 322/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 330.07it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 323/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 394.98it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 385.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 324/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 358.50it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 481.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 325/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 393.74it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 326/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 329.18it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 327/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 388.62it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 332.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 328/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 344.58it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 329/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 358.11it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 330/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 359.31it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 665.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 331/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 328.14it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 473.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 332/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 373.20it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 333/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 378.96it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 398.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 334/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 343.92it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 335/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 318.77it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 336/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 306.32it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 337/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 257.31it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 285.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 338/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 228.58it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 339/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 377.75it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 625.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 340/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 319.91it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 341/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 305.20it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 342/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 344.91it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 333.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 343/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 275.85it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 344/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 293.88it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 345/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 306.16it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0026, Test accuracy: 1.0000\n",
      "Epoch 346/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 360.49it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 347/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 363.65it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 348/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 275.86it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 476.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 349/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 347.74it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 350/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 306.23it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 498.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 351/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 265.35it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 395.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 352/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 304.96it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 333.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 353/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 188.59it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 354/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 330.50it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 487.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 355/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 358.75it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 482.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 356/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 357.55it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 384.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 357/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 315.58it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 327.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 358/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 377.96it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 359/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 360.24it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 485.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 360/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 331.80it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 361/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 317.47it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 498.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 362/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 376.86it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 363/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 377.18it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 364/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 342.94it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 365/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 330.44it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 665.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 366/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 344.98it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 367/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 373.52it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 368/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 376.74it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 333.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 369/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 375.39it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 665.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 370/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 293.85it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 666.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 371/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 345.64it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 485.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 372/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 316.98it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 485.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 373/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 373.19it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 393.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 374/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 375.51it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 375/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 342.64it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 664.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 376/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 317.53it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 995.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 377/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 392.82it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 333.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 378/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 340.55it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 326.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 379/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 344.31it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 323.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 380/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 358.66it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 486.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 381/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 345.76it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 626.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 382/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 343.43it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 484.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 383/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 280.62it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 384/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 294.88it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 385/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 341.26it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 386/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 373.42it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 493.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 387/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 341.81it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 388/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 341.69it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 389/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 355.12it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 390/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 374.11it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 391/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 327.87it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 392/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 328.95it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 487.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 393/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 317.58it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 485.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 394/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 305.02it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 395/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 217.58it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 178.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 396/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 170.09it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 244.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 397/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 179.80it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 219.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 398/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 175.63it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 216.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 399/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 133.30it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 400/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 168.18it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 219.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 401/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 160.81it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 216.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 402/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 166.94it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 196.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 403/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 146.61it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 217.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 404/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 146.08it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 217.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 405/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 312.98it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 389.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 406/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 375.73it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 407/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 329.60it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 640.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 408/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 344.54it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 473.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 409/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 339.80it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 626.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 410/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 328.17it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 411/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 293.27it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 412/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 375.76it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 332.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 413/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 330.98it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 389.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 414/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 343.78it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 487.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 415/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 341.79it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 484.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 416/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 315.76it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 417/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 392.35it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 415.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 418/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 317.70it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 419/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 360.67it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 420/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 359.78it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 421/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 361.51it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 665.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 422/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 341.93it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 423/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 326.70it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 424/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 374.32it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 498.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 425/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 388.54it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 666.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 426/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 377.51it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 487.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 427/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 330.42it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 486.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 428/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 315.88it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 429/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 392.87it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 430/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 359.58it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 392.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 431/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 361.77it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 432/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 438.39it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 488.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 433/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 346.60it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 487.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 434/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 360.57it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 394.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 435/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 361.97it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 498.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 436/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 331.51it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 642.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 437/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 274.85it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 438/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 306.17it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 439/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 296.23it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 665.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 440/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 343.39it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 441/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 347.73it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 442/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 363.64it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 443/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 380.82it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 444/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 257.20it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 445/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 378.65it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 392.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 446/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 304.82it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 447/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 285.71it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0024, Test accuracy: 1.0000\n",
      "Epoch 448/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 343.95it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 449/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 355.36it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 323.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 450/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 344.94it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 322.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 451/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 328.82it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 378.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 452/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 329.11it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 453/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 344.65it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 454/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 304.56it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 328.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 455/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 284.52it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 325.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 456/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 231.82it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 457/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 302.47it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 382.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 458/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 372.62it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 473.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 459/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 341.29it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 623.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 460/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 337.68it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 486.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 461/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 356.59it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 323.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 462/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 178.14it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 463/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 184.74it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 246.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 464/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 188.24it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 465/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 184.34it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 246.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 466/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 179.56it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 244.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 467/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 174.53it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 222.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 468/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 177.89it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 243.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 469/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 118.62it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 199.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 470/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 130.87it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 153.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 471/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 163.40it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 472/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 363.64it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 483.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 473/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 307.64it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 666.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 474/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 320.00it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 475/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 332.10it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 476/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 307.71it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 483.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 477/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 284.45it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 478/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 313.13it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 488.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 479/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 291.96it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 480/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 327.61it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 481/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 342.61it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 482/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 374.04it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 483/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 343.17it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 667.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 484/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 363.65it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 664.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 485/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 347.82it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 486/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 295.71it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 496.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 487/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 295.21it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 488/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 296.22it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 494.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 489/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 293.76it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 666.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 490/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 314.69it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 491/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 315.29it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 492/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 315.12it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 473.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 493/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 327.37it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 636.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 494/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 376.31it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 645.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 495/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 376.83it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 496/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 342.67it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 359.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 497/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 244.22it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 501.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 498/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 394.73it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 385.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 499/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 375.41it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 482.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 500/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 359.73it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 475.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 501/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 329.65it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 502/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 316.90it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 503/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 307.62it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 666.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 504/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 328.10it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 476.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 505/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 360.72it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 477.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 506/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 358.31it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 390.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 507/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 359.31it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 484.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 508/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 330.27it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 483.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 509/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 328.76it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 629.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 510/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 374.39it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 477.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 511/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 357.21it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 498.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 512/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 331.35it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 625.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 513/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 344.35it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 473.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 514/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 341.55it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 620.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 515/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 391.84it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 478.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 516/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 358.55it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 480.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 517/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 341.84it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 621.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 518/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 377.68it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 666.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 519/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 412.22it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 520/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 358.23it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 521/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 341.38it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 522/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 353.30it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 523/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 315.78it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 488.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 524/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 344.38it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 486.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 525/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 329.25it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 486.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 526/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 373.25it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 392.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 527/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 344.23it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 528/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 360.78it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 665.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 529/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 171.46it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 245.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 530/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 170.91it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 217.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 531/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 176.12it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 285.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 532/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 186.28it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 275.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 533/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 201.10it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 197.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 534/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 123.73it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 132.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 535/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 120.43it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 217.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0022, Test accuracy: 1.0000\n",
      "Epoch 536/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 147.54it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 199.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 537/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 143.10it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 164.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 538/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 196.73it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 479.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 539/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 329.75it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 540/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 377.08it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 332.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 541/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 341.44it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 333.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 542/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 376.60it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 543/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 325.31it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 544/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 322.42it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 545/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 325.52it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 476.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 546/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 342.05it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 385.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 547/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 359.47it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 321.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 548/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 393.58it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 476.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 549/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 341.97it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 550/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 342.29it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 475.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 551/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 374.59it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 552/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 342.66it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 385.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 553/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 356.92it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 477.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 554/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 376.97it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 489.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 555/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 317.41it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 482.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 556/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 301.60it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 557/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 315.21it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 501.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 558/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 325.17it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 472.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 559/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 358.08it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 560/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 391.02it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 561/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 324.89it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 562/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 325.28it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 563/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 345.24it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 498.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 564/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 374.31it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 565/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 371.94it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 566/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 391.60it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 567/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 333.02it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 568/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 358.67it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 569/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 391.82it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 666.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 570/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 376.88it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 571/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 249.95it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 279.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 572/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 339.20it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 333.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 573/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 389.11it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 574/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 340.65it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 575/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 335.75it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 576/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 375.08it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 577/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 344.00it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 333.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 578/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 374.60it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 579/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 358.34it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 580/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 328.18it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 581/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 375.09it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 582/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 412.07it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 453.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 583/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 342.80it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 584/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 342.29it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 585/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 340.17it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 586/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 325.22it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 471.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 587/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 340.94it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 391.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 588/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 360.05it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 481.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 589/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 373.93it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 473.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 590/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 341.10it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 476.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 591/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 342.21it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 481.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 592/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 317.26it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 593/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 373.88it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 487.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 594/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 391.54it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 325.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 595/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 357.01it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 471.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 596/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 360.35it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 597/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 315.36it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 598/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 327.98it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 599/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 388.58it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 600/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 328.69it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 482.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 601/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 355.57it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 602/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 234.49it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 333.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 603/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 254.54it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 332.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 604/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 358.09it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 605/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 372.42it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 665.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 606/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 352.83it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 607/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 313.71it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 643.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 608/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 281.71it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 609/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 302.52it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 610/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 282.16it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 625.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 611/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 343.08it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 612/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 327.30it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 613/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 411.46it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 385.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 614/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 342.03it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 385.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0020, Test accuracy: 1.0000\n",
      "Epoch 615/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 392.57it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 475.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 616/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 313.50it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 497.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 617/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 290.45it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 480.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 618/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 315.79it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 486.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 619/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 256.81it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 274.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 620/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 277.33it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 476.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 621/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 301.96it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 622/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 356.24it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 623/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 372.79it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 381.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 624/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 360.55it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 488.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 625/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 317.59it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 626/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 330.73it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 627/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 376.54it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 628/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 359.58it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 629/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 357.79it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 333.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 630/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 357.68it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 500.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 631/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 339.23it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 632/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 344.89it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 485.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 633/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 317.42it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 471.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 634/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 304.17it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 635/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 396.25it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 333.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 636/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 358.17it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 332.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 637/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 416.37it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 638/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 331.07it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 399.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 639/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 303.94it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 499.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 640/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 255.73it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 219.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 641/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 197.68it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 235.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 642/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 143.92it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 222.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 643/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 175.16it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 285.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 644/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 162.74it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 222.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 645/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 172.56it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 285.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 646/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 200.00it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 216.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 647/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 180.92it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 199.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 648/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 185.26it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 277.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 649/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 183.13it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 217.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 650/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 181.45it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 218.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 651/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 178.54it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 652/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 176.99it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 285.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 653/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 190.45it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 222.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 654/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 181.78it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 246.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 655/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 176.74it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 656/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 180.90it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 246.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 657/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 158.10it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 285.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 658/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 159.98it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 659/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 168.64it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 660/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 199.02it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 217.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 661/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 186.59it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 277.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 662/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 186.83it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 663/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 177.69it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 278.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 664/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 191.17it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 280.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 665/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 176.92it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 285.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 666/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 181.79it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 250.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 667/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 177.75it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 222.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 668/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 186.02it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 669/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 158.96it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 670/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 182.64it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 276.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 671/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 183.17it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 672/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 203.16it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 222.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 673/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 203.53it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 279.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 674/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 196.66it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 400.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 675/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 194.35it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 286.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 676/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 158.19it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 133.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 677/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 190.51it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 277.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 678/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 195.53it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 243.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 679/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 167.38it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 196.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 680/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 195.35it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 285.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 681/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 186.02it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 682/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 173.89it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 250.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 683/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 173.51it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 199.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 684/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 136.77it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 685/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 155.72it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 285.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 686/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 180.53it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 276.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 687/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 178.11it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 243.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 688/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 183.09it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 689/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 168.27it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 199.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 690/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 132.45it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 142.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 691/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 148.13it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 997.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 692/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 164.24it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 277.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 693/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 168.61it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 694/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 179.30it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 250.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 695/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 180.16it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 250.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 696/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 113.81it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 278.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 697/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 162.30it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 277.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 698/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 157.86it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 246.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 699/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 185.76it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 244.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 700/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 192.17it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 246.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 701/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 189.14it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 281.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 702/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 186.19it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 244.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 703/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 188.42it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 278.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 704/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 189.54it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 243.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 705/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 173.92it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 243.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 706/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 187.90it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 707/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 199.68it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 222.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 708/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 181.80it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 280.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 709/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 215.38it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 243.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 710/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 138.14it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 276.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 711/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 159.24it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 244.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 712/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 170.75it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 285.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 713/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 181.90it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 276.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 714/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 168.45it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 278.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 715/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 183.26it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 243.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 716/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 185.13it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 285.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 717/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 168.07it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 245.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 718/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 186.73it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 243.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 719/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 152.10it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 281.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 720/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 202.10it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 244.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 721/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 195.64it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 217.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 722/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 175.29it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 285.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 723/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 190.69it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 243.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 724/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 160.00it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 326.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 725/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 186.52it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 243.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 726/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 181.60it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 243.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 727/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 191.52it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 217.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 728/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 172.91it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 243.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 729/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 171.90it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 249.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 730/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 177.95it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 245.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 731/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 170.69it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 216.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 732/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 174.49it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 243.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 733/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 182.53it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 243.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 734/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 186.18it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 285.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 735/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 187.36it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 277.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 736/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 169.85it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 277.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 737/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 166.82it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 333.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 738/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 167.14it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 244.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 739/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 188.21it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 242.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 740/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 186.96it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 322.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 741/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 166.86it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 277.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 742/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 183.91it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 321.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 743/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 199.39it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 244.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 744/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 196.07it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 285.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 745/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 218.48it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 161.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 746/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 122.69it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 250.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 747/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 149.02it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 245.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 748/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 182.66it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 178.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 749/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 159.37it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 219.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 750/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 183.02it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 217.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the logistic regression model\n",
    "# Example usage:\n",
    "best_acc_model, best_loss_model, results = train_logreg_simplified(\n",
    "    batch_size=16,\n",
    "    train_feats_data=train_feats_simclr,\n",
    "    test_feats_data=test_feats_simclr,\n",
    "    feature_dim=train_feats_simclr.tensors[0].shape[1],\n",
    "    num_classes=2,\n",
    "    lr=5e-4,\n",
    "    weight_decay=1e-4,\n",
    "    max_epochs=750\n",
    ")\n",
    "#print(f\"Final Train Accuracy: {results['train_acc']:.4f}, Final Test Accuracy: {results['test_acc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (linear): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model= best_loss_model\n",
    "logreg_model\n",
    "logreg_model.eval()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the logistic regression model\n",
    "# Example usage:\n",
    "best_acc_model, best_loss_model, results = train_logreg_simplified(\n",
    "    batch_size=8,\n",
    "    train_feats_data=train_feats_simclr,\n",
    "    test_feats_data=test_feats_simclr,\n",
    "    feature_dim=train_feats_simclr.tensors[0].shape[1],\n",
    "    num_classes=2,\n",
    "    lr=5e-4,\n",
    "    weight_decay=1e-4,\n",
    "    max_epochs=100\n",
    ")\n",
    "#print(f\"Final Train Accuracy: {results['train_acc']:.4f}, Final Test Accuracy: {results['test_acc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save the best models by accuracy and loss\n",
    "torch.save(best_acc_model.state_dict(), \"1000epoch_best_acc_model.pth\")\n",
    "torch.save(best_loss_model.state_dict(), \"1000epoch_best_loss_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(512,2)\n",
    "logreg_model = logreg_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_22448\\4036842466.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\"1000epoch_best_loss_model.pth\")  # Load weights from the file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (linear): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Step 2: Load the saved state dict\n",
    "state_dict = torch.load(\"1000epoch_best_loss_model.pth\")  # Load weights from the file\n",
    "logreg_model.load_state_dict(state_dict)  # Load state dict into the model\n",
    "\n",
    "# Step 3: Set the model to evaluation mode (if not training)\n",
    "logreg_model.eval()  # This disables dropout and batchnorm for inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 512= feature_dim = train_feats_simclr.tensors[0].shape[1] =  before projection head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model state_dict\n",
    "torch.save(logreg_model.state_dict(), \"logreg_model_best.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1000 epochs: no outlier amoung exploded, control7, single dose\n",
    "#500 epochs, one outlier of exploder in ds closer to sd: which is ds41_g9_C10-T01   inbetween 4 ds closer\n",
    "# 100 epochs, one outlier of exploder also one outlier from ds_clos_tosd ds41_g5_E04-T01\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  100 adichu when its batch size =16  down checking whether we will get it by repeating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 18/18 [00:12<00:00,  1.45it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sorted by p(treated) in ascending order:\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G05-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F05-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G04-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E05-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G06-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G05-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D11-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F04-T01.tiff: 0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E10-T01.tiff: 0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D05-T01.tiff: 0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D07-T01.tiff: 0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G03-T01.tiff: 0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D08-T01.tiff: 0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D09-T01.tiff: 0.0003\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B09-T01.tiff: 0.0003\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G03-T01.tiff: 0.0003\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F08-T01.tiff: 0.0004\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E11-T01.tiff: 0.0004\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C07-T01.tiff: 0.0005\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E08-T01.tiff: 0.0005\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F06-T01.tiff: 0.0006\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E07-T01.tiff: 0.0007\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B07-T01.tiff: 0.0008\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B04-T01.tiff: 0.0010\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D06-T01.tiff: 0.0011\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E09-T01.tiff: 0.0014\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F09-T01.tiff: 0.0015\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B03-T01.tiff: 0.0015\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C08-T01.tiff: 0.0016\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F07-T01.tiff: 0.0017\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G08-T01.tiff: 0.0021\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B02-T01.tiff: 0.0038\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G07-T01.tiff: 0.0064\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G09-T01.tiff: 0.0065\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B03-T01.tiff: 0.0367\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B11-T01.tiff: 0.1922\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D07-T01.tiff: 0.5807\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C10-T01.tiff: 0.6250\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C11-T01.tiff: 0.6265\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B07-T01.tiff: 0.6446\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B08-T01.tiff: 0.6668\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E07-T01.tiff: 0.6846\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E07-T01.tiff: 0.7061\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D09-T01.tiff: 0.7817\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D10-T01.tiff: 0.7951\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G11-T01.tiff: 0.7993\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B10-T01.tiff: 0.8030\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E04-T01.tiff: 0.8073\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C07-T01.tiff: 0.8102\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D07-T01.tiff: 0.8194\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G10-T01.tiff: 0.8554\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G08-T01.tiff: 0.8725\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C09-T01.tiff: 0.8866\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C10-T01.tiff: 0.8871\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G07-T01.tiff: 0.8873\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B11-T01.tiff: 0.8905\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D08-T01.tiff: 0.8928\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E11-T01.tiff: 0.8959\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F07-T01.tiff: 0.8978\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B09-T01.tiff: 0.9086\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B04-T01.tiff: 0.9091\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D08-T01.tiff: 0.9229\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D09-T01.tiff: 0.9242\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D09-T01.tiff: 0.9248\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E08-T01.tiff: 0.9254\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F09-T01.tiff: 0.9272\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C08-T01.tiff: 0.9274\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F09-T01.tiff: 0.9289\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B04-T01.tiff: 0.9302\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G09-T01.tiff: 0.9310\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E09-T01.tiff: 0.9327\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B04-T01.tiff: 0.9341\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E10-T01.tiff: 0.9345\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D09-T01.tiff: 0.9353\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D11-T01.tiff: 0.9381\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E2.tif: 0.9402\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E05-T01.tiff: 0.9406\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G07-T01.tiff: 0.9436\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D10-T01.tiff: 0.9444\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C09-T01.tiff: 0.9470\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B07-T01.tiff: 0.9470\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C10-T01.tiff: 0.9477\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F11-T01.tiff: 0.9500\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F07-T01.tiff: 0.9506\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E09-T01.tiff: 0.9513\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E06-T01.tiff: 0.9513\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E04-T01.tiff: 0.9518\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D11-T01.tiff: 0.9537\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E5.tif: 0.9541\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E02-T01.tiff: 0.9543\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C07-T01.tiff: 0.9544\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F07-T01.tiff: 0.9548\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D08-T01.tiff: 0.9554\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G07-T01.tiff: 0.9556\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D07-T01.tiff: 0.9556\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B11-T01.tiff: 0.9566\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D10-T01.tiff: 0.9570\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C09-T01.tiff: 0.9574\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B11-T01.tiff: 0.9575\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G09-T01.tiff: 0.9581\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G10-T01.tiff: 0.9589\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E3.tif: 0.9589\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B08-T01.tiff: 0.9607\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G11-T01.tiff: 0.9624\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F08-T01.tiff: 0.9629\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G08-T01.tiff: 0.9631\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C10-T01.tiff: 0.9632\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B02-T01.tiff: 0.9632\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D08-T01.tiff: 0.9636\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E03-T01.tiff: 0.9637\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B10-T01.tiff: 0.9639\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E07-T01.tiff: 0.9646\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B09-T01.tiff: 0.9648\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D11-T01.tiff: 0.9649\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C07-T01.tiff: 0.9651\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C11-T01.tiff: 0.9653\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G09-T01.tiff: 0.9654\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C08-T01.tiff: 0.9659\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B09-T01.tiff: 0.9664\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F10-T01.tiff: 0.9671\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E4.tif: 0.9678\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C09-T01.tiff: 0.9687\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B10-T01.tiff: 0.9695\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E05-T01.tiff: 0.9702\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B03-T01.tiff: 0.9702\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F10-T01.tiff: 0.9703\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C08-T01.tiff: 0.9704\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D10-T01.tiff: 0.9708\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G10-T01.tiff: 0.9709\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D07-T01.tiff: 0.9723\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E09-T01.tiff: 0.9724\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G08-T01.tiff: 0.9730\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C11-T01.tiff: 0.9731\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B03-T01.tiff: 0.9737\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F11-T01.tiff: 0.9738\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F08-T01.tiff: 0.9747\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E06-T01.tiff: 0.9753\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B06-T01.tiff: 0.9762\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D11-T01.tiff: 0.9762\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B05-T01.tiff: 0.9772\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B10-T01.tiff: 0.9775\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E11-T01.tiff: 0.9776\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G11-T01.tiff: 0.9779\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B08-T01.tiff: 0.9801\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B07-T01.tiff: 0.9802\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F10-T01.tiff: 0.9803\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F09-T01.tiff: 0.9806\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B07-T01.tiff: 0.9819\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C07-T01.tiff: 0.9821\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E08-T01.tiff: 0.9847\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B08-T01.tiff: 0.9849\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F11-T01.tiff: 0.9856\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B09-T01.tiff: 0.9865\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E11-T01.tiff: 0.9866\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E10-T01.tiff: 0.9876\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E10-T01.tiff: 0.9876\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B06-T01.tiff: 0.9885\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B03-T01.tiff: 0.9886\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F08-T01.tiff: 0.9889\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C08-T01.tiff: 0.9893\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C09-T01.tiff: 0.9947\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F06-T01.tiff: 0.9950\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_c10.tif: 0.9965\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C06-T01.tiff: 0.9967\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C8.tif: 0.9977\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C03-T01.tiff: 0.9982\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C7.tif: 0.9985\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C10-T01.tiff: 0.9989\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B10-T01.tiff: 0.9990\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B07-T01.tiff: 0.9990\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B08-T01.tiff: 0.9990\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C11.tif: 0.9992\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C07-T01.tiff: 0.9992\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g9_C10-T01.tiff: 0.9995\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F04-T01.tiff: 0.9996\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C05-T01.tiff: 0.9996\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C08-T01.tiff: 0.9997\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B11-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C06-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C9.tif: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F03-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C04-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C02-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F05-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C04-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C02-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C03-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C05-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F02-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C11-T01.tiff: 1.0000\n"
     ]
    }
   ],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending ordergroups_data[group_name]\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 's' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[25], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43ms\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 's' is not defined"
     ]
    }
   ],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images copied and renamed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Assuming 'sorted_by_treated' is already defined as:\n",
    "# sorted_by_treated = [(img_path, p_tr), ...] sorted in ascending order by p_tr\n",
    "\n",
    "new_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\sort_ex_85\"\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "for i, (img_path, p_tr) in enumerate(sorted_by_treated, start=1):\n",
    "    # Extract the parent directory name and the original filename\n",
    "    parent_dir_name = os.path.basename(os.path.dirname(img_path))  # e.g. \"cond7\"\n",
    "    base_filename = os.path.basename(img_path)  # e.g. \"ds_41.tif\"\n",
    "    \n",
    "    # Combine them to get \"cond7_ds_41.tif\"\n",
    "    original_filename = f\"{parent_dir_name}_{base_filename}\"\n",
    "\n",
    "    # Format the probability score\n",
    "    formatted_score = f\"{p_tr:.4f}\"\n",
    "    \n",
    "    # Construct the new filename with index and score\n",
    "    new_filename = f\"{i}_{formatted_score}_{original_filename}\"\n",
    "    new_path = os.path.join(new_dir, new_filename)\n",
    "    \n",
    "    shutil.copy2(img_path, new_path)\n",
    "\n",
    "print(\"Images copied and renamed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 18/18 [00:12<00:00,  1.50it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sorted by p(treated) in ascending order:\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G09-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G07-T01.tiff: 0.0004\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C08-T01.tiff: 0.9311\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C04-T01.tiff: 0.9391\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F03-T01.tiff: 0.9884\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_c10.tif: 0.9890\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B08-T01.tiff: 0.9891\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C07-T01.tiff: 0.9919\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C11-T01.tiff: 0.9922\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B11-T01.tiff: 0.9939\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C10-T01.tiff: 0.9941\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C10-T01.tiff: 0.9952\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C04-T01.tiff: 0.9962\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C7.tif: 0.9970\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B07-T01.tiff: 0.9977\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B09-T01.tiff: 0.9979\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C8.tif: 0.9980\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C11.tif: 0.9980\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C9.tif: 0.9982\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B10-T01.tiff: 0.9984\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B11-T01.tiff: 0.9985\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g9_C10-T01.tiff: 0.9987\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C09-T01.tiff: 0.9988\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B07-T01.tiff: 0.9990\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C08-T01.tiff: 0.9991\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C02-T01.tiff: 0.9992\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D11-T01.tiff: 0.9993\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C09-T01.tiff: 0.9994\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C03-T01.tiff: 0.9994\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C11-T01.tiff: 0.9995\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C06-T01.tiff: 0.9995\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C03-T01.tiff: 0.9997\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B09-T01.tiff: 0.9997\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F06-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C06-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C05-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C07-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B10-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C02-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C05-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F05-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F02-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E2.tif: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E3.tif: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E5.tif: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E05-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E4.tif: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B03-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E05-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B03-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B05-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E02-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E03-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B02-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B03-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B10-T01.tiff: 1.0000\n"
     ]
    }
   ],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending ordergroups_data[group_name]\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sorted by p(treated) in ascending order:\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G09-T01.tiff: p(treated)=0.0001, p(control)=0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G07-T01.tiff: p(treated)=0.0004, p(control)=0.9996\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C08-T01.tiff: p(treated)=0.9311, p(control)=0.0689\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C04-T01.tiff: p(treated)=0.9391, p(control)=0.0609\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F03-T01.tiff: p(treated)=0.9884, p(control)=0.0116\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_c10.tif: p(treated)=0.9890, p(control)=0.0110\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B08-T01.tiff: p(treated)=0.9891, p(control)=0.0109\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C07-T01.tiff: p(treated)=0.9919, p(control)=0.0081\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C11-T01.tiff: p(treated)=0.9922, p(control)=0.0078\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B11-T01.tiff: p(treated)=0.9939, p(control)=0.0061\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C10-T01.tiff: p(treated)=0.9941, p(control)=0.0059\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C10-T01.tiff: p(treated)=0.9952, p(control)=0.0048\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C04-T01.tiff: p(treated)=0.9962, p(control)=0.0038\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C7.tif: p(treated)=0.9970, p(control)=0.0030\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B07-T01.tiff: p(treated)=0.9977, p(control)=0.0023\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B09-T01.tiff: p(treated)=0.9979, p(control)=0.0021\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C8.tif: p(treated)=0.9980, p(control)=0.0020\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C11.tif: p(treated)=0.9980, p(control)=0.0020\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C9.tif: p(treated)=0.9982, p(control)=0.0018\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B10-T01.tiff: p(treated)=0.9984, p(control)=0.0016\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B11-T01.tiff: p(treated)=0.9985, p(control)=0.0015\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g9_C10-T01.tiff: p(treated)=0.9987, p(control)=0.0013\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C09-T01.tiff: p(treated)=0.9988, p(control)=0.0012\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B07-T01.tiff: p(treated)=0.9990, p(control)=0.0010\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C08-T01.tiff: p(treated)=0.9991, p(control)=0.0009\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C02-T01.tiff: p(treated)=0.9992, p(control)=0.0008\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D11-T01.tiff: p(treated)=0.9993, p(control)=0.0007\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C09-T01.tiff: p(treated)=0.9994, p(control)=0.0006\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C03-T01.tiff: p(treated)=0.9994, p(control)=0.0006\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C11-T01.tiff: p(treated)=0.9995, p(control)=0.0005\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C06-T01.tiff: p(treated)=0.9995, p(control)=0.0005\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C03-T01.tiff: p(treated)=0.9997, p(control)=0.0003\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B09-T01.tiff: p(treated)=0.9997, p(control)=0.0003\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F06-T01.tiff: p(treated)=0.9998, p(control)=0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C06-T01.tiff: p(treated)=0.9998, p(control)=0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C05-T01.tiff: p(treated)=0.9998, p(control)=0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C07-T01.tiff: p(treated)=0.9998, p(control)=0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B10-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C02-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C05-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F05-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F02-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E2.tif: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E3.tif: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E06-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E5.tif: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E05-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E4.tif: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B03-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E05-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B03-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E06-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B05-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B06-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E02-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E03-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B02-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B03-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B06-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "\n",
      "Group-Wise Ranking Accuracy:\n",
      "Correct Transitions: 1\n",
      "Total Possible Transitions: 2\n",
      "Ranking Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1], entry[0]) for entry in all_images_data]\n",
    "\n",
    "# Print sorted images\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr, p_ctrl in sorted_by_treated:\n",
    "    print(f\"{img_path}: p(treated)={p_tr:.4f}, p(control)={p_ctrl:.4f}\")\n",
    "\n",
    "# Initialize group-wise data\n",
    "grouped_data = {group: [] for group in groups}\n",
    "for group in groups:\n",
    "    grouped_data[group].extend(groups_data[group])\n",
    "\n",
    "# Step 1: Sort distances and keep track of group membership\n",
    "sorted_distances = []\n",
    "for group, data in grouped_data.items():\n",
    "    for _, p_treated, _ in data:\n",
    "        sorted_distances.append((p_treated, group))\n",
    "\n",
    "sorted_distances.sort(key=lambda x: x[0])  # Sort by p(treated)\n",
    "\n",
    "# Step 2: Check for correct transitions between groups\n",
    "correct_transitions = 0\n",
    "total_transitions = len(groups) - 1  # Total possible adjacent group transitions\n",
    "\n",
    "for i in range(total_transitions):\n",
    "    group_i = groups[i]\n",
    "    group_j = groups[i + 1]\n",
    "\n",
    "    # Get all distances for groups i and j\n",
    "    distances_i = [dist for dist, grp in sorted_distances if grp == group_i]\n",
    "    distances_j = [dist for dist, grp in sorted_distances if grp == group_j]\n",
    "\n",
    "    # Check the condition: all d in G_i < all d in G_j\n",
    "    if all(d_i < d_j for d_i in distances_i for d_j in distances_j):\n",
    "        correct_transitions += 1\n",
    "\n",
    "# Step 3: Calculate ranking accuracy\n",
    "ranking_accuracy = correct_transitions / total_transitions if total_transitions > 0 else 1.0\n",
    "\n",
    "# Step 4: Print the group-wise ranking accuracy\n",
    "print(\"\\nGroup-Wise Ranking Accuracy:\")\n",
    "print(f\"Correct Transitions: {correct_transitions}\")\n",
    "print(f\"Total Possible Transitions: {total_transitions}\")\n",
    "print(f\"Ranking Accuracy: {ranking_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Assuming 'sorted_by_treated' is already defined as:\n",
    "# sorted_by_treated = [(img_path, p_tr), ...] sorted in ascending order by p_tr\n",
    "\n",
    "new_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\sorted_explodall\"\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "for i, (img_path, p_tr) in enumerate(sorted_by_treated, start=1):\n",
    "    # Extract the parent directory name and the original filename\n",
    "    parent_dir_name = os.path.basename(os.path.dirname(img_path))  # e.g. \"cond7\"\n",
    "    base_filename = os.path.basename(img_path)  # e.g. \"ds_41.tif\"\n",
    "    \n",
    "    # Combine them to get \"cond7_ds_41.tif\"\n",
    "    original_filename = f\"{parent_dir_name}_{base_filename}\"\n",
    "\n",
    "    # Format the probability score\n",
    "    formatted_score = f\"{p_tr:.4f}\"\n",
    "    \n",
    "    # Construct the new filename with index and score\n",
    "    new_filename = f\"{i}_{formatted_score}_{original_filename}\"\n",
    "    new_path = os.path.join(new_dir, new_filename)\n",
    "    \n",
    "    shutil.copy2(img_path, new_path)\n",
    "\n",
    "print(\"Images copied and renamed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Assuming 'sorted_by_treated' is already defined as:\n",
    "# sorted_by_treated = [(img_path, p_tr), ...] sorted in ascending order by p_tr\n",
    "\n",
    "new_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\sorted_cond10\"\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "for i, (img_path, p_tr) in enumerate(sorted_by_treated, start=1):\n",
    "    # Extract the parent directory name and the original filename\n",
    "    parent_dir_name = os.path.basename(os.path.dirname(img_path))  # e.g. \"cond7\"\n",
    "    base_filename = os.path.basename(img_path)  # e.g. \"ds_41.tif\"\n",
    "    \n",
    "    # Combine them to get \"cond7_ds_41.tif\"\n",
    "    original_filename = f\"{parent_dir_name}_{base_filename}\"\n",
    "\n",
    "    # Format the probability score\n",
    "    formatted_score = f\"{p_tr:.4f}\"\n",
    "    \n",
    "    # Construct the new filename with index and score\n",
    "    new_filename = f\"{i}_{formatted_score}_{original_filename}\"\n",
    "    new_path = os.path.join(new_dir, new_filename)\n",
    "    \n",
    "    shutil.copy2(img_path, new_path)\n",
    "\n",
    "print(\"Images copied and renamed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#500 epochs, one outlier of exploder in ds closer to sd: which is ds41_g9_C10-T01   inbetween 4 ds closer\n",
    "# 100 epochs, one outlier of exploder also one outlier from ds_clos_tosd ds41_g5_E04-T01\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "#from helper import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model definition\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, feature_dim, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Recreate the model structure\n",
    "feature_dim = 512 # Set this to the same dimension used during training\n",
    "num_classes = 2   # Since you trained for 2 classes\n",
    "logreg_model = LogisticRegression(feature_dim, num_classes).to(device)\n",
    "\n",
    "# Load the saved weights\n",
    "logreg_model.load_state_dict(torch.load(\"best_loss_model.pth\", map_location=device))\n",
    "logreg_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in descending order (highest p(treated) first)\n",
    "all_images_data.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Now all_images_data is sorted by p(treated)\n",
    "# Extract (img_path, p_treated)\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "# Print or handle as needed\n",
    "print(\"Images sorted by p(treated) in descending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup for inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess_Image(image_path):\n",
    "    # Load the image\n",
    "    image = tiff.imread(image_path)\n",
    "    \n",
    "    # Ensure the image has 3 layers (channels)\n",
    "    if image.shape[0] != 3:\n",
    "        raise ValueError(f\"Image at {image_path} does not have exactly 3 layers.\")\n",
    "    \n",
    "    # Normalize the 16-bit image to [0, 1]\n",
    "    image = image.astype(np.float32) / 65535.0\n",
    "    \n",
    "    # Convert to a torch tensor\n",
    "    image = torch.tensor(image, dtype=torch.float32)\n",
    "    \n",
    "    # Resize to (96, 96)\n",
    "    image = TF.resize(image, (96, 96))\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_of_image = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B07-T01.tiff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = Preprocess_Image(path_of_image)\n",
    "print(first_image.shape)\n",
    "prep_first_image = first_image.unsqueeze(0)\n",
    "print(prep_first_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image_np = first_image.numpy().transpose(1, 2, 0)  # (C, H, W) -> (H, W, C)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(first_image_np, cmap='gray')  # Use `cmap='gray'` if it's grayscale\n",
    "plt.title('First Image')\n",
    "plt.axis('off')  # Optional: turn off the axis for a cleaner look\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathimage = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B08-T01.tiff'\n",
    "second_image = Preprocess_Image(pathimage)\n",
    "print(second_image.shape)\n",
    "prep_second_image = second_image.unsqueeze(0)\n",
    "print(prep_second_image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_image_np = second_image.numpy().transpose(1, 2, 0)  # (C, H, W) -> (H, W, C)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(second_image_np, cmap='gray')  # Use `cmap='gray'` if it's grayscale\n",
    "plt.title('second Image')\n",
    "plt.axis('off')  # Optional: turn off the axis for a cleaner look\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extract_features(model, image_tensor):\n",
    "    # prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "    \n",
    "    # Move image tensor to device\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    # Extract features\n",
    "    features = network(image_tensor)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"simclr_model: {simclr_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for both images\n",
    "first_image_feats = extract_features(simclr_model, prep_first_image)\n",
    "second_image_feats = extract_features(simclr_model, prep_second_image)\n",
    "print(first_image_feats.shape)\n",
    "print(second_image_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSINE FROM NEWDATA CROP VAL&INFER\n",
    "# Compute cosine similarity between the feature vectors\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats, second_image_feats, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSINE old data crop\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats, second_image_feats, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\untreated\\D08-T01.tiff'\n",
    "untreated_image = Preprocess_Image(im_path)\n",
    "print(untreated_image.shape)\n",
    "prep_untreated_image = untreated_image.unsqueeze(0)\n",
    "print(prep_untreated_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_image_np = untreated_image.numpy().transpose(1, 2, 0)  # (C, H, W) -> (H, W, C)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(untreated_image_np, cmap='gray')  # Use `cmap='gray'` if it's grayscale\n",
    "plt.title('untreated Image')\n",
    "plt.axis('off')  # Optional: turn off the axis for a cleaner look\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_image_feats = extract_features(simclr_model, prep_untreated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSINE NEW DATA CROP\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats, untreated_image_feats, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine old data crop\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats, untreated_image_feats, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference after projection head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def features_after_projection(model, image_tensor):\n",
    "    # prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    #network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "    \n",
    "    # Move image tensor to device\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    # Extract features\n",
    "    features = network(image_tensor)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for both images\n",
    "first_image_feats_after = features_after_projection(simclr_model, prep_first_image)\n",
    "second_image_feats_after = features_after_projection(simclr_model, prep_second_image)\n",
    "print(first_image_feats_after.shape)\n",
    "print(second_image_feats_after.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine newdata crop \n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats_after, second_image_feats_after, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine old data crop\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats_after, second_image_feats_after, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")\n",
    "\n",
    "#Cosine similarity between features: 0.8507535457611084\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as expected after projection head cosine similarity is higher this leads to the question that maybe for ranking images with time series, this after projection maybe better option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_image_feats_after = features_after_projection(simclr_model, prep_untreated_image)\n",
    "print(untreated_image_feats_after.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between the feature vectors\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats_after, untreated_image_feats_after, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between the feature vectors\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats_after, untreated_image_feats_after, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as expected after projection head cosine similarity is lower for different class images this leads to the question that maybe for ranking images with time series, this after projection maybe better option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orig images (without simclr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_image)\n",
    "first_image.view(-1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(second_image)\n",
    "second_image.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_flat = first_image.view(-1)\n",
    "second_flat = second_image.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_flat.unsqueeze(0).shape == untreated_flat.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "similarity = F.cosine_similarity(first_flat.unsqueeze(0), second_flat.unsqueeze(0))\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_flat = untreated_image.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = F.cosine_similarity(first_flat.unsqueeze(0), untreated_flat.unsqueeze(0))\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_flat == untreated_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "orig without resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Load and normalize both images\n",
    "im1 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B07-T01.tiff')\n",
    "im2 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B08-T01.tiff')\n",
    "\n",
    "# Ensure each image has 3 layers (channels)\n",
    "if im1.shape[0] != 3 or im2.shape[0] != 3:\n",
    "    raise ValueError(\"Each image must have exactly 3 layers.\")\n",
    "\n",
    "# Normalize the 16-bit images to [0, 1]\n",
    "im1 = im1.astype(np.float32) / 65535.0\n",
    "im2 = im2.astype(np.float32) / 65535.0\n",
    "print(im2.shape)\n",
    "\n",
    "# Flatten the 3D images to 1D vectors\n",
    "im1_flattened = im1.flatten()\n",
    "im2_flattened = im2.flatten()\n",
    "print(im2_flattened.shape)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_similarity = np.dot(im1_flattened, im2_flattened) / (norm(im1_flattened) * norm(im2_flattened))\n",
    "\n",
    "print(f\"Cosine Similarity between the two images: {cosine_similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B07-T01.tiff')\n",
    "im2 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\untreated\\D08-T01.tiff')\n",
    "\n",
    "# Ensure each image has 3 layers (channels)\n",
    "if im1.shape[0] != 3 or im2.shape[0] != 3:\n",
    "    raise ValueError(\"Each image must have exactly 3 layers.\")\n",
    "\n",
    "# Normalize the 16-bit images to [0, 1]\n",
    "im1 = im1.astype(np.float32) / 65535.0\n",
    "im2 = im2.astype(np.float32) / 65535.0\n",
    "print(im2.shape)\n",
    "\n",
    "# Flatten the 3D images to 1D vectors\n",
    "im1_flattened = im1.flatten()\n",
    "im2_flattened = im2.flatten()\n",
    "print(im2_flattened.shape)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_similarity = np.dot(im1_flattened, im2_flattened) / (norm(im1_flattened) * norm(im2_flattened))\n",
    "\n",
    "print(f\"Cosine Similarity between the two images: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAS IST DAS?\n",
    "Mach kein Sinn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B07-T01.tiff')\n",
    "img2 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B08-T01.tiff')\n",
    "img3 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\untreated\\D08-T01.tiff')\n",
    "img1_flattened = img1.flatten()\n",
    "img2_flattened = img2.flatten()\n",
    "img3_flattened = img3.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = np.dot(img1_flattened, img2_flattened) / (norm(img1_flattened) * norm(img2_flattened))\n",
    "print(f\"Cosine Similarity between the two images: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = np.dot(img1_flattened, img3_flattened) / (norm(img1_flattened) * norm(img3_flattened))\n",
    "print(f\"Cosine Similarity between the two images: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, if we didn't use simclr and just try to find the cosine similarity between orig images: it doesn't deviate too  much not good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
