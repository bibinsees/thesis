{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "#from helper import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Now you can use the `device` variable\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay,max_epochs):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        # Load the pretrained ResNet-18 model\n",
    "        self.convnet = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "        \n",
    "        # Modify the fully connected layer\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4 * hidden_dim),  # Linear layer with 4*hidden_dim output\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * hidden_dim, 20)  # Output layer with hidden_dim output\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.AdamW(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        self.lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=max_epochs, eta_min=lr / 50)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convnet(x)\n",
    "\n",
    "    def info_nce_loss(self, imgs1, imgs2, device):\n",
    "\n",
    "        imgs = torch.cat((imgs1, imgs2), dim=0)  # Concatenate along the batch dimension\n",
    "        imgs = imgs.to(device)  # Move images to the device\n",
    "\n",
    "        # Encode all images\n",
    "        feats = self.forward(imgs)\n",
    "    \n",
    "        # Calculate cosine similarity\n",
    "        cos_sim = nn.functional.cosine_similarity(feats[:, None, :], feats[None, :, :], dim=-1)\n",
    "    \n",
    "        # Mask out cosine similarity to itself\n",
    "        self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "        cos_sim.masked_fill_(self_mask, -9e15)\n",
    "    \n",
    "        # Find positive example -> batch_size//2 away from the original example\n",
    "        pos_mask = self_mask.roll(shifts=cos_sim.shape[0] // 2, dims=0)\n",
    "    \n",
    "        # Normalize similarity scores by temperature\n",
    "        cos_sim = cos_sim / self.temperature\n",
    "\n",
    "        # InfoNCE loss\n",
    "        nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "        nll = nll.mean()\n",
    "\n",
    "        # Accuracy calculations\n",
    "        # Create a combination of positive and negative similarities for ranking\n",
    "        comb_sim = torch.cat([cos_sim[pos_mask][:, None],  # Positive example in first position\n",
    "                          cos_sim.masked_fill(pos_mask, -9e15)], dim=-1)\n",
    "    \n",
    "        # Sort and get the ranking position of the positive example\n",
    "        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
    "    \n",
    "        # Compute accuracy metrics\n",
    "        top1_acc = (sim_argsort == 0).float().mean()  # Top-1 accuracy\n",
    "        top5_acc = (sim_argsort < 5).float().mean()   # Top-5 accuracy\n",
    "        mean_pos = 1 + sim_argsort.float().mean()     # Mean position of the positive example\n",
    "\n",
    "        return nll, top1_acc, top5_acc, mean_pos\n",
    "\n",
    "    def train_epoch(self, train_loader, device):\n",
    "        self.train()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            imgs1, imgs2, _ = batch\n",
    "            imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "        \n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Calculate loss and accuracy metrics\n",
    "            loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            #self.lr_scheduler.step()\n",
    "\n",
    "            # Accumulate metrics\n",
    "            total_loss += loss.item()\n",
    "            total_top1_acc += top1_acc.item()\n",
    "            total_top5_acc += top5_acc.item()\n",
    "            total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(train_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(train_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(train_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos\n",
    "\n",
    "    def validate_epoch(self, val_loader, device):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "                imgs1, imgs2, _ = batch\n",
    "                imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "\n",
    "                # Calculate loss and accuracy metrics\n",
    "                loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "                # Accumulate metrics\n",
    "                total_loss += loss.item()\n",
    "                total_top1_acc += top1_acc.item()\n",
    "                total_top5_acc += top5_acc.item()\n",
    "                total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(val_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(val_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(val_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(val_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos\n",
    "    \n",
    "\n",
    "    def inference_epoch(self, inference_loader, device):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(inference_loader, desc=\"Inferencing\", leave=False):\n",
    "                imgs1, imgs2, _ = batch\n",
    "                imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "\n",
    "                # Calculate loss and accuracy metrics\n",
    "                loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "                # Accumulate metrics\n",
    "                total_loss += loss.item()\n",
    "                total_top1_acc += top1_acc.item()\n",
    "                total_top5_acc += top5_acc.item()\n",
    "                total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(inference_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(inference_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(inference_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(inference_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "model_path = r'C:\\Users\\k54739\\Bibi_new_thesis\\saved_model\\resize_simclr_modelepoch250.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_11920\\1145718020.py:1: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  simclr_model = torch.load(model_path)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (convnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=512, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simclr_model = torch.load(model_path)\n",
    "simclr_model.to(device)\n",
    "simclr_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference before projection head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledImageDataset(Dataset):\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "\n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Convert to a torch tensor and add channel dimension\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        \n",
    "        # Apply resize transform\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def load_and_split_data(root_dir, test_size=0.2):\n",
    "    #classes = ['untreated', 'single_dose', 'drug_screened']\n",
    "    classes = ['ex_40', 'sd']\n",
    "    image_files = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(root_dir, class_name)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir) if file.endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        labels.extend([idx] * len(files))\n",
    "    \n",
    "    # Check if the labels correctly reflect the classes\n",
    "    #print(\"Label distribution:\", {classes[i]: labels.count(i) for i in range(len(classes))})\n",
    "    \n",
    "    # Split data into training and test sets\n",
    "    train_files, test_files, train_labels, test_labels = train_test_split(\n",
    "        image_files, labels, test_size=test_size, stratify=labels, random_state=42)\n",
    "\n",
    "    return train_files, test_files, train_labels, test_labels\n",
    "\n",
    "\n",
    "# Directories for labeled data\n",
    "image_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\train_ex_vs_sd\"\n",
    "\n",
    "# Load and split the data\n",
    "train_files, test_files, train_labels, test_labels = load_and_split_data(image_dir, test_size=0.2)\n",
    "\n",
    "# Create the labeled datasets\n",
    "train_labeled_dataset = LabeledImageDataset(train_files, train_labels)\n",
    "test_labeled_dataset = LabeledImageDataset(test_files, test_labels)\n",
    "\n",
    "# Define DataLoaders\n",
    "batch_size = 16\n",
    "train_loader_labeled = DataLoader(train_labeled_dataset, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=0)\n",
    "test_loader_labeled = DataLoader(test_labeled_dataset, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 96, 96]) torch.Size([16]) torch.float32\n",
      "tensor([1, 1, 1, 1, 0, 1, 1, 1, 0, 1, 0, 1, 1, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "for anchor,label in train_loader_labeled:\n",
    "    print(anchor.shape, label.shape, anchor.dtype)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in train_loader_labeled: 114\n"
     ]
    }
   ],
   "source": [
    "# Initialize a counter\n",
    "total_images = 0\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for anchor, label in train_loader_labeled:\n",
    "    total_images += anchor.size(0)  # Increment by the batch size (number of images in the current batch)\n",
    "\n",
    "# Print the total number of images\n",
    "print(f\"Total number of images in train_loader_labeled: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in test_loader_labeled: 29\n"
     ]
    }
   ],
   "source": [
    "# Initialize a counter\n",
    "total_images = 0\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for anchor, label in test_loader_labeled:\n",
    "    total_images += anchor.size(0)  # Increment by the batch size (number of images in the current batch)\n",
    "\n",
    "# Print the total number of images\n",
    "print(f\"Total number of images in test_loader_labeled: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_data_features(model, dataloader):\n",
    "    # Prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    # Encode all images\n",
    "    feats, labels = [], []\n",
    "    for batch_imgs, batch_labels in tqdm(dataloader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        print(f\"Batch features shape: {batch_feats.shape}\")\n",
    "        print(f\"Batch labels shape: {batch_labels.shape}\")\n",
    "        \n",
    "        feats.append(batch_feats.detach().cpu())\n",
    "        labels.append(batch_labels)\n",
    "\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    \n",
    "    print(f\"Features shape after concatenation: {feats.shape}\")\n",
    "    print(f\"Labels shape after concatenation: {labels.shape}\")\n",
    "\n",
    "    return torch.utils.data.TensorDataset(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:00<00:06,  1.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:01<00:04,  1.26it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:02<00:03,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:03<00:02,  1.35it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [00:03<00:02,  1.38it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [00:04<00:01,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [00:05<00:00,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([2, 512])\n",
      "Batch labels shape: torch.Size([2])\n",
      "Features shape after concatenation: torch.Size([114, 512])\n",
      "Labels shape after concatenation: torch.Size([114])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.46it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.59it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([13, 512])\n",
      "Batch labels shape: torch.Size([13])\n",
      "Features shape after concatenation: torch.Size([29, 512])\n",
      "Labels shape after concatenation: torch.Size([29])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract features for train and test datasets\n",
    "train_feats_simclr = prepare_data_features(simclr_model, train_loader_labeled)\n",
    "test_feats_simclr = prepare_data_features(simclr_model, test_loader_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model definition\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, feature_dim, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_logistic_regression(model, train_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch_feats, batch_labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        batch_feats, batch_labels = batch_feats.to(device), batch_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_feats)\n",
    "        loss = nn.functional.cross_entropy(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_logistic_regression(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_feats, batch_labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            batch_feats, batch_labels = batch_feats.to(device), batch_labels.to(device)\n",
    "            \n",
    "            outputs = model(batch_feats)\n",
    "            loss = nn.functional.cross_entropy(outputs, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logreg_simplified(batch_size, train_feats_data, test_feats_data, feature_dim, num_classes, lr=5e-4, weight_decay=1e-4, max_epochs=50):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_feats_data, batch_size=batch_size, shuffle=True,\n",
    "                              drop_last=False, pin_memory=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_feats_data, batch_size=batch_size, shuffle=False,\n",
    "                             drop_last=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "    # Model, loss, and optimizer\n",
    "    model = LogisticRegression(feature_dim, num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                               milestones=[int(max_epochs * 0.6), int(max_epochs * 0.8)],\n",
    "                                               gamma=0.1)\n",
    "\n",
    "    # Store metrics for plotting\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    # Track best by accuracy\n",
    "    best_test_acc = -1.0\n",
    "    best_model_state_acc = None\n",
    "\n",
    "    # Track best by loss (with accuracy as a tiebreaker)\n",
    "    best_test_loss = float('inf')\n",
    "    best_test_loss_acc = -1.0\n",
    "    best_model_state_loss = None\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{max_epochs}\")\n",
    "\n",
    "        train_loss, train_acc = train_logistic_regression(model, train_loader, optimizer, scheduler, device)\n",
    "        test_loss, test_acc = evaluate_logistic_regression(model, test_loader, criterion, device)\n",
    "\n",
    "        print(f\"Training loss: {train_loss:.4f}, Training accuracy: {train_acc:.4f}\")\n",
    "        print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        test_accuracies.append(test_acc)\n",
    "\n",
    "        # Check for best accuracy model\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            best_model_state_acc = model.state_dict()\n",
    "\n",
    "        # Check for best loss model\n",
    "        # Condition: strictly lower loss OR equal loss but higher accuracy\n",
    "        if (test_loss < best_test_loss) or (test_loss == best_test_loss and test_acc > best_test_loss_acc):\n",
    "            best_test_loss = test_loss\n",
    "            best_test_loss_acc = test_acc\n",
    "            best_model_state_loss = model.state_dict()\n",
    "\n",
    "    # Now we have two best states: best_model_state_acc and best_model_state_loss\n",
    "    # Create two separate model instances for them\n",
    "    best_acc_model = LogisticRegression(feature_dim, num_classes).to(device)\n",
    "    best_acc_model.load_state_dict(best_model_state_acc)\n",
    "    best_acc_model.eval()\n",
    "\n",
    "    best_loss_model = LogisticRegression(feature_dim, num_classes).to(device)\n",
    "    best_loss_model.load_state_dict(best_model_state_loss)\n",
    "    best_loss_model.eval()\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Loss curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(max_epochs), train_losses, label='Train Loss')\n",
    "    plt.plot(range(max_epochs), test_losses, label='Test Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(max_epochs), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(max_epochs), test_accuracies, label='Test Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Return both models and the final results (e.g., last train_acc and test_acc recorded)\n",
    "    return best_acc_model, best_loss_model, {\"train_acc\": train_acc, \"test_acc\": test_acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 106.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 523.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.8325, Training accuracy: 0.5965\n",
      "Test loss: 0.4336, Test accuracy: 0.7931\n",
      "Epoch 2/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 211.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 444.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.2978, Training accuracy: 0.8860\n",
      "Test loss: 0.1964, Test accuracy: 0.9655\n",
      "Epoch 3/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 292.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 214.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1501, Training accuracy: 0.9561\n",
      "Test loss: 0.1224, Test accuracy: 0.9655\n",
      "Epoch 4/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 324.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 197.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0958, Training accuracy: 0.9737\n",
      "Test loss: 0.0921, Test accuracy: 0.9655\n",
      "Epoch 5/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 329.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 167.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0712, Training accuracy: 1.0000\n",
      "Test loss: 0.0756, Test accuracy: 0.9655\n",
      "Epoch 6/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 265.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0588, Training accuracy: 1.0000\n",
      "Test loss: 0.0642, Test accuracy: 0.9655\n",
      "Epoch 7/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 220.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 189.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0459, Training accuracy: 1.0000\n",
      "Test loss: 0.0573, Test accuracy: 0.9655\n",
      "Epoch 8/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 349.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0376, Training accuracy: 1.0000\n",
      "Test loss: 0.0527, Test accuracy: 0.9655\n",
      "Epoch 9/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 282.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1999.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0328, Training accuracy: 1.0000\n",
      "Test loss: 0.0488, Test accuracy: 0.9655\n",
      "Epoch 10/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 246.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1346.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0281, Training accuracy: 1.0000\n",
      "Test loss: 0.0449, Test accuracy: 0.9655\n",
      "Epoch 11/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 286.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0251, Training accuracy: 1.0000\n",
      "Test loss: 0.0418, Test accuracy: 0.9655\n",
      "Epoch 12/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 475.23it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 191.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0222, Training accuracy: 1.0000\n",
      "Test loss: 0.0400, Test accuracy: 0.9655\n",
      "Epoch 13/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 327.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 266.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0201, Training accuracy: 1.0000\n",
      "Test loss: 0.0380, Test accuracy: 0.9655\n",
      "Epoch 14/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 187.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0182, Training accuracy: 1.0000\n",
      "Test loss: 0.0355, Test accuracy: 1.0000\n",
      "Epoch 15/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 263.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0167, Training accuracy: 1.0000\n",
      "Test loss: 0.0340, Test accuracy: 1.0000\n",
      "Epoch 16/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 146.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0150, Training accuracy: 1.0000\n",
      "Test loss: 0.0323, Test accuracy: 1.0000\n",
      "Epoch 17/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 199.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0136, Training accuracy: 1.0000\n",
      "Test loss: 0.0313, Test accuracy: 1.0000\n",
      "Epoch 18/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 187.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 204.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0129, Training accuracy: 1.0000\n",
      "Test loss: 0.0301, Test accuracy: 1.0000\n",
      "Epoch 19/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 209.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0132, Training accuracy: 1.0000\n",
      "Test loss: 0.0292, Test accuracy: 1.0000\n",
      "Epoch 20/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0111, Training accuracy: 1.0000\n",
      "Test loss: 0.0273, Test accuracy: 1.0000\n",
      "Epoch 21/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 153.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0106, Training accuracy: 1.0000\n",
      "Test loss: 0.0274, Test accuracy: 1.0000\n",
      "Epoch 22/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 189.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 6369.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0100, Training accuracy: 1.0000\n",
      "Test loss: 0.0267, Test accuracy: 1.0000\n",
      "Epoch 23/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 162.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 632.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0092, Training accuracy: 1.0000\n",
      "Test loss: 0.0266, Test accuracy: 1.0000\n",
      "Epoch 24/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 160.53it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 781.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0087, Training accuracy: 1.0000\n",
      "Test loss: 0.0256, Test accuracy: 1.0000\n",
      "Epoch 25/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 152.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0079, Training accuracy: 1.0000\n",
      "Test loss: 0.0247, Test accuracy: 1.0000\n",
      "Epoch 26/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0086, Training accuracy: 1.0000\n",
      "Test loss: 0.0247, Test accuracy: 1.0000\n",
      "Epoch 27/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 194.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2542.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0069, Training accuracy: 1.0000\n",
      "Test loss: 0.0231, Test accuracy: 1.0000\n",
      "Epoch 28/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0068, Training accuracy: 1.0000\n",
      "Test loss: 0.0225, Test accuracy: 1.0000\n",
      "Epoch 29/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 204.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0062, Training accuracy: 1.0000\n",
      "Test loss: 0.0219, Test accuracy: 1.0000\n",
      "Epoch 30/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 187.44it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0061, Training accuracy: 1.0000\n",
      "Test loss: 0.0221, Test accuracy: 1.0000\n",
      "Epoch 31/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 169.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 418.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0057, Training accuracy: 1.0000\n",
      "Test loss: 0.0220, Test accuracy: 1.0000\n",
      "Epoch 32/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0069, Training accuracy: 1.0000\n",
      "Test loss: 0.0220, Test accuracy: 1.0000\n",
      "Epoch 33/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0057, Training accuracy: 1.0000\n",
      "Test loss: 0.0221, Test accuracy: 1.0000\n",
      "Epoch 34/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 259.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0057, Training accuracy: 1.0000\n",
      "Test loss: 0.0221, Test accuracy: 1.0000\n",
      "Epoch 35/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 173.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 190.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0065, Training accuracy: 1.0000\n",
      "Test loss: 0.0221, Test accuracy: 1.0000\n",
      "Epoch 36/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 842.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0056, Training accuracy: 1.0000\n",
      "Test loss: 0.0219, Test accuracy: 1.0000\n",
      "Epoch 37/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 163.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 133.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0056, Training accuracy: 1.0000\n",
      "Test loss: 0.0218, Test accuracy: 1.0000\n",
      "Epoch 38/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 196.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0057, Training accuracy: 1.0000\n",
      "Test loss: 0.0218, Test accuracy: 1.0000\n",
      "Epoch 39/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 125.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0058, Training accuracy: 1.0000\n",
      "Test loss: 0.0218, Test accuracy: 1.0000\n",
      "Epoch 40/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 195.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 295.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0055, Training accuracy: 1.0000\n",
      "Test loss: 0.0218, Test accuracy: 1.0000\n",
      "Epoch 41/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 165.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 211.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0054, Training accuracy: 1.0000\n",
      "Test loss: 0.0218, Test accuracy: 1.0000\n",
      "Epoch 42/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 207.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0058, Training accuracy: 1.0000\n",
      "Test loss: 0.0218, Test accuracy: 1.0000\n",
      "Epoch 43/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 146.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 289.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0055, Training accuracy: 1.0000\n",
      "Test loss: 0.0218, Test accuracy: 1.0000\n",
      "Epoch 44/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 160.67it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 121.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0054, Training accuracy: 1.0000\n",
      "Test loss: 0.0218, Test accuracy: 1.0000\n",
      "Epoch 45/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 170.02it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0054, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 46/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 259.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0055, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 47/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1024.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0055, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 48/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0055, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 49/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 188.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 224.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0067, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 50/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0058, Training accuracy: 1.0000\n",
      "Test loss: 0.0218, Test accuracy: 1.0000\n",
      "Epoch 51/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0055, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 52/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0057, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 53/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0064, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 54/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 187.02it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1597.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0054, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 55/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 194.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 878.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0054, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 56/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 157.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1439.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0055, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 57/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 148.90it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0054, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 58/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 167.02it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 459.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0054, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 59/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0055, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 60/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 174.90it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0055, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 61/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 185.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 187.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 62/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 190.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0055, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 63/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 195.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 261.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0054, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 64/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0074, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 65/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 194.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 852.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 66/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0057, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 67/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0064, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 68/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 184.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0056, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 69/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 70/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 71/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 195.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 72/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 188.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 206.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0217, Test accuracy: 1.0000\n",
      "Epoch 73/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 185.90it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 210.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0055, Training accuracy: 1.0000\n",
      "Test loss: 0.0216, Test accuracy: 1.0000\n",
      "Epoch 74/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 185.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 204.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0056, Training accuracy: 1.0000\n",
      "Test loss: 0.0216, Test accuracy: 1.0000\n",
      "Epoch 75/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 185.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 128.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0054, Training accuracy: 1.0000\n",
      "Test loss: 0.0216, Test accuracy: 1.0000\n",
      "Epoch 76/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 191.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 693.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0056, Training accuracy: 1.0000\n",
      "Test loss: 0.0216, Test accuracy: 1.0000\n",
      "Epoch 77/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 153.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 201.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0056, Training accuracy: 1.0000\n",
      "Test loss: 0.0216, Test accuracy: 1.0000\n",
      "Epoch 78/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 165.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 902.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0054, Training accuracy: 1.0000\n",
      "Test loss: 0.0216, Test accuracy: 1.0000\n",
      "Epoch 79/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 158.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1469.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0055, Training accuracy: 1.0000\n",
      "Test loss: 0.0216, Test accuracy: 1.0000\n",
      "Epoch 80/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 225.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0216, Test accuracy: 1.0000\n",
      "Epoch 81/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0216, Test accuracy: 1.0000\n",
      "Epoch 82/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 158.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1207.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0216, Test accuracy: 1.0000\n",
      "Epoch 83/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 190.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 889.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0056, Training accuracy: 1.0000\n",
      "Test loss: 0.0216, Test accuracy: 1.0000\n",
      "Epoch 84/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 156.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 170.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0056, Training accuracy: 1.0000\n",
      "Test loss: 0.0216, Test accuracy: 1.0000\n",
      "Epoch 85/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 157.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0216, Test accuracy: 1.0000\n",
      "Epoch 86/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 175.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 328.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0216, Test accuracy: 1.0000\n",
      "Epoch 87/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0054, Training accuracy: 1.0000\n",
      "Test loss: 0.0216, Test accuracy: 1.0000\n",
      "Epoch 88/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0054, Training accuracy: 1.0000\n",
      "Test loss: 0.0215, Test accuracy: 1.0000\n",
      "Epoch 89/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 172.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 217.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0215, Test accuracy: 1.0000\n",
      "Epoch 90/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 121.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 318.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0215, Test accuracy: 1.0000\n",
      "Epoch 91/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 128.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 203.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0055, Training accuracy: 1.0000\n",
      "Test loss: 0.0215, Test accuracy: 1.0000\n",
      "Epoch 92/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 173.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0056, Training accuracy: 1.0000\n",
      "Test loss: 0.0215, Test accuracy: 1.0000\n",
      "Epoch 93/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 193.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1090.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0054, Training accuracy: 1.0000\n",
      "Test loss: 0.0215, Test accuracy: 1.0000\n",
      "Epoch 94/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 217.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0052, Training accuracy: 1.0000\n",
      "Test loss: 0.0215, Test accuracy: 1.0000\n",
      "Epoch 95/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0215, Test accuracy: 1.0000\n",
      "Epoch 96/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 148.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 214.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0052, Training accuracy: 1.0000\n",
      "Test loss: 0.0215, Test accuracy: 1.0000\n",
      "Epoch 97/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 185.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0054, Training accuracy: 1.0000\n",
      "Test loss: 0.0215, Test accuracy: 1.0000\n",
      "Epoch 98/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 164.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 556.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0215, Test accuracy: 1.0000\n",
      "Epoch 99/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 160.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 814.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0215, Test accuracy: 1.0000\n",
      "Epoch 100/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 164.54it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 442.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0215, Test accuracy: 1.0000\n",
      "Epoch 101/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 167.51it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 616.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0073, Training accuracy: 1.0000\n",
      "Test loss: 0.0215, Test accuracy: 1.0000\n",
      "Epoch 102/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 128.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0214, Test accuracy: 1.0000\n",
      "Epoch 103/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 185.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0052, Training accuracy: 1.0000\n",
      "Test loss: 0.0214, Test accuracy: 1.0000\n",
      "Epoch 104/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 193.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 784.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0214, Test accuracy: 1.0000\n",
      "Epoch 105/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 158.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 206.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0058, Training accuracy: 1.0000\n",
      "Test loss: 0.0214, Test accuracy: 1.0000\n",
      "Epoch 106/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 219.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0060, Training accuracy: 1.0000\n",
      "Test loss: 0.0214, Test accuracy: 1.0000\n",
      "Epoch 107/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 196.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0062, Training accuracy: 1.0000\n",
      "Test loss: 0.0214, Test accuracy: 1.0000\n",
      "Epoch 108/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 192.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 201.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0051, Training accuracy: 1.0000\n",
      "Test loss: 0.0214, Test accuracy: 1.0000\n",
      "Epoch 109/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0052, Training accuracy: 1.0000\n",
      "Test loss: 0.0213, Test accuracy: 1.0000\n",
      "Epoch 110/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 34030.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0052, Training accuracy: 1.0000\n",
      "Test loss: 0.0213, Test accuracy: 1.0000\n",
      "Epoch 111/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 205.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0058, Training accuracy: 1.0000\n",
      "Test loss: 0.0213, Test accuracy: 1.0000\n",
      "Epoch 112/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 193.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0213, Test accuracy: 1.0000\n",
      "Epoch 113/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 168.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0054, Training accuracy: 1.0000\n",
      "Test loss: 0.0213, Test accuracy: 1.0000\n",
      "Epoch 114/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 125.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0213, Test accuracy: 1.0000\n",
      "Epoch 115/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 155.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0051, Training accuracy: 1.0000\n",
      "Test loss: 0.0213, Test accuracy: 1.0000\n",
      "Epoch 116/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 140.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 330.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0051, Training accuracy: 1.0000\n",
      "Test loss: 0.0213, Test accuracy: 1.0000\n",
      "Epoch 117/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 154.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0213, Test accuracy: 1.0000\n",
      "Epoch 118/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 389.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0051, Training accuracy: 1.0000\n",
      "Test loss: 0.0212, Test accuracy: 1.0000\n",
      "Epoch 119/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0052, Training accuracy: 1.0000\n",
      "Test loss: 0.0212, Test accuracy: 1.0000\n",
      "Epoch 120/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 161.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 182.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0051, Training accuracy: 1.0000\n",
      "Test loss: 0.0212, Test accuracy: 1.0000\n",
      "Epoch 121/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 167.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 303.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0051, Training accuracy: 1.0000\n",
      "Test loss: 0.0212, Test accuracy: 1.0000\n",
      "Epoch 122/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 153.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 194.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0051, Training accuracy: 1.0000\n",
      "Test loss: 0.0212, Test accuracy: 1.0000\n",
      "Epoch 123/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 127.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0212, Test accuracy: 1.0000\n",
      "Epoch 124/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 152.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0051, Training accuracy: 1.0000\n",
      "Test loss: 0.0212, Test accuracy: 1.0000\n",
      "Epoch 125/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 172.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0212, Test accuracy: 1.0000\n",
      "Epoch 126/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 167.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 182.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0051, Training accuracy: 1.0000\n",
      "Test loss: 0.0212, Test accuracy: 1.0000\n",
      "Epoch 127/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 100.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0058, Training accuracy: 1.0000\n",
      "Test loss: 0.0212, Test accuracy: 1.0000\n",
      "Epoch 128/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 161.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0051, Training accuracy: 1.0000\n",
      "Test loss: 0.0211, Test accuracy: 1.0000\n",
      "Epoch 129/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 350.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 408.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0052, Training accuracy: 1.0000\n",
      "Test loss: 0.0211, Test accuracy: 1.0000\n",
      "Epoch 130/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 314.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0050, Training accuracy: 1.0000\n",
      "Test loss: 0.0211, Test accuracy: 1.0000\n",
      "Epoch 131/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 434.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0057, Training accuracy: 1.0000\n",
      "Test loss: 0.0211, Test accuracy: 1.0000\n",
      "Epoch 132/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 299.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0211, Test accuracy: 1.0000\n",
      "Epoch 133/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 276.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0050, Training accuracy: 1.0000\n",
      "Test loss: 0.0211, Test accuracy: 1.0000\n",
      "Epoch 134/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 272.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 295.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0051, Training accuracy: 1.0000\n",
      "Test loss: 0.0211, Test accuracy: 1.0000\n",
      "Epoch 135/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 245.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 641.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0057, Training accuracy: 1.0000\n",
      "Test loss: 0.0211, Test accuracy: 1.0000\n",
      "Epoch 136/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 200.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0069, Training accuracy: 1.0000\n",
      "Test loss: 0.0210, Test accuracy: 1.0000\n",
      "Epoch 137/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 281.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 286.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0058, Training accuracy: 1.0000\n",
      "Test loss: 0.0210, Test accuracy: 1.0000\n",
      "Epoch 138/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 303.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0050, Training accuracy: 1.0000\n",
      "Test loss: 0.0210, Test accuracy: 1.0000\n",
      "Epoch 139/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 302.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0056, Training accuracy: 1.0000\n",
      "Test loss: 0.0209, Test accuracy: 1.0000\n",
      "Epoch 140/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 295.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0069, Training accuracy: 1.0000\n",
      "Test loss: 0.0209, Test accuracy: 1.0000\n",
      "Epoch 141/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 431.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0050, Training accuracy: 1.0000\n",
      "Test loss: 0.0209, Test accuracy: 1.0000\n",
      "Epoch 142/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 349.69it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 554.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0050, Training accuracy: 1.0000\n",
      "Test loss: 0.0209, Test accuracy: 1.0000\n",
      "Epoch 143/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 346.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3187.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0049, Training accuracy: 1.0000\n",
      "Test loss: 0.0209, Test accuracy: 1.0000\n",
      "Epoch 144/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 268.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1984.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0063, Training accuracy: 1.0000\n",
      "Test loss: 0.0209, Test accuracy: 1.0000\n",
      "Epoch 145/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 457.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0056, Training accuracy: 1.0000\n",
      "Test loss: 0.0208, Test accuracy: 1.0000\n",
      "Epoch 146/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 429.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0049, Training accuracy: 1.0000\n",
      "Test loss: 0.0208, Test accuracy: 1.0000\n",
      "Epoch 147/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 435.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0049, Training accuracy: 1.0000\n",
      "Test loss: 0.0208, Test accuracy: 1.0000\n",
      "Epoch 148/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 298.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0059, Training accuracy: 1.0000\n",
      "Test loss: 0.0208, Test accuracy: 1.0000\n",
      "Epoch 149/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 307.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0061, Training accuracy: 1.0000\n",
      "Test loss: 0.0208, Test accuracy: 1.0000\n",
      "Epoch 150/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 301.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0049, Training accuracy: 1.0000\n",
      "Test loss: 0.0208, Test accuracy: 1.0000\n",
      "Epoch 151/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 294.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0051, Training accuracy: 1.0000\n",
      "Test loss: 0.0208, Test accuracy: 1.0000\n",
      "Epoch 152/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 304.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0050, Training accuracy: 1.0000\n",
      "Test loss: 0.0208, Test accuracy: 1.0000\n",
      "Epoch 153/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 298.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0050, Training accuracy: 1.0000\n",
      "Test loss: 0.0208, Test accuracy: 1.0000\n",
      "Epoch 154/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 285.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 500.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0051, Training accuracy: 1.0000\n",
      "Test loss: 0.0208, Test accuracy: 1.0000\n",
      "Epoch 155/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 364.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0058, Training accuracy: 1.0000\n",
      "Test loss: 0.0208, Test accuracy: 1.0000\n",
      "Epoch 156/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 352.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 419.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0049, Training accuracy: 1.0000\n",
      "Test loss: 0.0208, Test accuracy: 1.0000\n",
      "Epoch 157/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 562.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 212.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0048, Training accuracy: 1.0000\n",
      "Test loss: 0.0208, Test accuracy: 1.0000\n",
      "Epoch 158/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 301.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0056, Training accuracy: 1.0000\n",
      "Test loss: 0.0208, Test accuracy: 1.0000\n",
      "Epoch 159/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 310.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0049, Training accuracy: 1.0000\n",
      "Test loss: 0.0208, Test accuracy: 1.0000\n",
      "Epoch 160/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 278.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0048, Training accuracy: 1.0000\n",
      "Test loss: 0.0208, Test accuracy: 1.0000\n",
      "Epoch 161/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 213.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 420.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0048, Training accuracy: 1.0000\n",
      "Test loss: 0.0207, Test accuracy: 1.0000\n",
      "Epoch 162/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 472.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0049, Training accuracy: 1.0000\n",
      "Test loss: 0.0207, Test accuracy: 1.0000\n",
      "Epoch 163/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 340.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 866.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0048, Training accuracy: 1.0000\n",
      "Test loss: 0.0207, Test accuracy: 1.0000\n",
      "Epoch 164/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 443.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0048, Training accuracy: 1.0000\n",
      "Test loss: 0.0207, Test accuracy: 1.0000\n",
      "Epoch 165/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 297.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0048, Training accuracy: 1.0000\n",
      "Test loss: 0.0207, Test accuracy: 1.0000\n",
      "Epoch 166/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 304.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0048, Training accuracy: 1.0000\n",
      "Test loss: 0.0207, Test accuracy: 1.0000\n",
      "Epoch 167/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 369.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0207, Test accuracy: 1.0000\n",
      "Epoch 168/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 338.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0048, Training accuracy: 1.0000\n",
      "Test loss: 0.0206, Test accuracy: 1.0000\n",
      "Epoch 169/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 379.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0047, Training accuracy: 1.0000\n",
      "Test loss: 0.0206, Test accuracy: 1.0000\n",
      "Epoch 170/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 318.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0048, Training accuracy: 1.0000\n",
      "Test loss: 0.0206, Test accuracy: 1.0000\n",
      "Epoch 171/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 485.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0050, Training accuracy: 1.0000\n",
      "Test loss: 0.0206, Test accuracy: 1.0000\n",
      "Epoch 172/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 439.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0048, Training accuracy: 1.0000\n",
      "Test loss: 0.0206, Test accuracy: 1.0000\n",
      "Epoch 173/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 300.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2757.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0048, Training accuracy: 1.0000\n",
      "Test loss: 0.0206, Test accuracy: 1.0000\n",
      "Epoch 174/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 280.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 500.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0048, Training accuracy: 1.0000\n",
      "Test loss: 0.0206, Test accuracy: 1.0000\n",
      "Epoch 175/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 345.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 364.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0049, Training accuracy: 1.0000\n",
      "Test loss: 0.0206, Test accuracy: 1.0000\n",
      "Epoch 176/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 357.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 436.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0047, Training accuracy: 1.0000\n",
      "Test loss: 0.0206, Test accuracy: 1.0000\n",
      "Epoch 177/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 373.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0048, Training accuracy: 1.0000\n",
      "Test loss: 0.0206, Test accuracy: 1.0000\n",
      "Epoch 178/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 440.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0051, Training accuracy: 1.0000\n",
      "Test loss: 0.0205, Test accuracy: 1.0000\n",
      "Epoch 179/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 432.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0049, Training accuracy: 1.0000\n",
      "Test loss: 0.0205, Test accuracy: 1.0000\n",
      "Epoch 180/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 337.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 423.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0052, Training accuracy: 1.0000\n",
      "Test loss: 0.0205, Test accuracy: 1.0000\n",
      "Epoch 181/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 364.19it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1311.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0046, Training accuracy: 1.0000\n",
      "Test loss: 0.0205, Test accuracy: 1.0000\n",
      "Epoch 182/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 322.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0055, Training accuracy: 1.0000\n",
      "Test loss: 0.0205, Test accuracy: 1.0000\n",
      "Epoch 183/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 355.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 440.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0046, Training accuracy: 1.0000\n",
      "Test loss: 0.0205, Test accuracy: 1.0000\n",
      "Epoch 184/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 338.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 456.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0046, Training accuracy: 1.0000\n",
      "Test loss: 0.0205, Test accuracy: 1.0000\n",
      "Epoch 185/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 306.51it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 672.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0047, Training accuracy: 1.0000\n",
      "Test loss: 0.0205, Test accuracy: 1.0000\n",
      "Epoch 186/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 424.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0046, Training accuracy: 1.0000\n",
      "Test loss: 0.0204, Test accuracy: 1.0000\n",
      "Epoch 187/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 464.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 230.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0046, Training accuracy: 1.0000\n",
      "Test loss: 0.0204, Test accuracy: 1.0000\n",
      "Epoch 188/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 425.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0047, Training accuracy: 1.0000\n",
      "Test loss: 0.0204, Test accuracy: 1.0000\n",
      "Epoch 189/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 478.50it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1632.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0046, Training accuracy: 1.0000\n",
      "Test loss: 0.0204, Test accuracy: 1.0000\n",
      "Epoch 190/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 293.78it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 448.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0047, Training accuracy: 1.0000\n",
      "Test loss: 0.0204, Test accuracy: 1.0000\n",
      "Epoch 191/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 303.16it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 812.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0204, Test accuracy: 1.0000\n",
      "Epoch 192/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 475.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 217.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0047, Training accuracy: 1.0000\n",
      "Test loss: 0.0204, Test accuracy: 1.0000\n",
      "Epoch 193/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 297.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0045, Training accuracy: 1.0000\n",
      "Test loss: 0.0203, Test accuracy: 1.0000\n",
      "Epoch 194/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 309.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0045, Training accuracy: 1.0000\n",
      "Test loss: 0.0203, Test accuracy: 1.0000\n",
      "Epoch 195/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 379.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0046, Training accuracy: 1.0000\n",
      "Test loss: 0.0203, Test accuracy: 1.0000\n",
      "Epoch 196/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 493.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 205.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0048, Training accuracy: 1.0000\n",
      "Test loss: 0.0203, Test accuracy: 1.0000\n",
      "Epoch 197/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 320.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 557.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0047, Training accuracy: 1.0000\n",
      "Test loss: 0.0203, Test accuracy: 1.0000\n",
      "Epoch 198/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 383.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0046, Training accuracy: 1.0000\n",
      "Test loss: 0.0203, Test accuracy: 1.0000\n",
      "Epoch 199/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 424.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0045, Training accuracy: 1.0000\n",
      "Test loss: 0.0203, Test accuracy: 1.0000\n",
      "Epoch 200/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 447.94it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0045, Training accuracy: 1.0000\n",
      "Test loss: 0.0203, Test accuracy: 1.0000\n",
      "Epoch 201/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 270.99it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 500.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0046, Training accuracy: 1.0000\n",
      "Test loss: 0.0202, Test accuracy: 1.0000\n",
      "Epoch 202/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 300.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0045, Training accuracy: 1.0000\n",
      "Test loss: 0.0202, Test accuracy: 1.0000\n",
      "Epoch 203/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 305.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 206.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0202, Test accuracy: 1.0000\n",
      "Epoch 204/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 300.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 285.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0051, Training accuracy: 1.0000\n",
      "Test loss: 0.0202, Test accuracy: 1.0000\n",
      "Epoch 205/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 239.99it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 485.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0045, Training accuracy: 1.0000\n",
      "Test loss: 0.0201, Test accuracy: 1.0000\n",
      "Epoch 206/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 307.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0045, Training accuracy: 1.0000\n",
      "Test loss: 0.0201, Test accuracy: 1.0000\n",
      "Epoch 207/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 296.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 352.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0045, Training accuracy: 1.0000\n",
      "Test loss: 0.0201, Test accuracy: 1.0000\n",
      "Epoch 208/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 297.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 4652.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0047, Training accuracy: 1.0000\n",
      "Test loss: 0.0201, Test accuracy: 1.0000\n",
      "Epoch 209/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 289.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1011.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0048, Training accuracy: 1.0000\n",
      "Test loss: 0.0201, Test accuracy: 1.0000\n",
      "Epoch 210/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 276.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1507.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0046, Training accuracy: 1.0000\n",
      "Test loss: 0.0201, Test accuracy: 1.0000\n",
      "Epoch 211/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 322.66it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1049.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0049, Training accuracy: 1.0000\n",
      "Test loss: 0.0201, Test accuracy: 1.0000\n",
      "Epoch 212/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 332.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 500.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0045, Training accuracy: 1.0000\n",
      "Test loss: 0.0200, Test accuracy: 1.0000\n",
      "Epoch 213/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 393.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0044, Training accuracy: 1.0000\n",
      "Test loss: 0.0200, Test accuracy: 1.0000\n",
      "Epoch 214/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 502.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 194.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0044, Training accuracy: 1.0000\n",
      "Test loss: 0.0200, Test accuracy: 1.0000\n",
      "Epoch 215/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 257.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 281.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0044, Training accuracy: 1.0000\n",
      "Test loss: 0.0200, Test accuracy: 1.0000\n",
      "Epoch 216/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 325.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 454.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0044, Training accuracy: 1.0000\n",
      "Test loss: 0.0200, Test accuracy: 1.0000\n",
      "Epoch 217/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 350.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 415.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0050, Training accuracy: 1.0000\n",
      "Test loss: 0.0200, Test accuracy: 1.0000\n",
      "Epoch 218/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 351.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0045, Training accuracy: 1.0000\n",
      "Test loss: 0.0200, Test accuracy: 1.0000\n",
      "Epoch 219/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 282.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0045, Training accuracy: 1.0000\n",
      "Test loss: 0.0199, Test accuracy: 1.0000\n",
      "Epoch 220/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 380.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 284.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0044, Training accuracy: 1.0000\n",
      "Test loss: 0.0199, Test accuracy: 1.0000\n",
      "Epoch 221/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 282.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 571.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0046, Training accuracy: 1.0000\n",
      "Test loss: 0.0199, Test accuracy: 1.0000\n",
      "Epoch 222/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 429.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 211.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0049, Training accuracy: 1.0000\n",
      "Test loss: 0.0199, Test accuracy: 1.0000\n",
      "Epoch 223/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 295.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 572.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0043, Training accuracy: 1.0000\n",
      "Test loss: 0.0199, Test accuracy: 1.0000\n",
      "Epoch 224/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 330.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 500.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0045, Training accuracy: 1.0000\n",
      "Test loss: 0.0198, Test accuracy: 1.0000\n",
      "Epoch 225/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 316.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 571.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0045, Training accuracy: 1.0000\n",
      "Test loss: 0.0198, Test accuracy: 1.0000\n",
      "Epoch 226/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 399.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 205.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0043, Training accuracy: 1.0000\n",
      "Test loss: 0.0198, Test accuracy: 1.0000\n",
      "Epoch 227/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 317.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0042, Training accuracy: 1.0000\n",
      "Test loss: 0.0198, Test accuracy: 1.0000\n",
      "Epoch 228/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 305.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0043, Training accuracy: 1.0000\n",
      "Test loss: 0.0198, Test accuracy: 1.0000\n",
      "Epoch 229/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 322.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 503.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0044, Training accuracy: 1.0000\n",
      "Test loss: 0.0198, Test accuracy: 1.0000\n",
      "Epoch 230/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 346.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0043, Training accuracy: 1.0000\n",
      "Test loss: 0.0197, Test accuracy: 1.0000\n",
      "Epoch 231/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 304.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2397.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0042, Training accuracy: 1.0000\n",
      "Test loss: 0.0197, Test accuracy: 1.0000\n",
      "Epoch 232/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 285.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 275.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0049, Training accuracy: 1.0000\n",
      "Test loss: 0.0197, Test accuracy: 1.0000\n",
      "Epoch 233/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 298.70it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0043, Training accuracy: 1.0000\n",
      "Test loss: 0.0197, Test accuracy: 1.0000\n",
      "Epoch 234/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 400.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1002.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0043, Training accuracy: 1.0000\n",
      "Test loss: 0.0197, Test accuracy: 1.0000\n",
      "Epoch 235/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 294.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 292.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0043, Training accuracy: 1.0000\n",
      "Test loss: 0.0197, Test accuracy: 1.0000\n",
      "Epoch 236/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 313.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 438.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0045, Training accuracy: 1.0000\n",
      "Test loss: 0.0197, Test accuracy: 1.0000\n",
      "Epoch 237/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 340.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 283.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0041, Training accuracy: 1.0000\n",
      "Test loss: 0.0196, Test accuracy: 1.0000\n",
      "Epoch 238/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 304.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0043, Training accuracy: 1.0000\n",
      "Test loss: 0.0196, Test accuracy: 1.0000\n",
      "Epoch 239/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 296.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1531.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0044, Training accuracy: 1.0000\n",
      "Test loss: 0.0196, Test accuracy: 1.0000\n",
      "Epoch 240/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 286.90it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 263.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0041, Training accuracy: 1.0000\n",
      "Test loss: 0.0196, Test accuracy: 1.0000\n",
      "Epoch 241/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 289.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0043, Training accuracy: 1.0000\n",
      "Test loss: 0.0196, Test accuracy: 1.0000\n",
      "Epoch 242/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 292.50it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 213.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0044, Training accuracy: 1.0000\n",
      "Test loss: 0.0196, Test accuracy: 1.0000\n",
      "Epoch 243/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 325.94it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0044, Training accuracy: 1.0000\n",
      "Test loss: 0.0195, Test accuracy: 1.0000\n",
      "Epoch 244/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 304.16it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0041, Training accuracy: 1.0000\n",
      "Test loss: 0.0195, Test accuracy: 1.0000\n",
      "Epoch 245/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 298.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 186.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0043, Training accuracy: 1.0000\n",
      "Test loss: 0.0195, Test accuracy: 1.0000\n",
      "Epoch 246/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 215.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 591.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0043, Training accuracy: 1.0000\n",
      "Test loss: 0.0195, Test accuracy: 1.0000\n",
      "Epoch 247/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 315.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0047, Training accuracy: 1.0000\n",
      "Test loss: 0.0195, Test accuracy: 1.0000\n",
      "Epoch 248/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 332.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 403.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0043, Training accuracy: 1.0000\n",
      "Test loss: 0.0195, Test accuracy: 1.0000\n",
      "Epoch 249/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 300.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 473.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0041, Training accuracy: 1.0000\n",
      "Test loss: 0.0195, Test accuracy: 1.0000\n",
      "Epoch 250/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 308.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 561.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0044, Training accuracy: 1.0000\n",
      "Test loss: 0.0195, Test accuracy: 1.0000\n",
      "Epoch 251/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 403.51it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0041, Training accuracy: 1.0000\n",
      "Test loss: 0.0194, Test accuracy: 1.0000\n",
      "Epoch 252/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 267.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 500.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0040, Training accuracy: 1.0000\n",
      "Test loss: 0.0194, Test accuracy: 1.0000\n",
      "Epoch 253/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 289.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 173.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0042, Training accuracy: 1.0000\n",
      "Test loss: 0.0194, Test accuracy: 1.0000\n",
      "Epoch 254/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 304.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 568.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0040, Training accuracy: 1.0000\n",
      "Test loss: 0.0194, Test accuracy: 1.0000\n",
      "Epoch 255/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 355.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 388.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0041, Training accuracy: 1.0000\n",
      "Test loss: 0.0194, Test accuracy: 1.0000\n",
      "Epoch 256/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 344.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0040, Training accuracy: 1.0000\n",
      "Test loss: 0.0194, Test accuracy: 1.0000\n",
      "Epoch 257/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 320.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0041, Training accuracy: 1.0000\n",
      "Test loss: 0.0194, Test accuracy: 1.0000\n",
      "Epoch 258/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 315.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 405.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0040, Training accuracy: 1.0000\n",
      "Test loss: 0.0193, Test accuracy: 1.0000\n",
      "Epoch 259/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 299.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 411.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0041, Training accuracy: 1.0000\n",
      "Test loss: 0.0193, Test accuracy: 1.0000\n",
      "Epoch 260/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 228.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 499.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0042, Training accuracy: 1.0000\n",
      "Test loss: 0.0193, Test accuracy: 1.0000\n",
      "Epoch 261/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 396.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0041, Training accuracy: 1.0000\n",
      "Test loss: 0.0193, Test accuracy: 1.0000\n",
      "Epoch 262/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 334.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 475.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0042, Training accuracy: 1.0000\n",
      "Test loss: 0.0193, Test accuracy: 1.0000\n",
      "Epoch 263/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 355.54it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 474.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0048, Training accuracy: 1.0000\n",
      "Test loss: 0.0193, Test accuracy: 1.0000\n",
      "Epoch 264/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 371.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 447.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0040, Training accuracy: 1.0000\n",
      "Test loss: 0.0192, Test accuracy: 1.0000\n",
      "Epoch 265/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 254.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 440.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0039, Training accuracy: 1.0000\n",
      "Test loss: 0.0192, Test accuracy: 1.0000\n",
      "Epoch 266/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 431.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0039, Training accuracy: 1.0000\n",
      "Test loss: 0.0192, Test accuracy: 1.0000\n",
      "Epoch 267/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 480.02it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0040, Training accuracy: 1.0000\n",
      "Test loss: 0.0192, Test accuracy: 1.0000\n",
      "Epoch 268/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 276.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0045, Training accuracy: 1.0000\n",
      "Test loss: 0.0192, Test accuracy: 1.0000\n",
      "Epoch 269/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 283.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 425.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0041, Training accuracy: 1.0000\n",
      "Test loss: 0.0191, Test accuracy: 1.0000\n",
      "Epoch 270/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 405.99it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0038, Training accuracy: 1.0000\n",
      "Test loss: 0.0191, Test accuracy: 1.0000\n",
      "Epoch 271/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 239.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0039, Training accuracy: 1.0000\n",
      "Test loss: 0.0191, Test accuracy: 1.0000\n",
      "Epoch 272/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 389.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 206.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0038, Training accuracy: 1.0000\n",
      "Test loss: 0.0191, Test accuracy: 1.0000\n",
      "Epoch 273/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 333.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 259.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0039, Training accuracy: 1.0000\n",
      "Test loss: 0.0191, Test accuracy: 1.0000\n",
      "Epoch 274/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 329.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0038, Training accuracy: 1.0000\n",
      "Test loss: 0.0191, Test accuracy: 1.0000\n",
      "Epoch 275/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 243.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 492.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0038, Training accuracy: 1.0000\n",
      "Test loss: 0.0190, Test accuracy: 1.0000\n",
      "Epoch 276/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 214.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0038, Training accuracy: 1.0000\n",
      "Test loss: 0.0190, Test accuracy: 1.0000\n",
      "Epoch 277/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 169.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 208.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0038, Training accuracy: 1.0000\n",
      "Test loss: 0.0190, Test accuracy: 1.0000\n",
      "Epoch 278/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 189.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 223.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0041, Training accuracy: 1.0000\n",
      "Test loss: 0.0190, Test accuracy: 1.0000\n",
      "Epoch 279/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0038, Training accuracy: 1.0000\n",
      "Test loss: 0.0190, Test accuracy: 1.0000\n",
      "Epoch 280/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 185.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 206.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0039, Training accuracy: 1.0000\n",
      "Test loss: 0.0190, Test accuracy: 1.0000\n",
      "Epoch 281/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 237.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 765.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0040, Training accuracy: 1.0000\n",
      "Test loss: 0.0190, Test accuracy: 1.0000\n",
      "Epoch 282/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0038, Training accuracy: 1.0000\n",
      "Test loss: 0.0190, Test accuracy: 1.0000\n",
      "Epoch 283/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.51it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0043, Training accuracy: 1.0000\n",
      "Test loss: 0.0189, Test accuracy: 1.0000\n",
      "Epoch 284/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 209.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 258.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0037, Training accuracy: 1.0000\n",
      "Test loss: 0.0189, Test accuracy: 1.0000\n",
      "Epoch 285/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0040, Training accuracy: 1.0000\n",
      "Test loss: 0.0188, Test accuracy: 1.0000\n",
      "Epoch 286/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0038, Training accuracy: 1.0000\n",
      "Test loss: 0.0189, Test accuracy: 1.0000\n",
      "Epoch 287/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 175.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0038, Training accuracy: 1.0000\n",
      "Test loss: 0.0188, Test accuracy: 1.0000\n",
      "Epoch 288/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 260.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0039, Training accuracy: 1.0000\n",
      "Test loss: 0.0188, Test accuracy: 1.0000\n",
      "Epoch 289/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.53it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0038, Training accuracy: 1.0000\n",
      "Test loss: 0.0188, Test accuracy: 1.0000\n",
      "Epoch 290/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0042, Training accuracy: 1.0000\n",
      "Test loss: 0.0188, Test accuracy: 1.0000\n",
      "Epoch 291/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 217.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0040, Training accuracy: 1.0000\n",
      "Test loss: 0.0188, Test accuracy: 1.0000\n",
      "Epoch 292/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 187.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 195.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0036, Training accuracy: 1.0000\n",
      "Test loss: 0.0188, Test accuracy: 1.0000\n",
      "Epoch 293/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 185.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 202.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0038, Training accuracy: 1.0000\n",
      "Test loss: 0.0188, Test accuracy: 1.0000\n",
      "Epoch 294/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 203.70it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 172.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0038, Training accuracy: 1.0000\n",
      "Test loss: 0.0188, Test accuracy: 1.0000\n",
      "Epoch 295/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.66it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0036, Training accuracy: 1.0000\n",
      "Test loss: 0.0188, Test accuracy: 1.0000\n",
      "Epoch 296/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 175.78it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0036, Training accuracy: 1.0000\n",
      "Test loss: 0.0188, Test accuracy: 1.0000\n",
      "Epoch 297/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 154.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0040, Training accuracy: 1.0000\n",
      "Test loss: 0.0188, Test accuracy: 1.0000\n",
      "Epoch 298/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 224.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0037, Training accuracy: 1.0000\n",
      "Test loss: 0.0187, Test accuracy: 1.0000\n",
      "Epoch 299/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0046, Training accuracy: 1.0000\n",
      "Test loss: 0.0187, Test accuracy: 1.0000\n",
      "Epoch 300/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 147.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 193.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0038, Training accuracy: 1.0000\n",
      "Test loss: 0.0188, Test accuracy: 1.0000\n",
      "Epoch 301/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 154.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 223.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0036, Training accuracy: 1.0000\n",
      "Test loss: 0.0188, Test accuracy: 1.0000\n",
      "Epoch 302/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.19it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 183.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0039, Training accuracy: 1.0000\n",
      "Test loss: 0.0188, Test accuracy: 1.0000\n",
      "Epoch 303/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 144.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0035, Training accuracy: 1.0000\n",
      "Test loss: 0.0188, Test accuracy: 1.0000\n",
      "Epoch 304/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0037, Training accuracy: 1.0000\n",
      "Test loss: 0.0188, Test accuracy: 1.0000\n",
      "Epoch 305/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.53it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0039, Training accuracy: 1.0000\n",
      "Test loss: 0.0187, Test accuracy: 1.0000\n",
      "Epoch 306/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 156.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 259.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0036, Training accuracy: 1.0000\n",
      "Test loss: 0.0187, Test accuracy: 1.0000\n",
      "Epoch 307/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 156.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 220.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0035, Training accuracy: 1.0000\n",
      "Test loss: 0.0187, Test accuracy: 1.0000\n",
      "Epoch 308/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 146.90it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 209.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0036, Training accuracy: 1.0000\n",
      "Test loss: 0.0186, Test accuracy: 1.0000\n",
      "Epoch 309/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 258.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0186, Test accuracy: 1.0000\n",
      "Epoch 310/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 156.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1606.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0036, Training accuracy: 1.0000\n",
      "Test loss: 0.0186, Test accuracy: 1.0000\n",
      "Epoch 311/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 156.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 201.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0036, Training accuracy: 1.0000\n",
      "Test loss: 0.0186, Test accuracy: 1.0000\n",
      "Epoch 312/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0035, Training accuracy: 1.0000\n",
      "Test loss: 0.0186, Test accuracy: 1.0000\n",
      "Epoch 313/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 136.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 446.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0185, Test accuracy: 1.0000\n",
      "Epoch 314/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 135.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0185, Test accuracy: 1.0000\n",
      "Epoch 315/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 171.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 292.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0036, Training accuracy: 1.0000\n",
      "Test loss: 0.0185, Test accuracy: 1.0000\n",
      "Epoch 316/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 155.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0185, Test accuracy: 1.0000\n",
      "Epoch 317/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0035, Training accuracy: 1.0000\n",
      "Test loss: 0.0185, Test accuracy: 1.0000\n",
      "Epoch 318/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 166.78it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 350.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0185, Test accuracy: 1.0000\n",
      "Epoch 319/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 128.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0184, Test accuracy: 1.0000\n",
      "Epoch 320/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 164.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0184, Test accuracy: 1.0000\n",
      "Epoch 321/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 206.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0035, Training accuracy: 1.0000\n",
      "Test loss: 0.0184, Test accuracy: 1.0000\n",
      "Epoch 322/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 171.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0184, Test accuracy: 1.0000\n",
      "Epoch 323/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 154.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 205.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0184, Test accuracy: 1.0000\n",
      "Epoch 324/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0184, Test accuracy: 1.0000\n",
      "Epoch 325/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 190.70it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 229.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0035, Training accuracy: 1.0000\n",
      "Test loss: 0.0183, Test accuracy: 1.0000\n",
      "Epoch 326/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 159.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0033, Training accuracy: 1.0000\n",
      "Test loss: 0.0183, Test accuracy: 1.0000\n",
      "Epoch 327/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0033, Training accuracy: 1.0000\n",
      "Test loss: 0.0183, Test accuracy: 1.0000\n",
      "Epoch 328/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0033, Training accuracy: 1.0000\n",
      "Test loss: 0.0183, Test accuracy: 1.0000\n",
      "Epoch 329/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0182, Test accuracy: 1.0000\n",
      "Epoch 330/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.51it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0033, Training accuracy: 1.0000\n",
      "Test loss: 0.0182, Test accuracy: 1.0000\n",
      "Epoch 331/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 210.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 118.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0033, Training accuracy: 1.0000\n",
      "Test loss: 0.0182, Test accuracy: 1.0000\n",
      "Epoch 332/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 229.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 116.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0033, Training accuracy: 1.0000\n",
      "Test loss: 0.0182, Test accuracy: 1.0000\n",
      "Epoch 333/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 208.94it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0033, Training accuracy: 1.0000\n",
      "Test loss: 0.0181, Test accuracy: 1.0000\n",
      "Epoch 334/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 157.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 186.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0032, Training accuracy: 1.0000\n",
      "Test loss: 0.0181, Test accuracy: 1.0000\n",
      "Epoch 335/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 167.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 222.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0032, Training accuracy: 1.0000\n",
      "Test loss: 0.0181, Test accuracy: 1.0000\n",
      "Epoch 336/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 229.19it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0032, Training accuracy: 1.0000\n",
      "Test loss: 0.0181, Test accuracy: 1.0000\n",
      "Epoch 337/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0038, Training accuracy: 1.0000\n",
      "Test loss: 0.0181, Test accuracy: 1.0000\n",
      "Epoch 338/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.16it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0032, Training accuracy: 1.0000\n",
      "Test loss: 0.0180, Test accuracy: 1.0000\n",
      "Epoch 339/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 165.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0033, Training accuracy: 1.0000\n",
      "Test loss: 0.0180, Test accuracy: 1.0000\n",
      "Epoch 340/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 155.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 247.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0032, Training accuracy: 1.0000\n",
      "Test loss: 0.0180, Test accuracy: 1.0000\n",
      "Epoch 341/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0037, Training accuracy: 1.0000\n",
      "Test loss: 0.0180, Test accuracy: 1.0000\n",
      "Epoch 342/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 188.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 175.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0031, Training accuracy: 1.0000\n",
      "Test loss: 0.0179, Test accuracy: 1.0000\n",
      "Epoch 343/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 187.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 196.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0178, Test accuracy: 1.0000\n",
      "Epoch 344/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 142.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 470.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0033, Training accuracy: 1.0000\n",
      "Test loss: 0.0178, Test accuracy: 1.0000\n",
      "Epoch 345/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 185.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 923.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0032, Training accuracy: 1.0000\n",
      "Test loss: 0.0178, Test accuracy: 1.0000\n",
      "Epoch 346/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 159.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0032, Training accuracy: 1.0000\n",
      "Test loss: 0.0178, Test accuracy: 1.0000\n",
      "Epoch 347/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 215.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3515.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0178, Test accuracy: 1.0000\n",
      "Epoch 348/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 220.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0032, Training accuracy: 1.0000\n",
      "Test loss: 0.0178, Test accuracy: 1.0000\n",
      "Epoch 349/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 199.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0031, Training accuracy: 1.0000\n",
      "Test loss: 0.0178, Test accuracy: 1.0000\n",
      "Epoch 350/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0031, Training accuracy: 1.0000\n",
      "Test loss: 0.0177, Test accuracy: 1.0000\n",
      "Epoch 351/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 172.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0031, Training accuracy: 1.0000\n",
      "Test loss: 0.0177, Test accuracy: 1.0000\n",
      "Epoch 352/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 153.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0177, Test accuracy: 1.0000\n",
      "Epoch 353/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 167.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0031, Training accuracy: 1.0000\n",
      "Test loss: 0.0177, Test accuracy: 1.0000\n",
      "Epoch 354/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0031, Training accuracy: 1.0000\n",
      "Test loss: 0.0177, Test accuracy: 1.0000\n",
      "Epoch 355/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 218.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 126.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0031, Training accuracy: 1.0000\n",
      "Test loss: 0.0177, Test accuracy: 1.0000\n",
      "Epoch 356/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0177, Test accuracy: 1.0000\n",
      "Epoch 357/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 173.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0030, Training accuracy: 1.0000\n",
      "Test loss: 0.0177, Test accuracy: 1.0000\n",
      "Epoch 358/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 217.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0030, Training accuracy: 1.0000\n",
      "Test loss: 0.0177, Test accuracy: 1.0000\n",
      "Epoch 359/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 190.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0030, Training accuracy: 1.0000\n",
      "Test loss: 0.0176, Test accuracy: 1.0000\n",
      "Epoch 360/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 167.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0030, Training accuracy: 1.0000\n",
      "Test loss: 0.0176, Test accuracy: 1.0000\n",
      "Epoch 361/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 210.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0030, Training accuracy: 1.0000\n",
      "Test loss: 0.0176, Test accuracy: 1.0000\n",
      "Epoch 362/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.16it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0030, Training accuracy: 1.0000\n",
      "Test loss: 0.0176, Test accuracy: 1.0000\n",
      "Epoch 363/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 226.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0031, Training accuracy: 1.0000\n",
      "Test loss: 0.0176, Test accuracy: 1.0000\n",
      "Epoch 364/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 128.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0030, Training accuracy: 1.0000\n",
      "Test loss: 0.0175, Test accuracy: 1.0000\n",
      "Epoch 365/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0029, Training accuracy: 1.0000\n",
      "Test loss: 0.0175, Test accuracy: 1.0000\n",
      "Epoch 366/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 175.23it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1234.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0030, Training accuracy: 1.0000\n",
      "Test loss: 0.0175, Test accuracy: 1.0000\n",
      "Epoch 367/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 159.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0030, Training accuracy: 1.0000\n",
      "Test loss: 0.0175, Test accuracy: 1.0000\n",
      "Epoch 368/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 168.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 369.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0029, Training accuracy: 1.0000\n",
      "Test loss: 0.0174, Test accuracy: 1.0000\n",
      "Epoch 369/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 154.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0031, Training accuracy: 1.0000\n",
      "Test loss: 0.0174, Test accuracy: 1.0000\n",
      "Epoch 370/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 222.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0031, Training accuracy: 1.0000\n",
      "Test loss: 0.0174, Test accuracy: 1.0000\n",
      "Epoch 371/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 217.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0029, Training accuracy: 1.0000\n",
      "Test loss: 0.0174, Test accuracy: 1.0000\n",
      "Epoch 372/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 192.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0029, Training accuracy: 1.0000\n",
      "Test loss: 0.0174, Test accuracy: 1.0000\n",
      "Epoch 373/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 199.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0029, Training accuracy: 1.0000\n",
      "Test loss: 0.0173, Test accuracy: 1.0000\n",
      "Epoch 374/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 174.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0029, Training accuracy: 1.0000\n",
      "Test loss: 0.0173, Test accuracy: 1.0000\n",
      "Epoch 375/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 226.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0030, Training accuracy: 1.0000\n",
      "Test loss: 0.0173, Test accuracy: 1.0000\n",
      "Epoch 376/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 175.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0029, Training accuracy: 1.0000\n",
      "Test loss: 0.0173, Test accuracy: 1.0000\n",
      "Epoch 377/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 172.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0029, Training accuracy: 1.0000\n",
      "Test loss: 0.0173, Test accuracy: 1.0000\n",
      "Epoch 378/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.44it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0028, Training accuracy: 1.0000\n",
      "Test loss: 0.0172, Test accuracy: 1.0000\n",
      "Epoch 379/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0028, Training accuracy: 1.0000\n",
      "Test loss: 0.0172, Test accuracy: 1.0000\n",
      "Epoch 380/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 173.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0029, Training accuracy: 1.0000\n",
      "Test loss: 0.0172, Test accuracy: 1.0000\n",
      "Epoch 381/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 154.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0032, Training accuracy: 1.0000\n",
      "Test loss: 0.0172, Test accuracy: 1.0000\n",
      "Epoch 382/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 161.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0029, Training accuracy: 1.0000\n",
      "Test loss: 0.0171, Test accuracy: 1.0000\n",
      "Epoch 383/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 171.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0028, Training accuracy: 1.0000\n",
      "Test loss: 0.0171, Test accuracy: 1.0000\n",
      "Epoch 384/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 173.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0028, Training accuracy: 1.0000\n",
      "Test loss: 0.0171, Test accuracy: 1.0000\n",
      "Epoch 385/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0028, Training accuracy: 1.0000\n",
      "Test loss: 0.0171, Test accuracy: 1.0000\n",
      "Epoch 386/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0028, Training accuracy: 1.0000\n",
      "Test loss: 0.0170, Test accuracy: 1.0000\n",
      "Epoch 387/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 127.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0029, Training accuracy: 1.0000\n",
      "Test loss: 0.0170, Test accuracy: 1.0000\n",
      "Epoch 388/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 172.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 267.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0028, Training accuracy: 1.0000\n",
      "Test loss: 0.0170, Test accuracy: 1.0000\n",
      "Epoch 389/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0028, Training accuracy: 1.0000\n",
      "Test loss: 0.0170, Test accuracy: 1.0000\n",
      "Epoch 390/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0028, Training accuracy: 1.0000\n",
      "Test loss: 0.0170, Test accuracy: 1.0000\n",
      "Epoch 391/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 211.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0029, Training accuracy: 1.0000\n",
      "Test loss: 0.0170, Test accuracy: 1.0000\n",
      "Epoch 392/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0027, Training accuracy: 1.0000\n",
      "Test loss: 0.0169, Test accuracy: 1.0000\n",
      "Epoch 393/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 146.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0027, Training accuracy: 1.0000\n",
      "Test loss: 0.0169, Test accuracy: 1.0000\n",
      "Epoch 394/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 167.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0027, Training accuracy: 1.0000\n",
      "Test loss: 0.0169, Test accuracy: 1.0000\n",
      "Epoch 395/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 169.78it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0027, Training accuracy: 1.0000\n",
      "Test loss: 0.0169, Test accuracy: 1.0000\n",
      "Epoch 396/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 200.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0030, Training accuracy: 1.0000\n",
      "Test loss: 0.0168, Test accuracy: 1.0000\n",
      "Epoch 397/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0027, Training accuracy: 1.0000\n",
      "Test loss: 0.0168, Test accuracy: 1.0000\n",
      "Epoch 398/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 208.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0032, Training accuracy: 1.0000\n",
      "Test loss: 0.0168, Test accuracy: 1.0000\n",
      "Epoch 399/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 154.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0026, Training accuracy: 1.0000\n",
      "Test loss: 0.0168, Test accuracy: 1.0000\n",
      "Epoch 400/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 173.94it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0026, Training accuracy: 1.0000\n",
      "Test loss: 0.0168, Test accuracy: 1.0000\n",
      "Epoch 401/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0026, Training accuracy: 1.0000\n",
      "Test loss: 0.0168, Test accuracy: 1.0000\n",
      "Epoch 402/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 171.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0032, Training accuracy: 1.0000\n",
      "Test loss: 0.0168, Test accuracy: 1.0000\n",
      "Epoch 403/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 219.54it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0026, Training accuracy: 1.0000\n",
      "Test loss: 0.0167, Test accuracy: 1.0000\n",
      "Epoch 404/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 215.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0026, Training accuracy: 1.0000\n",
      "Test loss: 0.0167, Test accuracy: 1.0000\n",
      "Epoch 405/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 173.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 307.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0026, Training accuracy: 1.0000\n",
      "Test loss: 0.0167, Test accuracy: 1.0000\n",
      "Epoch 406/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 173.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0026, Training accuracy: 1.0000\n",
      "Test loss: 0.0166, Test accuracy: 1.0000\n",
      "Epoch 407/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 137.67it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 705.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0166, Test accuracy: 1.0000\n",
      "Epoch 408/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1682.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0027, Training accuracy: 1.0000\n",
      "Test loss: 0.0166, Test accuracy: 1.0000\n",
      "Epoch 409/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 216.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0026, Training accuracy: 1.0000\n",
      "Test loss: 0.0166, Test accuracy: 1.0000\n",
      "Epoch 410/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 222.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0166, Test accuracy: 1.0000\n",
      "Epoch 411/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 152.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0027, Training accuracy: 1.0000\n",
      "Test loss: 0.0166, Test accuracy: 1.0000\n",
      "Epoch 412/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 141.94it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 263.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0166, Test accuracy: 1.0000\n",
      "Epoch 413/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 185.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0165, Test accuracy: 1.0000\n",
      "Epoch 414/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 144.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 261.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0165, Test accuracy: 1.0000\n",
      "Epoch 415/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 130.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 125.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0165, Test accuracy: 1.0000\n",
      "Epoch 416/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0026, Training accuracy: 1.0000\n",
      "Test loss: 0.0165, Test accuracy: 1.0000\n",
      "Epoch 417/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0165, Test accuracy: 1.0000\n",
      "Epoch 418/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 166.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0165, Test accuracy: 1.0000\n",
      "Epoch 419/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 163.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0026, Training accuracy: 1.0000\n",
      "Test loss: 0.0164, Test accuracy: 1.0000\n",
      "Epoch 420/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 158.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 164.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0164, Test accuracy: 1.0000\n",
      "Epoch 421/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 153.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0164, Test accuracy: 1.0000\n",
      "Epoch 422/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.50it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0024, Training accuracy: 1.0000\n",
      "Test loss: 0.0164, Test accuracy: 1.0000\n",
      "Epoch 423/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 216.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0035, Training accuracy: 1.0000\n",
      "Test loss: 0.0164, Test accuracy: 1.0000\n",
      "Epoch 424/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0163, Test accuracy: 1.0000\n",
      "Epoch 425/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 229.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0163, Test accuracy: 1.0000\n",
      "Epoch 426/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0028, Training accuracy: 1.0000\n",
      "Test loss: 0.0163, Test accuracy: 1.0000\n",
      "Epoch 427/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.78it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0024, Training accuracy: 1.0000\n",
      "Test loss: 0.0162, Test accuracy: 1.0000\n",
      "Epoch 428/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 175.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0024, Training accuracy: 1.0000\n",
      "Test loss: 0.0162, Test accuracy: 1.0000\n",
      "Epoch 429/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0161, Test accuracy: 1.0000\n",
      "Epoch 430/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 175.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 127.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0024, Training accuracy: 1.0000\n",
      "Test loss: 0.0161, Test accuracy: 1.0000\n",
      "Epoch 431/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 222.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0024, Training accuracy: 1.0000\n",
      "Test loss: 0.0161, Test accuracy: 1.0000\n",
      "Epoch 432/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0161, Test accuracy: 1.0000\n",
      "Epoch 433/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0161, Test accuracy: 1.0000\n",
      "Epoch 434/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 146.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0161, Test accuracy: 1.0000\n",
      "Epoch 435/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 167.51it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0161, Test accuracy: 1.0000\n",
      "Epoch 436/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 190.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0024, Training accuracy: 1.0000\n",
      "Test loss: 0.0160, Test accuracy: 1.0000\n",
      "Epoch 437/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 174.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0160, Test accuracy: 1.0000\n",
      "Epoch 438/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0160, Test accuracy: 1.0000\n",
      "Epoch 439/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0160, Test accuracy: 1.0000\n",
      "Epoch 440/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0160, Test accuracy: 1.0000\n",
      "Epoch 441/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 148.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0024, Training accuracy: 1.0000\n",
      "Test loss: 0.0159, Test accuracy: 1.0000\n",
      "Epoch 442/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 190.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 423.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0022, Training accuracy: 1.0000\n",
      "Test loss: 0.0159, Test accuracy: 1.0000\n",
      "Epoch 443/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0026, Training accuracy: 1.0000\n",
      "Test loss: 0.0159, Test accuracy: 1.0000\n",
      "Epoch 444/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 168.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0027, Training accuracy: 1.0000\n",
      "Test loss: 0.0159, Test accuracy: 1.0000\n",
      "Epoch 445/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 155.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0159, Test accuracy: 1.0000\n",
      "Epoch 446/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0024, Training accuracy: 1.0000\n",
      "Test loss: 0.0159, Test accuracy: 1.0000\n",
      "Epoch 447/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0159, Test accuracy: 1.0000\n",
      "Epoch 448/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0159, Test accuracy: 1.0000\n",
      "Epoch 449/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 128.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0022, Training accuracy: 1.0000\n",
      "Test loss: 0.0159, Test accuracy: 1.0000\n",
      "Epoch 450/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 187.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0159, Test accuracy: 1.0000\n",
      "Epoch 451/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 189.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 203.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0022, Training accuracy: 1.0000\n",
      "Test loss: 0.0159, Test accuracy: 1.0000\n",
      "Epoch 452/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0022, Training accuracy: 1.0000\n",
      "Test loss: 0.0159, Test accuracy: 1.0000\n",
      "Epoch 453/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.69it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 199.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0024, Training accuracy: 1.0000\n",
      "Test loss: 0.0158, Test accuracy: 1.0000\n",
      "Epoch 454/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 294.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0022, Training accuracy: 1.0000\n",
      "Test loss: 0.0158, Test accuracy: 1.0000\n",
      "Epoch 455/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 169.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 273.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0022, Training accuracy: 1.0000\n",
      "Test loss: 0.0158, Test accuracy: 1.0000\n",
      "Epoch 456/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 274.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0158, Test accuracy: 1.0000\n",
      "Epoch 457/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 197.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0158, Test accuracy: 1.0000\n",
      "Epoch 458/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 235.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 258.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0157, Test accuracy: 1.0000\n",
      "Epoch 459/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 194.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0157, Test accuracy: 1.0000\n",
      "Epoch 460/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0157, Test accuracy: 1.0000\n",
      "Epoch 461/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2358.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0031, Training accuracy: 1.0000\n",
      "Test loss: 0.0157, Test accuracy: 1.0000\n",
      "Epoch 462/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 195.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0022, Training accuracy: 1.0000\n",
      "Test loss: 0.0156, Test accuracy: 1.0000\n",
      "Epoch 463/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 236.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0156, Test accuracy: 1.0000\n",
      "Epoch 464/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 155.51it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0155, Test accuracy: 1.0000\n",
      "Epoch 465/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0022, Training accuracy: 1.0000\n",
      "Test loss: 0.0155, Test accuracy: 1.0000\n",
      "Epoch 466/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.67it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0155, Test accuracy: 1.0000\n",
      "Epoch 467/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 215.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0155, Test accuracy: 1.0000\n",
      "Epoch 468/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 144.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0155, Test accuracy: 1.0000\n",
      "Epoch 469/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 167.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 154.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0155, Test accuracy: 1.0000\n",
      "Epoch 470/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 174.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0154, Test accuracy: 1.0000\n",
      "Epoch 471/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0154, Test accuracy: 1.0000\n",
      "Epoch 472/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 146.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0020, Training accuracy: 1.0000\n",
      "Test loss: 0.0154, Test accuracy: 1.0000\n",
      "Epoch 473/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 189.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 259.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0154, Test accuracy: 1.0000\n",
      "Epoch 474/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 171.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 132.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0020, Training accuracy: 1.0000\n",
      "Test loss: 0.0153, Test accuracy: 1.0000\n",
      "Epoch 475/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 571.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0153, Test accuracy: 1.0000\n",
      "Epoch 476/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 218.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0153, Test accuracy: 1.0000\n",
      "Epoch 477/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 170.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 154.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0153, Test accuracy: 1.0000\n",
      "Epoch 478/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 172.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 120.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0020, Training accuracy: 1.0000\n",
      "Test loss: 0.0153, Test accuracy: 1.0000\n",
      "Epoch 479/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 127.44it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0152, Test accuracy: 1.0000\n",
      "Epoch 480/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 175.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0152, Test accuracy: 1.0000\n",
      "Epoch 481/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 193.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0152, Test accuracy: 1.0000\n",
      "Epoch 482/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 208.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0020, Training accuracy: 1.0000\n",
      "Test loss: 0.0151, Test accuracy: 1.0000\n",
      "Epoch 483/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 247.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0020, Training accuracy: 1.0000\n",
      "Test loss: 0.0151, Test accuracy: 1.0000\n",
      "Epoch 484/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 174.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0151, Test accuracy: 1.0000\n",
      "Epoch 485/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.02it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0020, Training accuracy: 1.0000\n",
      "Test loss: 0.0151, Test accuracy: 1.0000\n",
      "Epoch 486/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2457.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0020, Training accuracy: 1.0000\n",
      "Test loss: 0.0151, Test accuracy: 1.0000\n",
      "Epoch 487/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 234.19it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1295.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0151, Test accuracy: 1.0000\n",
      "Epoch 488/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 225.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0150, Test accuracy: 1.0000\n",
      "Epoch 489/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 168.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0150, Test accuracy: 1.0000\n",
      "Epoch 490/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 222.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0151, Test accuracy: 1.0000\n",
      "Epoch 491/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 220.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2842.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0151, Test accuracy: 1.0000\n",
      "Epoch 492/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 221.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0020, Training accuracy: 1.0000\n",
      "Test loss: 0.0151, Test accuracy: 1.0000\n",
      "Epoch 493/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 223.44it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0020, Training accuracy: 1.0000\n",
      "Test loss: 0.0151, Test accuracy: 1.0000\n",
      "Epoch 494/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0151, Test accuracy: 1.0000\n",
      "Epoch 495/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 214.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0151, Test accuracy: 1.0000\n",
      "Epoch 496/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0150, Test accuracy: 1.0000\n",
      "Epoch 497/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0020, Training accuracy: 1.0000\n",
      "Test loss: 0.0150, Test accuracy: 1.0000\n",
      "Epoch 498/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 145.66it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 272.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0150, Test accuracy: 1.0000\n",
      "Epoch 499/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0150, Test accuracy: 1.0000\n",
      "Epoch 500/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 175.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0150, Test accuracy: 1.0000\n",
      "Epoch 501/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 224.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0149, Test accuracy: 1.0000\n",
      "Epoch 502/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0149, Test accuracy: 1.0000\n",
      "Epoch 503/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0149, Test accuracy: 1.0000\n",
      "Epoch 504/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0149, Test accuracy: 1.0000\n",
      "Epoch 505/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 173.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 169.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0148, Test accuracy: 1.0000\n",
      "Epoch 506/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 192.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0149, Test accuracy: 1.0000\n",
      "Epoch 507/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.66it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0149, Test accuracy: 1.0000\n",
      "Epoch 508/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.44it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0148, Test accuracy: 1.0000\n",
      "Epoch 509/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 174.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 127.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0148, Test accuracy: 1.0000\n",
      "Epoch 510/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0148, Test accuracy: 1.0000\n",
      "Epoch 511/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0149, Test accuracy: 1.0000\n",
      "Epoch 512/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 116.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 190.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0149, Test accuracy: 1.0000\n",
      "Epoch 513/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 129.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0148, Test accuracy: 1.0000\n",
      "Epoch 514/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 174.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 178.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0148, Test accuracy: 1.0000\n",
      "Epoch 515/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 137.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 185.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0020, Training accuracy: 1.0000\n",
      "Test loss: 0.0148, Test accuracy: 1.0000\n",
      "Epoch 516/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 138.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0148, Test accuracy: 1.0000\n",
      "Epoch 517/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 220.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0147, Test accuracy: 1.0000\n",
      "Epoch 518/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0147, Test accuracy: 1.0000\n",
      "Epoch 519/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0147, Test accuracy: 1.0000\n",
      "Epoch 520/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 167.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0147, Test accuracy: 1.0000\n",
      "Epoch 521/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0146, Test accuracy: 1.0000\n",
      "Epoch 522/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0146, Test accuracy: 1.0000\n",
      "Epoch 523/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 219.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0146, Test accuracy: 1.0000\n",
      "Epoch 524/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 203.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0146, Test accuracy: 1.0000\n",
      "Epoch 525/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0146, Test accuracy: 1.0000\n",
      "Epoch 526/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0145, Test accuracy: 1.0000\n",
      "Epoch 527/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 175.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0145, Test accuracy: 1.0000\n",
      "Epoch 528/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 187.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0145, Test accuracy: 1.0000\n",
      "Epoch 529/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 170.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 144.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0144, Test accuracy: 1.0000\n",
      "Epoch 530/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 174.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0144, Test accuracy: 1.0000\n",
      "Epoch 531/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 156.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 199.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0144, Test accuracy: 1.0000\n",
      "Epoch 532/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 190.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 193.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0144, Test accuracy: 1.0000\n",
      "Epoch 533/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 153.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 230.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0144, Test accuracy: 1.0000\n",
      "Epoch 534/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 306.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0144, Test accuracy: 1.0000\n",
      "Epoch 535/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 194.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 187.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0143, Test accuracy: 1.0000\n",
      "Epoch 536/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0143, Test accuracy: 1.0000\n",
      "Epoch 537/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.70it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 123.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0143, Test accuracy: 1.0000\n",
      "Epoch 538/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 687.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0143, Test accuracy: 1.0000\n",
      "Epoch 539/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.19it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 194.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0143, Test accuracy: 1.0000\n",
      "Epoch 540/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 197.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 258.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0142, Test accuracy: 1.0000\n",
      "Epoch 541/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 213.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0142, Test accuracy: 1.0000\n",
      "Epoch 542/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 147.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 225.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0142, Test accuracy: 1.0000\n",
      "Epoch 543/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 190.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0142, Test accuracy: 1.0000\n",
      "Epoch 544/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 166.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 250.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0142, Test accuracy: 1.0000\n",
      "Epoch 545/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 189.66it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0142, Test accuracy: 1.0000\n",
      "Epoch 546/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0141, Test accuracy: 1.0000\n",
      "Epoch 547/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 216.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0141, Test accuracy: 1.0000\n",
      "Epoch 548/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 166.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0141, Test accuracy: 1.0000\n",
      "Epoch 549/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 189.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0141, Test accuracy: 1.0000\n",
      "Epoch 550/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 158.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0141, Test accuracy: 1.0000\n",
      "Epoch 551/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0141, Test accuracy: 1.0000\n",
      "Epoch 552/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0141, Test accuracy: 1.0000\n",
      "Epoch 553/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0140, Test accuracy: 1.0000\n",
      "Epoch 554/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 153.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 250.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0140, Test accuracy: 1.0000\n",
      "Epoch 555/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0140, Test accuracy: 1.0000\n",
      "Epoch 556/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 187.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 251.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0140, Test accuracy: 1.0000\n",
      "Epoch 557/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 167.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 263.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0140, Test accuracy: 1.0000\n",
      "Epoch 558/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 144.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 609.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0139, Test accuracy: 1.0000\n",
      "Epoch 559/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 135.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 250.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0139, Test accuracy: 1.0000\n",
      "Epoch 560/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 204.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0139, Test accuracy: 1.0000\n",
      "Epoch 561/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 107.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0139, Test accuracy: 1.0000\n",
      "Epoch 562/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 197.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 128.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0139, Test accuracy: 1.0000\n",
      "Epoch 563/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 224.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0139, Test accuracy: 1.0000\n",
      "Epoch 564/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0139, Test accuracy: 1.0000\n",
      "Epoch 565/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 142.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 302.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0022, Training accuracy: 1.0000\n",
      "Test loss: 0.0139, Test accuracy: 1.0000\n",
      "Epoch 566/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 185.99it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0138, Test accuracy: 1.0000\n",
      "Epoch 567/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.70it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0138, Test accuracy: 1.0000\n",
      "Epoch 568/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 173.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0138, Test accuracy: 1.0000\n",
      "Epoch 569/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0137, Test accuracy: 1.0000\n",
      "Epoch 570/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 213.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0137, Test accuracy: 1.0000\n",
      "Epoch 571/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 228.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0138, Test accuracy: 1.0000\n",
      "Epoch 572/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 129.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0138, Test accuracy: 1.0000\n",
      "Epoch 573/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 207.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 129.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0138, Test accuracy: 1.0000\n",
      "Epoch 574/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0138, Test accuracy: 1.0000\n",
      "Epoch 575/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 217.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0138, Test accuracy: 1.0000\n",
      "Epoch 576/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 175.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0138, Test accuracy: 1.0000\n",
      "Epoch 577/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 228.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0138, Test accuracy: 1.0000\n",
      "Epoch 578/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0138, Test accuracy: 1.0000\n",
      "Epoch 579/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 138.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 162.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0138, Test accuracy: 1.0000\n",
      "Epoch 580/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 153.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 194.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0138, Test accuracy: 1.0000\n",
      "Epoch 581/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 215.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0138, Test accuracy: 1.0000\n",
      "Epoch 582/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 145.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 220.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0138, Test accuracy: 1.0000\n",
      "Epoch 583/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 158.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0138, Test accuracy: 1.0000\n",
      "Epoch 584/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 212.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0137, Test accuracy: 1.0000\n",
      "Epoch 585/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 185.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0137, Test accuracy: 1.0000\n",
      "Epoch 586/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 221.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0137, Test accuracy: 1.0000\n",
      "Epoch 587/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 206.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0137, Test accuracy: 1.0000\n",
      "Epoch 588/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 155.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 191.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0137, Test accuracy: 1.0000\n",
      "Epoch 589/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 224.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1055.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0136, Test accuracy: 1.0000\n",
      "Epoch 590/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 281.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0137, Test accuracy: 1.0000\n",
      "Epoch 591/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 194.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0136, Test accuracy: 1.0000\n",
      "Epoch 592/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0136, Test accuracy: 1.0000\n",
      "Epoch 593/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.02it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0136, Test accuracy: 1.0000\n",
      "Epoch 594/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 148.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0136, Test accuracy: 1.0000\n",
      "Epoch 595/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0136, Test accuracy: 1.0000\n",
      "Epoch 596/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0135, Test accuracy: 1.0000\n",
      "Epoch 597/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 213.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0136, Test accuracy: 1.0000\n",
      "Epoch 598/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0136, Test accuracy: 1.0000\n",
      "Epoch 599/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 258.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0135, Test accuracy: 1.0000\n",
      "Epoch 600/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 172.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0135, Test accuracy: 1.0000\n",
      "Epoch 601/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 218.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0135, Test accuracy: 1.0000\n",
      "Epoch 602/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0134, Test accuracy: 1.0000\n",
      "Epoch 603/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0134, Test accuracy: 1.0000\n",
      "Epoch 604/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 226.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0134, Test accuracy: 1.0000\n",
      "Epoch 605/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0134, Test accuracy: 1.0000\n",
      "Epoch 606/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 245.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0133, Test accuracy: 1.0000\n",
      "Epoch 607/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0133, Test accuracy: 1.0000\n",
      "Epoch 608/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 208.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0132, Test accuracy: 1.0000\n",
      "Epoch 609/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 209.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3233.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0132, Test accuracy: 1.0000\n",
      "Epoch 610/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0132, Test accuracy: 1.0000\n",
      "Epoch 611/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 224.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1990.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0132, Test accuracy: 1.0000\n",
      "Epoch 612/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 226.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1160.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0132, Test accuracy: 1.0000\n",
      "Epoch 613/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0131, Test accuracy: 1.0000\n",
      "Epoch 614/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 197.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0131, Test accuracy: 1.0000\n",
      "Epoch 615/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 187.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 194.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0131, Test accuracy: 1.0000\n",
      "Epoch 616/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.67it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0131, Test accuracy: 1.0000\n",
      "Epoch 617/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0131, Test accuracy: 1.0000\n",
      "Epoch 618/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 175.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 190.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0131, Test accuracy: 1.0000\n",
      "Epoch 619/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 247.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0131, Test accuracy: 1.0000\n",
      "Epoch 620/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 148.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 114.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0131, Test accuracy: 1.0000\n",
      "Epoch 621/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 284.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0131, Test accuracy: 1.0000\n",
      "Epoch 622/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 175.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0130, Test accuracy: 1.0000\n",
      "Epoch 623/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0131, Test accuracy: 1.0000\n",
      "Epoch 624/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0131, Test accuracy: 1.0000\n",
      "Epoch 625/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0131, Test accuracy: 1.0000\n",
      "Epoch 626/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 208.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0131, Test accuracy: 1.0000\n",
      "Epoch 627/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 190.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 184.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0131, Test accuracy: 1.0000\n",
      "Epoch 628/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0131, Test accuracy: 1.0000\n",
      "Epoch 629/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0130, Test accuracy: 1.0000\n",
      "Epoch 630/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 166.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1603.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0130, Test accuracy: 1.0000\n",
      "Epoch 631/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 185.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 218.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0130, Test accuracy: 1.0000\n",
      "Epoch 632/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0130, Test accuracy: 1.0000\n",
      "Epoch 633/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 291.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0130, Test accuracy: 1.0000\n",
      "Epoch 634/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 220.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0130, Test accuracy: 1.0000\n",
      "Epoch 635/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 130.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 182.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0129, Test accuracy: 1.0000\n",
      "Epoch 636/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 117.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0129, Test accuracy: 1.0000\n",
      "Epoch 637/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0129, Test accuracy: 1.0000\n",
      "Epoch 638/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 171.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0129, Test accuracy: 1.0000\n",
      "Epoch 639/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 192.02it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0129, Test accuracy: 1.0000\n",
      "Epoch 640/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 188.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0129, Test accuracy: 1.0000\n",
      "Epoch 641/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 194.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0129, Test accuracy: 1.0000\n",
      "Epoch 642/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 167.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 323.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0128, Test accuracy: 1.0000\n",
      "Epoch 643/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 225.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 215.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0128, Test accuracy: 1.0000\n",
      "Epoch 644/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 138.66it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0128, Test accuracy: 1.0000\n",
      "Epoch 645/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 138.70it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 218.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0127, Test accuracy: 1.0000\n",
      "Epoch 646/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 139.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 222.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0127, Test accuracy: 1.0000\n",
      "Epoch 647/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 174.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 135.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0127, Test accuracy: 1.0000\n",
      "Epoch 648/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 128.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 202.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0127, Test accuracy: 1.0000\n",
      "Epoch 649/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 161.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0126, Test accuracy: 1.0000\n",
      "Epoch 650/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 265.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 278.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0126, Test accuracy: 1.0000\n",
      "Epoch 651/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 279.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0126, Test accuracy: 1.0000\n",
      "Epoch 652/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 272.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 444.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0126, Test accuracy: 1.0000\n",
      "Epoch 653/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 240.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 458.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0126, Test accuracy: 1.0000\n",
      "Epoch 654/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 231.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 275.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0126, Test accuracy: 1.0000\n",
      "Epoch 655/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 229.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0126, Test accuracy: 1.0000\n",
      "Epoch 656/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 313.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 540.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0126, Test accuracy: 1.0000\n",
      "Epoch 657/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 297.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0126, Test accuracy: 1.0000\n",
      "Epoch 658/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 275.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0126, Test accuracy: 1.0000\n",
      "Epoch 659/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 303.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0126, Test accuracy: 1.0000\n",
      "Epoch 660/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 288.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0125, Test accuracy: 1.0000\n",
      "Epoch 661/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 460.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0125, Test accuracy: 1.0000\n",
      "Epoch 662/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 460.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0125, Test accuracy: 1.0000\n",
      "Epoch 663/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 341.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0125, Test accuracy: 1.0000\n",
      "Epoch 664/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 305.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0125, Test accuracy: 1.0000\n",
      "Epoch 665/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 297.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0125, Test accuracy: 1.0000\n",
      "Epoch 666/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 206.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0124, Test accuracy: 1.0000\n",
      "Epoch 667/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 462.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 222.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0124, Test accuracy: 1.0000\n",
      "Epoch 668/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 306.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0124, Test accuracy: 1.0000\n",
      "Epoch 669/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 283.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0124, Test accuracy: 1.0000\n",
      "Epoch 670/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 314.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0124, Test accuracy: 1.0000\n",
      "Epoch 671/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 427.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 259.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0124, Test accuracy: 1.0000\n",
      "Epoch 672/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 386.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 258.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0124, Test accuracy: 1.0000\n",
      "Epoch 673/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 301.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 278.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0124, Test accuracy: 1.0000\n",
      "Epoch 674/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 462.99it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3112.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0124, Test accuracy: 1.0000\n",
      "Epoch 675/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 299.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0124, Test accuracy: 1.0000\n",
      "Epoch 676/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 306.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0124, Test accuracy: 1.0000\n",
      "Epoch 677/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 430.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 211.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0123, Test accuracy: 1.0000\n",
      "Epoch 678/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 476.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0123, Test accuracy: 1.0000\n",
      "Epoch 679/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 277.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0123, Test accuracy: 1.0000\n",
      "Epoch 680/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 259.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 827.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0123, Test accuracy: 1.0000\n",
      "Epoch 681/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 310.51it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 886.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0123, Test accuracy: 1.0000\n",
      "Epoch 682/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 271.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 424.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0123, Test accuracy: 1.0000\n",
      "Epoch 683/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 369.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0122, Test accuracy: 1.0000\n",
      "Epoch 684/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 342.16it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0122, Test accuracy: 1.0000\n",
      "Epoch 685/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 271.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0122, Test accuracy: 1.0000\n",
      "Epoch 686/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 294.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 245.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0122, Test accuracy: 1.0000\n",
      "Epoch 687/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 332.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0122, Test accuracy: 1.0000\n",
      "Epoch 688/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 302.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0122, Test accuracy: 1.0000\n",
      "Epoch 689/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 440.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0121, Test accuracy: 1.0000\n",
      "Epoch 690/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 443.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0121, Test accuracy: 1.0000\n",
      "Epoch 691/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 456.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0121, Test accuracy: 1.0000\n",
      "Epoch 692/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 309.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 466.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0121, Test accuracy: 1.0000\n",
      "Epoch 693/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 319.67it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 431.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0121, Test accuracy: 1.0000\n",
      "Epoch 694/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 499.78it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 259.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0121, Test accuracy: 1.0000\n",
      "Epoch 695/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 295.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0121, Test accuracy: 1.0000\n",
      "Epoch 696/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 294.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0121, Test accuracy: 1.0000\n",
      "Epoch 697/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 445.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0120, Test accuracy: 1.0000\n",
      "Epoch 698/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 429.23it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0120, Test accuracy: 1.0000\n",
      "Epoch 699/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 308.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 505.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0120, Test accuracy: 1.0000\n",
      "Epoch 700/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 244.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 500.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0120, Test accuracy: 1.0000\n",
      "Epoch 701/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 340.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 554.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0120, Test accuracy: 1.0000\n",
      "Epoch 702/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 418.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0120, Test accuracy: 1.0000\n",
      "Epoch 703/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 296.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0120, Test accuracy: 1.0000\n",
      "Epoch 704/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 310.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0119, Test accuracy: 1.0000\n",
      "Epoch 705/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 299.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0119, Test accuracy: 1.0000\n",
      "Epoch 706/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 335.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 500.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0119, Test accuracy: 1.0000\n",
      "Epoch 707/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 305.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 400.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0119, Test accuracy: 1.0000\n",
      "Epoch 708/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 175.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0119, Test accuracy: 1.0000\n",
      "Epoch 709/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0119, Test accuracy: 1.0000\n",
      "Epoch 710/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0119, Test accuracy: 1.0000\n",
      "Epoch 711/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 185.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0119, Test accuracy: 1.0000\n",
      "Epoch 712/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 212.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 223.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0118, Test accuracy: 1.0000\n",
      "Epoch 713/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 224.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2617.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0118, Test accuracy: 1.0000\n",
      "Epoch 714/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 225.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0119, Test accuracy: 1.0000\n",
      "Epoch 715/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 247.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0118, Test accuracy: 1.0000\n",
      "Epoch 716/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 260.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0118, Test accuracy: 1.0000\n",
      "Epoch 717/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 223.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0118, Test accuracy: 1.0000\n",
      "Epoch 718/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 225.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 227.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0118, Test accuracy: 1.0000\n",
      "Epoch 719/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 129.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0118, Test accuracy: 1.0000\n",
      "Epoch 720/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 205.50it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0118, Test accuracy: 1.0000\n",
      "Epoch 721/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 166.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0118, Test accuracy: 1.0000\n",
      "Epoch 722/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 169.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 178.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0117, Test accuracy: 1.0000\n",
      "Epoch 723/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 158.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0117, Test accuracy: 1.0000\n",
      "Epoch 724/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 216.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0118, Test accuracy: 1.0000\n",
      "Epoch 725/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0117, Test accuracy: 1.0000\n",
      "Epoch 726/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0118, Test accuracy: 1.0000\n",
      "Epoch 727/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 154.44it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 586.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0118, Test accuracy: 1.0000\n",
      "Epoch 728/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 154.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0118, Test accuracy: 1.0000\n",
      "Epoch 729/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0118, Test accuracy: 1.0000\n",
      "Epoch 730/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 153.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0117, Test accuracy: 1.0000\n",
      "Epoch 731/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 170.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 229.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0117, Test accuracy: 1.0000\n",
      "Epoch 732/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 252.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0117, Test accuracy: 1.0000\n",
      "Epoch 733/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 290.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0117, Test accuracy: 1.0000\n",
      "Epoch 734/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1333.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0117, Test accuracy: 1.0000\n",
      "Epoch 735/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 851.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2471.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0116, Test accuracy: 1.0000\n",
      "Epoch 736/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 1496.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0116, Test accuracy: 1.0000\n",
      "Epoch 737/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 983.44it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0116, Test accuracy: 1.0000\n",
      "Epoch 738/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 919.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0116, Test accuracy: 1.0000\n",
      "Epoch 739/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 1116.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0116, Test accuracy: 1.0000\n",
      "Epoch 740/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 904.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0116, Test accuracy: 1.0000\n",
      "Epoch 741/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 864.66it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0115, Test accuracy: 1.0000\n",
      "Epoch 742/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 800.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1999.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0115, Test accuracy: 1.0000\n",
      "Epoch 743/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 1547.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0115, Test accuracy: 1.0000\n",
      "Epoch 744/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 966.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1999.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0115, Test accuracy: 1.0000\n",
      "Epoch 745/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 1393.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 4031.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0115, Test accuracy: 1.0000\n",
      "Epoch 746/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 3603.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 425.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0115, Test accuracy: 1.0000\n",
      "Epoch 747/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 1602.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 755.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0115, Test accuracy: 1.0000\n",
      "Epoch 748/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 2075.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 469.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0115, Test accuracy: 1.0000\n",
      "Epoch 749/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 1615.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0115, Test accuracy: 1.0000\n",
      "Epoch 750/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 928.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2000.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0115, Test accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the logistic regression model\n",
    "# Example usage:\n",
    "best_acc_model, best_loss_model, results = train_logreg_simplified(\n",
    "    batch_size=8,\n",
    "    train_feats_data=train_feats_simclr,\n",
    "    test_feats_data=test_feats_simclr,\n",
    "    feature_dim=train_feats_simclr.tensors[0].shape[1],\n",
    "    num_classes=2,\n",
    "    lr=5e-4,\n",
    "    weight_decay=1e-4,\n",
    "    max_epochs=750\n",
    ")\n",
    "#print(f\"Final Train Accuracy: {results['train_acc']:.4f}, Final Test Accuracy: {results['test_acc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (linear): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model= best_loss_model\n",
    "logreg_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the logistic regression model\n",
    "# Example usage:\n",
    "best_acc_model, best_loss_model, results = train_logreg_simplified(\n",
    "    batch_size=8,\n",
    "    train_feats_data=train_feats_simclr,\n",
    "    test_feats_data=test_feats_simclr,\n",
    "    feature_dim=train_feats_simclr.tensors[0].shape[1],\n",
    "    num_classes=2,\n",
    "    lr=5e-4,\n",
    "    weight_decay=1e-4,\n",
    "    max_epochs=100\n",
    ")\n",
    "#print(f\"Final Train Accuracy: {results['train_acc']:.4f}, Final Test Accuracy: {results['test_acc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best models by accuracy and loss\n",
    "torch.save(best_acc_model.state_dict(), \"1000epoch_best_acc_model.pth\")\n",
    "torch.save(best_loss_model.state_dict(), \"1000epoch_best_loss_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(512,2)\n",
    "logreg_model = logreg_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_22448\\4036842466.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\"1000epoch_best_loss_model.pth\")  # Load weights from the file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (linear): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Step 2: Load the saved state dict\n",
    "state_dict = torch.load(\"1000epoch_best_loss_model.pth\")  # Load weights from the file\n",
    "logreg_model.load_state_dict(state_dict)  # Load state dict into the model\n",
    "\n",
    "# Step 3: Set the model to evaluation mode (if not training)\n",
    "logreg_model.eval()  # This disables dropout and batchnorm for inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 512= feature_dim = train_feats_simclr.tensors[0].shape[1] =  before projection head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model state_dict\n",
    "torch.save(logreg_model.state_dict(), \"logreg_model_best.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1000 epochs: no outlier amoung exploded, control7, single dose\n",
    "#500 epochs, one outlier of exploder in ds closer to sd: which is ds41_g9_C10-T01   inbetween 4 ds closer\n",
    "# 100 epochs, one outlier of exploder also one outlier from ds_clos_tosd ds41_g5_E04-T01\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we got 100 % down checking whether we will get it by repeating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 18/18 [00:12<00:00,  1.43it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA90AAASmCAYAAAAzjMgKAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAADTZklEQVR4nOzde1iUdf7/8dcoMCACinIUQjyWx9x0PXTwUJJadtDKzXKxsm9l2ZodzUxsS8o2t7aDbZtilqbbdlhLU/GYm7qp5WrawQqVUoTwMIiIAp/fH/6YHAHlMDczMM/Hdc2Vc9/3fO73fJh485q5575txhgjAAAAAADgdg08XQAAAAAAAPUVoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihG7BAv3791K9fP+f9OXPmyGazVXh79tlnKzVuRkaG7r//fl1wwQUKDg5WYGCgWrZsqVtvvVWrV6+WMcaiZ+RdTp48qfPPP7/S82al+fPn68UXX7Rk7NLXze7du53LRo0apeuuu86S/QFAfURPtlZ5PXn9+vVKSUnR4cOHPVeYpNdee01z5syxZGybzaaUlBTn/VmzZqlFixbKz8+3ZH+o2wjdQC246qqrtGHDhjK3gQMHSpKuv/76c46xaNEide7cWYsWLVJycrI+/PBDLVu2TJMnT1Zubq4GDBigVatWWf1UvMJrr72mQ4cOady4cZ4uxdLQXZ6UlBQtXrzYZ37WAOBu9GT3Kq8nr1+/XlOnTq3XoftMycnJCg4O1vTp02tlf6hb/DxdAOALIiIiFBER4bIsPz9fGzZs0CWXXKL27duf9fE//vijbr75ZnXs2FErVqxQaGioc13fvn11xx13aM2aNWratOlZxzl27JgaNWpU/SfiBYqKivT888/r9ttvV3BwsKfLqZLi4mIVFRXJbrdXe4zWrVtr0KBBevbZZzVgwAA3VgcAvoGe7D7u6skFBQUKCgpyY2W1z8/PT3fddZf+/Oc/69FHH63zP1u4F590o9749ttvdfPNNysqKkp2u13nnXee/vjHP6qwsNC5zddff61rr71WTZs2VWBgoC688EK99dZbLuOsWbNGNptN7777riZNmqTY2FiFhobqiiuu0HfffeeyrTFG06dPV0JCggIDA/W73/1On376aaXqXbhwoY4ePaoxY8acc9sZM2bo2LFjeu2111ya++n69eunrl27Ou+npKTIZrPpyy+/1A033KCmTZuqdevWkqTjx49r4sSJSkxMVEBAgFq0aKF77723zDvSZx46Vaply5YaPXq0837poXrp6em67bbbFB4eruDgYA0dOlQ//fTTOZ9faa1fffWVhg0bptDQUIWFhenWW29VTk6Oy7aLFi3SL7/8olGjRpUZp7ZfA/369dPixYu1Z88el0MTJWn37t2y2WyaPn26nn76aSUmJsput2v16tXO59G7d281atRIISEhGjhwoDZs2HDOuZJOHWK+YsUK/fjjj5XaHgBqGz3Zd3tySkqKHn74YUlSYmKiszeuWbPGWe/VV1+tDz74QN26dVNgYKCmTp0qScrKytJdd92luLg4BQQEKDExUVOnTlVRUZHLfqdOnaqePXsqPDxcoaGh+t3vfqdZs2a5HNLfsmVL7dixQ2vXrnXW0LJlS+d6h8Ohhx56yGXex48fX+bwcIfDoTvvvFPNmjVT48aNNWjQIH3//fflzt0tt9wih8OhBQsWnHOe4WMMUA9s3brVNG7c2LRs2dK8/vrrZuXKleadd94xN910k3E4HMYYY7799lsTEhJiWrdubebOnWsWL15sbr75ZiPJPPfcc86xVq9ebSSZli1bmltuucUsXrzYvPvuu+a8884zbdu2NUVFRc5tp0yZYiSZO+64w3z66afmjTfeMC1atDDR0dGmb9++Z625T58+JjQ01OTn55/z+bVt29bExMRUaU5Ka0tISDCPPvqoSU9PNx999JEpKSkxV155pfHz8zOTJ082y5cvN3/5y19McHCw6datmzl+/LhzDElmypQpZcZOSEgwycnJzvtpaWlGkomPjze33367cy4iIyNNfHy8OXToUKVrffjhh82yZcvMjBkznDWdOHHCue3tt99uIiMjy4zhidfAjh07zMUXX2yio6PNhg0bnDdjjMnIyDCSTIsWLUz//v3Nv/71L7N8+XKTkZFh5s2bZySZpKQk89FHH5mFCxeaiy66yAQEBJh169aVmdeMjAyX53rgwAEjyfztb38767wCgCfQk8vypZ6cmZlpxo0bZySZDz74wNkbjxw54qw3JibGtGrVysyePdusXr3afPHFF2b//v0mPj7eJCQkmL///e9mxYoV5s9//rOx2+1m9OjRLvsYPXq0mTVrlklPTzfp6enmz3/+swkKCjJTp051bvPll1+aVq1amW7dujlr+PLLL40xxuTn55sLL7zQNG/e3MyYMcOsWLHCvPTSSyYsLMwMGDDAlJSUGGOMKSkpMf379zd2u90888wzZvny5WbKlCmmVatWFf48LrjgAjNs2LCzzjF8D6Eb9cKAAQNMkyZNTHZ2doXb/OEPfzB2u93s3bvXZfngwYNNo0aNzOHDh40xvzX4IUOGuGz3z3/+00hyhqpDhw6ZwMBAc/3117ts9/nnnxtJZ23w33zzjZFk7rrrrko9v8DAQNOrV68yy4uLi83Jkyedt+LiYue60qb55JNPujxm6dKlRpKZPn26y/KFCxcaSeaNN95wLqtqg69oLp5++umzPr/SWh944AGX5aXh9J133nEuu+CCC8ygQYPKjOGJ14Axxlx11VUmISGhzL5KQ3fr1q1d/kApLi42sbGxpnPnzi4/r7y8PBMZGWn69OnjXFZR6DbGmBYtWpgRI0ZU+FwBwFPoyfTk559/vsL+lZCQYBo2bGi+++47l+V33XWXady4sdmzZ4/L8r/85S9GktmxY0e59ZbO+1NPPWWaNWvmDMzGGNOxY8dyf/apqammQYMGZtOmTS7L//WvfxlJZsmSJcYYYz799FMjybz00ksu2z3zzDMV/jxuueUWExUVVW6t8F0cXo4679ixY1q7dq1uuummMt/ROt2qVat0+eWXKz4+3mX56NGjdezYsTKH9l5zzTUu97t06SJJ2rNnjyRpw4YNOn78uG655RaX7fr06aOEhISz1jxr1ixJqtRhbGczbNgw+fv7O2/3339/mW2GDx/ucr/0xC6nH4omSTfeeKOCg4O1cuXKatdT0VyUHlJd1cffdNNN8vPzc3n8vn37FBkZ6bKdp14DlXHNNdfI39/fef+7777Tvn37NGrUKDVo8Nuv4MaNG2v48OHauHGjjh07ds5xIyMj9csvv1S6DgCoDfRkenJldOnSRe3atXNZ9sknn6h///6KjY1VUVGR8zZ48GBJ0tq1a53brlq1SldccYXCwsLUsGFD+fv768knn1Rubq6ys7PPuf9PPvlEnTp10oUXXuiyryuvvNLlUPjS53rmXIwcObLCsSMjI5WdnV3mkHj4NkI36rxDhw6puLhYcXFxZ90uNzdXMTExZZbHxsY615+uWbNmLvdLT35VUFDgsn10dHSZMctbVurkyZOaO3euunbtqu7du5+15lLnnXdeuUHvhRde0KZNm7Rp06YKH3vmc87NzZWfn1+ZP4ZsNpuio6PLzENVVDQXlR3zzMf7+fmpWbNmLo8vKChQYGCgy3aeeg1URnnzX97y0jpKSkp06NChc44bGBhYpToAoDbQk+nJlVHez/7AgQP6+OOPXd648Pf3V8eOHSVJv/76qyTpiy++UFJSkiTpH//4hz7//HNt2rRJkyZNctZ0LgcOHNC2bdvK7CskJETGGOe+Sn8+Z77+zvaaCgwMlDFGx48fr8RMwFdw9nLUeeHh4WrYsKF+/vnns27XrFkz7d+/v8zyffv2SZKaN29epf2W/gLOysoqsy4rK8vlZB2n++STT5Sdna3JkydXel8DBw7Uq6++qs2bN7v8UVB6EpazKT2x1+l1FxUVKScnx6XJG2OUlZWlHj16OJfZ7XaXk96UqqhhVzQXbdq0OWedpdu2aNHCeb+oqEi5ubkuza558+Y6ePCgy+M89RqojPLmX1KFdTRo0OCcZ7yVpIMHD1b4GgMAT6Enn50v9OTKOHMeSsfq0qWLnnnmmXIfU/qGzIIFC+Tv769PPvnEJfB/9NFHld5/8+bNFRQUpNmzZ1e4Xvrt53Pm8y5vbksdPHhQdrtdjRs3rnQ9qP/4pBt1XlBQkPr27av33nvP+c5keS6//HKtWrXK2dBLzZ07V40aNVKvXr2qtN9evXopMDBQ8+bNc1m+fv36sx5+PGvWLAUGBpY5VOlsHnjgATVq1Ej33nuv8vLyqlTnmS6//HJJ0jvvvOOy/P3331d+fr5zvXTqzJ/btm1z2W7VqlU6evRouWNXNBf9+vWrVG1nPv6f//ynioqKXB5//vnnlzlrt6deA9KpP4Kq8olz+/bt1aJFC82fP9/lLKv5+fl6//33nWc0P5uioiJlZmaqQ4cOVa4XAKxET66a+tiTpeodGXb11Vfr66+/VuvWrdW9e/cyt9LQbbPZ5Ofnp4YNGzofW1BQoLfffrvcOsqr4eqrr9aPP/6oZs2albuv0jdp+vfvX+5czJ8/v8Ln8dNPP9GfUQafdKNemDFjhi655BL17NlTjz32mNq0aaMDBw5o0aJF+vvf/66QkBBNmTLF+X2hJ598UuHh4Zo3b54WL16s6dOnKywsrEr7bNq0qR566CE9/fTTGjNmjG688UZlZmYqJSWlwsOO9u3bp6VLl2rEiBGV+jSzVOvWrfXuu+/q5ptvVufOnXXPPffod7/7nex2u7Kzs7V8+XJJqvDSJacbOHCgrrzySj366KNyOBy6+OKLtW3bNk2ZMkXdunVzuezHqFGjNHnyZD355JPq27evdu7cqVdeeaXCudq8ebPLXEyaNEktWrTQ2LFjK/U8P/jgA/n5+WngwIHasWOHJk+erK5du+qmm25ybtOvXz899dRTZa5v6onXgCR17txZH3zwgWbOnKmLLrpIDRo0OOshig0aNND06dN1yy236Oqrr9Zdd92lwsJCPf/88zp8+LCeffbZc+5z27ZtOnbsmPOPAQDwJvRkenLnzp0lSS+99JKSk5Pl7++v9u3bKyQkpML9PfXUU0pPT1efPn10//33q3379jp+/Lh2796tJUuW6PXXX1dcXJyuuuoqzZgxQyNHjtT//d//KTc3V3/5y1+cQf90nTt31oIFC7Rw4UK1atVKgYGB6ty5s8aPH6/3339fl112mR544AF16dJFJSUl2rt3r5YvX64HH3xQPXv2VFJSki677DI98sgjys/PV/fu3fX555+XG/AlqaSkRF988YXuuOOOSs0xfIhHT+MGuNHOnTvNjTfeaJo1a2YCAgLMeeedZ0aPHu1yuY3t27eboUOHmrCwMBMQEGC6du1q0tLSXMYpPVPqe++957K89GzUp29fUlJiUlNTTXx8vAkICDBdunQxH3/8senbt2+5Z8ssPdvlqlWrqvUcf/zxRzNu3DjTvn17ExQUZOx2u0lISDA33nij+fDDD13O2Fl69tGcnJwy4xQUFJhHH33UJCQkGH9/fxMTE2PuueeeMpcRKSwsNI888oiJj483QUFBpm/fvmbr1q0Vnil1+fLlZtSoUaZJkyYmKCjIDBkyxOzateucz6u01i1btpihQ4eaxo0bm5CQEHPzzTebAwcOuGz7ww8/GJvNZv75z3+WGccTr4GDBw+aG264wTRp0sTYbDZT+mu1dNvnn3++3Of80UcfmZ49e5rAwEATHBxsLr/8cvP555+7bFPR2csnT55smjdv7vK8AMCb0JPpyRMnTjSxsbGmQYMGRpJZvXq1MebU2cuvuuqqcvedk5Nj7r//fpOYmGj8/f1NeHi4ueiii8ykSZPM0aNHndvNnj3btG/f3tjtdtOqVSuTmppqZs2aVaZn7t692yQlJZmQkBDnZdBKHT161DzxxBOmffv2JiAgwISFhZnOnTubBx54wGRlZTm3O3z4sLn99ttNkyZNTKNGjczAgQPNt99+W+7Zy1euXOmcO+B0NmNOO74RAKphzpw5uu2227Rp06ZKn4jmdCkpKZo6dapycnIq9T2+oUOHqqioSJ9++ml1yq3TiouL1aZNG40cObLC770BAHwXPdlzRo0apZ9++kmff/65p0uBl+E73QDqnNTUVK1YseKsZ4itr9555x0dPXpUDz/8sKdLAQDAp3vy6X788UctXLhQzz33nKdLgRcidAOoczp16qS0tLSznj20viopKdG8efPUpEkTT5cCAIBP9+TT7d27V6+88oouueQST5cCL8Th5QAAAAAAWIRPugEAAAAAsAihGwAAAAAAixC6AQAAAACwiJ+nC/AGJSUl2rdvn0JCQmSz2TxdDgDARxhjlJeXp9jYWDVowPvgp6M3AwA8wYreTOiWtG/fPsXHx3u6DACAj8rMzFRcXJyny/Aq9GYAgCe5szcTuiWFhIRIOjWxoaGhHq4GAOArHA6H4uPjnX0Iv6E3AwA8wYreTOiWnIethYaG0tgBALWOw6fLojcDADzJnb2ZL5ABAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgET9PFwAAQG3IycmRw+Fwy1ihoaGKiIhwy1ioHfz8AQCeQugGANR7OTk5uvW2MTqYd8wt44WHNNI7aW8SvOqInJwc3TNmpAqP5rplPHvjZpr55nx+/gCASiF0AwDqPYfDoYN5xxTRe7iCw6NqNFb+wQPK2fC+HA4HoauOcDgcKjyaqweH2hUfEVSjsTJzCvTCx7n8/AEAlUboBgD4jODwKIVGxtV4nBw31ILaFx8RpNYtgt0wUqEbxgAA+ApOpAYAAAAAgEW8OnTPnDlTXbp0UWhoqEJDQ9W7d299+umnzvWjR4+WzWZzufXq1cuDFQMAUL/RmwEAqBqvPrw8Li5Ozz77rNq0aSNJeuutt3Tttdfqq6++UseOHSVJgwYNUlpamvMxAQEBHqkVAABfQG8GAKBqvDp0Dx061OX+M888o5kzZ2rjxo3Oxm632xUdHe2J8gAA8Dn0ZgAAqsarDy8/XXFxsRYsWKD8/Hz17t3buXzNmjWKjIxUu3btdOeddyo7O9uDVQIA4DvozQAAnJtXf9ItSdu3b1fv3r11/PhxNW7cWB9++KE6dOggSRo8eLBuvPFGJSQkKCMjQ5MnT9aAAQO0ZcsW2e32CscsLCxUYeFvZx51OByWPw8AAOoLejMAAJXn9aG7ffv22rp1qw4fPqz3339fycnJWrt2rTp06KARI0Y4t+vUqZO6d++uhIQELV68WMOGDatwzNTUVE2dOrU2ygcAoN6hNwMAUHlef3h5QECA2rRpo+7duys1NVVdu3bVSy+9VO62MTExSkhI0K5du8465sSJE3XkyBHnLTMz04rSAQCol+jNAABUntd/0n0mY4zL4Weny83NVWZmpmJiYs46ht1uP+shbgAAoPLozQAAVMyrQ/fjjz+uwYMHKz4+Xnl5eVqwYIHWrFmjpUuX6ujRo0pJSdHw4cMVExOj3bt36/HHH1fz5s11/fXXe7p0AADqJXozAABV49Wh+8CBAxo1apT279+vsLAwdenSRUuXLtXAgQNVUFCg7du3a+7cuTp8+LBiYmLUv39/LVy4UCEhIZ4uHQCAeoneDABA1Xh16J41a1aF64KCgrRs2bJarAYAANCbAQCoGq8/kRoAAAAAAHUVoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALCIV4fumTNnqkuXLgoNDVVoaKh69+6tTz/91LneGKOUlBTFxsYqKChI/fr1044dOzxYMQAA9Ru9GQCAqvHq0B0XF6dnn31Wmzdv1ubNmzVgwABde+21zuY9ffp0zZgxQ6+88oo2bdqk6OhoDRw4UHl5eR6uHACA+oneDABA1Xh16B46dKiGDBmidu3aqV27dnrmmWfUuHFjbdy4UcYYvfjii5o0aZKGDRumTp066a233tKxY8c0f/58T5cOAEC9RG8GAKBqvDp0n664uFgLFixQfn6+evfurYyMDGVlZSkpKcm5jd1uV9++fbV+/XoPVgoAgG+gNwMAcG5+ni7gXLZv367evXvr+PHjaty4sT788EN16NDB2byjoqJcto+KitKePXvOOmZhYaEKCwud9x0Oh/sLBwCgnqI3AwBQeV7/SXf79u21detWbdy4Uffcc4+Sk5O1c+dO53qbzeayvTGmzLIzpaamKiwszHmLj4+3pHYAAOojejMAAJXn9aE7ICBAbdq0Uffu3ZWamqquXbvqpZdeUnR0tCQpKyvLZfvs7Owy77CfaeLEiTpy5IjzlpmZaVn9AADUN/RmAAAqz+tD95mMMSosLFRiYqKio6OVnp7uXHfixAmtXbtWffr0OesYdrvdeamT0hsAAKgeejMAABXz6u90P/744xo8eLDi4+OVl5enBQsWaM2aNVq6dKlsNpvGjx+vadOmqW3btmrbtq2mTZumRo0aaeTIkZ4uHQCAeoneDABA1Xh16D5w4IBGjRql/fv3KywsTF26dNHSpUs1cOBASdIjjzyigoICjR07VocOHVLPnj21fPlyhYSEeLhyAADqJ3ozAABV49Whe9asWWddb7PZlJKSopSUlNopCAAAH0dvBgCgaurcd7oBAAAAAKgrCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFvDp0p6amqkePHgoJCVFkZKSuu+46fffddy7bjB49WjabzeXWq1cvD1UMAED9Rm8GAKBqvDp0r127Vvfee682btyo9PR0FRUVKSkpSfn5+S7bDRo0SPv373felixZ4qGKAQCo3+jNAABUjZ+nCzibpUuXutxPS0tTZGSktmzZossuu8y53G63Kzo6urbLAwDA59CbAQCoGq/+pPtMR44ckSSFh4e7LF+zZo0iIyPVrl073XnnncrOzj7rOIWFhXI4HC43AABQdfRmAADOrs6EbmOMJkyYoEsuuUSdOnVyLh88eLDmzZunVatW6YUXXtCmTZs0YMAAFRYWVjhWamqqwsLCnLf4+PjaeAoAANQr9GYAAM7Nqw8vP919992nbdu26T//+Y/L8hEjRjj/3alTJ3Xv3l0JCQlavHixhg0bVu5YEydO1IQJE5z3HQ4HzR0AgCqiNwMAcG51InSPGzdOixYt0meffaa4uLizbhsTE6OEhATt2rWrwm3sdrvsdru7ywQAwGfQmwEAqByvDt3GGI0bN04ffvih1qxZo8TExHM+Jjc3V5mZmYqJiamFCgEA8C30ZgAAqsarv9N977336p133tH8+fMVEhKirKwsZWVlqaCgQJJ09OhRPfTQQ9qwYYN2796tNWvWaOjQoWrevLmuv/56D1cPAED9Q28GAKBqvPqT7pkzZ0qS+vXr57I8LS1No0ePVsOGDbV9+3bNnTtXhw8fVkxMjPr376+FCxcqJCTEAxUDAFC/0ZsBAKgarw7dxpizrg8KCtKyZctqqRoAAEBvBgCgarz68HIAAAAAAOoyQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABaxLHS3atVKubm5ZZYfPnxYrVq1smq3AACgHPRlAAA8w7LQvXv3bhUXF5dZXlhYqF9++cWq3QIAgHLQlwEA8Aw/dw+4aNEi57+XLVumsLAw5/3i4mKtXLlSLVu2dPduAQBAOejLAAB4lttD93XXXSdJstlsSk5Odlnn7++vli1b6oUXXnD3bgEAQDnoywAAeJbbQ3dJSYkkKTExUZs2bVLz5s3dvQsAAFBJ9GUAADzLsu90Z2Rk1Lixp6amqkePHgoJCVFkZKSuu+46fffddy7bGGOUkpKi2NhYBQUFqV+/ftqxY0eN9gsAQH3jjr4s0ZsBAKgqt3/SfbqVK1dq5cqVys7Odr7TXmr27NnnfPzatWt17733qkePHioqKtKkSZOUlJSknTt3Kjg4WJI0ffp0zZgxQ3PmzFG7du309NNPa+DAgfruu+8UEhJiyfMCAKAuqmlflujNAABUlWWhe+rUqXrqqafUvXt3xcTEyGazVXmMpUuXutxPS0tTZGSktmzZossuu0zGGL344ouaNGmShg0bJkl66623FBUVpfnz5+uuu+5yy3MBAKCuc0dflujNAABUlWWh+/XXX9ecOXM0atQot4155MgRSVJ4eLikU4fKZWVlKSkpybmN3W5X3759tX79+gobe2FhoQoLC533HQ6H22oEAMAbWdGXJXozAADnYtl3uk+cOKE+ffq4bTxjjCZMmKBLLrlEnTp1kiRlZWVJkqKioly2jYqKcq4rT2pqqsLCwpy3+Ph4t9UJAIA3cndflujNAABUhmWhe8yYMZo/f77bxrvvvvu0bds2vfvuu2XWnXmInDHmrIfNTZw4UUeOHHHeMjMz3VYnAADeyN19WaI3AwBQGZYdXn78+HG98cYbWrFihbp06SJ/f3+X9TNmzKj0WOPGjdOiRYv02WefKS4uzrk8Ojpa0ql31WNiYpzLs7Ozy7zDfjq73S673V7p/QMAUNe5sy9L9GYAACrLstC9bds2XXjhhZKkr7/+2mVdZU/eYozRuHHj9OGHH2rNmjVKTEx0WZ+YmKjo6Gilp6erW7dukk4dPrd27Vo999xzNX8SAADUE+7oyxK9GQCAqrIsdK9evbrGY9x7772aP3++/v3vfyskJMT5XbCwsDAFBQXJZrNp/PjxmjZtmtq2bau2bdtq2rRpatSokUaOHFnj/QMAUF+4oy9L9GYAAKrK0ut019TMmTMlSf369XNZnpaWptGjR0uSHnnkERUUFGjs2LE6dOiQevbsqeXLl3MdUAAALEBvBgCgaiwL3f379z/r4WqrVq065xjGmHNuY7PZlJKSopSUlKqUBwCAT3FHX5bozQAAVJVlobv0e2OlTp48qa1bt+rrr79WcnKyVbsFAADloC8DAOAZloXuv/71r+UuT0lJ0dGjR63aLQAAKAd9GQAAz7DsOt0VufXWWzV79uza3i0AACgHfRkAAGvVeujesGGDAgMDa3u3AACgHPRlAACsZdnh5cOGDXO5b4zR/v37tXnzZk2ePNmq3QIAgHLQlwEA8AzLQndYWJjL/QYNGqh9+/Z66qmnlJSUZNVuAQBAOejLAAB4hmWhOy0tzaqhAQBAFdGXAQDwDMtCd6ktW7bom2++kc1mU4cOHdStWzerdwkAACpAXwYAoHZZFrqzs7P1hz/8QWvWrFGTJk1kjNGRI0fUv39/LViwQBEREVbtGgAAnIG+DACAZ1h29vJx48bJ4XBox44dOnjwoA4dOqSvv/5aDodD999/v1W7BQAA5aAvAwDgGZZ90r106VKtWLFCF1xwgXNZhw4d9Oqrr3LCFgAAahl9GQAAz7Dsk+6SkhL5+/uXWe7v76+SkhKrdgsAAMpBXwYAwDMsC90DBgzQn/70J+3bt8+57JdfftEDDzygyy+/3KrdAgCActCXAQDwDMtC9yuvvKK8vDy1bNlSrVu3Vps2bZSYmKi8vDy9/PLLVu0WAACUg74MAIBnWPad7vj4eH355ZdKT0/Xt99+K2OMOnTooCuuuMKqXQIAgArQlwEA8Ay3f9K9atUqdejQQQ6HQ5I0cOBAjRs3Tvfff7969Oihjh07at26de7eLQAAKAd9GQAAz3J76H7xxRd15513KjQ0tMy6sLAw3XXXXZoxY4a7dwsAAMpBXwYAwLPcHrr/97//adCgQRWuT0pK0pYtW9y9WwAAUA76MgAAnuX20H3gwIFyL0lSys/PTzk5Oe7eLQAAKAd9GQAAz3J76G7RooW2b99e4fpt27YpJibG3bsFAADloC8DAOBZbg/dQ4YM0ZNPPqnjx4+XWVdQUKApU6bo6quvdvduAQBAOejLAAB4ltsvGfbEE0/ogw8+ULt27XTfffepffv2stls+uabb/Tqq6+quLhYkyZNcvduAQBAOejLAAB4lttDd1RUlNavX6977rlHEydOlDFGkmSz2XTllVfqtddeU1RUlLt3CwAAykFfBgDAs9weuiUpISFBS5Ys0aFDh/TDDz/IGKO2bduqadOmVuwOAACcBX0ZAADPsSR0l2ratKl69Ohh5S4AAEAl0ZcBAKh9bj+RGgAAAAAAOIXQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEW8PnR/9tlnGjp0qGJjY2Wz2fTRRx+5rB89erRsNpvLrVevXp4pFgAAH0BvBgCg8rw+dOfn56tr16565ZVXKtxm0KBB2r9/v/O2ZMmSWqwQAADfQm8GAKDy/DxdwLkMHjxYgwcPPus2drtd0dHRtVQRAAC+jd4MAEDlef0n3ZWxZs0aRUZGql27drrzzjuVnZ191u0LCwvlcDhcbgAAwH3ozQAAnFLnQ/fgwYM1b948rVq1Si+88II2bdqkAQMGqLCwsMLHpKamKiwszHmLj4+vxYoBAKjf6M0AAPzG6w8vP5cRI0Y4/92pUyd1795dCQkJWrx4sYYNG1buYyZOnKgJEyY47zscDpo7AABuQm8GAOA3dT50nykmJkYJCQnatWtXhdvY7XbZ7fZarAoAAN9FbwYA+LI6f3j5mXJzc5WZmamYmBhPlwIAAERvBgD4Nq//pPvo0aP64YcfnPczMjK0detWhYeHKzw8XCkpKRo+fLhiYmK0e/duPf7442revLmuv/56D1YNAED9RW8GAKDyvD50b968Wf3793feL/2+V3JysmbOnKnt27dr7ty5Onz4sGJiYtS/f38tXLhQISEhnioZAIB6jd4MAEDleX3o7tevn4wxFa5ftmxZLVYDAADozQAAVF69+043AAAAAADegtANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBF/DxdAM4uJydHDofDLWOFhoYqIiLCLWMBAAAA8D3kk6ojdHuxnJwc3XrbGB3MO+aW8cJDGumdtDd94oUNAAAAwL1ycnJ0z5iRKjya65bx7I2baeab8+t9PiF0ezGHw6GDeccU0Xu4gsOjajRW/sEDytnwvhwOR71/UQMAAABwP4fDocKjuXpwqF3xEUE1Giszp0AvfJzrE/mE0F0HBIdHKTQyrsbj5LihFgAAAAC+LT4iSK1bBLthpEI3jOH9OJEaAAAAAAAW8frQ/dlnn2no0KGKjY2VzWbTRx995LLeGKOUlBTFxsYqKChI/fr1044dOzxTLAAAPoDeDABA5Xl96M7Pz1fXrl31yiuvlLt++vTpmjFjhl555RVt2rRJ0dHRGjhwoPLy8mq5UgAAfAO9GQCAyvP673QPHjxYgwcPLnedMUYvvviiJk2apGHDhkmS3nrrLUVFRWn+/Pm66667arNUAAB8Ar0ZAIDK8/pPus8mIyNDWVlZSkpKci6z2+3q27ev1q9fX+HjCgsL5XA4XG4AAKDm6M0AALiq06E7KytLkhQV5Xo5raioKOe68qSmpiosLMx5i4+Pt7ROAAB8Bb0ZAABXdTp0l7LZbC73jTFllp1u4sSJOnLkiPOWmZlpdYkAAPgUejMAAKd4/Xe6zyY6OlrSqXfVY2JinMuzs7PLvMN+OrvdLrvdbnl9AAD4GnozAACu6vQn3YmJiYqOjlZ6erpz2YkTJ7R27Vr16dPHg5UBAOCb6M0AALjy+k+6jx49qh9++MF5PyMjQ1u3blV4eLjOO+88jR8/XtOmTVPbtm3Vtm1bTZs2TY0aNdLIkSM9WDUAAPUXvRkAgMrz+tC9efNm9e/f33l/woQJkqTk5GTNmTNHjzzyiAoKCjR27FgdOnRIPXv21PLlyxUSEuKpkgEAqNfozQAAVJ7Xh+5+/frJGFPhepvNppSUFKWkpNReUQAA+DB6MwAAlef1oRsA4LtycnLccr3mPXv2qOhkkRsqAqTCEye1Z8+eGo8TGhqqiIgIN1QEAPBmhG4AgFfKycnRrbeN0cG8YzUe63jBMf38y36dd/KkGyqDL8t1nNBPGXv07JPjany2dXvjZpr55nyCNwDUc4RuAIBXcjgcOph3TBG9hys4vOJLTVVG9o9fa0/mbBUXEbpRM0cLihXQoEgPXB2gdvFNqj1OZk6BXvg4Vw6Hg9ANAPUcoRsA4NWCw6MUGhlXozGO5ma5qRrglLiIQLVuEVzDUQrdUgsAwLvV6et0AwAAAADgzQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEU4ezk8KicnRw6Hwy1jhYaGctmVKmDuAQCov+jznsG8ozyEbnhMTk6Obr1tjA7mHXPLeOEhjfRO2pv8cqoE5h4AgPorJydH94wZqcKjuW4Zz964mWa+OZ8+fw7MOypC6IbHOBwOHcw7pojewxUcHlWjsfIPHlDOhvflcDj4xVQJzD0AAPWXw+FQ4dFcPTjUrviIoBqNlZlToBc+zqXPVwLzjooQuuFxweFRCo2Mq/E4OW6oxdcw9wAA1F/xEUFq3SLYDSMVumEM38G840ycSA0AAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIv4eboA1J6TJ05oz549bhkrNDRUERERbhkLQP2Sk5Mjh8NR43H27NmjopNFbqgI8E6FJ07SlwHUCrf25iJ6c1URun1E4dEj2p3xk8Y/niK73V7j8cJDGumdtDdp8ABc5OTk6Nbbxuhg3rEaj3W84Jh+/mW/zjt50g2VAd4l13FCP2Xs0bNPjnNLX7Y3bqaZb86nLwMoIycnR/eMGanCo7k1Hiv/WKEOZGWq8GSYGyrzHYRuH3GysEAlNj817zVMzWITajRW/sEDytnwvhwOB80dgAuHw6GDeccU0Xu4gsOjajRW9o9fa0/mbBUXEbpR/xwtKFZAgyI9cHWA2sU3qdFYmTkFeuHjXPoygHI5HA4VHs3Vg0Ptio8IqtFYG785pGfmFqm4mE+7q4LQ7WMaNY1QaGRcjcfJcUMtAOqv4PCoGv+uOZqb5aZqAO8VFxGo1i2C3TBSoRvGAFCfxUcE1fj3zZ4DBW6qxrfU+ROppaSkyGazudyio6M9XRYAAD6L3gwAwG/qxSfdHTt21IoVK5z3GzZs6MFqAAAAvRkAgFPqRej28/PjHXQAALwIvRkAgFPq/OHlkrRr1y7FxsYqMTFRf/jDH/TTTz95uiQAAHwavRkAgFPq/CfdPXv21Ny5c9WuXTsdOHBATz/9tPr06aMdO3aoWbNm5T6msLBQhYW/nXDEHdes8zXuuOY31+CtP3zhGvDuur6ltz4/wJ3ozbCCu34PS977u5hrKeN0hSdOuuXvK14PnlfnQ/fgwYOd/+7cubN69+6t1q1b66233tKECRPKfUxqaqqmTp1aWyXWO+665jfX4K0ffOEa8O689rQ3Pj/A3ejNcDd3XmdY8s7rmnMtZZwu13FCP2Xs0bNPjqvx31e8HjyvzofuMwUHB6tz587atWtXhdtMnDjRpek7HA7Fx8fXRnn1gruu+c01eOsHX7gGvLuuPe2tzw+wGr0ZNeXO6wx763XNuZYyTne0oFgBDYr0wNUBahffpEZj8XrwvHoXugsLC/XNN9/o0ksvrXAbu93ulk/kfF1Nr/nNNXjrF1+4Brw7rj3tzc8PsAq9Ge7ijusMn+K91zXnWso4XVxEIK+HeqDOn0jtoYce0tq1a5WRkaH//ve/uuGGG+RwOJScnOzp0gAA8En0ZgAAflPnP+n++eefdfPNN+vXX39VRESEevXqpY0bNyohoWaHuQIAgOqhNwMA8Js6H7oXLFjg6RIAAMBp6M0AAPymzh9eDgAAAACAt6rzn3QDqF/q+zW/6/vzA4DT+cJ1p33hOQKoGUI3AK9R36/5Xd+fHwCczheuO+0LzxFAzRG6AXiN+n7N7/r+/ADgdL5w3WlfeI4Aao7QDcDr1Pdrftf35wcAp/OF6077wnMEUH2cSA0AAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLcPZywGI5OTlyOBxuGSs0NJTLQ8Hp5IkT2rNnj1vG4rUFoJS7+taePXtUVMTlr/Ab/iaCryJ0AxbKycnRrbeN0cG8Y24ZLzykkd5Je5MmAxUePaLdGT9p/OMpstvtNR6P1xYA6VTfumfMSBUeza3xWPnHCnUgK1OFJ8PcUBnqOne+tiTJ3riZZr45n76FOoHQDVjI4XDoYN4xRfQeruDwqBqNlX/wgHI2vC+Hw0GDgU4WFqjE5qfmvYapWWxCjcbitQWglMPhUOHRXD041K74iKAajbXxm0N6Zm6Riov5tBvufW1l5hTohY9z6VuoMwjdQC0IDo9SaGRcjcfJcUMtqF8aNY3gtQXA7eIjgtS6RXCNxthzoMBN1aA+ccdr65RCN4wB1A5OpAYAAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhBOpAeVw6zVKT3LWVng/d13zm9c84BmFJ0667/9hrq2NOsBdr3mJa37DeoRu4AzuvLb28YJj+vmX/Trv5Ek3VAZYw53X/OY1D9S+XMcJ/ZSxR88+Oa7G/w9zbW3UBe58zUtc8xvWI3QDZ3DntbWzf/xaezJnq7iIAALv5c5rfvOaB2rf0YJiBTQo0gNXB6hdfJMajcW1tVEXuPM1zzW/URsI3UAF3HFt7aO5WW6qBrCeO675zWse8Jy4iECurQ2f4o7X/Clc8xvW4kRqAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEU4kZoFuMazZ3CdYZyJ1wQAoDxc1xyn4/XgOb5yvXVCt5txjWfP4DrDOBOvCQBAebiuOU7H68FzfOl664RuN+Maz57BdYZxJl4TAIDycF1znI7Xg+f40vXWCd0W4RrPnsF1hnEmXhMAgPJwXXOcjteD5/jC9dY5kRoAAAAAABapN6H7tddeU2JiogIDA3XRRRdp3bp1ni4JAACfRm8GAKCehO6FCxdq/PjxmjRpkr766itdeumlGjx4sPbu3evp0gAA8En0ZgAATqkXoXvGjBm64447NGbMGF1wwQV68cUXFR8fr5kzZ3q6NAAAfBK9GQCAU+p86D5x4oS2bNmipKQkl+VJSUlav369h6oCAMB30ZsBAPhNnT97+a+//qri4mJFRblenisqKkpZWeWfcbiwsFCFhb+d3e7IkSOSTl3uq6by8vJUXFSkw/t36+Txml2r25H9s0xJiRxZmfKz1awubxzLG2vy5rHyD2WrsKBAO3fuVF5eXo3GyszM1Injx3md1vJY3lgTY1Vd/qFsFRcVKS8vr8Z9o/TxxpiaFeVlvLE3nywq1reZeco7VrNL+fy4P1/FJUbfZ+aruMTf4+MwFmNZPdYvuQU6VlBY478/MjMzdbyw0Kv+P2Ss+jPWL7kFOllU7L292dRxv/zyi5Fk1q9f77L86aefNu3bty/3MVOmTDGSuHHjxo0bN6+4ZWZm1kbLrDX0Zm7cuHHjVtdv7uzNdf6T7ubNm6thw4Zl3jnPzs4u8w57qYkTJ2rChAnO+yUlJTp48KCaNWsmm831IxCHw6H4+HhlZmYqNDTU/U+gnmLeqod5qx7mrXqYt+px57wZY5SXl6fY2Fg3VecdrO7NVcHrvHqYt+ph3qqHease5q16zjVvVvTmOh+6AwICdNFFFyk9PV3XX3+9c3l6erquvfbach9jt9tlt9tdljVp0uSs+wkNDeXFXA3MW/Uwb9XDvFUP81Y97pq3sLAwN1TjXWqrN1cFr/PqYd6qh3mrHuatepi36jnbvLm7N9f50C1JEyZM0KhRo9S9e3f17t1bb7zxhvbu3au7777b06UBAOCT6M0AAJxSL0L3iBEjlJubq6eeekr79+9Xp06dtGTJEiUkJHi6NAAAfBK9GQCAU+pF6JaksWPHauzYsW4f1263a8qUKWUOecPZMW/Vw7xVD/NWPcxb9TBvlWdVb64Kfl7Vw7xVD/NWPcxb9TBv1eOJebMZU8+uUwIAAAAAgJdo4OkCAAAAAACorwjdAAAAAABYhNANAAAAAIBFCN2SXnvtNSUmJiowMFAXXXSR1q1bd9bt165dq4suukiBgYFq1aqVXn/99Vqq1LtUZd4++OADDRw4UBEREQoNDVXv3r21bNmyWqzWe1T19Vbq888/l5+fny688EJrC/RSVZ23wsJCTZo0SQkJCbLb7WrdurVmz55dS9V6j6rO27x589S1a1c1atRIMTExuu2225Sbm1tL1XqHzz77TEOHDlVsbKxsNps++uijcz6GvuBZ9PHqoY9XD328eujj1UMfrzqv7OPGxy1YsMD4+/ubf/zjH2bnzp3mT3/6kwkODjZ79uwpd/uffvrJNGrUyPzpT38yO3fuNP/4xz+Mv7+/+de//lXLlXtWVeftT3/6k3nuuefMF198Yb7//nszceJE4+/vb7788startyzqjpvpQ4fPmxatWplkpKSTNeuXWunWC9SnXm75pprTM+ePU16errJyMgw//3vf83nn39ei1V7XlXnbd26daZBgwbmpZdeMj/99JNZt26d6dixo7nuuutquXLPWrJkiZk0aZJ5//33jSTz4YcfnnV7+oJn0cerhz5ePfTx6qGPVw99vHq8sY/7fOj+/e9/b+6++26XZeeff7557LHHyt3+kUceMeeff77Lsrvuusv06tXLshq9UVXnrTwdOnQwU6dOdXdpXq268zZixAjzxBNPmClTpvhks67qvH366acmLCzM5Obm1kZ5Xquq8/b888+bVq1auSz729/+ZuLi4iyr0dtVplnTFzyLPl499PHqoY9XD328eujjNectfdynDy8/ceKEtmzZoqSkJJflSUlJWr9+fbmP2bBhQ5ntr7zySm3evFknT560rFZvUp15O1NJSYny8vIUHh5uRYleqbrzlpaWph9//FFTpkyxukSvVJ15W7Rokbp3767p06erRYsWateunR566CEVFBTURsleoTrz1qdPH/38889asmSJjDE6cOCA/vWvf+mqq66qjZLrLPqC59DHq4c+Xj308eqhj1cPfbz21EZf8HPLKHXUr7/+quLiYkVFRbksj4qKUlZWVrmPycrKKnf7oqIi/frrr4qJibGsXm9RnXk70wsvvKD8/HzddNNNVpTolaozb7t27dJjjz2mdevWyc/PN/93rc68/fTTT/rPf/6jwMBAffjhh/r11181duxYHTx40Ge+D1adeevTp4/mzZunESNG6Pjx4yoqKtI111yjl19+uTZKrrPoC55DH68e+nj10Merhz5ePfTx2lMbfcGnP+kuZbPZXO4bY8osO9f25S2v76o6b6XeffddpaSkaOHChYqMjLSqPK9V2XkrLi7WyJEjNXXqVLVr1662yvNaVXm9lZSUyGazad68efr973+vIUOGaMaMGZozZ45PvUsuVW3edu7cqfvvv19PPvmktmzZoqVLlyojI0N33313bZRap9EXPIs+Xj308eqhj1cPfbx66OO1w+q+4Jtvuf1/zZs3V8OGDcu8W5SdnV3m3Y5S0dHR5W7v5+enZs2aWVarN6nOvJVauHCh7rjjDr333nu64oorrCzT61R13vLy8rR582Z99dVXuu+++ySdakLGGPn5+Wn58uUaMGBArdTuSdV5vcXExKhFixYKCwtzLrvgggtkjNHPP/+stm3bWlqzN6jOvKWmpuriiy/Www8/LEnq0qWLgoODdemll+rpp5/2iU8Aq4O+4Dn08eqhj1cPfbx66OPVQx+vPbXRF3z6k+6AgABddNFFSk9Pd1menp6uPn36lPuY3r17l9l++fLl6t69u/z9/S2r1ZtUZ96kU++Mjx49WvPnz/fJ75ZUdd5CQ0O1fft2bd261Xm7++671b59e23dulU9e/asrdI9qjqvt4svvlj79u3T0aNHncu+//57NWjQQHFxcZbW6y2qM2/Hjh1TgwaubaFhw4aSfnvHF2XRFzyHPl499PHqoY9XD328eujjtadW+oLbTslWR5Wein/WrFlm586dZvz48SY4ONjs3r3bGGPMY489ZkaNGuXcvvSU8g888IDZuXOnmTVrlk9faqSy8zZ//nzj5+dnXn31VbN//37n7fDhw556Ch5R1Xk7k6+e9bSq85aXl2fi4uLMDTfcYHbs2GHWrl1r2rZta8aMGeOpp+ARVZ23tLQ04+fnZ1577TXz448/mv/85z+me/fu5ve//72nnoJH5OXlma+++sp89dVXRpKZMWOG+eqrr5yXaKEveBf6ePXQx6uHPl499PHqoY9Xjzf2cZ8P3cYY8+qrr5qEhAQTEBBgfve735m1a9c61yUnJ5u+ffu6bL9mzRrTrVs3ExAQYFq2bGlmzpxZyxV7h6rMW9++fY2kMrfk5OTaL9zDqvp6O52vNmtjqj5v33zzjbniiitMUFCQiYuLMxMmTDDHjh2r5ao9r6rz9re//c106NDBBAUFmZiYGHPLLbeYn3/+uZar9qzVq1ef9fcVfcH70Merhz5ePfTx6qGPVw99vOq8sY/bjOFYAwAAAAAArODT3+kGAAAAAMBKhG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYgSUpJSdGFF15Y43FsNps++uijCtfv3r1bNptNW7dulSStWbNGNptNhw8fliTNmTNHTZo0qXEdAADUdfRmoH4gdAN10OjRo2Wz2WSz2eTv769WrVrpoYceUn5+vqdLO6f4+Hjt379fnTp1Knf9iBEj9P333zvvu+sPDgAArERvBlARP08XAKB6Bg0apLS0NJ08eVLr1q3TmDFjlJ+fr5kzZ7psd/LkSfn7+3uoyrIaNmyo6OjoCtcHBQUpKCioFisCAMA96M0AysMn3UAdZbfbFR0drfj4eI0cOVK33HKLPvroI+e7z7Nnz1arVq1kt9tljNHevXt17bXXqnHjxgoNDdVNN92kAwcOlBn373//u+Lj49WoUSPdeOONzkPLJGnTpk0aOHCgmjdvrrCwMPXt21dffvllmTH279+vwYMHKygoSImJiXrvvfec6848hO1Mpx/CNmfOHE2dOlX/+9//nJ8ezJkzR7fffruuvvpql8cVFRUpOjpas2fPrvpkAgDgBvRmejNQHkI3UE8EBQXp5MmTkqQffvhB//znP/X+++87G+h1112ngwcPau3atUpPT9ePP/6oESNGuIxR+riPP/5YS5cu1datW3Xvvfc61+fl5Sk5OVnr1q3Txo0b1bZtWw0ZMkR5eXku40yePFnDhw/X//73P9166626+eab9c0331T5OY0YMUIPPvigOnbsqP3792v//v0aMWKExowZo6VLl2r//v3ObZcsWaKjR4/qpptuqvJ+AACwAr2Z3gxIHF4O1AtffPGF5s+fr8svv1ySdOLECb399tuKiIiQJKWnp2vbtm3KyMhQfHy8JOntt99Wx44dtWnTJvXo0UOSdPz4cb311luKi4uTJL388su66qqr9MILLyg6OloDBgxw2e/f//53NW3aVGvXrnV5d/vGG2/UmDFjJEl//vOflZ6erpdfflmvvfZalZ5XUFCQGjduLD8/P5fD3vr06aP27dvr7bff1iOPPCJJSktL04033qjGjRtXaR8AAFiB3kxvBkrxSTdQR33yySdq3LixAgMD1bt3b1122WV6+eWXJUkJCQnOpi5J33zzjeLj451NXZI6dOigJk2auLzLfd555zmbuiT17t1bJSUl+u677yRJ2dnZuvvuu9WuXTuFhYUpLCxMR48e1d69e11q6927d5n71Xk3/WzGjBmjtLQ0Z12LFy/W7bff7tZ9AABQFfRmejNQHj7pBuqo/v37a+bMmfL391dsbKzLCVmCg4NdtjXGyGazlRmjouWlSteV/nf06NHKycnRiy++qISEBNntdvXu3VsnTpw4Z71n2091/PGPf9Rjjz2mDRs2aMOGDWrZsqUuvfRSt+4DAICqoDfTm4Hy8Ek3UEcFBwerTZs2SkhIOOcZUDt06KC9e/cqMzPTuWznzp06cuSILrjgAueyvXv3at++fc77GzZsUIMGDdSuXTtJ0rp163T//fdryJAh6tixo+x2u3799dcy+9u4cWOZ++eff361nmdAQICKi4vLLG/WrJmuu+46paWlKS0tTbfddlu1xgcAwF3ozfRmoDx80g34gCuuuEJdunTRLbfcohdffFFFRUUaO3as+vbtq+7duzu3CwwMVHJysv7yl7/I4XDo/vvv10033eT8zlabNm309ttvq3v37nI4HHr44YfLvYTIe++9p+7du+uSSy7RvHnz9MUXX2jWrFnVqr1ly5bKyMjQ1q1bFRcXp5CQENntdkmnDmO7+uqrVVxcrOTk5GqNDwCAJ9CbAd/BJ92AD7DZbProo4/UtGlTXXbZZbriiivUqlUrLVy40GW7Nm3aaNiwYRoyZIiSkpLUqVMnlxOszJ49W4cOHVK3bt00atQo3X///YqMjCyzv6lTp2rBggXq0qWL3nrrLc2bN08dOnSoVu3Dhw/XoEGD1L9/f0VEROjdd991rrviiisUExOjK6+8UrGxsdUaHwAAT6A3A77DZowxni4CAKrj2LFjio2N1ezZszVs2DBPlwMAgM+jNwNlcXg5gDqnpKREWVlZeuGFFxQWFqZrrrnG0yUBAODT6M1AxQjdAOqcvXv3KjExUXFxcZozZ478/PhVBgCAJ9GbgYpxeDkAAAAAABbhRGoAAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3QAAAAAAWITQDQAAAACARQjdAAAAAABYhNANAAAAAIBFCN0AAAAAAFiE0A0AAAAAgEUI3YCb7Ny5U3a7XTabTZs3by6zPjs7W6NHj1bz5s3VqFEj9e7dWytXrqzSPj755BNde+21io2NVUBAgEJCQtStWzdNmTJFe/fudddT8Xrr1q2T3W7Xnj17PFrHsWPHlJKSojVr1lgyfr9+/dSvXz/n/UOHDqlJkyb66KOPLNkfANQX9OTaU15Pfu211zRnzhzPFSVp3759SklJ0datW90+9pw5c2Sz2bR7927nsssuu0zjx493+75QPxC6ATcoLi7W7bffrubNm5e7vrCwUJdffrlWrlypl156Sf/+978VFRWlQYMGae3ateccv6SkRMnJyRo6dKhOnjyp1NRUpaen67333tOwYcP09ttv6+KLL3b30/JKxhiNHz9ed955pxISEjxay7FjxzR16lTLQveZmjZtqgceeEAPP/ywTpw4USv7BIC6hp5ceyrqyd4SuqdOnWpJ6C7Pn//8Z7322mv67rvvamV/qGMMgBp7/vnnTYsWLcxLL71kJJlNmza5rH/11VeNJLN+/XrnspMnT5oOHTqY3//+9+ccf9q0aUaSSU1NLXf9yZMnzSuvvHLOcY4dO3bObbzdkiVLjCTz7bfferoUk5OTYySZKVOmVGr7/Pz8Ko3ft29f07dvX5dlWVlZxs/Pz8ybN69KYwGAr6An156KenLHjh3L9K+KnDhxwpw8edLttW3atMlIMmlpaW4fOy0tzUgyGRkZLss7depk7rzzTrfvD3UfoRv1yvfff29uvvlmExERYQICAsz555/v0vgKCgrMhRdeaFq3bm0OHz7sXL5//34TFRVl+vbta4qKiqq8z6CgIPPvf//b+Uv4zAZ/xRVXmPbt25d5bGnj/vnnnyscv7Cw0DRp0sR06tSpSnUlJCSYq666yrz//vvmwgsvNHa73Tz66KPGGGO2b99urrnmGtOkSRNjt9tN165dzZw5c1weX1FDWb16tZFkVq9e7VzWt29f07FjR/PZZ5+Znj17msDAQBMbG2ueeOKJSs1naa0ffPCB6dy5s7Hb7SYxMdG89NJLZbYdOnSo6dGjR7njzJs3z/Tq1csEBweb4OBg07VrV/Pmm2+6bDNr1izTpUsXY7fbTdOmTc11111ndu7c6bJNcnKyCQ4ONrt27TKDBw82wcHBJi4uzkyYMMEcP37cGGNMRkaGkVTmlpycbIwxZsqUKUaS2bJlixk+fLhp0qSJiY6ONsaceh0+9thjpmXLlsbf39/ExsaasWPHmkOHDrnUUV7oNsaYwYMHm0svvfSc8woAnkRP/o0v9eSEhIQyvTEhIcGl3rlz55oJEyaY2NhYY7PZzDfffGOMMSY9Pd0MGDDAhISEmKCgINOnTx+zYsUKl/F37dplRo8ebdq0aWOCgoJMbGysufrqq822bdvKzMuZt9PfJN+0aZMZOnSoadq0qbHb7ebCCy80CxcuLPMcN2zYYPr06WPsdruJiYkxjz32mHnjjTfK/Xk899xzJjg42DgcjnPOM3wLoRv1xo4dO0xYWJjp3LmzmTt3rlm+fLl58MEHTYMGDUxKSopzu++//96EhISYYcOGGWOMKS4uNgMGDDCRkZFm3759VdpnSUmJueyyy8yNN95ojDEVNvjo6GjnNqf75JNPjCSzbNmyCvfx+eefG0lm4sSJVaotISHBxMTEmFatWpnZs2eb1atXmy+++MJ8++23JiQkxLRu3drMnTvXLF682Nx8881Gknnuueecj69qg2/WrJmJjY01f/vb38yyZcvM/fffbySZe++9t1K1tmjRwpx33nlm9uzZZsmSJeaWW24xkszzzz/v3K6wsNAEBQWZRx55pMwYkydPNpLMsGHDzHvvvWeWL19uZsyYYSZPnuzcpvQPqptvvtksXrzYzJ0717Rq1cqEhYWZ77//3rldcnKyCQgIMBdccIH5y1/+YlasWGGefPJJY7PZzNSpU40xxhw/ftwsXbrUSDJ33HGH2bBhg9mwYYP54YcfjDG/he6EhATz6KOPmvT0dPPRRx+ZkpISc+WVVxo/Pz8zefJks3z5cvOXv/zFBAcHm27dujlDfem8lhe6n3vuOdOgQYMyIR0AvAU92ZUv9eQvv/zStGrVynTr1s3ZG7/88kuXelu0aGFuuOEGs2jRIvPJJ5+Y3Nxc8/bbbxubzWauu+4688EHH5iPP/7YXH311aZhw4YuwXvt2rXmwQcfNP/617/M2rVrzYcffmiuu+46ExQU5PzE/ciRI845e+KJJ5x1ZGZmGmOMWbVqlQkICDCXXnqpWbhwoVm6dKkZPXp0mU/Gd+zYYRo1amQ6dOhg3n33XfPvf//bXHnllea8884r9+fx3//+10gyixYtOuc8w7cQulFvXHnllSYuLs4cOXLEZfl9991nAgMDzcGDB53LFi5caCSZF1980Tz55JOmQYMGZvny5VXe58svv2yaNm1qsrKyjDEVN3h/f39z1113lXn8+vXrjSQzf/78CvexYMECI8m8/vrrZdadPHnS5Xa6hIQE07BhQ/Pdd9+5LP/DH/5g7Ha72bt3r8vywYMHm0aNGjk/bahqg5dk/v3vf7tse+edd5oGDRqYPXv2VPj8Smu12Wxm69atLssHDhxoQkNDnYdllzazBQsWuGz3008/mYYNG5pbbrmlwn0cOnTIBAUFmSFDhrgs37t3r7Hb7WbkyJHOZcnJyUaS+ec//+my7ZAhQ1w+HTnb4eWlofvJJ590WV4a1KdPn+6yvPQ1+cYbbziXVRS609PTjSTz6aefVvh8AcCT6Mm+25ONqfjw8tJ6L7vsMpfl+fn5Jjw83AwdOtRleXFxsenatetZD/svKioyJ06cMG3btjUPPPCAc/nZDi8///zzTbdu3cr8nK6++moTExNjiouLjTHGjBgxwgQFBTlfU6X7O//888v9eZw4ccLYbDbnUQxAKU6khnrh+PHjWrlypa6//no1atRIRUVFztuQIUN0/Phxbdy40bn9TTfdpHvuuUcPP/ywnn76aT3++OMaOHBglfa5Z88eTZw4Uc8//7yioqLOub3NZqvWuoocPnxY/v7+Lrczz9DapUsXtWvXzmXZqlWrdPnllys+Pt5l+ejRo3Xs2DFt2LChyrVIUkhIiK655hqXZSNHjlRJSYk+++yzcz6+Y8eO6tq1a5nHOxwOffnll5JOnRRFkiIjI122S09PV3Fxse69994Kx9+wYYMKCgo0evRol+Xx8fEaMGBAmbPW2mw2DR061GVZly5dqnzG9OHDh7vcX7VqlSSVqePGG29UcHBwpc6eW/r8f/nllyrVAgC1gZ7s2z25Ms7sjevXr9fBgweVnJzs8nopKSnRoEGDtGnTJuXn50uSioqKNG3aNHXo0EEBAQHy8/NTQECAdu3apW+++eac+/7hhx/07bff6pZbbnGOd/rrc//+/c6Toa1evVqXX365y2uqYcOGGjFiRLlj+/v7q0mTJvRnlEHoRr2Qm5uroqIivfzyy2Wa3pAhQyRJv/76q8tjbr/9dp08eVJ+fn66//77q7zPe++9V506ddLw4cN1+PBhHT58WMeOHZMkHT16VEeOHHFu26xZM+Xm5pYZ4+DBg5Kk8PDwCvdz3nnnSVKZsBcSEqJNmzZp06ZNmjJlSrmPjYmJKbMsNze33OWxsbHO9dVR3h850dHRlR6zdNuzPb6goECSFBgY6LJdTk6OJCkuLq7C8UvHqOi5n1ljo0aNyuzHbrfr+PHjZ30eZzpzf7m5ufLz81NERITLcpvNpujo6ErNVWldpfMBAN6EnuzbPbkyznzOBw4ckCTdcMMNZV4zzz33nIwxzp/PhAkTNHnyZF133XX6+OOP9d///lebNm1S165dK9UXS/f10EMPldnX2LFjJf32+szNzT3rXJQnMDCQ/owy/DxdAOAOTZs2VcOGDTVq1KgKP+1MTEx0/js/P1+jRo1Su3btdODAAY0ZM0b//ve/q7TPr7/+Wnv27FHTpk3LrOvfv7/CwsJ0+PBhSVLnzp21ffv2MtuVLuvUqVOF+7nooovUtGlTffzxx5o2bZpzecOGDdW9e3dnLeUp7936Zs2aaf/+/WWWl75jXXqJldImWlhY6LLdmX8olSptYqfLyspy7vNcSrc92+NLayttvKVKA+zPP/9c5tOCUqVjVPTcK7q0TE2d+TNo1qyZioqKlJOT4xK8jTHKyspSjx49zjlm6fO3qmYAqAl6sm/35Mo4cy5Kx3r55ZfVq1evch9T+kbCO++8oz/+8Y8u8y+dmosmTZqcc9+l+5o4caKGDRtW7jbt27eXdOq5nm0uynPo0CH6M8rgk27UC40aNVL//v311VdfqUuXLurevXuZ2+lN5u6779bevXv1wQcfaNasWVq0aJH++te/VmmfCxYs0OrVq11ujz76qCTp9ddf1yeffOLc9vrrr9e3336r//73v85lRUVFeuedd9SzZ0/nO9rlCQgI0MMPP6yvv/5azz33XJVqLM/ll1+uVatWORt6qblz56pRo0bOZteyZUtJ0rZt21y2W7RoUbnj5uXllVk3f/58NWjQQJdddtk569qxY4f+97//lXl8SEiIfve730mSLrjgAknSjz/+6LJdUlKSGjZsqJkzZ1Y4fu/evRUUFKR33nnHZfnPP//sPLyvqux2u6SqfeJcup8z63j//feVn59fqTp++uknSVKHDh0qvV8AqC305Mqrjz1ZOtUfq9IbL774YjVp0kQ7d+4s9/XSvXt3BQQESDoV2Ev7b6nFixeXOaS7oh7dvn17tW3bVv/73/8q3FdISIikU2/YrFy50uVNjOLiYi1cuLDc57Fv3z4dP36c/oyyPP2lcsBdduzYYZo2bWp+//vfm7S0NLN69WqzaNEiM2PGDNO/f3/ndv/4xz/KnFjjvvvuM/7+/ua///1vjWqo6KQtx48fNx07djTx8fFm3rx5Jj093Vx//fXGz8/PrFmz5pzjFhcXmz/+8Y9GkhkyZIh56623zNq1a83y5cvN66+/brp3724aNmxoduzY4XxM6SU/zlR6ptR27dqZd955x+WspKef3KuoqMi0b9/enHfeeWb+/Pnm008/Nf/3f/9nEhMTz3qm1JdfftksW7bM/OlPfzKSzD333HPO53fmmVI//fRTZ02nn73VGGNatWplbr755jJjlJ69/IYbbjDvv/++WbFihfnb3/7mciKz0rOXjxo1yixZssS8/fbbpk2bNuWevTw4OLjMPkpPjnZm7e3btzfLli0zmzZtcp5UpXTbnJwcl+1Lz17u7+9vUlJSTHp6unnhhRdM48aNK3328nHjxplmzZqZkpKSiicVADyInuzbPTk5OdnY7XazYMEC88UXXzgv51V6IrX33nuvzGPefvtt06BBAzNixAjz3nvvmbVr15p//etfZvLkyebuu+92bvfHP/7R2O1289e//tWsXLnSTJ8+3URERJi4uDiXnpmfn2+CgoLMxRdfbFavXm02bdpkfvnlF2PMqbOX2+12k5SUZObPn+88C/q0adPMDTfc4Bxj+/btJigoyHTo0MEsWLDALFq0yFx55ZUmPj6+3BOpvf/++0aSy+XLAGM4eznqmYyMDHP77bebFi1aGH9/fxMREWH69Oljnn76aWOMMdu2bTNBQUHOaymXOn78uLnoootMy5Yta3QZpooavDHGZGVlmT/+8Y8mPDzcBAYGml69epn09PQqjb9o0SIzdOhQExUVZfz8/ExISIi58MILzYMPPui8TEapihq8MaeayNChQ01YWJgJCAgwXbt2Lffsnt9//71JSkoyoaGhJiIiwowbN84sXry4wmuCrlmzxnTv3t15LcvHH3+8zJlBy1Na67/+9S/TsWNHExAQYFq2bGlmzJhRZtvJkyebpk2buoTTUnPnzjU9evQwgYGBzhB75vN68803TZcuXUxAQIAJCwsz1157rcsfRsZULXSvWLHCdOvWzdjt9nKv031m6Dbm1LVpH330UZOQkGD8/f1NTEyMueeeeyp1ne6SkhKTkJBgxo0bV2ZcAPAm9OTf+FpP3r17t0lKSjIhISHlXqe7vNBtzKnLgV111VUmPDzc+Pv7mxYtWpirrrrKZftDhw6ZO+64w0RGRppGjRqZSy65xKxbt67cnvnuu++a888/3/j7+5e52sj//vc/c9NNN5nIyEjj7+9voqOjzYABA8qcmf7zzz83vXr1Mna73URHR5uHH364wut0jxo1ynTu3PkcMwxfZDPGGOs/TwdQn/Xr10+//vprhd9jO5eWLVuqU6dOLof/VWTfvn1KTEzU3LlzKzx7aH22cuVKJSUlaceOHTr//PM9XQ4AwMvQkz3D4XAoNjZWf/3rX3XnnXd6uhx4Gb7TDaBOiY2N1fjx4/XMM8+opKTE0+XUuqefflq33347gRsA4HG+3pNP99e//lXnnXeebrvtNk+XAi/E2cuBMxhjVFxcfNZtGjZsWK3reMI9nnjiCTVq1Ei//PJLhWcrr48OHTqkvn37Oi9pAgD1HT3Z+/lqTz5TaGio5syZIz8/4hXK4vBy4Axr1qxR//79z7pNWlqaRo8eXTsFAQDgo+jJAOoDQjdwhry8PH333Xdn3SYxMbFS17kEAADVR08GUB8QugEAAAAAsAgnUgMAAAAAwCJ8019SSUmJ9u3bp5CQEE7EAQCoNcYY5eXlKTY2Vg0a8D746ejNAABPsKI3E7p16hqDvny2RQCAZ2VmZiouLs7TZXgVejMAwJPc2ZsJ3ZJCQkIknZrY0NBQD1cDAPAVDodD8fHxzj6E39CbAQCeYEVvJnRLzsPWQkNDaewAgFrH4dNl0ZsBAJ7kzt7MF8gAAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwiJ+nCwAAoDbk5OTI4XC4ZazQ0FBFRES4ZSzUDn7+AABPIXQDAOq9nJwc3XrbGB3MO+aW8cJDGumdtDcJXnVETk6O7hkzUoVHc90ynr1xM818cz4/fwBApRC6AQD1nsPh0MG8Y4roPVzB4VE1Giv/4AHlbHhfDoeD0FVHOBwOFR7N1YND7YqPCKrRWJk5BXrh41x+/gCASiN0AwB8RnB4lEIj42o8To4bakHti48IUusWwW4YqdANYwAAfAUnUgMAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAiXh26Z86cqS5duig0NFShoaHq3bu3Pv30U+f60aNHy2azudx69erlwYoBAKjf6M0AAFSNn6cLOJu4uDg9++yzatOmjSTprbfe0rXXXquvvvpKHTt2lCQNGjRIaWlpzscEBAR4pFYAAHwBvRkAgKrx6tA9dOhQl/vPPPOMZs6cqY0bNzobu91uV3R0tCfKAwDA59CbAQCoGq8+vPx0xcXFWrBggfLz89W7d2/n8jVr1igyMlLt2rXTnXfeqezs7HOOVVhYKIfD4XIDAABVQ28GAODcvD50b9++XY0bN5bdbtfdd9+tDz/8UB06dJAkDR48WPPmzdOqVav0wgsvaNOmTRowYIAKCwvPOmZqaqrCwsKct/j4+Np4KgAA1Av0ZgAAKs+rDy+XpPbt22vr1q06fPiw3n//fSUnJ2vt2rXq0KGDRowY4dyuU6dO6t69uxISErR48WINGzaswjEnTpyoCRMmOO87HA6aOwAAlURvBgCg8rw+dAcEBDhP1tK9e3dt2rRJL730kv7+97+X2TYmJkYJCQnatWvXWce02+2y2+2W1AsAQH1HbwYAoPK8/vDyMxljKjxELTc3V5mZmYqJianlqgAA8F30ZgAAKubVn3Q//vjjGjx4sOLj45WXl6cFCxZozZo1Wrp0qY4ePaqUlBQNHz5cMTEx2r17tx5//HE1b95c119/vadLBwCgXqI3AwBQNV4dug8cOKBRo0Zp//79CgsLU5cuXbR06VINHDhQBQUF2r59u+bOnavDhw8rJiZG/fv318KFCxUSEuLp0gEAqJfozQAAVI1Xh+5Zs2ZVuC4oKEjLli2rxWoAAAC9GQCAqqlz3+kGAAAAAKCuIHQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBGvDt0zZ85Uly5dFBoaqtDQUPXu3Vuffvqpc70xRikpKYqNjVVQUJD69eunHTt2eLBiAADqN3ozAABV49WhOy4uTs8++6w2b96szZs3a8CAAbr22mudzXv69OmaMWOGXnnlFW3atEnR0dEaOHCg8vLyPFw5AAD1E70ZAICq8erQPXToUA0ZMkTt2rVTu3bt9Mwzz6hx48bauHGjjDF68cUXNWnSJA0bNkydOnXSW2+9pWPHjmn+/PmeLh0AgHqJ3gwAQNV4deg+XXFxsRYsWKD8/Hz17t1bGRkZysrKUlJSknMbu92uvn37av369R6sFAAA30BvBgDg3Pw8XcC5bN++Xb1799bx48fVuHFjffjhh+rQoYOzeUdFRblsHxUVpT179px1zMLCQhUWFjrvOxwO9xcOAEA9RW8GAKDyvP6T7vbt22vr1q3auHGj7rnnHiUnJ2vnzp3O9TabzWV7Y0yZZWdKTU1VWFiY8xYfH29J7QAA1Ef0ZgAAKs/rQ3dAQIDatGmj7t27KzU1VV27dtVLL72k6OhoSVJWVpbL9tnZ2WXeYT/TxIkTdeTIEectMzPTsvoBAKhv6M0AAFSe14fuMxljVFhYqMTEREVHRys9Pd257sSJE1q7dq369Olz1jHsdrvzUielNwAAUD30ZgAAKubV3+l+/PHHNXjwYMXHxysvL08LFizQmjVrtHTpUtlsNo0fP17Tpk1T27Zt1bZtW02bNk2NGjXSyJEjPV06AAD1Er0ZAICq8erQfeDAAY0aNUr79+9XWFiYunTpoqVLl2rgwIGSpEceeUQFBQUaO3asDh06pJ49e2r58uUKCQnxcOUAANRP9GYAAKrGq0P3rFmzzrreZrMpJSVFKSkptVMQAAA+jt4MAEDV1LnvdAMAAAAAUFcQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLeHXoTk1NVY8ePRQSEqLIyEhdd911+u6771y2GT16tGw2m8utV69eHqoYAID6jd4MAEDVeHXoXrt2re69915t3LhR6enpKioqUlJSkvLz8122GzRokPbv3++8LVmyxEMVAwBQv9GbAQCoGj9PF3A2S5cudbmflpamyMhIbdmyRZdddplzud1uV3R0dG2XBwCAz6E3AwBQNV79SfeZjhw5IkkKDw93Wb5mzRpFRkaqXbt2uvPOO5WdnX3WcQoLC+VwOFxuAACg6ujNAACcXZ0J3cYYTZgwQZdccok6derkXD548GDNmzdPq1at0gsvvKBNmzZpwIABKiwsrHCs1NRUhYWFOW/x8fG18RQAAKhX6M0AAJybVx9efrr77rtP27Zt03/+8x+X5SNGjHD+u1OnTurevbsSEhK0ePFiDRs2rNyxJk6cqAkTJjjvOxwOmjsAAFVEbwYA4NzqROgeN26cFi1apM8++0xxcXFn3TYmJkYJCQnatWtXhdvY7XbZ7XZ3lwkAgM+gNwMAUDleHbqNMRo3bpw+/PBDrVmzRomJied8TG5urjIzMxUTE1MLFQIA4FvozQAAVI1Xf6f73nvv1TvvvKP58+crJCREWVlZysrKUkFBgSTp6NGjeuihh7Rhwwbt3r1ba9as0dChQ9W8eXNdf/31Hq4eAID6h94MAEDVePUn3TNnzpQk9evXz2V5WlqaRo8erYYNG2r79u2aO3euDh8+rJiYGPXv318LFy5USEiIByoGAKB+ozcDAFA1Xh26jTFnXR8UFKRly5bVUjUAAIDeDABA1Xj14eUAAAAAANRlhG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKEbgAAAAAALELoBgAAAADAIoRuAAAAAAAsQugGAAAAAMAihG4AAAAAACxC6AYAAAAAwCKWhe5WrVopNze3zPLDhw+rVatWVu0WAACUg74MAIBnWBa6d+/ereLi4jLLCwsL9csvv1i1WwAAUA76MgAAnuHn7gEXLVrk/PeyZcsUFhbmvF9cXKyVK1eqZcuW7t4tAAAoB30ZAADPcnvovu666yRJNptNycnJLuv8/f3VsmVLvfDCC+7eLQAAKAd9GQAAz3J76C4pKZEkJSYmatOmTWrevLm7dwEAACqJvgwAgGe5PXSXysjIsGpoAABQRfRlAAA8w7LQLUkrV67UypUrlZ2d7XynvdTs2bOt3DUAADgDfRkAgNpnWeieOnWqnnrqKXXv3l0xMTGy2WxW7QoAAJwDfRkAAM+wLHS//vrrmjNnjkaNGmXVLgAAQCXRlwEA8AzLrtN94sQJ9enTx6rhAQBAFdCXAQDwDMtC95gxYzR//nyrhgcAAFVAXwYAwDMsO7z8+PHjeuONN7RixQp16dJF/v7+LutnzJhh1a4BAMAZ6MsAAHiGZaF727ZtuvDCCyVJX3/9tcs6Tt4CAEDtoi8DAOAZloXu1atXWzU0AACoIvoyAACeYdl3ut0hNTVVPXr0UEhIiCIjI3Xdddfpu+++c9nGGKOUlBTFxsYqKChI/fr1044dOzxUMQAA9Ru9GQCAqrHsk+7+/fuf9XC1VatWnXOMtWvX6t5771WPHj1UVFSkSZMmKSkpSTt37lRwcLAkafr06ZoxY4bmzJmjdu3a6emnn9bAgQP13XffKSQkxG3PBwCAuswdfVmiNwMAUFWWhe7S742VOnnypLZu3aqvv/5aycnJlRpj6dKlLvfT0tIUGRmpLVu26LLLLpMxRi+++KImTZqkYcOGSZLeeustRUVFaf78+brrrrvc8lwAAKjr3NGXJXozAABVZVno/utf/1ru8pSUFB09erRaYx45ckSSFB4eLknKyMhQVlaWkpKSnNvY7Xb17dtX69evr7CxFxYWqrCw0Hnf4XBUqx4AAOoKK/qyRG8GAOBcav073bfeeqtmz55d5ccZYzRhwgRdcskl6tSpkyQpKytLkhQVFeWybVRUlHNdeVJTUxUWFua8xcfHV7keAADqg+r2ZYneDABAZdR66N6wYYMCAwOr/Lj77rtP27Zt07vvvltm3ZnfUTPGnPV7axMnTtSRI0ect8zMzCrXAwBAfVDdvizRmwEAqAzLDi8v/R5XKWOM9u/fr82bN2vy5MlVGmvcuHFatGiRPvvsM8XFxTmXR0dHSzr1rnpMTIxzeXZ2dpl32E9nt9tlt9urVAMAAHWZO/uyRG8GAKCyLPuk+/RDxMLCwhQeHq5+/fppyZIlmjJlSqXGMMbovvvu0wcffKBVq1YpMTHRZX1iYqKio6OVnp7uXHbixAmtXbtWffr0cevzAQCgLnNHX5bozQAAVJVln3SnpaXVeIx7771X8+fP17///W+FhIQ4vwsWFhamoKAg2Ww2jR8/XtOmTVPbtm3Vtm1bTZs2TY0aNdLIkSNrvH8AAOoLd/Rlid4MAEBVWRa6S23ZskXffPONbDabOnTooG7dulX6sTNnzpQk9evXz2V5WlqaRo8eLUl65JFHVFBQoLFjx+rQoUPq2bOnli9fznVAAQAoR036skRvBgCgqiwL3dnZ2frDH/6gNWvWqEmTJjLG6MiRI+rfv78WLFigiIiIc45hjDnnNjabTSkpKUpJSXFD1QAA1E/u6MsSvRkAgKqy7Dvd48aNk8Ph0I4dO3Tw4EEdOnRIX3/9tRwOh+6//36rdgsAAMpBXwYAwDMs+6R76dKlWrFihS644ALnsg4dOujVV19VUlKSVbsFAADloC8DAOAZln3SXVJSIn9//zLL/f39VVJSYtVuAQBAOejLAAB4hmWhe8CAAfrTn/6kffv2OZf98ssveuCBB3T55ZdbtVsAAFAO+jIAAJ5hWeh+5ZVXlJeXp5YtW6p169Zq06aNEhMTlZeXp5dfftmq3QIAgHLQlwEA8AzLvtMdHx+vL7/8Uunp6fr2229ljFGHDh10xRVXWLVLAABQAfoyAACe4fZPuletWqUOHTrI4XBIkgYOHKhx48bp/vvvV48ePdSxY0etW7fO3bsFAADloC8DAOBZbg/dL774ou68806FhoaWWRcWFqa77rpLM2bMcPduAQBAOejLAAB4lttD9//+9z8NGjSowvVJSUnasmWLu3cLAADKQV8GAMCz3B66Dxw4UO4lSUr5+fkpJyfH3bsFAADloC8DAOBZbg/dLVq00Pbt2ytcv23bNsXExLh7twAAoBz0ZQAAPMvtoXvIkCF68skndfz48TLrCgoKNGXKFF199dXu3i0AACgHfRkAAM9y+yXDnnjiCX3wwQdq166d7rvvPrVv3142m03ffPONXn31VRUXF2vSpEnu3i0AACgHfRkAAM9ye+iOiorS+vXrdc8992jixIkyxkiSbDabrrzySr322muKiopy924BAEA56MsAAHiW20O3JCUkJGjJkiU6dOiQfvjhBxlj1LZtWzVt2tSK3QEAgLOgLwMA4DmWhO5STZs2VY8ePazcBQAAqCT6MgAAtc/tJ1IDAAAAAACnELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwCKEbAAAAAACLELoBAAAAALAIoRsAAAAAAIsQugEAAAAAsAihGwAAAAAAixC6AQAAAACwiNeH7s8++0xDhw5VbGysbDabPvroI5f1o0ePls1mc7n16tXLM8UCAOAD6M0AAFSe14fu/Px8de3aVa+88kqF2wwaNEj79+933pYsWVKLFQIA4FvozQAAVJ6fpws4l8GDB2vw4MFn3cZutys6OrqWKgIAwLfRmwEAqDyv/6S7MtasWaPIyEi1a9dOd955p7Kzsz1dEgAAPo3eDADAKV7/Sfe5DB48WDfeeKMSEhKUkZGhyZMna8CAAdqyZYvsdnu5jyksLFRhYaHzvsPhqK1yAQCo9+jNAAD8ps6H7hEjRjj/3alTJ3Xv3l0JCQlavHixhg0bVu5jUlNTNXXq1NoqEQAAn0JvBgDgN/Xi8PLTxcTEKCEhQbt27apwm4kTJ+rIkSPOW2ZmZi1WCACAb6E3AwB8WZ3/pPtMubm5yszMVExMTIXb2O32Cg9vAwAA7kVvBgD4Mq8P3UePHtUPP/zgvJ+RkaGtW7cqPDxc4eHhSklJ0fDhwxUTE6Pdu3fr8ccfV/PmzXX99dd7sGoAAOovejMAAJXn9aF78+bN6t+/v/P+hAkTJEnJycmaOXOmtm/frrlz5+rw4cOKiYlR//79tXDhQoWEhHiqZAAA6jV6MwAAlef1obtfv34yxlS4ftmyZbVYDQAAoDcDAFB59e5EagAAAAAAeAtCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARrw/dn332mYYOHarY2FjZbDZ99NFHLuuNMUpJSVFsbKyCgoLUr18/7dixwzPFAgDgA+jNAABUnteH7vz8fHXt2lWvvPJKueunT5+uGTNm6JVXXtGmTZsUHR2tgQMHKi8vr5YrBQDAN9CbAQCoPD9PF3AugwcP1uDBg8tdZ4zRiy++qEmTJmnYsGGSpLfeektRUVGaP3++7rrrrtosFQAAn0BvBgCg8rz+k+6zycjIUFZWlpKSkpzL7Ha7+vbtq/Xr11f4uMLCQjkcDpcbAACoOXozAACu6nTozsrKkiRFRUW5LI+KinKuK09qaqrCwsKct/j4eEvrBADAV9CbAQBwVadDdymbzeZy3xhTZtnpJk6cqCNHjjhvmZmZVpcIAIBPoTcDAHCK13+n+2yio6MlnXpXPSYmxrk8Ozu7zDvsp7Pb7bLb7ZbXBwCAr6E3AwDgqk5/0p2YmKjo6Gilp6c7l504cUJr165Vnz59PFgZAAC+id4MAIArr/+k++jRo/rhhx+c9zMyMrR161aFh4frvPPO0/jx4zVt2jS1bdtWbdu21bRp09SoUSONHDnSg1UDAFB/0ZsBAKg8rw/dmzdvVv/+/Z33J0yYIElKTk7WnDlz9Mgjj6igoEBjx47VoUOH1LNnTy1fvlwhISGeKhkAgHqN3gwAQOV5feju16+fjDEVrrfZbEpJSVFKSkrtFQUAgA+jNwMAUHl1+jvdAAAAAAB4M0I3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYJE6H7pTUlJks9lcbtHR0Z4uCwAAn0VvBgDgN36eLsAdOnbsqBUrVjjvN2zY0IPVAAAAejMAAKfUi9Dt5+fHO+gAAHgRejMAAKfU+cPLJWnXrl2KjY1VYmKi/vCHP+inn3466/aFhYVyOBwuNwAA4D70ZgAATqnzobtnz56aO3euli1bpn/84x/KyspSnz59lJubW+FjUlNTFRYW5rzFx8fXYsUAANRv9GYAAH5T50P34MGDNXz4cHXu3FlXXHGFFi9eLEl66623KnzMxIkTdeTIEectMzOztsoFAKDeozcDAPCbevGd7tMFBwerc+fO2rVrV4Xb2O122e32WqwKAADfRW8GAPiyOv9J95kKCwv1zTffKCYmxtOlAAAA0ZsBAL6tzofuhx56SGvXrlVGRob++9//6oYbbpDD4VBycrKnSwMAwCfRmwEA+E2dP7z8559/1s0336xff/1VERER6tWrlzZu3KiEhARPlwYAgE+iNwMA8Js6H7oXLFjg6RIAAMBp6M0AAPymzh9eDgAAAACAtyJ0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBFCNwAAAAAAFiF0AwAAAABgEUI3AAAAAAAWIXQDAAAAAGARQjcAAAAAABYhdAMAAAAAYBE/TxdQH+Xk5MjhcLhlrNDQUEVERLhlLACoa9z1+3TPnj0qOlnkhooAqfDESe3Zs6fG49DjAfg6X8lNhG43y8nJ0a23jdHBvGNuGS88pJHeSXvTa19AAGAVd/4+PV5wTD//sl/nnTzphsrgy3IdJ/RTxh49++Q42e32Go1lb9xMM9+cT48H4JNycnJ0z5iRKjya65bxvPl3KqHbzRwOhw7mHVNE7+EKDo+q0Vj5Bw8oZ8P7cjgcXvniAQArufP3afaPX2tP5mwVFxG6UTNHC4oV0KBID1wdoHbxTao9TmZOgV74OJceD8BnORwOFR7N1YND7YqPCKrRWN7+O5XQbZHg8CiFRsbVeJwcN9QCAHWZO36fHs3NclM1wClxEYFq3SK4hqMUuqUWAKjL4iOC3PD7VPLm36n15kRqr732mhITExUYGKiLLrpI69at83RJAAD4NHozAAD1JHQvXLhQ48eP16RJk/TVV1/p0ksv1eDBg7V3715PlwYAgE+iNwMAcEq9CN0zZszQHXfcoTFjxuiCCy7Qiy++qPj4eM2cOdPTpQEA4JPozQAAnFLnQ/eJEye0ZcsWJSUluSxPSkrS+vXrPVQVAAC+i94MAMBv6vyJ1H799VcVFxcrKsr1zLZRUVHKyir/xDmFhYUqLPzti/ZHjhyRJLdcIy4vL0/FRUU6vH+3Th6v2WVu8g9lq7CgQDt37lReXl6NawOAuiQzM1Mnjh93y+9TR/bPMiUlcmRlys9Ws7ryD2WruKhIeXl5Ne4bpY83xtSsKC/jjb35ZFGxvs3MU96xml2v/cf9+SouMfo+M1/FJf7VHueX3AIdKyikxwPwWZmZmTpeWOiW382/5BboZFGx1/bmOh+6S9lsrn9FGWPKLCuVmpqqqVOnllkeHx/vvoLWr3HbUNdcc43bxgKAOueL/7htqHWvT3TbWN26dXPbWHl5eQoLC3PbeN7C23rzss/cNpRumLrdLeOsoscD8HErPnffWMu8tDfX+dDdvHlzNWzYsMw759nZ2WXeYS81ceJETZgwwXm/pKREBw8eVLNmzZx/DDgcDsXHxyszM1OhoaHWPQEvxhwwB6WYB+agFPPg3jkwxigvL0+xsbFuqs47WNWbq4vXLXMgMQelmAfmQGIOSpU3D1b05jofugMCAnTRRRcpPT1d119/vXN5enq6rr322nIfY7fbZbfbXZY1adKk3G1DQ0N9+oUoMQcSc1CKeWAOSjEP7puD+vgJt9W9ubp43TIHEnNQinlgDiTmoNSZ8+Du3lznQ7ckTZgwQaNGjVL37t3Vu3dvvfHGG9q7d6/uvvtuT5cGAIBPojcDAHBKvQjdI0aMUG5urp566int379fnTp10pIlS5SQkODp0gAA8En0ZgAATqkXoVuSxo4dq7Fjx7ptPLvdrilTppQ51M2XMAfMQSnmgTkoxTwwB1Xh7t5cXfzMmAOJOSjFPDAHEnNQqrbmwWbq23VKAAAAAADwEg08XQAAAAAAAPUVoRsAAAAAAIsQugEAAAAAsIjPhO7XXntNiYmJCgwM1EUXXaR169b9v/buPL6pKv//+Dt0SVtoy94FSksV2REERMARECiKIAwqKIhFxZ8OKosiwihSdKYMqIiyKUrZFFBEEJVB6gLiAIIsOgKKsqutlLVlK13O7w++zRjaQpdc0qSv5+ORB+Tk5NxzPznpJ5/k5qbQvoMGDZLNZst3ady4sVO/pUuXqlGjRrLb7WrUqJGWLVtm9W6UiqtjMHfu3AL7nDt37krsTokVJw6S9M477+jaa69VUFCQIiIidP/99+vo0aNOfbx5LUiXj0F5WQvTp09Xw4YNFRgYqPr162v+/Pn5+nj7WrhcDDxtLXz11Vfq2bOnIiMjZbPZtHz58sveZ+3atWrZsqUCAgIUGxur119/PV8fT1sHnqa469YbHzNXx8DTnrt5ihOHlJQU9e/fX/Xr11eFChU0fPjwAvt581ooSgw8cS0UJwYffPCBunbtqho1aigkJERt27bVp59+mq+fp60DyfVx8Pa18PXXX6t9+/aqVq2aAgMD1aBBA73yyiv5+rlkLZhyYPHixcbPz8+8+eabZufOnWbYsGGmYsWK5sCBAwX2P3HihElJSXFcDh06ZKpWrWrGjRvn6LN+/Xrj4+NjEhMTza5du0xiYqLx9fU1GzduvEJ7VTxWxGDOnDkmJCTEqV9KSsoV2qOSKW4c1q1bZypUqGBeffVVs3fvXrNu3TrTuHFj07t3b0cfb18LRYlBeVgLM2bMMMHBwWbx4sVmz549ZtGiRaZSpUpmxYoVjj7evhaKEgNPWwsrV640zzzzjFm6dKmRZJYtW3bJ/nv37jVBQUFm2LBhZufOnebNN980fn5+5v3333f08bR14GmKu2698TGzIgae9tw1pvhx2Ldvnxk6dKiZN2+ead68uRk2bFi+Pt6+FooSA09bC8WNwbBhw8zEiRPNpk2bzO7du82YMWOMn5+f2bp1q6OPp60DY6yJg7evha1bt5qFCxeaH374wezbt88sWLDABAUFmTfeeMPRx1VroVwU3ddff7155JFHnNoaNGhgRo8eXaT7L1u2zNhsNrN//35HW9++fc0tt9zi1K9bt27m7rvvLv2ELWBFDObMmWNCQ0NdOU3LFTcOL774oomNjXVqe+2110zt2rUd1719LRQlBuVhLbRt29aMHDnSqW3YsGGmffv2juvevhaKEgNPXAt5ilJ0jxo1yjRo0MCp7eGHHzY33HCD47qnrQNPU9x1642PmRUx8MTnbmle23To0KHAgtPb18KfFRYDT1sLpX2Na4wxjRo1MuPHj3dc97R1YIw1cSiPa+Gvf/2ruffeex3XXbUWvP7w8vPnz2vLli2Ki4tzao+Li9P69euLNMbs2bPVpUsXRUdHO9o2bNiQb8xu3boVecwryaoYSNKpU6cUHR2t2rVrq0ePHtq2bZvL5u1qJYlDu3bt9Ouvv2rlypUyxuiPP/7Q+++/r9tuu83Rx9vXQlFiIHn/WsjMzFRAQIBTW2BgoDZt2qSsrCxJ3r8WihIDybPWQnEV9hh/++23HrkOPE1J1q23PWZWxUDyrOeuK17bFMTb10JRecpacEUMcnNzlZGRoapVqzraPGkdSNbFQSpfa2Hbtm1av369OnTo4Ghz1Vrw+qL7yJEjysnJUVhYmFN7WFiYUlNTL3v/lJQU/fvf/9bgwYOd2lNTU0s85pVmVQwaNGiguXPnasWKFVq0aJECAgLUvn17/fzzzy6dv6uUJA7t2rXTO++8o379+snf31/h4eGqXLmypk6d6ujj7WuhKDEoD2uhW7dueuutt7RlyxYZY/Ttt98qKSlJWVlZOnLkiCTvXwtFiYGnrYXiKuwxzs7O9sh14GlKsm697TGzKgae9twt7Wubwnj7WigKT1oLrojByy+/rNOnT6tv376ONk9aB5J1cSgva6F27dqy2+1q1aqVHn30Uaeax1VrwbdYvT2YzWZzum6MyddWkLlz56py5crq3bu3y8Z0F1fH4IYbbtANN9zguN6+fXtdd911mjp1ql577TWXzNkKxYnDzp07NXToUD333HPq1q2bUlJS9NRTT+mRRx7R7NmzSzRmWeDqGJSHtTB27FilpqbqhhtukDFGYWFhGjRokCZNmiQfH58SjVkWuDoGnroWiqOgmF3c7mnrwNMUN77e+Ji5Ogae+ty14nHz9rVwOZ64Fkoag0WLFikhIUEffvihatas6ZIx3cnVcSgva2HdunU6deqUNm7cqNGjR+vqq6/WPffcU6oxL+b1n3RXr15dPj4++d6NOHz4cL53LS5mjFFSUpIGDhwof39/p9vCw8NLNKY7WBWDi1WoUEGtW7cuk+9+SSWLw4QJE9S+fXs99dRTatasmbp166YZM2YoKSlJKSkpkrx/LRQlBhfzxrUQGBiopKQknTlzRvv379fBgwcVExOj4OBgVa9eXZL3r4WixOBiZX0tFFdhj7Gvr6+qVat2yT5lcR14mpKsW297zKyKwcXK+nO3NK9tLsXb10JJlOW1UJoYvPvuu3rwwQf13nvvqUuXLk63edI6kKyLw8W8dS3UrVtXTZs21UMPPaQRI0YoISHBcZur1oLXF93+/v5q2bKlkpOTndqTk5PVrl27S9537dq1+uWXX/Tggw/mu61t27b5xly9evVlx3QHq2JwMWOMtm/froiIiFLN1yolicOZM2dUoYLz0yTvE728Twm8fS0UJQYX88a1kMfPz0+1a9eWj4+PFi9erB49ejji4+1rIc+lYnCxsr4Wiquwx7hVq1by8/O7ZJ+yuA48TUnWrbc9ZlbF4GJl/blbmr9hl+Lta6EkyvJaKGkMFi1apEGDBmnhwoX5zlEjedY6kKyLw8W8cS1czBijzMxMx3WXrYVinXbNQ+WdPn727Nlm586dZvjw4aZixYqOM3GPHj3aDBw4MN/97r33XtOmTZsCx/zPf/5jfHx8zL/+9S+za9cu869//atM/5SAFTFISEgwq1atMnv27DHbtm0z999/v/H19TXffPONpftSGsWNw5w5c4yvr6+ZMWOG2bNnj/n6669Nq1atzPXXX+/o4+1roSgxKA9r4aeffjILFiwwu3fvNt98843p16+fqVq1qtm3b5+jj7evhaLEwNPWQkZGhtm2bZvZtm2bkWQmT55stm3b5vh5kYtjkPfTSyNGjDA7d+40s2fPzvfTS562DjxNcdetNz5mVsTA0567xpTstU3e871ly5amf//+Ztu2bWbHjh2O2719LRhz+Rh42loobgwWLlxofH19zfTp051+BuvEiROOPp62DoyxJg7evhamTZtmVqxYYXbv3m12795tkpKSTEhIiHnmmWccfVy1FspF0W2MMdOnTzfR0dHG39/fXHfddWbt2rWO2+Lj402HDh2c+p84ccIEBgaaWbNmFTrmkiVLTP369Y2fn59p0KCBWbp0qVXTdwlXx2D48OGmTp06xt/f39SoUcPExcWZ9evXW7kLLlHcOLz22mumUaNGJjAw0ERERJgBAwaYX3/91amPt6+Fy8WgPKyFnTt3mubNm5vAwEATEhJievXqZX788cd8Y3rzWihKDDxtLXz55ZdGUr5LfHy8Mabg58OaNWtMixYtjL+/v4mJiTEzZ87MN66nrQNPU9y/Yd74mLk6Bp723M1T3DgU9HyPjo526uPta+FyMfDEtVCcGHTo0OGSf/fzeNo6MMb1cfD2tfDaa6+Zxo0bm6CgIBMSEmJatGhhZsyYYXJycpzGdMVasBlTyPGhAAAAAACgVLz+O90AAAAAALgLRTcAAAAAABah6AYAAAAAwCIU3QAAAAAAWISiGwAAAAAAi1B0AwAAAABgEYpuAAAAAAAsQtENAAAAAIBFKLoBSJISEhLUvHnzUo9js9m0fPnyQm/fv3+/bDabtm/fLklas2aNbDabTpw4IUmaO3euKleuXOp5AADg6cjNgHeg6AY80KBBg2Sz2WSz2eTn56fY2FiNHDlSp0+fdvfULisqKkopKSlq0qRJgbf369dPu3fvdlx31QsOAACsRG4GUBhfd08AQMnccsstmjNnjrKysrRu3ToNHjxYp0+f1syZM536ZWVlyc/Pz02zzM/Hx0fh4eGF3h4YGKjAwMArOCMAAFyD3AygIHzSDXgou92u8PBwRUVFqX///howYICWL1/uePc5KSlJsbGxstvtMsbo4MGD6tWrlypVqqSQkBD17dtXf/zxR75x33jjDUVFRSkoKEh33XWX49AySdq8ebO6du2q6tWrKzQ0VB06dNDWrVvzjZGSkqJbb71VgYGBqlu3rpYsWeK47eJD2C7250PY5s6dq/Hjx+u7775zfHowd+5cPfDAA+rRo4fT/bKzsxUeHq6kpKTiBxMAABcgN5ObgYJQdANeIjAwUFlZWZKkX375Re+9956WLl3qSKC9e/fWsWPHtHbtWiUnJ2vPnj3q16+f0xh59/voo4+0atUqbd++XY8++qjj9oyMDMXHx2vdunXauHGj6tWrp+7duysjI8NpnLFjx+qOO+7Qd999p3vvvVf33HOPdu3aVex96tevn5588kk1btxYKSkpSklJUb9+/TR48GCtWrVKKSkpjr4rV67UqVOn1Ldv32JvBwAAK5Cbyc2AxOHlgFfYtGmTFi5cqM6dO0uSzp8/rwULFqhGjRqSpOTkZH3//ffat2+foqKiJEkLFixQ48aNtXnzZrVu3VqSdO7cOc2bN0+1a9eWJE2dOlW33XabXn75ZYWHh+vmm2922u4bb7yhKlWqaO3atU7vbt91110aPHiwJOmFF15QcnKypk6dqhkzZhRrvwIDA1WpUiX5+vo6HfbWrl071a9fXwsWLNCoUaMkSXPmzNFdd92lSpUqFWsbAABYgdxMbgby8Ek34KE+/vhjVapUSQEBAWrbtq1uuukmTZ06VZIUHR3tSOqStGvXLkVFRTmSuiQ1atRIlStXdnqXu06dOo6kLklt27ZVbm6ufvrpJ0nS4cOH9cgjj+iaa65RaGioQkNDderUKR08eNBpbm3bts13vSTvpl/K4MGDNWfOHMe8PvnkEz3wwAMu3QYAAMVBbiY3AwXhk27AQ3Xq1EkzZ86Un5+fIiMjnU7IUrFiRae+xhjZbLZ8YxTWnifvtrx/Bw0apLS0NE2ZMkXR0dGy2+1q27atzp8/f9n5Xmo7JXHfffdp9OjR2rBhgzZs2KCYmBj95S9/cek2AAAoDnIzuRkoCJ90Ax6qYsWKuvrqqxUdHX3ZM6A2atRIBw8e1KFDhxxtO3fu1MmTJ9WwYUNH28GDB/X77787rm/YsEEVKlTQNddcI0lat26dhg4dqu7du6tx48ay2+06cuRIvu1t3Lgx3/UGDRqUaD/9/f2Vk5OTr71atWrq3bu35syZozlz5uj+++8v0fgAALgKuZncDBSET7qBcqBLly5q1qyZBgwYoClTpig7O1tDhgxRhw4d1KpVK0e/gIAAxcfH66WXXlJ6erqGDh2qvn37Or6zdfXVV2vBggVq1aqV0tPT9dRTTxX4EyJLlixRq1atdOONN+qdd97Rpk2bNHv27BLNPSYmRvv27dP27dtVu3ZtBQcHy263S7pwGFuPHj2Uk5Oj+Pj4Eo0PAIA7kJuB8oNPuoFywGazafny5apSpYpuuukmdenSRbGxsXr33Xed+l199dXq06ePunfvrri4ODVp0sTpBCtJSUk6fvy4WrRooYEDB2ro0KGqWbNmvu2NHz9eixcvVrNmzTRv3jy98847atSoUYnmfscdd+iWW25Rp06dVKNGDS1atMhxW5cuXRQREaFu3bopMjKyROMDAOAO5Gag/LAZY4y7JwEAJXHmzBlFRkYqKSlJffr0cfd0AAAo98jNQH4cXg7A4+Tm5io1NVUvv/yyQkNDdfvtt7t7SgAAlGvkZqBwFN0APM7BgwdVt25d1a5dW3PnzpWvL3/KAABwJ3IzUDgOLwcAAAAAwCKcSA0AAAAAAItQdAMAAAAAYBGKbgAAAAAALELRDQAAAACARSi6AQAAAACwCEU3AAAAAAAWoegGAAAAAMAiFN0AAAAAAFiEohsAAAAAAItQdAMAAAAAYBGKbgAAAAAALELRDQAAAACARSi6AQAAAACwCEU3AAAAAAAWoehGmTJo0CDFxMRYvp2YmBgNGjTI8u382ZXat9L4+OOP1atXL0VGRsrf31/BwcFq0aKFxo0bp4MHD7p7elfMunXrZLfbdeDAAbfO48yZM0pISNCaNWssGb9jx47q2LGj4/rx48dVuXJlLV++3JLtAfAs5GT3IidfUFBOnjFjhubOneu+SUn6/ffflZCQoO3bt7t87Llz58pms2n//v2OtptuuknDhw93+bZwZVB0o0wZO3asli1b5u5plDu5ubmKj49Xz549lZWVpQkTJig5OVlLlixRnz59tGDBArVv397d07wijDEaPny4HnroIUVHR7t1LmfOnNH48eMtK7ovVqVKFY0YMUJPPfWUzp8/f0W2CaDsIie7Bzn5fwrLyWWl6B4/frwlRXdBXnjhBc2YMUM//fTTFdkeXMvX3RMA/uyqq65y9xTKpYkTJ2r+/PmaMGGCRo8e7XTbLbfcojFjxuiNN9647Dhnz55VYGCgVdO8IlatWqWtW7dq4cKF7p5KsZ05c0ZBQUGlGuORRx7RP/7xD73//vvq37+/i2YGwBORk92DnPw/rsjJWVlZstls8vX17LKnQ4cOql+/vl5++WXNmjXL3dNBMfFJN66YtLQ0/b//9/8UFRUlu92uGjVqqH379vrss88cfQo63Mtms+mxxx7TggUL1LBhQwUFBenaa6/Vxx9/nG8bH374oZo1aya73a7Y2Fi9+uqrSkhIkM1mu+z80tPTNXLkSNWtW1f+/v6qVauWhg8frtOnTxd7X+fOnav69evLbrerYcOGmj9/foH9jh07piFDhqhWrVry9/dXbGysnnnmGWVmZjr1W7Jkidq0aaPQ0FAFBQUpNjZWDzzwgEvmf/78eU2aNElNmjTJl9zz+Pr66tFHH3Vqi4mJUY8ePfTBBx+oRYsWCggI0Pjx4yVJP/zwg3r16qUqVaooICBAzZs317x58/LF6OJDpyRpzZo1stlsTp/uduzYUU2aNNG6det0ww03KDAwULVq1dLYsWOVk5Nzyf3781yXLVumZs2aKSAgQLGxsXrttdfy9Z05c6Zat26t+vXr57tt4cKFatu2rSpVqqRKlSqpefPmmj17tlOfpKQkXXvttQoICFDVqlX117/+Vbt27XLqM2jQIFWqVEm//PKLunfvrkqVKikqKkpPPvmk47Hfv3+/atSoIUkaP368bDabbDab4xDMvHW9detW3XnnnapSpYrjBfK5c+c0ZswYp7Xw6KOP6sSJE5eNVVhYmLp27arXX3/9sn0BeC5ycn7kZM/IyTExMdqxY4fWrl3ryI156zRvvgsWLNCTTz6pWrVqyW6365dffpEkffbZZ+rcubNCQkIUFBSk9u3b6/PPP3fa5i+//KL7779f9erVU1BQkGrVqqWePXvqv//9r1NcWrduLUm6//77HfNISEhw9Pn22291++23q2rVqgoICFCLFi303nvv5dvHjRs3qn379goICFBkZKTGjBmjrKysAmM3cOBALVy4UBkZGZeNM8oYA1wh3bp1MzVq1DCzZs0ya9asMcuXLzfPPfecWbx4saNPfHy8iY6OdrqfJBMTE2Ouv/56895775mVK1eajh07Gl9fX7Nnzx5Hv3//+9+mQoUKpmPHjmbZsmVmyZIlpk2bNiYmJsZcvNSjo6NNfHy84/rp06dN8+bNTfXq1c3kyZPNZ599Zl599VUTGhpqbr75ZpObm1vk/ZwzZ46RZHr16mU++ugj8/bbb5urr77aREVFOe3b2bNnTbNmzUzFihXNSy+9ZFavXm3Gjh1rfH19Tffu3R391q9fb2w2m7n77rvNypUrzRdffGHmzJljBg4c6JL5/+c//zGSzJgxY4q8j8ZciGFERISJjY01SUlJ5ssvvzSbNm0yP/74owkODjZXXXWVmT9/vvnkk0/MPffcYySZiRMn5ovTvn37nMb98ssvjSTz5ZdfOto6dOhgqlWrZiIjI81rr71mPv30UzN06FAjyTz66KNFmmutWrVMnTp1TFJSklm5cqUZMGCAkWRefPFFR7/MzEwTGBhoRo0alW+MsWPHGkmmT58+ZsmSJWb16tVm8uTJZuzYsY4+iYmJRpK55557zCeffGLmz59vYmNjTWhoqNm9e7ejX3x8vPH39zcNGzY0L730kvnss8/Mc889Z2w2mxk/frwxxphz586ZVatWGUnmwQcfNBs2bDAbNmwwv/zyizHGmHHjxhlJJjo62jz99NMmOTnZLF++3OTm5ppu3boZX19fM3bsWLN69Wrz0ksvmYoVK5oWLVqYc+fOOcW1Q4cO+fZ14sSJpkKFCub48eOXjS0Az0ROJid7ak7eunWriY2NNS1atHDkxq1btzrNt1atWubOO+80K1asMB9//LE5evSoWbBggbHZbKZ3797mgw8+MB999JHp0aOH8fHxMZ999plj/LVr15onn3zSvP/++2bt2rVm2bJlpnfv3iYwMND8+OOPxhhjTp486YjZs88+65jHoUOHjDHGfPHFF8bf39/85S9/Me+++65ZtWqVGTRokJFk5syZ49jWjh07TFBQkGnUqJFZtGiR+fDDD023bt1MnTp1Cnw8vvnmGyPJrFix4rJxRtlC0Y0rplKlSmb48OGX7FNYgg8LCzPp6emOttTUVFOhQgUzYcIER1vr1q1NVFSUyczMdLRlZGSYatWqXTbBT5gwwVSoUMFs3rzZqd/7779vJJmVK1cWaR9zcnJMZGSkue6665yS6v79+42fn5/Tvr3++utGknnvvfecxpg4caKRZFavXm2MMeall14yksyJEycK3W5p5r948WIjybz++uv5bsvKynK6/Fl0dLTx8fExP/30k1P73Xffbex2uzl48KBT+6233mqCgoIc+1HcBC/JfPjhh059H3roIVOhQgVz4MCBQvcvb642m81s377dqb1r164mJCTEnD592hjzv2T25xedxhizd+9e4+PjYwYMGFDoNo4fP24CAwOdXpwZY8zBgweN3W43/fv3d7TFx8cX+Nh3797d1K9f33E9LS3NSDLjxo3Lt728ovu5555zas8r1CdNmuTU/u677xpJZtasWY62woru5ORkI8n8+9//LnR/AXg2cjI52VNzsjHGNG7cuMD8lTffm266yan99OnTpmrVqqZnz55O7Tk5Oebaa681119/faHzzc7ONufPnzf16tUzI0aMcLRv3rw5XxGdp0GDBqZFixb5HqcePXqYiIgIk5OTY4wxpl+/fiYwMNCkpqY6ba9BgwYFPh7nz583NpvNPP3004XOF2UTh5fjirn++us1d+5c/eMf/9DGjRsLPXSmIJ06dVJwcLDjelhYmGrWrOk4k+Xp06f17bffqnfv3vL393f0q1Spknr27HnZ8T/++GM1adJEzZs3V3Z2tuPSrVu3fIdVXcpPP/2k33//Xf3793c6fC46Olrt2rVz6vvFF1+oYsWKuvPOO53a8w4fzjvcKe/wpb59++q9997Tb7/9Ztn8/+zEiRPy8/Nzunz77bdOfZo1a6Zrrrkm33517txZUVFR+fbrzJkz2rBhQ7HnIknBwcG6/fbbndr69++v3NxcffXVV5e9f+PGjXXttdfmu396erq2bt0q6cJJUSSpZs2aTv2Sk5OVk5OT73C+P9uwYYPOnj2b7wy8UVFRuvnmm/Mdvmaz2fKtzWbNmhX7jOl33HGH0/UvvvhCkvLN46677lLFihXzzaMgeftf0FoD4B3IyeRkT83JRXFxbly/fr2OHTum+Ph4p8ckNzdXt9xyizZv3uw49D87O1uJiYlq1KiR/P395evrK39/f/3888/5vi5WkF9++UU//vijBgwY4Bgv79K9e3elpKQ4Tob25ZdfqnPnzgoLC3Pc38fHR/369StwbD8/P1WuXJn87IEounHFvPvuu4qPj9dbb72ltm3bqmrVqrrvvvuUmpp62ftWq1YtX5vdbtfZs2clXfipI2OM0x+tPAW1XeyPP/7Q999/ny+hBQcHyxijI0eOFGEPpaNHj0qSwsPD8912cdvRo0cVHh6e77ttNWvWlK+vr2Osm266ScuXL1d2drbuu+8+1a5dW02aNNGiRYtcMv86depIUr5iLzg4WJs3b9bmzZs1bty4Au8bERFRYAwKao+MjHTcXhIFPY55MS3KmJd6TPLun7eeAgICnPqlpaVJkmrXrl3o+HljFLbvF88xKCgo33bsdrvOnTt3yf242MXbO3r0qHx9fR3fB89js9kUHh5epFjlzSsvHgC8DzmZnJx3e0m4MycXxcX7/Mcff0iS7rzzznyPy8SJE2WM0bFjxyRJTzzxhMaOHavevXvro48+0jfffKPNmzfr2muvLVJezNvWyJEj821ryJAhkuRYA3nrrrBYFCQgIID87IE8+zR+8CjVq1fXlClTNGXKFB08eFArVqzQ6NGjdfjwYa1atapUY1epUkU2m83xh+7PivIConr16goMDFRSUlKhtxdF3guRgrZ5cVu1atX0zTffyBjjlOQPHz6s7Oxsp2326tVLvXr1UmZmpjZu3KgJEyaof//+iomJUdu2bUs1/5YtW6pKlSr66KOPlJiY6Gj38fFRq1atJF04CUtBCjoZTrVq1ZSSkpKvPe8d67y55CXRi09QU9iLkUs9tgW9ACys76Xunze3vMSbJ6+A/fXXX/N9WpAnb4zC9r2oa6i4Ln4MqlWrpuzsbKWlpTkV3sYYpaamOj6luZS8/bdqzgDcj5xMTv7zXDwpJxfFxbHIG2vq1Km64YYbCrxP3hsJb7/9tu677z6n+EsXYlG5cuXLbjtvW2PGjFGfPn0K7JN3Yrhq1aoVaX3+2fHjx8nPHohPuuEWderU0WOPPaauXbs6DiMqjYoVK6pVq1Zavny50+8Lnzp1qsAzql6sR48e2rNnj6pVq6ZWrVrlu1x89tbC1K9fXxEREVq0aJGMMY72AwcOaP369U59O3furFOnTmn58uVO7XlnVe3cuXO+8e12uzp06KCJEydKkrZt21bq+fv7++upp57SDz/84Bi3NDp37qwvvvjCkdD/vF9BQUGOZJc3p++//96p34oVKwocNyMjI99tCxcuVIUKFXTTTTdddl47duzQd999l+/+wcHBuu666yRJDRs2lCTt2bPHqV9cXJx8fHw0c+bMQsdv27atAgMD9fbbbzu1//rrr47D+4rLbrdLKt4nznnbuXgeS5cu1enTp4s0j71790qSGjVqVOTtAvBc5GRysiflZMn5yIqiaN++vSpXrqydO3cW+Ji0atXK8VUIm83myL95Pvnkk3yHdBeWo+vXr6969erpu+++K3RbeV/P6NSpkz7//HOnNzFycnL07rvvFrgfv//+u86dO0d+9kB80o0r4uTJk+rUqZP69++vBg0aOA6TWrVqVaHvAhbX888/r9tuu03dunXTsGHDlJOToxdffFGVKlW67Lukw4cP19KlS3XTTTdpxIgRatasmXJzc3Xw4EGtXr1aTz75pNq0aXPZOVSoUEEvvPCCBg8erL/+9a966KGHdOLECSUkJOQ7VOi+++7T9OnTFR8fr/3796tp06b6+uuvlZiYqO7du6tLly6SpOeee06//vqrOnfurNq1a+vEiRN69dVX5efnpw4dOrhk/k8//bR+/PFHjR49Wl999ZX69eunmJgYZWZmau/evXrrrbfk4+NTpN+AHjdunD7++GN16tRJzz33nKpWrap33nlHn3zyiSZNmqTQ0FBJcvwEyMiRI5Wdna0qVapo2bJl+vrrrwsct1q1avrb3/6mgwcP6pprrtHKlSv15ptv6m9/+5vjcLxLiYyM1O23366EhARFRETo7bffVnJysiZOnOjYr9q1ays2NlYbN27U0KFDHfeNiYnR3//+d73wwgs6e/as7rnnHoWGhmrnzp06cuSIxo8fr8qVK2vs2LH6+9//rvvuu0/33HOPjh49qvHjxysgIKDQwwEvJTg4WNHR0frwww/VuXNnVa1aVdWrV7/kC7auXbuqW7duevrpp5Wenq727dvr+++/17hx49SiRQsNHDjwstvduHGjqlWrpqZNmxZ7zgDKPnIyOdmTc7IkNW3aVIsXL9a7776r2NhYBQQEXDJnVapUSVOnTlV8fLyOHTumO++8UzVr1lRaWpq+++47paWlOd5Y79Gjh+bOnasGDRqoWbNm2rJli1588cV8XzG76qqrFBgYqHfeeUcNGzZUpUqVFBkZqcjISL3xxhu69dZb1a1bNw0aNEi1atXSsWPHtGvXLm3dulVLliyRJD377LNasWKFbr75Zj333HMKCgrS9OnTC/1puY0bN0q6UKzDw7jn/G0ob86dO2ceeeQR06xZMxMSEmICAwNN/fr1zbhx4xxnqTSm8DOlFvQTFBef7dQYY5YtW2aaNm1q/P39TZ06dcy//vUvM3ToUFOlSpXL3vfUqVPm2WefNfXr1zf+/v4mNDTUNG3a1IwYMcLprJJF8dZbb5l69eoZf39/c80115ikpKQC9+3o0aPmkUceMREREcbX19dER0ebMWPGOP2s08cff2xuvfVWU6tWLePv729q1qxpunfvbtatW+fy+a9YscL07NnThIWFGV9fXxMcHGyaN29unnzyScfPZOSJjo42t912W4Hj/Pe//zU9e/Y0oaGhxt/f31x77bUFnt1z9+7dJi4uzoSEhJgaNWqYxx9/3HzyyScFnim1cePGZs2aNaZVq1bGbrebiIgI8/e//z3fmUELkjfX999/3zRu3Nj4+/ubmJgYM3ny5Hx9x44da6pUqeL0GOSZP3++ad26tQkICDCVKlUyLVq0yLdfb731lmnWrJnjMejVq5fZsWOHU5/4+HhTsWLFfOPnnZH8zz777DPTokULY7fbjSTHus3rm5aWlm+cs2fPmqefftpER0cbPz8/ExERYf72t7/l+wmwgs5enpuba6Kjo83jjz+eb1wA3oGcTE729Jy8f/9+ExcXZ4KDgx0/n2nM/85evmTJkgK3vXbtWnPbbbeZqlWrGj8/P1OrVi1z2223OfU/fvy4efDBB03NmjVNUFCQufHGG826desKzJmLFi0yDRo0MH5+fvl+beS7774zffv2NTVr1jR+fn4mPDzc3HzzzfnOTP+f//zH3HDDDcZut5vw8HDz1FNPmVmzZhV49vKBAweapk2bXibCKItsxvzpeBvAy2RlZal58+aqVauWVq9e7e7poIQ6duyoI0eOFPo9tsuJiYlRkyZNinRY4++//666detq/vz5hZ491Jt9/vnniouL044dO9SgQQN3TweAFyEnewdysnukp6crMjJSr7zyih566CF3TwfFxOHl8CoPPvigunbtqoiICKWmpur111/Xrl279Oqrr7p7avAQkZGRGj58uP75z3/qrrvuUoUK5evUF//4xz/0wAMPUHADKDVyMkqrvOfkP3vllVdUp04d3X///e6eCkqAohteJSMjQyNHjlRaWpr8/Px03XXXaeXKlY7vYpVGbm6ucnNzL9nH15enlDd49tlnFRQUpN9++63Qs5V7o+PHj6tDhw6OnzQBgNIgJ8MVymtOvlhISIjmzp3LuvZQHF4OFNGgQYM0b968S/bh6QQAgPXIyQA8CUU3UET79+8v9Pcq8+T9hiYAALAOORmAJ6HoBgAAAADAIuX3bAQAAAAAAFiMb+Lrwsk4fv/9dwUHB8tms7l7OgCAcsIYo4yMDEVGRpbrs/IWhNwMAHAHK3IzRbcu/AZgeT4bIgDAvQ4dOqTatWu7explCrkZAOBOrszNFN2SgoODJV0IbEhIiJtnAwAoL9LT0xUVFeXIQ/gfcjMAwB2syM0U3ZLjsLWQkBASOwDgiuPw6fzIzQAAd3JlbuYLZAAAAAAAWISiGwAAAAAAi1B0AwAAAABgEYpuAAAAAAAsQtENAAAAAIBFKLoBAAAAALAIRTcAAAAAABah6AYAAAAAwCIU3QAAAAAAWISiGwAAAAAAi1B0AwAAAABgEV93T8AbpaWlKT093SVjhYSEqEaNGi4ZCwAAAADKivJSN1F0u1haWpruvX+wjmWcccl4VYOD9Pact8rsAgIAAACA4kpLS9PfBvdX5qmjLhnPXqmaZr61sEzWTRTdLpaenq5jGWdUo+0dqlg1rFRjnT72h9I2LFV6enqZXDwAAAAAUBLp6enKPHVUT/a0K6pGYKnGOpR2Vi9/dLTM1k0U3RapWDVMITVrl3qcNBfMBQAAAADKoqgagbqqVkUXjJTpgjGswYnUAAAAAACwCEU3AAAAAAAWoegGAAAAAMAiFN0AAAAAAFiEohsAAAAAAItQdAMAAAAAYBGKbgAAAAAALELRDQAAAACARSi6AQAAAACwCEU3AAAAAAAWoegGAAAAAMAiFN0AAAAAAFiEohsAAAAAAItQdAMAAAAAYBGKbgAAAAAALELRDQAAAACARSi6AQAAAACwCEU3AAAAAAAWcWvR/dVXX6lnz56KjIyUzWbT8uXLnW43xighIUGRkZEKDAxUx44dtWPHDqc+mZmZevzxx1W9enVVrFhRt99+u3799dcruBcAAHgPcjMAAK7l1qL79OnTuvbaazVt2rQCb580aZImT56sadOmafPmzQoPD1fXrl2VkZHh6DN8+HAtW7ZMixcv1tdff61Tp06pR48eysnJuVK7AQCA1yA3AwDgWr7u3Pitt96qW2+9tcDbjDGaMmWKnnnmGfXp00eSNG/ePIWFhWnhwoV6+OGHdfLkSc2ePVsLFixQly5dJElvv/22oqKi9Nlnn6lbt25XbF8AAPAG5GYAAFyrzH6ne9++fUpNTVVcXJyjzW63q0OHDlq/fr0kacuWLcrKynLqExkZqSZNmjj6FCQzM1Pp6elOFwAAcGnkZgAAiq/MFt2pqamSpLCwMKf2sLAwx22pqany9/dXlSpVCu1TkAkTJig0NNRxiYqKcvHsAQDwPuRmAACKr8wW3XlsNpvTdWNMvraLXa7PmDFjdPLkScfl0KFDLpkrAADlAbkZAICiK7NFd3h4uCTle1f88OHDjnfYw8PDdf78eR0/frzQPgWx2+0KCQlxugAAgEsjNwMAUHxltuiuW7euwsPDlZyc7Gg7f/681q5dq3bt2kmSWrZsKT8/P6c+KSkp+uGHHxx9AACAa5CbAQAoPreevfzUqVP65ZdfHNf37dun7du3q2rVqqpTp46GDx+uxMRE1atXT/Xq1VNiYqKCgoLUv39/SVJoaKgefPBBPfnkk6pWrZqqVq2qkSNHqmnTpo4zpgIAgKIjNwMA4FpuLbq//fZbderUyXH9iSeekCTFx8dr7ty5GjVqlM6ePashQ4bo+PHjatOmjVavXq3g4GDHfV555RX5+vqqb9++Onv2rDp37qy5c+fKx8fniu8PAACejtwMAIBrubXo7tixo4wxhd5us9mUkJCghISEQvsEBARo6tSpmjp1qgUzBACgfCE3AwDgWmX2O90AAAAAAHg6im4AAAAAACxC0Q0AAAAAgEUougEAAAAAsAhFNwAAAAAAFqHoBgAAAADAIhTdAAAAAABYhKIbAAAAAACLUHQDAAAAAGARim4AAAAAACxC0Q0AAAAAgEUougEAAAAAsAhFNwAAAAAAFqHoBgAAAADAIhTdAAAAAABYhKIbAAAAAACLUHQDAAAAAGARim4AAAAAACxC0Q0AAAAAgEUougEAAAAAsAhFNwAAAAAAFqHoBgAAAADAIhTdAAAAAABYhKIbAAAAAACLUHQDAAAAAGARim4AAAAAACxC0Q0AAAAAgEUougEAAAAAsAhFNwAAAAAAFqHoBgAAAADAIhTdAAAAAABYhKIbAAAAAACLUHQDAAAAAGARim4AAAAAACxC0Q0AAAAAgEUougEAAAAAsAhFNwAAAAAAFqHoBgAAAADAIhTdAAAAAABYhKIbAAAAAACLUHQDAAAAAGARim4AAAAAACxC0Q0AAAAAgEUougEAAAAAsEiZLrqzs7P17LPPqm7dugoMDFRsbKyef/555ebmOvoYY5SQkKDIyEgFBgaqY8eO2rFjhxtnDQCA9yI3AwBQPGW66J44caJef/11TZs2Tbt27dKkSZP04osvaurUqY4+kyZN0uTJkzVt2jRt3rxZ4eHh6tq1qzIyMtw4cwAAvBO5GQCA4inTRfeGDRvUq1cv3XbbbYqJidGdd96puLg4ffvtt5IuvJM+ZcoUPfPMM+rTp4+aNGmiefPm6cyZM1q4cKGbZw8AgPchNwMAUDxluui+8cYb9fnnn2v37t2SpO+++05ff/21unfvLknat2+fUlNTFRcX57iP3W5Xhw4dtH79erfMGQAAb0ZuBgCgeHzdPYFLefrpp3Xy5Ek1aNBAPj4+ysnJ0T//+U/dc889kqTU1FRJUlhYmNP9wsLCdODAgULHzczMVGZmpuN6enq6BbMHAMD7kJsBACieMv1J97vvvqu3335bCxcu1NatWzVv3jy99NJLmjdvnlM/m83mdN0Yk6/tzyZMmKDQ0FDHJSoqypL5AwDgbcjNAAAUT5kuup966imNHj1ad999t5o2baqBAwdqxIgRmjBhgiQpPDxc0v/eVc9z+PDhfO+w/9mYMWN08uRJx+XQoUPW7QQAAF6E3AwAQPGU6aL7zJkzqlDBeYo+Pj6OnyWpW7euwsPDlZyc7Lj9/PnzWrt2rdq1a1fouHa7XSEhIU4XAABweeRmAACKp0x/p7tnz5765z//qTp16qhx48batm2bJk+erAceeEDShUPXhg8frsTERNWrV0/16tVTYmKigoKC1L9/fzfPHgAA70NuBgCgeMp00T116lSNHTtWQ4YM0eHDhxUZGamHH35Yzz33nKPPqFGjdPbsWQ0ZMkTHjx9XmzZttHr1agUHB7tx5gAAeCdyMwAAxVOmi+7g4GBNmTJFU6ZMKbSPzWZTQkKCEhISrti8AAAor8jNAAAUT5n+TjcAAAAAAJ6MohsAAAAAAItQdAMAAAAAYBGKbgAAAAAALELRDQAAAACARSi6AQAAAACwCEU3AAAAAAAWoegGAAAAAMAiFN0AAAAAAFiEohsAAAAAAItQdAMAAAAAYBGKbgAAAAAALELRDQAAAACARSi6AQAAAACwCEU3AAAAAAAWoegGAAAAAMAiFN0AAAAAAFiEohsAAAAAAItQdAMAAAAAYBGKbgAAAAAALELRDQAAAACARSi6AQAAAACwCEU3AAAAAAAWoegGAAAAAMAiFN0AAAAAAFiEohsAAAAAAItQdAMAAAAAYBGKbgAAAAAALELRDQAAAACARSi6AQAAAACwCEU3AAAAAAAWoegGAAAAAMAiFN0AAAAAAFiEohsAAAAAAItQdAMAAAAAYBGKbgAAAAAALELRDQAAAACARSi6AQAAAACwSImK7tjYWB09ejRf+4kTJxQbG1vqSQEAgOIhNwMAUDaVqOjev3+/cnJy8rVnZmbqt99+K/WkAABA8ZCbAQAom3yL03nFihWO/3/66acKDQ11XM/JydHnn3+umJgYl00OAABcGrkZAICyrVhFd+/evSVJNptN8fHxTrf5+fkpJiZGL7/8sssmBwAALo3cDABA2Vasojs3N1eSVLduXW3evFnVq1e3ZFIAAKBoyM0AAJRtxSq68+zbt8/V8wAAAKVAbgYAoGwqUdEtSZ9//rk+//xzHT582PEue56kpKRSTyzPb7/9pqefflr//ve/dfbsWV1zzTWaPXu2WrZsKUkyxmj8+PGaNWuWjh8/rjZt2mj69Olq3Lixy+YAAIAnIDcDAFD2lOjs5ePHj1dcXJw+//xzHTlyRMePH3e6uMrx48fVvn17+fn56d///rd27typl19+WZUrV3b0mTRpkiZPnqxp06Zp8+bNCg8PV9euXZWRkeGyeQAAUNaRmwEAKJtK9En366+/rrlz52rgwIGuno+TiRMnKioqSnPmzHG0/fkMrMYYTZkyRc8884z69OkjSZo3b57CwsK0cOFCPfzww5bODwCAsoLcDABA2VSiT7rPnz+vdu3auXou+axYsUKtWrXSXXfdpZo1a6pFixZ68803Hbfv27dPqampiouLc7TZ7XZ16NBB69evt3x+AACUFeRmAADKphIV3YMHD9bChQtdPZd89u7dq5kzZ6pevXr69NNP9cgjj2jo0KGaP3++JCk1NVWSFBYW5nS/sLAwx20FyczMVHp6utMFAABPRm4GAKBsKtHh5efOndOsWbP02WefqVmzZvLz83O6ffLkyS6ZXG5urlq1aqXExERJUosWLbRjxw7NnDlT9913n6OfzWZzup8xJl/bn02YMEHjx493yRwBACgLyM0AAJRNJSq6v//+ezVv3lyS9MMPPzjddqmEWlwRERFq1KiRU1vDhg21dOlSSVJ4eLikC++qR0REOPocPnw43zvsfzZmzBg98cQTjuvp6emKiopy2bwBALjSyM0AAJRNJSq6v/zyS1fPo0Dt27fXTz/95NS2e/duRUdHS5Lq1q2r8PBwJScnq0WLFpIufKdt7dq1mjhxYqHj2u122e126yYOAMAVRm4GAKBsKvHvdF8JI0aMULt27ZSYmKi+fftq06ZNmjVrlmbNmiXpwjv3w4cPV2JiourVq6d69eopMTFRQUFB6t+/v5tnDwCA9yE3AwBQPCUqujt16nTJQ9W++OKLEk/oz1q3bq1ly5ZpzJgxev7551W3bl1NmTJFAwYMcPQZNWqUzp49qyFDhuj48eNq06aNVq9ereDgYJfMAQAAT0BuBgCgbCpR0Z33nbE8WVlZ2r59u3744QfFx8e7Yl4OPXr0UI8ePQq93WazKSEhQQkJCS7dLgAAnoTcDABA2VSiovuVV14psD0hIUGnTp0q1YQAAEDxkZsBACibSvQ73YW59957lZSU5MohAQBAKZCbAQBwL5cW3Rs2bFBAQIArhwQAAKVAbgYAwL1KdHh5nz59nK4bY5SSkqJvv/1WY8eOdcnEAABA0ZGbAQAom0pUdIeGhjpdr1ChgurXr6/nn39ecXFxLpkYAAAoOnIzAABlU4mK7jlz5rh6HgAAoBTIzQAAlE0lKrrzbNmyRbt27ZLNZlOjRo3UokULV80LAACUALkZAICypURF9+HDh3X33XdrzZo1qly5sowxOnnypDp16qTFixerRo0arp4nAAC4BHIzAABlU4nOXv74448rPT1dO3bs0LFjx3T8+HH98MMPSk9P19ChQ109RwAAcBnkZgAAyqYSfdK9atUqffbZZ2rYsKGjrVGjRpo+fTonawEAwA3IzQAAlE0l+qQ7NzdXfn5++dr9/PyUm5tb6kkBAIDiITcDAFA2lajovvnmmzVs2DD9/vvvjrbffvtNI0aMUOfOnV02OQAAUDTkZgAAyqYSFd3Tpk1TRkaGYmJidNVVV+nqq69W3bp1lZGRoalTp7p6jgAA4DLIzQAAlE0l+k53VFSUtm7dquTkZP34448yxqhRo0bq0qWLq+cHAACKgNwMAEDZVKxPur/44gs1atRI6enpkqSuXbvq8ccf19ChQ9W6dWs1btxY69ats2SiAAAgP3IzAABlW7GK7ilTpuihhx5SSEhIvttCQ0P18MMPa/LkyS6bHAAAuDRyMwAAZVuxiu7vvvtOt9xyS6G3x8XFacuWLaWeFAAAKBpyMwAAZVuxiu4//vijwJ8jyePr66u0tLRSTwoAABQNuRkAgLKtWEV3rVq19N///rfQ27///ntFRESUelIAAKBoyM0AAJRtxSq6u3fvrueee07nzp3Ld9vZs2c1btw49ejRw2WTAwAAl0ZuBgCgbCvWT4Y9++yz+uCDD3TNNdfoscceU/369WWz2bRr1y5Nnz5dOTk5euaZZ6yaKwAAuAi5GQCAsq1YRXdYWJjWr1+vv/3tbxozZoyMMZIkm82mbt26acaMGQoLC7NkogAAID9yMwAAZVuxim5Jio6O1sqVK3X8+HH98ssvMsaoXr16qlKlihXzAwAAl0FuBgCg7Cp20Z2nSpUqat26tSvnAgAASoHcDABA2VOsE6kBAAAAAICio+gGAAAAAMAiFN0AAAAAAFiEohsAAAAAAItQdAMAAAAAYBGKbgAAAAAALELRDQAAAACARSi6AQAAAACwCEU3AAAAAAAWoegGAAAAAMAiFN0AAAAAAFiEohsAAAAAAItQdAMAAAAAYBGKbgAAAAAALELRDQAAAACARSi6AQAAAACwCEU3AAAAAAAWoegGAAAAAMAiFN0AAAAAAFiEohsAAAAAAItQdAMAAAAAYBGPKronTJggm82m4cOHO9qMMUpISFBkZKQCAwPVsWNH7dixw32TBACgHCE3AwBwaR5TdG/evFmzZs1Ss2bNnNonTZqkyZMna9q0adq8ebPCw8PVtWtXZWRkuGmmAACUD+RmAAAuzyOK7lOnTmnAgAF68803VaVKFUe7MUZTpkzRM888oz59+qhJkyaaN2+ezpw5o4ULF7pxxgAAeDdyMwAAReMRRfejjz6q2267TV26dHFq37dvn1JTUxUXF+dos9vt6tChg9avX1/oeJmZmUpPT3e6AACAoiM3AwBQNL7unsDlLF68WFu3btXmzZvz3ZaamipJCgsLc2oPCwvTgQMHCh1zwoQJGj9+vGsnCgBAOUFuBgCg6Mr0J92HDh3SsGHD9PbbbysgIKDQfjabzem6MSZf25+NGTNGJ0+edFwOHTrksjkDAODNyM0AABRPmf6ke8uWLTp8+LBatmzpaMvJydFXX32ladOm6aeffpJ04V31iIgIR5/Dhw/ne4f9z+x2u+x2u3UTBwDAS5GbAQAonjL9SXfnzp313//+V9u3b3dcWrVqpQEDBmj79u2KjY1VeHi4kpOTHfc5f/681q5dq3bt2rlx5gAAeCdyMwAAxVOmP+kODg5WkyZNnNoqVqyoatWqOdqHDx+uxMRE1atXT/Xq1VNiYqKCgoLUv39/d0wZAACvRm4GAKB4ynTRXRSjRo3S2bNnNWTIEB0/flxt2rTR6tWrFRwc7O6pAQBQLpGbAQD4H48rutesWeN03WazKSEhQQkJCW6ZDwAA5R25GQCAwpXp73QDAAAAAODJKLoBAAAAALAIRTcAAAAAABah6AYAAAAAwCIU3QAAAAAAWISiGwAAAAAAi1B0AwAAAABgEYpuAAAAAAAsQtENAAAAAIBFKLoBAAAAALAIRTcAAAAAABah6AYAAAAAwCIU3QAAAAAAWISiGwAAAAAAi1B0AwAAAABgEYpuAAAAAAAsQtENAAAAAIBFKLoBAAAAALAIRTcAAAAAABah6AYAAAAAwCIU3QAAAAAAWISiGwAAAAAAi1B0AwAAAABgEYpuAAAAAAAsQtENAAAAAIBFKLoBAAAAALAIRTcAAAAAABah6AYAAAAAwCIU3QAAAAAAWISiGwAAAAAAi1B0AwAAAABgEYpuAAAAAAAsQtENAAAAAIBFKLoBAAAAALAIRTcAAAAAABah6AYAAAAAwCIU3QAAAAAAWISiGwAAAAAAi1B0AwAAAABgEYpuAAAAAAAsQtENAAAAAIBFKLoBAAAAALAIRTcAAAAAABah6AYAAAAAwCJluuieMGGCWrdureDgYNWsWVO9e/fWTz/95NTHGKOEhARFRkYqMDBQHTt21I4dO9w0YwAAvBu5GQCA4inTRffatWv16KOPauPGjUpOTlZ2drbi4uJ0+vRpR59JkyZp8uTJmjZtmjZv3qzw8HB17dpVGRkZbpw5AADeidwMAEDx+Lp7ApeyatUqp+tz5sxRzZo1tWXLFt10000yxmjKlCl65pln1KdPH0nSvHnzFBYWpoULF+rhhx92x7QBAPBa5GYAAIqnTH/SfbGTJ09KkqpWrSpJ2rdvn1JTUxUXF+foY7fb1aFDB61fv77QcTIzM5Wenu50AQAAxUduBgDg0jym6DbG6IknntCNN96oJk2aSJJSU1MlSWFhYU59w8LCHLcVZMKECQoNDXVcoqKirJs4AABeitwMAMDleUzR/dhjj+n777/XokWL8t1ms9mcrhtj8rX92ZgxY3Ty5EnH5dChQy6fLwAA3o7cDADA5ZXp73Tnefzxx7VixQp99dVXql27tqM9PDxc0oV31SMiIhzthw8fzvcO+5/Z7XbZ7XbrJgwAgJcjNwMAUDRl+pNuY4wee+wxffDBB/riiy9Ut25dp9vr1q2r8PBwJScnO9rOnz+vtWvXql27dld6ugAAeD1yMwAAxVOmP+l+9NFHtXDhQn344YcKDg52fBcsNDRUgYGBstlsGj58uBITE1WvXj3Vq1dPiYmJCgoKUv/+/d08ewAAvA+5GQCA4inTRffMmTMlSR07dnRqnzNnjgYNGiRJGjVqlM6ePashQ4bo+PHjatOmjVavXq3g4OArPFsAALwfuRkAgOIp00W3MeayfWw2mxISEpSQkGD9hAAAKOfIzQAAFE+Z/k43AAAAAACejKIbAAAAAACLUHQDAAAAAGARim4AAAAAACxC0Q0AAAAAgEUougEAAAAAsAhFNwAAAAAAFqHoBgAAAADAIhTdAAAAAABYhKIbAAAAAACLUHQDAAAAAGARim4AAAAAACxC0Q0AAAAAgEUougEAAAAAsAhFNwAAAAAAFqHoBgAAAADAIhTdAAAAAABYhKIbAAAAAACLUHQDAAAAAGARim4AAAAAACxC0Q0AAAAAgEUougEAAAAAsAhFNwAAAAAAFqHoBgAAAADAIhTdAAAAAABYhKIbAAAAAACL+Lp7Ari0rPPndeDAAZeMFRISoho1arhkLAAAAADlT1pamtLT00s9zoEDB5Sdne2CGZV9FN1lWOapk9q/b6+G/z1Bdru91ONVDQ7S23PeovAGAAAAUGxpaWn62+D+yjx1tNRjnT6TqT9SDykzK9QFMyvbKLrLsKzMs8q1+ar6DX1ULTK6VGOdPvaH0jYsVXp6OkU3AAAAgGJLT09X5qmjerKnXVE1Aks11sZdx/XP+dnKyfH+T7spuj1AUJUaCqlZu9TjpLlgLgAAAADKt6gagbqqVsVSjXHgj7Mumk3Zx4nUAAAAAACwCEU3AAAAAAAWoegGAAAAAMAiFN0AAAAAAFiEohsAAAAAAItQdAMAAAAAYBGKbgAAAAAALMLvdJcjWefP68CBAy4ZKyQkRDVq1HDJWAAAAACsk5aWpvT09FKPc+DAAWVnZ7tgRuULRXc5kXnqpPbv26vhf0+Q3W4v9XhVg4P09py3KLwBAACAMiwtLU1/G9xfmaeOlnqs02cy9UfqIWVmhbpgZuUHRXc5kZV5Vrk2X1W/oY+qRUaXaqzTx/5Q2oalSk9Pp+gGAAAAyrD09HRlnjqqJ3vaFVUjsFRjbdx1XP+cn62cHD7tLg6K7nImqEoNhdSsXepx0lwwFwAAAABXRlSNQF1Vq2Kpxjjwx1kXzaZ84URqAAAAAABYhE+64TVcdYIIiRPFAQAAlBe8hoTVKLrhFdLS0nTv/YN1LOOMS8bjRHEAAADez5UnGZMke6VqmvnWQl5DwonXFN0zZszQiy++qJSUFDVu3FhTpkzRX/7yF3dPC1dIenq6jmWcUY22d6hi1bBSjcWJ4gDANcjNAMo6V55k7FDaWb380VFeQyIfryi63333XQ0fPlwzZsxQ+/bt9cYbb+jWW2/Vzp07VadOHXdPzyu56je/XX0ITsWqYZwoDkCBOHzwyipruZnHH8CluOIkYxdkumCMC/htbe/hFUX35MmT9eCDD2rw4MGSpClTpujTTz/VzJkzNWHCBDfPzvu48je/OYwbwJXAV1CuvLKUmzl8FICn4be1vYvHF93nz5/Xli1bNHr0aKf2uLg4rV+/3k2z8m6u+s1vDuMGcKXwFZQrq6zlZg4fBeBp+G1t7+LxRfeRI0eUk5OjsDDnF1FhYWFKTU0t8D6ZmZnKzPzfoR8nT56UJJccvpGRkaGc7GydSNmvrHOl+0Ql/fCvMrm5Sk89JF9b6eZlxVjZmedKtY9ZmWeVefasdu7cqYyMjFLN6dChQzp/7pxL4n76+GGXzQtA2ZD3NyIr82yp/0ZkZZ5VTna2MjIySp038u5vjCnVOGVNWczNWdk5On0uWxlnSvei8/S5bJ05m0mOALzEoUOHdC4zUz8eyij134ffjp512d+HvHmdPudT6nmdycxRTq7R7kOnlZPrV6qx9qScLpNj/Xb0rLKyc8pubjYe7rfffjOSzPr1653a//GPf5j69esXeJ9x48YZSVy4cOHChUuZuBw6dOhKpMwrhtzMhQsXLlw8/eLK3Ozxn3RXr15dPj4++d45P3z4cL532POMGTNGTzzxhON6bm6ujh07pmrVqslmK93HwOnp6YqKitKhQ4cUEhJSqrFAPF2JWLoW8XSt8hpPY4wyMjIUGRnp7qm4VFnLzZ6ivD4PrEI8XYt4uhbxdC1XxtOK3OzxRbe/v79atmyp5ORk/fWvf3W0Jycnq1evXgXex2635zsBWOXKlV06r5CQEJ5ALkQ8XYdYuhbxdK3yGM/Q0FB3T8Hlympu9hTl8XlgJeLpWsTTtYina7kqnq7OzR5fdEvSE088oYEDB6pVq1Zq27atZs2apYMHD+qRRx5x99QAACiXyM0AAFzgFUV3v379dPToUT3//PNKSUlRkyZNtHLlSkVHR7t7agAAlEvkZgAALvCKoluShgwZoiFDhrh7GrLb7Ro3blypf78aFxBP1yGWrkU8XYt4eqeykps9Bc8D1yKerkU8XYt4ulZZj6fNGC/7nRIAAAAAAMqICu6eAAAAAAAA3oqiGwAAAAAAi1B0AwAAAABgEYrui8yYMUN169ZVQECAWrZsqXXr1l2y/9q1a9WyZUsFBAQoNjZWr7/+er4+S5cuVaNGjWS329WoUSMtW7as1Nv1FO6IZ0JCgmw2m9MlPDzcpfvlDq6O5Y4dO3THHXcoJiZGNptNU6ZMccl2PYU74umta1NyfTzffPNN/eUvf1GVKlVUpUoVdenSRZs2bSr1dgErFXc9Tp8+XQ0bNlRgYKDq16+v+fPn5+szZcoU1a9fX4GBgYqKitKIESN07ty5Um3XU7gjnvyd/p/LxTMrK0vPP/+8rrrqKgUEBOjaa6/VqlWrSr1dT+GOeHrj+vzqq6/Us2dPRUZGymazafny5Ze9j0fWXwYOixcvNn5+fubNN980O3fuNMOGDTMVK1Y0Bw4cKLD/3r17TVBQkBk2bJjZuXOnefPNN42fn595//33HX3Wr19vfHx8TGJiotm1a5dJTEw0vr6+ZuPGjSXerqdwVzzHjRtnGjdubFJSUhyXw4cPW76/VrIilps2bTIjR440ixYtMuHh4eaVV14p9XY9hbvi6Y1r0xhr4tm/f38zffp0s23bNrNr1y5z//33m9DQUPPrr7+WeLuAlYq7HmfMmGGCg4PN4sWLzZ49e8yiRYtMpUqVzIoVKxx93n77bWO3280777xj9u3bZz799FMTERFhhg8fXuLtegp3xZO/0xcUJZ6jRo0ykZGR5pNPPjF79uwxM2bMMAEBAWbr1q0l3q6ncFc8vXF9rly50jzzzDNm6dKlRpJZtmzZJft7av1F0f0n119/vXnkkUec2ho0aGBGjx5dYP9Ro0aZBg0aOLU9/PDD5oYbbnBc79u3r7nllluc+nTr1s3cfffdJd6up3BXPMeNG2euvfbaUs6+bLEiln8WHR1dYJHI2rzAVfH0xrVpjPXxNMaY7OxsExwcbObNm1fi7QJWKu56bNu2rRk5cqRT27Bhw0z79u0d1x999FFz8803O/V54oknzI033lji7XoKd8WTv9MXFCWeERERZtq0aU59evXqZQYMGFDi7XoKd8XTW9dnnqIU3Z5af3F4+f85f/68tmzZori4OKf2uLg4rV+/vsD7bNiwIV//bt266dtvv1VWVtYl++SNWZLtegJ3xTPPzz//rMjISNWtW1d333239u7dW9pdchurYmnFdj2Bu+KZx5vWpnTl4nnmzBllZWWpatWqJd4uYJWSrMfMzEwFBAQ4tQUGBmrTpk2O58GNN96oLVu2OL5asXfvXq1cuVK33XZbibfrCdwVzzz8nS5aPAvr8/XXX5d4u57AXfHM423rs7g8tf6i6P4/R44cUU5OjsLCwpzaw8LClJqaWuB9UlNTC+yfnZ2tI0eOXLJP3pgl2a4ncFc8JalNmzaaP3++Pv30U7355ptKTU1Vu3btdPToUVfs2hVnVSyt2K4ncFc8Je9bm9KVi+fo0aNVq1YtdenSpcTbBaxSkvXYrVs3vfXWW9qyZYuMMfr222+VlJSkrKwsx/Pg7rvv1gsvvKAbb7xRfn5+uuqqq9SpUyeNHj26xNv1BO6Kp8Tf6TxFiWe3bt00efJk/fzzz8rNzVVycrI+/PBDpaSklHi7nsBd8ZS8c30Wl6fWXxTdF7HZbE7XjTH52i7X/+L2ooxZ3O16CnfE89Zbb9Udd9yhpk2bqkuXLvrkk08kSfPmzSvZTpQRVsTSiu16CnfE01vXpmRtPCdNmqRFixbpgw8+yPcpgLeuT3im4qzHsWPH6tZbb9UNN9wgPz8/9erVS4MGDZIk+fj4SJLWrFmjf/7zn5oxY4a2bt2qDz74QB9//LFeeOGFEm/Xk7gjnvydvqAo8Xz11VdVr149NWjQQP7+/nrsscd0//33O24vyXY9iTvi6c3rszg8sf6i6P4/1atXl4+PT753Nw4fPpzvXZA84eHhBfb39fVVtWrVLtknb8ySbNcTuCueBalYsaKaNm2qn3/+uSS74nZWxdKK7XoCd8WzIJ6+NiXr4/nSSy8pMTFRq1evVrNmzUq1XcAqJVmPgYGBSkpK0pkzZ7R//34dPHhQMTExCg4OVvXq1SVdeKE+cOBADR48WE2bNtVf//pXJSYmasKECcrNzfXa54G74lmQ8vp3uijxrFGjhpYvX67Tp0/rwIED+vHHH1WpUiXVrVu3xNv1BO6KZ0G8YX0Wl6fWXxTd/8ff318tW7ZUcnKyU3tycrLatWtX4H3atm2br//q1avVqlUr+fn5XbJP3pgl2a4ncFc8C5KZmaldu3YpIiKiJLvidlbF0ortegJ3xbMgnr42JWvj+eKLL+qFF17QqlWr1KpVq1JvF7BKadajn5+fateuLR8fHy1evFg9evRQhQoXXp6dOXPG8f88Pj4+MhdOhOu1zwN3xbMg5fXvdJ5LxTNPQECAatWqpezsbC1dulS9evUq9XbLMnfFsyDesD6Ly2PrL0tOz+ah8k4dP3v2bLNz504zfPhwU7FiRbN//35jjDGjR482AwcOdPTPO2X9iBEjzM6dO83s2bPznbL+P//5j/Hx8TH/+te/zK5du8y//vWvQk9ZX9h2PZW74vnkk0+aNWvWmL1795qNGzeaHj16mODgYI+OpxWxzMzMNNu2bTPbtm0zERERZuTIkWbbtm3m559/LvJ2PZW74umNa9MYa+I5ceJE4+/vb95//32nn0bJyMgo8naBK6m4z4OffvrJLFiwwOzevdt88803pl+/fqZq1apm3759jj7jxo0zwcHBZtGiRWbv3r1m9erV5qqrrjJ9+/Yt8nY9lbviyd/pC4oSz40bN5qlS5eaPXv2mK+++srcfPPNpm7duub48eNF3q6nclc8vXF9ZmRkOF4/STKTJ08227Ztc/x0l7fUXxTdF5k+fbqJjo42/v7+5rrrrjNr16513BYfH286dOjg1H/NmjWmRYsWxt/f38TExJiZM2fmG3PJkiWmfv36xs/PzzRo0MAsXbq0WNv1ZO6IZ79+/UxERITx8/MzkZGRpk+fPmbHjh2W7N+V5OpY7tu3z0jKd7l4HNbmBa6Ip7euTWNcH8/o6OgC4zlu3Lgibxe40orzPNi5c6dp3ry5CQwMNCEhIaZXr17mxx9/dBovKyvLJCQkmKuuusoEBASYqKgoM2TIEKcX4ZfbridzRzz5O31BUeK5Zs0a07BhQ2O32021atXMwIEDzW+//Vas7Xoyd8TTG9fnl19+WWC+j4+PN8Z4T/1lM6aQ42kAAAAAAECp8J1uAAAAAAAsQtENAAAAAIBFKLoBAAAAALAIRTcAAAAAABah6AYAAAAAwCIU3QAAAAAAWISiGwAAAAAAi1B0AwAAAABgEYpuAJKkhIQENW/evNTj2Gw2LV++vNDb9+/fL5vNpu3bt0uS1qxZI5vNphMnTkiS5s6dq8qVK5d6HgAAeDpyM+AdKLoBDzRo0CDZbDbZbDb5+fkpNjZWI0eO1OnTp909tcuKiopSSkqKmjRpUuDt/fr10+7dux3XXfWCAwAAK5GbARTG190TAFAyt9xyi+bMmaOsrCytW7dOgwcP1unTpzVz5kynfllZWfLz83PTLPPz8fFReHh4obcHBgYqMDDwCs4IAADXIDcDKAifdAMeym63Kzw8XFFRUerfv78GDBig5cuXO959TkpKUmxsrOx2u4wxOnjwoHr16qVKlSopJCREffv21R9//JFv3DfeeENRUVEKCgrSXXfd5Ti0TJI2b96srl27qnr16goNDVWHDh20devWfGOkpKTo1ltvVWBgoOrWraslS5Y4brv4ELaL/fkQtrlz52r8+PH67rvvHJ8ezJ07Vw888IB69OjhdL/s7GyFh4crKSmp+MEEAMAFyM3kZqAgFN2AlwgMDFRWVpYk6ZdfftF7772npUuXOhJo7969dezYMa1du1bJycnas2eP+vXr5zRG3v0++ugjrVq1Stu3b9ejjz7quD0jI0Px8fFat26dNm7cqHr16ql79+7KyMhwGmfs2LG644479N133+nee+/VPffco127dhV7n/r166cnn3xSjRs3VkpKilJSUtSvXz8NHjxYq1atUkpKiqPvypUrderUKfXt27fY2wEAwArkZnIzIHF4OeAVNm3apIULF6pz586SpPPnz2vBggWqUaOGJCk5OVnff/+99u3bp6ioKEnSggUL1LhxY23evFmtW7eWJJ07d07z5s1T7dq1JUlTp07Vbbfdppdfflnh4eG6+eabnbb7xhtvqEqVKlq7dq3Tu9t33XWXBg8eLEl64YUXlJycrKlTp2rGjBnF2q/AwEBVqlRJvr6+Toe9tWvXTvXr19eCBQs0atQoSdKcOXN01113qVKlSsXaBgAAViA3k5uBPHzSDXiojz/+WJUqVVJAQIDatm2rm266SVOnTpUkRUdHO5K6JO3atUtRUVGOpC5JjRo1UuXKlZ3e5a5Tp44jqUtS27ZtlZubq59++kmSdPjwYT3yyCO65pprFBoaqtDQUJ06dUoHDx50mlvbtm3zXS/Ju+mXMnjwYM2ZM8cxr08++UQPPPCAS7cBAEBxkJvJzUBB+KQb8FCdOnXSzJkz5efnp8jISKcTslSsWNGprzFGNpst3xiFtefJuy3v30GDBiktLU1TpkxRdHS07Ha72rZtq/Pnz192vpfaTkncd999Gj16tDZs2KANGzYoJiZGf/nLX1y6DQAAioPcTG4GCsIn3YCHqlixoq6++mpFR0df9gyojRo10sGDB3Xo0CFH286dO3Xy5Ek1bNjQ0Xbw4EH9/vvvjusbNmxQhQoVdM0110iS1q1bp6FDh6p79+5q3Lix7Ha7jhw5km97GzduzHe9QYMGJdpPf39/5eTk5GuvVq2aevfurTlz5mjOnDm6//77SzQ+AACuQm4mNwMF4ZNuoBzo0qWLmjVrpgEDBmjKlCnKzs7WkCFD1KFDB7Vq1crRLyAgQPHx8XrppZeUnp6uoUOHqm/fvo7vbF199dVasGCBWrVqpfT0dD311FMF/oTIkiVL1KpVK91444165513tGnTJs2ePbtEc4+JidG+ffu0fft21a5dW8HBwbLb7ZIuHMbWo0cP5eTkKD4+vkTjAwDgDuRmoPzgk26gHLDZbFq+fLmqVKmim266SV26dFFsbKzeffddp35XX321+vTpo+7duysuLk5NmjRxOsFKUlKSjh8/rhYtWmjgwIEaOnSoatasmW9748eP1+LFi9WsWTPNmzdP77zzjho1alSiud9xxx265ZZb1KlTJ9WoUUOLFi1y3NalSxdFRESoW7duioyMLNH4AAC4A7kZKD9sxhjj7kkAQEmcOXNGkZGRSkpKUp8+fdw9HQAAyj1yM5Afh5cD8Di5ublKTU3Vyy+/rNDQUN1+++3unhIAAOUauRkoHEU3AI9z8OBB1a1bV7Vr19bcuXPl68ufMgAA3IncDBSOw8sBAAAAALAIJ1IDAAAAAMAiFN0AAAAAAFiEohsAAAAAAItQdAMAAAAAYBGKbgAAAAAALELRDQAAAACARSi6AQAAAACwCEU3AAAAAAAWoegGAAAAAMAi/x8hsmNKMrditwAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 1000x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sorted by p(treated) in ascending order:\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C05-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C03-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C08-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C07-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C9.tif: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F03-T01.tiff: 0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C06-T01.tiff: 0.0003\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g9_C10-T01.tiff: 0.0005\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B10-T01.tiff: 0.0005\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C02-T01.tiff: 0.0007\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F02-T01.tiff: 0.0008\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F05-T01.tiff: 0.0008\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F05-T01.tiff: 0.0010\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B07-T01.tiff: 0.0014\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C10-T01.tiff: 0.0015\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B08-T01.tiff: 0.0016\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C05-T01.tiff: 0.0016\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C11.tif: 0.0016\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G10-T01.tiff: 0.0017\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B11-T01.tiff: 0.0019\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C03-T01.tiff: 0.0030\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C03-T01.tiff: 0.0030\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C06-T01.tiff: 0.0034\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_c10.tif: 0.0038\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C7.tif: 0.0041\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E06-T01.tiff: 0.0043\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G09-T01.tiff: 0.0044\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F04-T01.tiff: 0.0046\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C06-T01.tiff: 0.0047\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B03-T01.tiff: 0.0048\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C8.tif: 0.0053\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G11-T01.tiff: 0.0056\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B09-T01.tiff: 0.0057\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B05-T01.tiff: 0.0067\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F04-T01.tiff: 0.0072\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D06-T01.tiff: 0.0109\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G08-T01.tiff: 0.0116\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E02-T01.tiff: 0.0123\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B03-T01.tiff: 0.0125\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G10-T01.tiff: 0.0128\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F02-T01.tiff: 0.0147\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C09-T01.tiff: 0.0161\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C08-T01.tiff: 0.0178\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G06-T01.tiff: 0.0181\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E11-T01.tiff: 0.0194\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G05-T01.tiff: 0.0209\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G03-T01.tiff: 0.0214\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B04-T01.tiff: 0.0228\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E08-T01.tiff: 0.0230\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D08-T01.tiff: 0.0241\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G04-T01.tiff: 0.0268\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B02-T01.tiff: 0.0274\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D05-T01.tiff: 0.0290\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F09-T01.tiff: 0.0298\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D03-T01.tiff: 0.0314\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F08-T01.tiff: 0.0361\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B06-T01.tiff: 0.0439\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B07-T01.tiff: 0.0451\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D07-T01.tiff: 0.0466\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C09-T01.tiff: 0.0466\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E10-T01.tiff: 0.0581\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B08-T01.tiff: 0.0701\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D02-T01.tiff: 0.0710\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C10-T01.tiff: 0.0712\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E05-T01.tiff: 0.0731\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F11-T01.tiff: 0.0823\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E07-T01.tiff: 0.0857\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E04-T01.tiff: 0.0859\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F07-T01.tiff: 0.0925\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C11-T01.tiff: 0.1166\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C03-T01.tiff: 0.1170\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D10-T01.tiff: 0.1211\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B10-T01.tiff: 0.1287\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F03-T01.tiff: 0.1398\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G07-T01.tiff: 0.1445\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F02-T01.tiff: 0.1532\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G02-T01.tiff: 0.1620\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E03-T01.tiff: 0.2115\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D11-T01.tiff: 0.2307\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G11-T01.tiff: 0.2309\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G06-T01.tiff: 0.2621\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G03-T01.tiff: 0.2641\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F06-T01.tiff: 0.2892\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C05-T01.tiff: 0.2911\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C05-T01.tiff: 0.2916\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D03-T01.tiff: 0.2994\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E09-T01.tiff: 0.3225\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F09-T01.tiff: 0.3336\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D04-T01.tiff: 0.3368\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B02-T01.tiff: 0.3396\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B08-T01.tiff: 0.3845\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E11-T01.tiff: 0.4002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C04-T01.tiff: 0.4089\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C07-T01.tiff: 0.4317\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C10-T01.tiff: 0.4350\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B10-T01.tiff: 0.4386\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E02-T01.tiff: 0.4591\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E04-T01.tiff: 0.4678\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C09-T01.tiff: 0.4730\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C04-T01.tiff: 0.4855\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D10-T01.tiff: 0.4887\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C02-T01.tiff: 0.4904\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E03-T01.tiff: 0.4906\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F10-T01.tiff: 0.4917\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G04-T01.tiff: 0.4992\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D02-T01.tiff: 0.5175\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B11-T01.tiff: 0.5220\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F11-T01.tiff: 0.5251\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C06-T01.tiff: 0.6043\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D09-T01.tiff: 0.6069\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F04-T01.tiff: 0.6304\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F08-T01.tiff: 0.6342\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B05-T01.tiff: 0.6581\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D07-T01.tiff: 0.7273\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D08-T01.tiff: 0.7326\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F03-T01.tiff: 0.7327\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G02-T01.tiff: 0.7366\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B04-T01.tiff: 0.7524\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E10-T01.tiff: 0.7557\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B07-T01.tiff: 0.7612\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F10-T01.tiff: 0.7623\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F06-T01.tiff: 0.7644\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F07-T01.tiff: 0.7771\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D11-T01.tiff: 0.7806\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C08-T01.tiff: 0.7996\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C11-T01.tiff: 0.8128\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G09-T01.tiff: 0.8238\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D09-T01.tiff: 0.8311\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E09-T01.tiff: 0.8421\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E06-T01.tiff: 0.8601\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E07-T01.tiff: 0.8609\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D04-T01.tiff: 0.8641\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B06-T01.tiff: 0.8656\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F06-T01.tiff: 0.8810\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G08-T01.tiff: 0.8861\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G05-T01.tiff: 0.8875\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F05-T01.tiff: 0.8904\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D06-T01.tiff: 0.8906\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D05-T01.tiff: 0.9007\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C07-T01.tiff: 0.9083\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C02-T01.tiff: 0.9121\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G07-T01.tiff: 0.9125\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E08-T01.tiff: 0.9191\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B09-T01.tiff: 0.9204\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E05-T01.tiff: 0.9705\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B04-T01.tiff: 0.9774\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D11-T01.tiff: 0.9935\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C08-T01.tiff: 0.9938\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C07-T01.tiff: 0.9963\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E06-T01.tiff: 0.9967\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C08-T01.tiff: 0.9968\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E10-T01.tiff: 0.9973\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E08-T01.tiff: 0.9975\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E08-T01.tiff: 0.9978\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D07-T01.tiff: 0.9981\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D08-T01.tiff: 0.9982\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D09-T01.tiff: 0.9983\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E05-T01.tiff: 0.9987\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E07-T01.tiff: 0.9987\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D08-T01.tiff: 0.9987\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C07-T01.tiff: 0.9988\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E10-T01.tiff: 0.9989\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D07-T01.tiff: 0.9989\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E07-T01.tiff: 0.9990\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C10-T01.tiff: 0.9991\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B03-T01.tiff: 0.9991\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F07-T01.tiff: 0.9991\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E10-T01.tiff: 0.9992\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D10-T01.tiff: 0.9992\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E2.tif: 0.9993\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F10-T01.tiff: 0.9993\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E3.tif: 0.9994\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D07-T01.tiff: 0.9995\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B07-T01.tiff: 0.9995\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C10-T01.tiff: 0.9995\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F08-T01.tiff: 0.9995\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B08-T01.tiff: 0.9995\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C11-T01.tiff: 0.9995\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C09-T01.tiff: 0.9996\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B02-T01.tiff: 0.9996\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C08-T01.tiff: 0.9996\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D08-T01.tiff: 0.9996\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F11-T01.tiff: 0.9996\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B07-T01.tiff: 0.9996\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F07-T01.tiff: 0.9997\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C07-T01.tiff: 0.9997\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B08-T01.tiff: 0.9997\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E09-T01.tiff: 0.9997\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E07-T01.tiff: 0.9997\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C09-T01.tiff: 0.9997\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F09-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F09-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E11-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F08-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E11-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B10-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E09-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F09-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D10-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G08-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B07-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E11-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C09-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E5.tif: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B11-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E04-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B09-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F10-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E4.tif: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B08-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F07-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D09-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B09-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B03-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D09-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D10-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E09-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B11-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B04-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B03-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D11-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D08-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C07-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D09-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G08-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B08-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D07-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F10-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B05-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B06-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G07-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E05-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B07-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C10-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D10-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B09-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B06-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C10-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E02-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E03-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B11-T01.tiff: 1.0000\n"
     ]
    }
   ],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending ordergroups_data[group_name]\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images copied and renamed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Assuming 'sorted_by_treated' is already defined as:\n",
    "# sorted_by_treated = [(img_path, p_tr), ...] sorted in ascending order by p_tr\n",
    "\n",
    "new_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\sort_ex_85\"\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "for i, (img_path, p_tr) in enumerate(sorted_by_treated, start=1):\n",
    "    # Extract the parent directory name and the original filename\n",
    "    parent_dir_name = os.path.basename(os.path.dirname(img_path))  # e.g. \"cond7\"\n",
    "    base_filename = os.path.basename(img_path)  # e.g. \"ds_41.tif\"\n",
    "    \n",
    "    # Combine them to get \"cond7_ds_41.tif\"\n",
    "    original_filename = f\"{parent_dir_name}_{base_filename}\"\n",
    "\n",
    "    # Format the probability score\n",
    "    formatted_score = f\"{p_tr:.4f}\"\n",
    "    \n",
    "    # Construct the new filename with index and score\n",
    "    new_filename = f\"{i}_{formatted_score}_{original_filename}\"\n",
    "    new_path = os.path.join(new_dir, new_filename)\n",
    "    \n",
    "    shutil.copy2(img_path, new_path)\n",
    "\n",
    "print(\"Images copied and renamed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features:   0%|          | 0/18 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 18/18 [00:12<00:00,  1.50it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sorted by p(treated) in ascending order:\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G09-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G07-T01.tiff: 0.0004\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C08-T01.tiff: 0.9311\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C04-T01.tiff: 0.9391\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F03-T01.tiff: 0.9884\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_c10.tif: 0.9890\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B08-T01.tiff: 0.9891\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C07-T01.tiff: 0.9919\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C11-T01.tiff: 0.9922\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B11-T01.tiff: 0.9939\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C10-T01.tiff: 0.9941\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C10-T01.tiff: 0.9952\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C04-T01.tiff: 0.9962\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C7.tif: 0.9970\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B07-T01.tiff: 0.9977\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B09-T01.tiff: 0.9979\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C8.tif: 0.9980\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C11.tif: 0.9980\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C9.tif: 0.9982\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B10-T01.tiff: 0.9984\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B11-T01.tiff: 0.9985\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g9_C10-T01.tiff: 0.9987\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C09-T01.tiff: 0.9988\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B07-T01.tiff: 0.9990\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C08-T01.tiff: 0.9991\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C02-T01.tiff: 0.9992\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D11-T01.tiff: 0.9993\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C09-T01.tiff: 0.9994\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C03-T01.tiff: 0.9994\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C11-T01.tiff: 0.9995\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C06-T01.tiff: 0.9995\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C03-T01.tiff: 0.9997\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B09-T01.tiff: 0.9997\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F06-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C06-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C05-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C07-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B10-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C02-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C05-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F05-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F02-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E2.tif: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E3.tif: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E5.tif: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E05-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E4.tif: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B03-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E05-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B03-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B05-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E02-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E03-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B02-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B03-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B10-T01.tiff: 1.0000\n"
     ]
    }
   ],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending ordergroups_data[group_name]\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sorted by p(treated) in ascending order:\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G09-T01.tiff: p(treated)=0.0001, p(control)=0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G07-T01.tiff: p(treated)=0.0004, p(control)=0.9996\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C08-T01.tiff: p(treated)=0.9311, p(control)=0.0689\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C04-T01.tiff: p(treated)=0.9391, p(control)=0.0609\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F03-T01.tiff: p(treated)=0.9884, p(control)=0.0116\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_c10.tif: p(treated)=0.9890, p(control)=0.0110\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B08-T01.tiff: p(treated)=0.9891, p(control)=0.0109\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C07-T01.tiff: p(treated)=0.9919, p(control)=0.0081\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C11-T01.tiff: p(treated)=0.9922, p(control)=0.0078\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B11-T01.tiff: p(treated)=0.9939, p(control)=0.0061\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C10-T01.tiff: p(treated)=0.9941, p(control)=0.0059\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C10-T01.tiff: p(treated)=0.9952, p(control)=0.0048\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C04-T01.tiff: p(treated)=0.9962, p(control)=0.0038\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C7.tif: p(treated)=0.9970, p(control)=0.0030\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B07-T01.tiff: p(treated)=0.9977, p(control)=0.0023\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B09-T01.tiff: p(treated)=0.9979, p(control)=0.0021\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C8.tif: p(treated)=0.9980, p(control)=0.0020\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C11.tif: p(treated)=0.9980, p(control)=0.0020\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C9.tif: p(treated)=0.9982, p(control)=0.0018\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B10-T01.tiff: p(treated)=0.9984, p(control)=0.0016\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B11-T01.tiff: p(treated)=0.9985, p(control)=0.0015\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g9_C10-T01.tiff: p(treated)=0.9987, p(control)=0.0013\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C09-T01.tiff: p(treated)=0.9988, p(control)=0.0012\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B07-T01.tiff: p(treated)=0.9990, p(control)=0.0010\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C08-T01.tiff: p(treated)=0.9991, p(control)=0.0009\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C02-T01.tiff: p(treated)=0.9992, p(control)=0.0008\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D11-T01.tiff: p(treated)=0.9993, p(control)=0.0007\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C09-T01.tiff: p(treated)=0.9994, p(control)=0.0006\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C03-T01.tiff: p(treated)=0.9994, p(control)=0.0006\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C11-T01.tiff: p(treated)=0.9995, p(control)=0.0005\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C06-T01.tiff: p(treated)=0.9995, p(control)=0.0005\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C03-T01.tiff: p(treated)=0.9997, p(control)=0.0003\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B09-T01.tiff: p(treated)=0.9997, p(control)=0.0003\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F06-T01.tiff: p(treated)=0.9998, p(control)=0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C06-T01.tiff: p(treated)=0.9998, p(control)=0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C05-T01.tiff: p(treated)=0.9998, p(control)=0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C07-T01.tiff: p(treated)=0.9998, p(control)=0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B10-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C02-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C05-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F05-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F02-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E2.tif: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E3.tif: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E06-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E5.tif: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E05-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E4.tif: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B03-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E05-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B03-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E06-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B05-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B06-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E02-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E03-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B02-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B03-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B06-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "\n",
      "Group-Wise Ranking Accuracy:\n",
      "Correct Transitions: 1\n",
      "Total Possible Transitions: 2\n",
      "Ranking Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1], entry[0]) for entry in all_images_data]\n",
    "\n",
    "# Print sorted images\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr, p_ctrl in sorted_by_treated:\n",
    "    print(f\"{img_path}: p(treated)={p_tr:.4f}, p(control)={p_ctrl:.4f}\")\n",
    "\n",
    "# Initialize group-wise data\n",
    "grouped_data = {group: [] for group in groups}\n",
    "for group in groups:\n",
    "    grouped_data[group].extend(groups_data[group])\n",
    "\n",
    "# Step 1: Sort distances and keep track of group membership\n",
    "sorted_distances = []\n",
    "for group, data in grouped_data.items():\n",
    "    for _, p_treated, _ in data:\n",
    "        sorted_distances.append((p_treated, group))\n",
    "\n",
    "sorted_distances.sort(key=lambda x: x[0])  # Sort by p(treated)\n",
    "\n",
    "# Step 2: Check for correct transitions between groups\n",
    "correct_transitions = 0\n",
    "total_transitions = len(groups) - 1  # Total possible adjacent group transitions\n",
    "\n",
    "for i in range(total_transitions):\n",
    "    group_i = groups[i]\n",
    "    group_j = groups[i + 1]\n",
    "\n",
    "    # Get all distances for groups i and j\n",
    "    distances_i = [dist for dist, grp in sorted_distances if grp == group_i]\n",
    "    distances_j = [dist for dist, grp in sorted_distances if grp == group_j]\n",
    "\n",
    "    # Check the condition: all d in G_i < all d in G_j\n",
    "    if all(d_i < d_j for d_i in distances_i for d_j in distances_j):\n",
    "        correct_transitions += 1\n",
    "\n",
    "# Step 3: Calculate ranking accuracy\n",
    "ranking_accuracy = correct_transitions / total_transitions if total_transitions > 0 else 1.0\n",
    "\n",
    "# Step 4: Print the group-wise ranking accuracy\n",
    "print(\"\\nGroup-Wise Ranking Accuracy:\")\n",
    "print(f\"Correct Transitions: {correct_transitions}\")\n",
    "print(f\"Total Possible Transitions: {total_transitions}\")\n",
    "print(f\"Ranking Accuracy: {ranking_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Assuming 'sorted_by_treated' is already defined as:\n",
    "# sorted_by_treated = [(img_path, p_tr), ...] sorted in ascending order by p_tr\n",
    "\n",
    "new_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\sorted_explodall\"\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "for i, (img_path, p_tr) in enumerate(sorted_by_treated, start=1):\n",
    "    # Extract the parent directory name and the original filename\n",
    "    parent_dir_name = os.path.basename(os.path.dirname(img_path))  # e.g. \"cond7\"\n",
    "    base_filename = os.path.basename(img_path)  # e.g. \"ds_41.tif\"\n",
    "    \n",
    "    # Combine them to get \"cond7_ds_41.tif\"\n",
    "    original_filename = f\"{parent_dir_name}_{base_filename}\"\n",
    "\n",
    "    # Format the probability score\n",
    "    formatted_score = f\"{p_tr:.4f}\"\n",
    "    \n",
    "    # Construct the new filename with index and score\n",
    "    new_filename = f\"{i}_{formatted_score}_{original_filename}\"\n",
    "    new_path = os.path.join(new_dir, new_filename)\n",
    "    \n",
    "    shutil.copy2(img_path, new_path)\n",
    "\n",
    "print(\"Images copied and renamed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Assuming 'sorted_by_treated' is already defined as:\n",
    "# sorted_by_treated = [(img_path, p_tr), ...] sorted in ascending order by p_tr\n",
    "\n",
    "new_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\sorted_cond10\"\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "for i, (img_path, p_tr) in enumerate(sorted_by_treated, start=1):\n",
    "    # Extract the parent directory name and the original filename\n",
    "    parent_dir_name = os.path.basename(os.path.dirname(img_path))  # e.g. \"cond7\"\n",
    "    base_filename = os.path.basename(img_path)  # e.g. \"ds_41.tif\"\n",
    "    \n",
    "    # Combine them to get \"cond7_ds_41.tif\"\n",
    "    original_filename = f\"{parent_dir_name}_{base_filename}\"\n",
    "\n",
    "    # Format the probability score\n",
    "    formatted_score = f\"{p_tr:.4f}\"\n",
    "    \n",
    "    # Construct the new filename with index and score\n",
    "    new_filename = f\"{i}_{formatted_score}_{original_filename}\"\n",
    "    new_path = os.path.join(new_dir, new_filename)\n",
    "    \n",
    "    shutil.copy2(img_path, new_path)\n",
    "\n",
    "print(\"Images copied and renamed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#500 epochs, one outlier of exploder in ds closer to sd: which is ds41_g9_C10-T01   inbetween 4 ds closer\n",
    "# 100 epochs, one outlier of exploder also one outlier from ds_clos_tosd ds41_g5_E04-T01\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "#from helper import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model definition\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, feature_dim, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Recreate the model structure\n",
    "feature_dim = 512 # Set this to the same dimension used during training\n",
    "num_classes = 2   # Since you trained for 2 classes\n",
    "logreg_model = LogisticRegression(feature_dim, num_classes).to(device)\n",
    "\n",
    "# Load the saved weights\n",
    "logreg_model.load_state_dict(torch.load(\"best_loss_model.pth\", map_location=device))\n",
    "logreg_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in descending order (highest p(treated) first)\n",
    "all_images_data.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Now all_images_data is sorted by p(treated)\n",
    "# Extract (img_path, p_treated)\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "# Print or handle as needed\n",
    "print(\"Images sorted by p(treated) in descending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup for inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess_Image(image_path):\n",
    "    # Load the image\n",
    "    image = tiff.imread(image_path)\n",
    "    \n",
    "    # Ensure the image has 3 layers (channels)\n",
    "    if image.shape[0] != 3:\n",
    "        raise ValueError(f\"Image at {image_path} does not have exactly 3 layers.\")\n",
    "    \n",
    "    # Normalize the 16-bit image to [0, 1]\n",
    "    image = image.astype(np.float32) / 65535.0\n",
    "    \n",
    "    # Convert to a torch tensor\n",
    "    image = torch.tensor(image, dtype=torch.float32)\n",
    "    \n",
    "    # Resize to (96, 96)\n",
    "    image = TF.resize(image, (96, 96))\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_of_image = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B07-T01.tiff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = Preprocess_Image(path_of_image)\n",
    "print(first_image.shape)\n",
    "prep_first_image = first_image.unsqueeze(0)\n",
    "print(prep_first_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image_np = first_image.numpy().transpose(1, 2, 0)  # (C, H, W) -> (H, W, C)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(first_image_np, cmap='gray')  # Use `cmap='gray'` if it's grayscale\n",
    "plt.title('First Image')\n",
    "plt.axis('off')  # Optional: turn off the axis for a cleaner look\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathimage = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B08-T01.tiff'\n",
    "second_image = Preprocess_Image(pathimage)\n",
    "print(second_image.shape)\n",
    "prep_second_image = second_image.unsqueeze(0)\n",
    "print(prep_second_image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_image_np = second_image.numpy().transpose(1, 2, 0)  # (C, H, W) -> (H, W, C)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(second_image_np, cmap='gray')  # Use `cmap='gray'` if it's grayscale\n",
    "plt.title('second Image')\n",
    "plt.axis('off')  # Optional: turn off the axis for a cleaner look\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extract_features(model, image_tensor):\n",
    "    # prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "    \n",
    "    # Move image tensor to device\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    # Extract features\n",
    "    features = network(image_tensor)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"simclr_model: {simclr_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for both images\n",
    "first_image_feats = extract_features(simclr_model, prep_first_image)\n",
    "second_image_feats = extract_features(simclr_model, prep_second_image)\n",
    "print(first_image_feats.shape)\n",
    "print(second_image_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSINE FROM NEWDATA CROP VAL&INFER\n",
    "# Compute cosine similarity between the feature vectors\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats, second_image_feats, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSINE old data crop\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats, second_image_feats, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\untreated\\D08-T01.tiff'\n",
    "untreated_image = Preprocess_Image(im_path)\n",
    "print(untreated_image.shape)\n",
    "prep_untreated_image = untreated_image.unsqueeze(0)\n",
    "print(prep_untreated_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_image_np = untreated_image.numpy().transpose(1, 2, 0)  # (C, H, W) -> (H, W, C)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(untreated_image_np, cmap='gray')  # Use `cmap='gray'` if it's grayscale\n",
    "plt.title('untreated Image')\n",
    "plt.axis('off')  # Optional: turn off the axis for a cleaner look\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_image_feats = extract_features(simclr_model, prep_untreated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSINE NEW DATA CROP\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats, untreated_image_feats, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine old data crop\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats, untreated_image_feats, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference after projection head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def features_after_projection(model, image_tensor):\n",
    "    # prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    #network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "    \n",
    "    # Move image tensor to device\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    # Extract features\n",
    "    features = network(image_tensor)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for both images\n",
    "first_image_feats_after = features_after_projection(simclr_model, prep_first_image)\n",
    "second_image_feats_after = features_after_projection(simclr_model, prep_second_image)\n",
    "print(first_image_feats_after.shape)\n",
    "print(second_image_feats_after.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine newdata crop \n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats_after, second_image_feats_after, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine old data crop\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats_after, second_image_feats_after, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")\n",
    "\n",
    "#Cosine similarity between features: 0.8507535457611084\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as expected after projection head cosine similarity is higher this leads to the question that maybe for ranking images with time series, this after projection maybe better option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_image_feats_after = features_after_projection(simclr_model, prep_untreated_image)\n",
    "print(untreated_image_feats_after.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between the feature vectors\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats_after, untreated_image_feats_after, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between the feature vectors\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats_after, untreated_image_feats_after, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as expected after projection head cosine similarity is lower for different class images this leads to the question that maybe for ranking images with time series, this after projection maybe better option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orig images (without simclr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_image)\n",
    "first_image.view(-1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(second_image)\n",
    "second_image.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_flat = first_image.view(-1)\n",
    "second_flat = second_image.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_flat.unsqueeze(0).shape == untreated_flat.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "similarity = F.cosine_similarity(first_flat.unsqueeze(0), second_flat.unsqueeze(0))\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_flat = untreated_image.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = F.cosine_similarity(first_flat.unsqueeze(0), untreated_flat.unsqueeze(0))\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_flat == untreated_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "orig without resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Load and normalize both images\n",
    "im1 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B07-T01.tiff')\n",
    "im2 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B08-T01.tiff')\n",
    "\n",
    "# Ensure each image has 3 layers (channels)\n",
    "if im1.shape[0] != 3 or im2.shape[0] != 3:\n",
    "    raise ValueError(\"Each image must have exactly 3 layers.\")\n",
    "\n",
    "# Normalize the 16-bit images to [0, 1]\n",
    "im1 = im1.astype(np.float32) / 65535.0\n",
    "im2 = im2.astype(np.float32) / 65535.0\n",
    "print(im2.shape)\n",
    "\n",
    "# Flatten the 3D images to 1D vectors\n",
    "im1_flattened = im1.flatten()\n",
    "im2_flattened = im2.flatten()\n",
    "print(im2_flattened.shape)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_similarity = np.dot(im1_flattened, im2_flattened) / (norm(im1_flattened) * norm(im2_flattened))\n",
    "\n",
    "print(f\"Cosine Similarity between the two images: {cosine_similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B07-T01.tiff')\n",
    "im2 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\untreated\\D08-T01.tiff')\n",
    "\n",
    "# Ensure each image has 3 layers (channels)\n",
    "if im1.shape[0] != 3 or im2.shape[0] != 3:\n",
    "    raise ValueError(\"Each image must have exactly 3 layers.\")\n",
    "\n",
    "# Normalize the 16-bit images to [0, 1]\n",
    "im1 = im1.astype(np.float32) / 65535.0\n",
    "im2 = im2.astype(np.float32) / 65535.0\n",
    "print(im2.shape)\n",
    "\n",
    "# Flatten the 3D images to 1D vectors\n",
    "im1_flattened = im1.flatten()\n",
    "im2_flattened = im2.flatten()\n",
    "print(im2_flattened.shape)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_similarity = np.dot(im1_flattened, im2_flattened) / (norm(im1_flattened) * norm(im2_flattened))\n",
    "\n",
    "print(f\"Cosine Similarity between the two images: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAS IST DAS?\n",
    "Mach kein Sinn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B07-T01.tiff')\n",
    "img2 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B08-T01.tiff')\n",
    "img3 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\untreated\\D08-T01.tiff')\n",
    "img1_flattened = img1.flatten()\n",
    "img2_flattened = img2.flatten()\n",
    "img3_flattened = img3.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = np.dot(img1_flattened, img2_flattened) / (norm(img1_flattened) * norm(img2_flattened))\n",
    "print(f\"Cosine Similarity between the two images: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = np.dot(img1_flattened, img3_flattened) / (norm(img1_flattened) * norm(img3_flattened))\n",
    "print(f\"Cosine Similarity between the two images: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, if we didn't use simclr and just try to find the cosine similarity between orig images: it doesn't deviate too  much not good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
