{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "#from helper import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Now you can use the `device` variable\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay,max_epochs):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        # Load the pretrained ResNet-18 model\n",
    "        self.convnet = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "        \n",
    "        # Modify the fully connected layer\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4 * hidden_dim),  # Linear layer with 4*hidden_dim output\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * hidden_dim, 20)  # Output layer with hidden_dim output\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.AdamW(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        self.lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=max_epochs, eta_min=lr / 50)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convnet(x)\n",
    "\n",
    "    def info_nce_loss(self, imgs1, imgs2, device):\n",
    "\n",
    "        imgs = torch.cat((imgs1, imgs2), dim=0)  # Concatenate along the batch dimension\n",
    "        imgs = imgs.to(device)  # Move images to the device\n",
    "\n",
    "        # Encode all images\n",
    "        feats = self.forward(imgs)\n",
    "    \n",
    "        # Calculate cosine similarity\n",
    "        cos_sim = nn.functional.cosine_similarity(feats[:, None, :], feats[None, :, :], dim=-1)\n",
    "    \n",
    "        # Mask out cosine similarity to itself\n",
    "        self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "        cos_sim.masked_fill_(self_mask, -9e15)\n",
    "    \n",
    "        # Find positive example -> batch_size//2 away from the original example\n",
    "        pos_mask = self_mask.roll(shifts=cos_sim.shape[0] // 2, dims=0)\n",
    "    \n",
    "        # Normalize similarity scores by temperature\n",
    "        cos_sim = cos_sim / self.temperature\n",
    "\n",
    "        # InfoNCE loss\n",
    "        nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "        nll = nll.mean()\n",
    "\n",
    "        # Accuracy calculations\n",
    "        # Create a combination of positive and negative similarities for ranking\n",
    "        comb_sim = torch.cat([cos_sim[pos_mask][:, None],  # Positive example in first position\n",
    "                          cos_sim.masked_fill(pos_mask, -9e15)], dim=-1)\n",
    "    \n",
    "        # Sort and get the ranking position of the positive example\n",
    "        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
    "    \n",
    "        # Compute accuracy metrics\n",
    "        top1_acc = (sim_argsort == 0).float().mean()  # Top-1 accuracy\n",
    "        top5_acc = (sim_argsort < 5).float().mean()   # Top-5 accuracy\n",
    "        mean_pos = 1 + sim_argsort.float().mean()     # Mean position of the positive example\n",
    "\n",
    "        return nll, top1_acc, top5_acc, mean_pos\n",
    "\n",
    "    def train_epoch(self, train_loader, device):\n",
    "        self.train()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            imgs1, imgs2, _ = batch\n",
    "            imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "        \n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Calculate loss and accuracy metrics\n",
    "            loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            #self.lr_scheduler.step()\n",
    "\n",
    "            # Accumulate metrics\n",
    "            total_loss += loss.item()\n",
    "            total_top1_acc += top1_acc.item()\n",
    "            total_top5_acc += top5_acc.item()\n",
    "            total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(train_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(train_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(train_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos\n",
    "\n",
    "    def validate_epoch(self, val_loader, device):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "                imgs1, imgs2, _ = batch\n",
    "                imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "\n",
    "                # Calculate loss and accuracy metrics\n",
    "                loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "                # Accumulate metrics\n",
    "                total_loss += loss.item()\n",
    "                total_top1_acc += top1_acc.item()\n",
    "                total_top5_acc += top5_acc.item()\n",
    "                total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(val_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(val_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(val_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(val_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos\n",
    "    \n",
    "\n",
    "    def inference_epoch(self, inference_loader, device):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(inference_loader, desc=\"Inferencing\", leave=False):\n",
    "                imgs1, imgs2, _ = batch\n",
    "                imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "\n",
    "                # Calculate loss and accuracy metrics\n",
    "                loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "                # Accumulate metrics\n",
    "                total_loss += loss.item()\n",
    "                total_top1_acc += top1_acc.item()\n",
    "                total_top5_acc += top5_acc.item()\n",
    "                total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(inference_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(inference_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(inference_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(inference_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "model_path = r'C:\\Users\\k54739\\Bibi_new_thesis\\saved_model\\sweetcrop_simclr_model_epoch_245.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_26056\\3778111997.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  simclr_model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (convnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=512, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simclr_model = SimCLR(hidden_dim=128, lr=5e-4, temperature=0.07, weight_decay=1e-4,max_epochs=245)\n",
    "simclr_model.load_state_dict(torch.load(model_path))\n",
    "simclr_model.to(device)\n",
    "simclr_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference before projection head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledImageDataset(Dataset):\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "\n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Convert to a torch tensor and add channel dimension\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        \n",
    "        # Apply resize transform\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def load_and_split_data(root_dir, test_size=0.2):\n",
    "    #classes = ['untreated', 'single_dose', 'drug_screened']\n",
    "    classes = ['control', 'ex_40']\n",
    "    image_files = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(root_dir, class_name)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir) if file.endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        labels.extend([idx] * len(files))\n",
    "    \n",
    "    # Check if the labels correctly reflect the classes\n",
    "    #print(\"Label distribution:\", {classes[i]: labels.count(i) for i in range(len(classes))})\n",
    "    \n",
    "    # Split data into training and test sets\n",
    "    train_files, test_files, train_labels, test_labels = train_test_split(\n",
    "        image_files, labels, test_size=test_size, stratify=labels, random_state=42)\n",
    "\n",
    "    return train_files, test_files, train_labels, test_labels\n",
    "\n",
    "\n",
    "# Directories for labeled data\n",
    "image_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\train_ex\"\n",
    "\n",
    "# Load and split the data\n",
    "train_files, test_files, train_labels, test_labels = load_and_split_data(image_dir, test_size=0.2)\n",
    "\n",
    "# Create the labeled datasets\n",
    "train_labeled_dataset = LabeledImageDataset(train_files, train_labels)\n",
    "test_labeled_dataset = LabeledImageDataset(test_files, test_labels)\n",
    "\n",
    "# Define DataLoaders\n",
    "batch_size = 16\n",
    "train_loader_labeled = DataLoader(train_labeled_dataset, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=0)\n",
    "test_loader_labeled = DataLoader(test_labeled_dataset, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 96, 96]) torch.Size([16]) torch.float32\n",
      "tensor([0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "for anchor,label in train_loader_labeled:\n",
    "    print(anchor.shape, label.shape, anchor.dtype)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in train_loader_labeled: 128\n"
     ]
    }
   ],
   "source": [
    "# Initialize a counter\n",
    "total_images = 0\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for anchor, label in train_loader_labeled:\n",
    "    total_images += anchor.size(0)  # Increment by the batch size (number of images in the current batch)\n",
    "\n",
    "# Print the total number of images\n",
    "print(f\"Total number of images in train_loader_labeled: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in test_loader_labeled: 32\n"
     ]
    }
   ],
   "source": [
    "# Initialize a counter\n",
    "total_images = 0\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for anchor, label in test_loader_labeled:\n",
    "    total_images += anchor.size(0)  # Increment by the batch size (number of images in the current batch)\n",
    "\n",
    "# Print the total number of images\n",
    "print(f\"Total number of images in test_loader_labeled: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_data_features(model, dataloader):\n",
    "    # Prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    # Encode all images\n",
    "    feats, labels = [], []\n",
    "    for batch_imgs, batch_labels in tqdm(dataloader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        print(f\"Batch features shape: {batch_feats.shape}\")\n",
    "        print(f\"Batch labels shape: {batch_labels.shape}\")\n",
    "        \n",
    "        feats.append(batch_feats.detach().cpu())\n",
    "        labels.append(batch_labels)\n",
    "\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    \n",
    "    print(f\"Features shape after concatenation: {feats.shape}\")\n",
    "    print(f\"Labels shape after concatenation: {labels.shape}\")\n",
    "\n",
    "    return torch.utils.data.TensorDataset(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:00<00:06,  1.02it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:01<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:02<00:03,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:03<00:02,  1.40it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [00:03<00:02,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [00:04<00:01,  1.47it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 88%|████████▊ | 7/8 [00:04<00:00,  1.50it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Features shape after concatenation: torch.Size([128, 512])\n",
      "Labels shape after concatenation: torch.Size([128])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.49it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.45it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Features shape after concatenation: torch.Size([32, 512])\n",
      "Labels shape after concatenation: torch.Size([32])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract features for train and test datasets\n",
    "train_feats_simclr = prepare_data_features(simclr_model, train_loader_labeled)\n",
    "test_feats_simclr = prepare_data_features(simclr_model, test_loader_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model definition\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, feature_dim, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_logistic_regression(model, train_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch_feats, batch_labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        batch_feats, batch_labels = batch_feats.to(device), batch_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_feats)\n",
    "        loss = nn.functional.cross_entropy(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_logistic_regression(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_feats, batch_labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            batch_feats, batch_labels = batch_feats.to(device), batch_labels.to(device)\n",
    "            \n",
    "            outputs = model(batch_feats)\n",
    "            loss = nn.functional.cross_entropy(outputs, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logreg_simplified(batch_size, train_feats_data, test_feats_data, feature_dim, num_classes, lr=5e-4, weight_decay=1e-4, max_epochs=50):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_feats_data, batch_size=batch_size, shuffle=True,\n",
    "                              drop_last=False, pin_memory=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_feats_data, batch_size=batch_size, shuffle=False,\n",
    "                             drop_last=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "    # Model, loss, and optimizer\n",
    "    model = LogisticRegression(feature_dim, num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                               milestones=[int(max_epochs * 0.6), int(max_epochs * 0.8)],\n",
    "                                               gamma=0.1)\n",
    "\n",
    "    # Store metrics for plotting\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    # Track best by accuracy\n",
    "    best_test_acc = -1.0\n",
    "    best_model_state_acc = None\n",
    "\n",
    "    # Track best by loss (with accuracy as a tiebreaker)\n",
    "    best_test_loss = float('inf')\n",
    "    best_test_loss_acc = -1.0\n",
    "    best_model_state_loss = None\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{max_epochs}\")\n",
    "\n",
    "        train_loss, train_acc = train_logistic_regression(model, train_loader, optimizer, scheduler, device)\n",
    "        test_loss, test_acc = evaluate_logistic_regression(model, test_loader, criterion, device)\n",
    "\n",
    "        print(f\"Training loss: {train_loss:.4f}, Training accuracy: {train_acc:.4f}\")\n",
    "        print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        test_accuracies.append(test_acc)\n",
    "\n",
    "        # Check for best accuracy model\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            best_model_state_acc = model.state_dict()\n",
    "\n",
    "        # Check for best loss model\n",
    "        # Condition: strictly lower loss OR equal loss but higher accuracy\n",
    "        if (test_loss < best_test_loss) or (test_loss == best_test_loss and test_acc > best_test_loss_acc):\n",
    "            best_test_loss = test_loss\n",
    "            best_test_loss_acc = test_acc\n",
    "            best_model_state_loss = model.state_dict()\n",
    "\n",
    "    # Now we have two best states: best_model_state_acc and best_model_state_loss\n",
    "    # Create two separate model instances for them\n",
    "    best_acc_model = LogisticRegression(feature_dim, num_classes).to(device)\n",
    "    best_acc_model.load_state_dict(best_model_state_acc)\n",
    "    best_acc_model.eval()\n",
    "\n",
    "    best_loss_model = LogisticRegression(feature_dim, num_classes).to(device)\n",
    "    best_loss_model.load_state_dict(best_model_state_loss)\n",
    "    best_loss_model.eval()\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Loss curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(max_epochs), train_losses, label='Train Loss')\n",
    "    plt.plot(range(max_epochs), test_losses, label='Test Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(max_epochs), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(max_epochs), test_accuracies, label='Test Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Return both models and the final results (e.g., last train_acc and test_acc recorded)\n",
    "    return best_acc_model, best_loss_model, {\"train_acc\": train_acc, \"test_acc\": test_acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 109.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2623.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1822, Training accuracy: 0.9375\n",
      "Test loss: 0.0732, Test accuracy: 1.0000\n",
      "Epoch 2/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 233.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0527, Training accuracy: 0.9844\n",
      "Test loss: 0.0269, Test accuracy: 1.0000\n",
      "Epoch 3/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 171.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0267, Training accuracy: 1.0000\n",
      "Test loss: 0.0158, Test accuracy: 1.0000\n",
      "Epoch 4/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 196.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 201.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0186, Training accuracy: 1.0000\n",
      "Test loss: 0.0120, Test accuracy: 1.0000\n",
      "Epoch 5/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 214.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0127, Training accuracy: 1.0000\n",
      "Test loss: 0.0089, Test accuracy: 1.0000\n",
      "Epoch 6/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 178.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 285.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0100, Training accuracy: 1.0000\n",
      "Test loss: 0.0072, Test accuracy: 1.0000\n",
      "Epoch 7/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 243.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0083, Training accuracy: 1.0000\n",
      "Test loss: 0.0060, Test accuracy: 1.0000\n",
      "Epoch 8/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 166.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 262.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0069, Training accuracy: 1.0000\n",
      "Test loss: 0.0051, Test accuracy: 1.0000\n",
      "Epoch 9/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 200.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0059, Training accuracy: 1.0000\n",
      "Test loss: 0.0044, Test accuracy: 1.0000\n",
      "Epoch 10/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 142.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 297.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0052, Training accuracy: 1.0000\n",
      "Test loss: 0.0039, Test accuracy: 1.0000\n",
      "Epoch 11/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 143.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 250.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0045, Training accuracy: 1.0000\n",
      "Test loss: 0.0034, Test accuracy: 1.0000\n",
      "Epoch 12/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 186.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0041, Training accuracy: 1.0000\n",
      "Test loss: 0.0031, Test accuracy: 1.0000\n",
      "Epoch 13/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 197.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 226.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0036, Training accuracy: 1.0000\n",
      "Test loss: 0.0028, Test accuracy: 1.0000\n",
      "Epoch 14/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 157.78it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 199.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0033, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 15/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 222.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0030, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 16/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 220.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0027, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 17/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 185.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 259.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 18/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 19/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 224.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0022, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 20/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 196.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0020, Training accuracy: 1.0000\n",
      "Test loss: 0.0015, Test accuracy: 1.0000\n",
      "Epoch 21/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 152.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 298.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0014, Test accuracy: 1.0000\n",
      "Epoch 22/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 186.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0014, Test accuracy: 1.0000\n",
      "Epoch 23/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 223.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0013, Test accuracy: 1.0000\n",
      "Epoch 24/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 184.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 301.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0012, Test accuracy: 1.0000\n",
      "Epoch 25/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 180.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 187.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0011, Test accuracy: 1.0000\n",
      "Epoch 26/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 218.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0014, Training accuracy: 1.0000\n",
      "Test loss: 0.0011, Test accuracy: 1.0000\n",
      "Epoch 27/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 225.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0010, Test accuracy: 1.0000\n",
      "Epoch 28/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 213.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0010, Test accuracy: 1.0000\n",
      "Epoch 29/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 195.44it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 205.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0010, Test accuracy: 1.0000\n",
      "Epoch 30/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 149.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 229.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 31/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 188.94it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 32/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 230.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 33/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 153.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 259.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 34/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 262.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 213.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 35/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 198.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 36/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 236.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 119.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 37/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 134.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 38/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 168.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 39/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 200.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 40/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 165.23it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 219.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 41/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 186.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 42/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.69it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 43/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 231.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 44/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 45/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 238.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 46/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 47/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 188.94it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 48/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.70it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 546.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 49/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 166.19it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 50/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 189.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 51/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 188.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 52/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 166.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 53/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 174.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 54/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 128.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 55/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 232.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 56/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 236.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 57/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 223.53it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 122.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 58/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 59/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 205.44it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 127.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 60/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 204.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 61/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 8050.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 62/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 242.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 63/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 181.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 64/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 196.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 221.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 65/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 238.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 66/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 241.54it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 212.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 67/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 212.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 68/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 196.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 248.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 69/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 196.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 188.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 70/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 165.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 71/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 127.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 72/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 188.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 73/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 158.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 74/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 199.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 185.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 75/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 197.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 76/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 185.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 172.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 77/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 207.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 211.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 78/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 185.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 79/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 175.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 364.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 80/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 274.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 81/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 178.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 82/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 182.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 157.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 83/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 179.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 84/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 123.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 85/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 86/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 189.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 87/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 617.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 88/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 143.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 89/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 184.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 90/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 164.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 107.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 91/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 92/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 93/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 150.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 94/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 153.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 224.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 95/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 189.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 96/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 127.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 97/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 127.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 98/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 99/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 137.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 512.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 100/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 164.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 206.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 101/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 163.16it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 102/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 196.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 103/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 155.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 549.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 104/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 158.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 120.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 105/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 195.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 182.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 106/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 200.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 107/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 192.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 108/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 208.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 109/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 146.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 700.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 110/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 165.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 111/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 171.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 112/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 142.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 113/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 189.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 127.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 114/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 183.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 115/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 196.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 116/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 176.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 117/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 135.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 125.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 118/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 197.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 119/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 120/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 185.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 121/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 137.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 122/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 144.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 123/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 188.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 198.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 124/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 120.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 125/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 206.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 194.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 126/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 139.78it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 127/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 127.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 292.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 128/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 184.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 136.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 129/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 163.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 130/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 182.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 131/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 148.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1033.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 132/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 143.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 218.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 133/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 134/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 157.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 135/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 174.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 136/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 163.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 137/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 419.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 138/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 172.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 139/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 140/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 184.69it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 141/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 180.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 306.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 142/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 173.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 225.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 143/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 144/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 180.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 145/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 130.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 146/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 176.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 221.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 147/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 174.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 414.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 148/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 127.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 149/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 184.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 200.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 150/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 170.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 151/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 185.53it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 152/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 218.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 153/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 197.78it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 185.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 154/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 163.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 230.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 155/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 197.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 219.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 156/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 157.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 157/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 158/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 159/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 160/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 181.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 142.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 161/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 121.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 162/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 115.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 168.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 163/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 157.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 164/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 236.99it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 164.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 165/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 215.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 166/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 203.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 167/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 168/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 169/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 170/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 188.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 124.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 171/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 224.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 187.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 172/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 175.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 173/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 187.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 174/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 175/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 155.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 176/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 188.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 177/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 158.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 178/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 179/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 180/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 153.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 128.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 181/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 154.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 270.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 182/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 183/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 184/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 185/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 186/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 202.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 187/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 163.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 198.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 188/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 198.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 189/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 186.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 127.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 190/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 189.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 191/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 187.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 192/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 158.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 193/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 194/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 189.19it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 195/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.90it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 196/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 197/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 225.69it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 198/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 241.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 219.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 199/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 200/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 153.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 201/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 204.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 202/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 207.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 145.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 203/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 204/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 175.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 205/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 157.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 206/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 187.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 208.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 207/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.90it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 191.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 208/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 137.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 209/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 167.99it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 199.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 210/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 137.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 138.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 211/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 206.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 251.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 212/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 213/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 212.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 263.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 214/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 177.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 215/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 117.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 193.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 216/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 135.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 217.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 217/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 163.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 487.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 218/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 334.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 510.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 219/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 296.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 493.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 220/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 282.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 489.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 221/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 284.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 442.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 222/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 302.90it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 250.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 223/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 185.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 266.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 224/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 306.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 441.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 225/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 296.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 457.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 226/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 313.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 503.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 227/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 344.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 228/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 322.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 229/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 320.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 230/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 323.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 231/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 240.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 211.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 232/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 311.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 203.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 233/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 286.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 401.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 234/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 288.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 235/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 316.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 236/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 311.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 237/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 320.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 238/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 292.99it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 239/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 320.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 264.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 240/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 272.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 446.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 241/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 300.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 498.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 242/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 573.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 445.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 243/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 402.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 244/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 451.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 203.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 245/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 380.50it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 496.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 246/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 348.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 563.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 247/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 381.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 505.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 248/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 198.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 270.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 249/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 182.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 261.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 250/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 184.94it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 283.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 251/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 212.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 276.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 252/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 163.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 23831.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 253/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 230.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 254/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 183.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 230.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 255/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 141.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 256/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 140.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 190.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 257/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 266.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 791.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 258/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 319.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 562.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 259/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 319.50it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 260/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 241.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 261/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 312.23it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 262/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 314.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 199.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 263/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 321.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 204.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 264/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 375.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 265/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 314.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 266/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 316.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 267/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 219.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 508.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 268/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 301.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 269/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 248.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 270/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 319.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 271/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 240.90it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 272/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 328.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 212.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 273/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 242.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 274/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 312.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 275/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 317.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 276/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 326.51it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 277/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 277.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1972.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 278/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 316.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 279/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 258.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 395.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 280/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 238.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 466.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 281/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 359.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 496.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 282/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 340.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 572.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 283/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 378.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 487.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 284/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 520.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 285/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 319.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 286/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 386.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 8081.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 287/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 310.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 288/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 336.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 289/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 316.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 290/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 449.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 291/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 311.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 292/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 251.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 444.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 293/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 371.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 285.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 294/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 155.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 295/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 237.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 202.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 296/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 333.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 297/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 288.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 568.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 298/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 327.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 480.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 299/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 333.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 568.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 300/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 323.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 301/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 327.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 223.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 302/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 363.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 981.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 303/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 347.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 502.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 304/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 373.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 558.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 305/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 391.54it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 506.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 306/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 340.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 500.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 307/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 365.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 499.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 308/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 319.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 387.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 309/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 322.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 570.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 310/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 323.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 500.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 311/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 377.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 312/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 368.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 499.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 313/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 355.94it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 571.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 314/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 323.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 499.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 315/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 523.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 316/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 278.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 570.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 317/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 479.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 195.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 318/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 532.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 319/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 323.70it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 320/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 323.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 321/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 444.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 322/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 331.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 587.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 323/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 342.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 571.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 324/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 447.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 272.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 325/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 488.02it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1486.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 326/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 334.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 327/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 328/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 212.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 329/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 164.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 330/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 189.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 331/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 332/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 182.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 333/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 334/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 183.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 335/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 248.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 336/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 184.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 337/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 188.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 207.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 338/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 202.90it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 339/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 340/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 188.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 341/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 197.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 342/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 164.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 5157.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 343/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 344/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 189.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 345/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 181.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 346/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 197.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 212.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 347/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 223.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 348/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.02it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 349/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 208.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 350/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 166.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 351/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 208.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 352/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 188.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 353/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 354/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 355/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 141.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 356/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 179.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 339.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 357/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 179.69it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 358/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 359/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 360/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 361/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 362/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 363/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 191.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 364/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 164.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 365/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 120.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 366/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 223.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 367/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 368/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 369/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 370/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.67it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 371/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 187.53it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 215.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 372/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 373/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 158.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 374/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 227.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 375/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 245.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 376/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 163.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 377/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 378/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 188.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 248.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 379/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 380/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.69it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 381/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 4770.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 382/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 383/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 384/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 247.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 385/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 386/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 183.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 387/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 200.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 388/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 221.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 389/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 195.54it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 216.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 390/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 195.44it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 225.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 391/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 392/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 214.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 393/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 394/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 395/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.53it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 396/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 188.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 250.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 397/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 156.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 398/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 213.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 399/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 400/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 189.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 401/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 156.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 402/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 230.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 403/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 158.50it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 251.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 404/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 405/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 187.50it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 406/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 407/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 408/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 188.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 218.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 409/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 195.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 743.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 410/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 164.54it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 225.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 411/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.67it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 412/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3198.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 413/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 189.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 414/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 415/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 416/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 178.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 417/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 209.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 152.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 418/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 219.02it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 121.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 419/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 173.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 617.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 420/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 148.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 368.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 421/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 163.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 422/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 423/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.50it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 424/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 425/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 158.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 160.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 426/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 168.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 416.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 427/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 164.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2552.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 428/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.19it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 229.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 429/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 195.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 430/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 247.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 431/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.94it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 432/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 188.99it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 126.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 433/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 434/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 435/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 436/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 227.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 437/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 222.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 438/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 172.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 439/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 210.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 142.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 440/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 441/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 206.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 442/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 196.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 443/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 170.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 482.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 444/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 445/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 446/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 447/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 448/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.02it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 449/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 450/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 153.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 294.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 451/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 170.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1603.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 452/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.53it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 227.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 453/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 454/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 455/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 456/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 229.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 457/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 458/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 459/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 250.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 460/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 461/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 222.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 462/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 176.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 463/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 209.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 130.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 464/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 179.90it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 329.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 465/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 167.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 247.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 466/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 467/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 468/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.67it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 469/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 470/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 471/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 472/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 127.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 473/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 183.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 298.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 474/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 165.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 475/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 160.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 476/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 174.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 250.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 477/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 478/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 248.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 479/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 203.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 480/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 167.70it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 481/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 177.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 483.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 482/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 155.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 287.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 483/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 484/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 485/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 9714.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 486/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 487/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 169.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 488/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 172.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 489/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 490/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 141.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 491/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 165.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 604.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 492/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 158.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 218.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 493/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 198.90it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 223.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 494/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 495/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 496/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.78it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 124.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 497/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 241.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 226.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 498/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 499/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 143.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 500/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 153.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 501/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.67it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 220.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 502/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 503/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 229.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 504/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 230.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 505/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 506/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 169.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 507/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 214.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 134.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 508/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 168.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 749.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 509/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 510/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 158.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 511/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 230.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 512/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3137.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 513/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 189.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 514/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.70it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 515/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 138.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 516/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 169.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 180.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 517/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 518/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 519/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.53it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 520/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 137.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 521/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 271.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 522/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 523/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 135.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 283.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 524/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 525/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 526/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 527/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 195.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 528/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.94it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 245.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 529/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 530/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 226.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 531/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 258.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 532/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 533/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 204.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 534/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 202.67it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 535/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 188.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 248.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 536/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 177.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 408.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 537/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 158.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 251.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 538/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 539/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 540/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 206.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 541/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 165.51it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 542/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 215.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 543/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 544/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 118.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 545/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 546/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 547/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 137.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 223.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 548/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 10401.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 549/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.16it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 550/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 551/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 121.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 552/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 553/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 554/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 555/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 556/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 557/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 558/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 187.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 278.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 559/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.54it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 122.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 560/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 243.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2933.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 561/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 147.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 562/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 172.19it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 337.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 563/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 178.78it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 444.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 564/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 565/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 566/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 136.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 245.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 567/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 185.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 568/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 163.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 569/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 163.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 570/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 571/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 229.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 572/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 137.69it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 245.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 573/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 188.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 574/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 168.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 575/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 158.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 731.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 576/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 158.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 577/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 149.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 434.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 578/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 579/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 163.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 580/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 165.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 419.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 581/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 582/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 583/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 251.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 584/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 585/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 586/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 587/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 136.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 198.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 588/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 204.19it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 129.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 589/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 183.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 364.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 590/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 591/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1923.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 592/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 593/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 594/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 164.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 595/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 596/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 597/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.51it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 598/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 170.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 599/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 213.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 138.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 600/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 183.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 247.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 601/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 165.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 220.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 602/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 207.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 603/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 200.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 227.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 604/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 605/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.16it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 606/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 607/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 608/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 609/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 144.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 610/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 165.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 753.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 611/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 208.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 612/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 613/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 220.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 614/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 615/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 616/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 617/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 155.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 618/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 180.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 619/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 620/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.67it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 275.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 621/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 120.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 622/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 623/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2899.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 624/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 167.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 625/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 178.66it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 250.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 626/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 183.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 332.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 627/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 165.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1831.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 628/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 629/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 212.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 630/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 631/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.78it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 121.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 632/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 633/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 149.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 455.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 634/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 250.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 635/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 239.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3018.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 636/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 637/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 638/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 168.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 639/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 211.44it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 150.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 640/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 180.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 641/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 183.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 356.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 642/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 171.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 844.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 643/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 156.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 276.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 644/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 245.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 645/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 646/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 119.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 647/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 648/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 188.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 649/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 229.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 650/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 131.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 372.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 651/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 164.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 652/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 186.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 271.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 653/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 136.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 654/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 655/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 656/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.02it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 4199.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 657/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 658/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 150.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 417.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 659/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 165.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2554.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 660/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 661/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 662/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 663/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 664/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 665/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 666/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 150.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 667/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 182.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 260.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 668/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 153.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 669/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 153.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 670/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 671/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.69it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 672/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 673/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 674/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 248.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 675/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 210.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 676/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 201.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 205.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 677/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 203.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 118.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 678/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 167.53it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1638.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 679/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 156.99it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 267.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 680/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 681/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 682/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 119.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 683/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 684/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 685/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 131.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 411.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 686/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.67it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 687/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 688/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 137.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 689/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 178.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 545.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 690/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 691/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.50it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 692/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 119.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 693/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 694/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 695/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 696/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 204.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 697/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 172.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 762.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 698/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 699/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 248.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 700/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3761.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 701/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 702/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 703/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 166.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 704/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 705/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 185.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 283.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 706/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 123.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 707/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 224.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 708/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 194.66it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3138.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 709/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 219.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 710/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 164.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 711/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.90it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 712/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 124.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 713/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 714/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.44it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 715/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 716/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 717/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 718/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 208.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 719/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.54it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 720/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 721/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 722/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 190.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 723/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 724/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 725/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 726/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 727/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 204.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 728/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 164.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 248.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 729/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 730/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 731/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 159.66it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 732/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 163.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 733/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 161.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 734/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 735/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 736/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 737/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 157.78it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 247.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 738/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 739/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 740/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 208.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 741/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 164.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 245.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 742/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 160.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 743/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 193.44it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 144.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 744/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 228.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 284.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 745/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 180.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 367.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 746/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 162.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 747/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 191.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 748/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 137.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 749/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 156.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 278.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 750/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 16/16 [00:00<00:00, 192.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the logistic regression model\n",
    "# Example usage:\n",
    "best_acc_model, best_loss_model, results = train_logreg_simplified(\n",
    "    batch_size=8,\n",
    "    train_feats_data=train_feats_simclr,\n",
    "    test_feats_data=test_feats_simclr,\n",
    "    feature_dim=train_feats_simclr.tensors[0].shape[1],\n",
    "    num_classes=2,\n",
    "    lr=5e-4,\n",
    "    weight_decay=1e-4,\n",
    "    max_epochs=750\n",
    ")\n",
    "#print(f\"Final Train Accuracy: {results['train_acc']:.4f}, Final Test Accuracy: {results['test_acc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (linear): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model= best_loss_model\n",
    "logreg_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the logistic regression model\n",
    "# Example usage:\n",
    "best_acc_model, best_loss_model, results = train_logreg_simplified(\n",
    "    batch_size=8,\n",
    "    train_feats_data=train_feats_simclr,\n",
    "    test_feats_data=test_feats_simclr,\n",
    "    feature_dim=train_feats_simclr.tensors[0].shape[1],\n",
    "    num_classes=2,\n",
    "    lr=5e-4,\n",
    "    weight_decay=1e-4,\n",
    "    max_epochs=100\n",
    ")\n",
    "#print(f\"Final Train Accuracy: {results['train_acc']:.4f}, Final Test Accuracy: {results['test_acc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best models by accuracy and loss\n",
    "torch.save(best_acc_model.state_dict(), \"1000epoch_best_acc_model.pth\")\n",
    "torch.save(best_loss_model.state_dict(), \"1000epoch_best_loss_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(512,2)\n",
    "logreg_model = logreg_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_22448\\4036842466.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\"1000epoch_best_loss_model.pth\")  # Load weights from the file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (linear): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Step 2: Load the saved state dict\n",
    "state_dict = torch.load(\"1000epoch_best_loss_model.pth\")  # Load weights from the file\n",
    "logreg_model.load_state_dict(state_dict)  # Load state dict into the model\n",
    "\n",
    "# Step 3: Set the model to evaluation mode (if not training)\n",
    "logreg_model.eval()  # This disables dropout and batchnorm for inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 512= feature_dim = train_feats_simclr.tensors[0].shape[1] =  before projection head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model state_dict\n",
    "torch.save(logreg_model.state_dict(), \"logreg_model_best.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1000 epochs: no outlier amoung exploded, control7, single dose\n",
    "#500 epochs, one outlier of exploder in ds closer to sd: which is ds41_g9_C10-T01   inbetween 4 ds closer\n",
    "# 100 epochs, one outlier of exploder also one outlier from ds_clos_tosd ds41_g5_E04-T01\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we got 100 % down checking whether we will get it by repeating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 18/18 [00:11<00:00,  1.50it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sorted by p(treated) in ascending order:\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B07-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B02-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D07-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F08-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B11-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D08-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E05-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C02-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C05-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F06-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B04-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F04-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C11-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D08-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F07-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D11-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E02-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F06-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C09-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G04-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E07-T01.tiff: 0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E09-T01.tiff: 0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B09-T01.tiff: 0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C03-T01.tiff: 0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D05-T01.tiff: 0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C06-T01.tiff: 0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B11-T01.tiff: 0.0003\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B10-T01.tiff: 0.0004\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F09-T01.tiff: 0.0005\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D10-T01.tiff: 0.0008\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D10-T01.tiff: 0.0009\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E06-T01.tiff: 0.0009\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G10-T01.tiff: 0.0011\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G10-T01.tiff: 0.0013\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B10-T01.tiff: 0.0013\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B02-T01.tiff: 0.0014\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C08-T01.tiff: 0.0014\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B08-T01.tiff: 0.0015\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C07-T01.tiff: 0.0016\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F10-T01.tiff: 0.0017\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B04-T01.tiff: 0.0017\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D08-T01.tiff: 0.0018\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E07-T01.tiff: 0.0021\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C07-T01.tiff: 0.0024\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D08-T01.tiff: 0.0026\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B07-T01.tiff: 0.0028\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D07-T01.tiff: 0.0031\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E3.tif: 0.0035\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B10-T01.tiff: 0.0044\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B11-T01.tiff: 0.0052\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C10-T01.tiff: 0.0058\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G09-T01.tiff: 0.0060\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E09-T01.tiff: 0.0062\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F11-T01.tiff: 0.0065\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B03-T01.tiff: 0.0077\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D09-T01.tiff: 0.0078\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G10-T01.tiff: 0.0082\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B04-T01.tiff: 0.0083\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E5.tif: 0.0094\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B07-T01.tiff: 0.0100\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G07-T01.tiff: 0.0107\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C10-T01.tiff: 0.0120\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F08-T01.tiff: 0.0127\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D09-T01.tiff: 0.0142\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C09-T01.tiff: 0.0164\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E08-T01.tiff: 0.0167\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D11-T01.tiff: 0.0178\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F10-T01.tiff: 0.0186\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C10-T01.tiff: 0.0215\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G09-T01.tiff: 0.0225\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F07-T01.tiff: 0.0235\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B08-T01.tiff: 0.0275\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E07-T01.tiff: 0.0287\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E07-T01.tiff: 0.0293\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C09-T01.tiff: 0.0357\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C11-T01.tiff: 0.0360\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D11-T01.tiff: 0.0431\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C08-T01.tiff: 0.0440\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G07-T01.tiff: 0.0456\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B04-T01.tiff: 0.0492\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C11-T01.tiff: 0.0513\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D08-T01.tiff: 0.0587\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E09-T01.tiff: 0.0604\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B03-T01.tiff: 0.0604\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B06-T01.tiff: 0.0612\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F10-T01.tiff: 0.0614\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E4.tif: 0.0645\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B08-T01.tiff: 0.0693\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F09-T01.tiff: 0.0785\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D07-T01.tiff: 0.0799\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E11-T01.tiff: 0.0855\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B05-T01.tiff: 0.0856\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E05-T01.tiff: 0.0898\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D07-T01.tiff: 0.0908\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G07-T01.tiff: 0.0983\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B09-T01.tiff: 0.1068\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E10-T01.tiff: 0.1128\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B11-T01.tiff: 0.1130\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E03-T01.tiff: 0.1166\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B10-T01.tiff: 0.1337\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B09-T01.tiff: 0.1485\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C08-T01.tiff: 0.1507\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G08-T01.tiff: 0.1553\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F09-T01.tiff: 0.1878\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G09-T01.tiff: 0.2098\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E11-T01.tiff: 0.2474\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C10-T01.tiff: 0.2783\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F07-T01.tiff: 0.3249\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E04-T01.tiff: 0.3524\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F07-T01.tiff: 0.3633\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G08-T01.tiff: 0.3867\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G11-T01.tiff: 0.4160\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E09-T01.tiff: 0.4253\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B08-T01.tiff: 0.4349\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G08-T01.tiff: 0.4683\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C08-T01.tiff: 0.4699\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D09-T01.tiff: 0.4810\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D10-T01.tiff: 0.5213\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C07-T01.tiff: 0.5258\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E2.tif: 0.5904\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G11-T01.tiff: 0.5953\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F11-T01.tiff: 0.6393\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B07-T01.tiff: 0.7306\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B09-T01.tiff: 0.7519\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E04-T01.tiff: 0.7677\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B03-T01.tiff: 0.8396\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B07-T01.tiff: 0.8506\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F08-T01.tiff: 0.8901\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E06-T01.tiff: 0.8975\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E06-T01.tiff: 0.9026\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D11-T01.tiff: 0.9299\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E10-T01.tiff: 0.9301\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E05-T01.tiff: 0.9366\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B11-T01.tiff: 0.9377\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C09-T01.tiff: 0.9381\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F09-T01.tiff: 0.9382\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F11-T01.tiff: 0.9390\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C07-T01.tiff: 0.9454\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E10-T01.tiff: 0.9557\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E02-T01.tiff: 0.9624\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E11-T01.tiff: 0.9651\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F08-T01.tiff: 0.9729\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D09-T01.tiff: 0.9791\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D10-T01.tiff: 0.9835\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D08-T01.tiff: 0.9899\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G11-T01.tiff: 0.9925\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E08-T01.tiff: 0.9951\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_c10.tif: 0.9988\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C7.tif: 0.9990\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C11.tif: 0.9992\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C8.tif: 0.9993\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C9.tif: 0.9994\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C10-T01.tiff: 0.9994\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F03-T01.tiff: 0.9994\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B08-T01.tiff: 0.9995\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C07-T01.tiff: 0.9997\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C04-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g9_C10-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C03-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C09-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C05-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C03-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C05-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C02-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F02-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C02-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F05-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B11-T01.tiff: 1.0000\n"
     ]
    }
   ],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending ordergroups_data[group_name]\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images copied and renamed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Assuming 'sorted_by_treated' is already defined as:\n",
    "# sorted_by_treated = [(img_path, p_tr), ...] sorted in ascending order by p_tr\n",
    "\n",
    "new_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\sort_ex_85\"\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "for i, (img_path, p_tr) in enumerate(sorted_by_treated, start=1):\n",
    "    # Extract the parent directory name and the original filename\n",
    "    parent_dir_name = os.path.basename(os.path.dirname(img_path))  # e.g. \"cond7\"\n",
    "    base_filename = os.path.basename(img_path)  # e.g. \"ds_41.tif\"\n",
    "    \n",
    "    # Combine them to get \"cond7_ds_41.tif\"\n",
    "    original_filename = f\"{parent_dir_name}_{base_filename}\"\n",
    "\n",
    "    # Format the probability score\n",
    "    formatted_score = f\"{p_tr:.4f}\"\n",
    "    \n",
    "    # Construct the new filename with index and score\n",
    "    new_filename = f\"{i}_{formatted_score}_{original_filename}\"\n",
    "    new_path = os.path.join(new_dir, new_filename)\n",
    "    \n",
    "    shutil.copy2(img_path, new_path)\n",
    "\n",
    "print(\"Images copied and renamed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 18/18 [00:12<00:00,  1.42it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA1IAAAHUCAYAAAAwUBnrAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjkuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8hTgPZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABUHklEQVR4nO3dd3gU5d7/8c+ShPRGIA1CAKVXlXIIekJHEBBR4NAj4iPSBFSkiARU0HBAHkGwHLrELjycIyIRBERQA4IoIIhUhRBKSCEhdX5/+MseliSQiSG7gffruvbSmbln5jubG9hP7pl7LYZhGAIAAAAAFFsFexcAAAAAAOUNQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKQLmQnZ2tevXq6ZVXXrF3KYqNjdX8+fNvyrGXL18ui8Wi48ePW9cNHjxYvXr1KvYxatSoIYvFIovFogoVKsjX11f169fXkCFDtHHjxkL3sVgsio6ONlXr+vXrTe9T2Lnyr3nXrl2mj1WU06dPKzo6Wnv37i2wLTo6WhaLpdTOVRLZ2dkKDg6WxWLRxx9/bNdaysK6detksVgUEBCgzMzMQtvUqFFDUVFR1uXjx4/LYrFo+fLlxTrH2bNnNWXKFDVr1kw+Pj6qWLGiqlWrpt69e2vdunXKzc0thSsBgP8iSAEoFxYtWqSkpCSNGTPG3qXc1CBVmOjoaH322WfavHlzsfdp06aNdu7cqR07duiTTz7R6NGjdezYMXXp0kWPPPKIsrOzbdrv3LlTw4cPN1XX+vXrNWPGDFP7lPRcZp0+fVozZswoNEgNHz5cO3fuvKnnv5H//Oc/Onv2rCRpyZIldq2lLORf48WLF7V27dpSP/63336rxo0b65133lHPnj31/vvv68svv9Qrr7wiFxcX9e7du9iBDACKy9neBQDAjeTk5GjOnDkaNmyYPD097V2OKbm5ucrJyZGrq2uJj3HHHXfo/vvv1yuvvKL27dsXax8/Pz/97W9/sy537NhRo0aNUnR0tGbMmKHnn39er776qnX71W1vBsMwdOXKFbm7u9/0c91ItWrVVK1aNbvWsGTJElWsWFGRkZHauHGjfv/991KrKT09XR4eHqVyrNKQkJCg9evXq3379tqxY4eWLFmifv36ldrxL126pF69esnLy0vffPONQkJCbLYPGjRI+/bt04ULF657nIyMDLm5udl9tBJA+cGIFAC7yL+9as+ePerdu7d8fHzk6+urQYMG6dy5czZt161bpz/++EODBw8ucJxffvlF/fv3V1BQkFxdXVW9enUNGTLE5vahn3/+WQ8++KD8/f3l5uamZs2aacWKFTbH2bJliywWi9577z1NnTpVoaGh8vHxUceOHXXo0CFru7Zt2+qzzz7TiRMnrLfP5X/wyr8VKSYmRi+99JJq1qwpV1dXffXVV9braN26tTw8POTt7a1OnToVe2Rk8ODB+vLLL/Xbb78V7w0uQnR0tBo2bKiFCxfqypUr1vXX3m6Xnp6uZ555RjVr1pSbm5sqVaqk5s2b67333pMkRUVF6Y033rDum//KvyXRYrFo9OjRevPNN1W/fn25urpa3/OibiNMSkrSo48+qkqVKsnT01M9evTQ0aNHbdpce/tXvrZt26pt27aS/vxZtmjRQpL06KOPWmvLP2dht/bl5eUpJiZG9erVk6urqwIDAzVkyBD9/vvvBc7TqFEjxcfH67777pOHh4dq1aqlV155RXl5eUW/8Vc5ffq0NmzYoB49eujZZ59VXl5ekaMlsbGxat26tby8vOTl5aVmzZrZjGDl17Nt2zZFRETIw8NDw4YNkySdPHlSgwYNUmBgoFxdXVW/fn3NnTu3QJ2LFy9W06ZN5eXlJW9vb9WrV09Tpkyxbr9RX7iRFStWKCcnR+PHj1fv3r21adMmnThxolj7Fsc777yjs2fPKiYmpkCIytekSRO1a9fOupx/O+nGjRs1bNgwValSRR4eHsrMzCx2XyhOX5T++3fLu+++qwkTJig4OFju7u6KjIzUnj17bPY9evSo/vGPfyg0NFSurq4KCgpShw4dCh1ZBWB/BCkAdvXQQw/pzjvv1Mcff6zo6GitXbtWXbp0sbn17LPPPlNgYKAaNGhgs++PP/6oFi1a6Ntvv9XMmTP1+eefa/bs2crMzFRWVpYk6dChQ4qIiND+/fv1+uuv69NPP1WDBg0UFRWlmJiYAvVMmTJFJ06c0L/+9S+9/fbb+vXXX9WjRw/r8xWLFi1SmzZtFBwcrJ07d1pfV3v99de1efNm/fOf/9Tnn3+uevXqKTY2Vg8++KB8fHz03nvvacmSJUpKSlLbtm21ffv2G75Pbdu2lWEYWr9+ven3+Fo9evRQenr6dZ9JmjBhghYvXqyxY8dqw4YNWrVqlfr06WP9rf60adP0yCOPSJLN+3D1B9m1a9dq8eLFeuGFF/TFF1/ovvvuu25djz32mCpUqGC9dfL7779X27ZtdenSJVPXd/fdd2vZsmWSpOeff95a2/VuJ3zyySf13HPPqVOnTlq3bp1efPFFbdiwQRERETp//rxN24SEBA0cOFCDBg3SunXr1LVrV02ePFnvvvtusepbvny5cnNzNWzYMHXs2FHh4eFaunSpDMOwaffCCy9o4MCBCg0N1fLly7VmzRoNHTq0QAg5c+aMBg0apAEDBmj9+vUaOXKkzp07p4iICG3cuFEvvvii1q1bp44dO+qZZ57R6NGjrfu+//77GjlypCIjI7VmzRqtXbtW48eP1+XLl61tbtQXbmTp0qUKCQlR165dNWzYsOsGx5KIi4uTk5OTunXrZnrfYcOGycXFRatWrdLHH38sFxcXU33BjClTpujo0aP617/+pX/96186ffq02rZta/PLgm7dumn37t2KiYlRXFycFi9erLvuusv0nwEAZcQAADuYPn26IckYP368zfrVq1cbkox3333Xuq5+/frG/fffX+AY7du3N/z8/IzExMQiz/OPf/zDcHV1NU6ePGmzvmvXroaHh4dx6dIlwzAM46uvvjIkGd26dbNp9+GHHxqSjJ07d1rXPfDAA0Z4eHiBcx07dsyQZNxxxx1GVlaWdX1ubq4RGhpqNG7c2MjNzbWuT01NNQIDA42IiAjrumXLlhmSjGPHjhU4ftWqVY1+/foVea35wsPDjQceeKDI7YsXLzYkGR988IF1nSRj+vTp1uVGjRoZvXr1uu55Ro0aZRT1z4gkw9fX17h48WKh264+V/41P/TQQzbtvvnmG0OS8dJLL9lc29ChQwscMzIy0oiMjLQux8fHG5KMZcuWFWib3/fyHTx40JBkjBw50qbdd999Z0gypkyZYnMeScZ3331n07ZBgwZGly5dCpzrWnl5ecadd95pVK1a1cjJybGpZ9OmTdZ2R48eNZycnIyBAwde93j59Vy9r2EYxqRJkwqt88knnzQsFotx6NAhwzAMY/To0Yafn991z1GcvlCUbdu2GZKMSZMmGYbx5/XXrFnTCA8PN/Ly8mzaXvuzzf/zVNjP8Gr16tUzgoODC6zPzc01srOzra+r/+zl97khQ4bY7GOmLxS3L+b/3XL33XfbXPPx48cNFxcXY/jw4YZhGMb58+cNScb8+fOve70AHAcjUgDsauDAgTbLffv2lbOzs/V2OOnPW6ECAwNt2qWnp2vr1q3q27evqlSpUuTxN2/erA4dOigsLMxmfVRUlNLT0wuMJvXs2dNmuUmTJpJk6laknj17ysXFxbp86NAhnT59WoMHD1aFCv/9a9fLy0sPP/ywvv32W6Wnp9/wuIGBgfrjjz+KXUdRjGtGPgrTsmVLff7555o0aZK2bNmijIwM0+dp3769/P39i93+2r4QERGh8PBwm75wM+Qf/9rbtFq2bKn69etr06ZNNuuDg4PVsmVLm3VNmjQpVh/ZunWrjhw5oqFDh8rJyUnSf28/XLp0qbVdXFyccnNzNWrUqBse09/fv8Czc5s3b1aDBg0K1BkVFSXDMKwTl7Rs2VKXLl1S//799X//93+Fjrj8lb6Qfxti/u2GFotFUVFROnHiRIH3tbRNmDBBLi4u1te1f7Yl6eGHH7ZZNtsXzBgwYIDNLaXh4eGKiIiwnrNSpUq64447NGfOHM2bN0979uwp9u2iAOyDIAXAroKDg22WnZ2dFRAQYHPbUP5D4FdLSkpSbm7uDR/Qv3DhQqHPTYSGhlq3Xy0gIMBmOX+SCDMfHq89X/45iqojLy9PSUlJNzyum5tbiQLNtfI/8Oe/B4V5/fXX9dxzz2nt2rVq166dKlWqpF69eunXX38t9nmKel6lKNf2hfx1xb2FrKRu9PO5UR+R/uwnxfnZ5AeLhx56SJcuXdKlS5fk6+ure++9V5988on1Fq785wSLMwFFYXUXt98PHjxYS5cu1YkTJ/Twww8rMDBQrVq1UlxcnHWfkvaF1NRUffTRR2rZsqWqVKlivd6HHnpIFoul1GYrrF69us6dO1fglxFPP/204uPjFR8fX2RfNPtn9a/0xRv1b4vFok2bNqlLly6KiYnR3XffrSpVqmjs2LFKTU0t8XkB3DwEKQB2lZCQYLOck5OjCxcu2HxYrVy5si5evGjTrlKlSnJycirwAPi1AgICdObMmQLrT58+bT12abt2IoP8aymqjgoVKhRr5ObixYt/uV7DMPTvf/9bnp6eat68eZHtPD09NWPGDP3yyy9KSEjQ4sWL9e2336pHjx7FPpfZ2c+u7Qv5667uC25uboV+D9FfeXblRj+f0uojycnJ+uSTTyRJLVq0kL+/v/X19ddf68qVK4qNjZUk6yjrjfq3VPj7bKbfP/roo9qxY4eSk5P12WefyTAMde/e3Rq4S9oX3nvvPaWnp+v777+3udYmTZrIMAytWbOmWL9AuJFOnTopNze3wPODYWFhat68uZo3b66KFSsWuq/ZP6tXv29m+2Jx+nd4eLiWLFmihIQEHTp0SOPHj9eiRYv07LPPFnpMAPZFkAJgV6tXr7ZZ/vDDD5WTk2Mz61W9evUKzFaXP+vVRx99dN0P0R06dNDmzZutHyDzrVy5Uh4eHiWairu4ow/56tatq6pVqyo2NtbmtrrLly/rk08+sc7kdz05OTk6depUgQk3zJoxY4YOHDigp556qsAoX1GCgoIUFRWl/v3769ChQ9bf/JdktO56ru0LO3bs0IkTJ2z6Qo0aNbRv3z6bdocPH7aZWdFsbfm3xV07WUR8fLwOHjyoDh06FPsaric2NlYZGRl68cUX9dVXXxV4Va5c2Xp7X+fOneXk5KTFixeX6FwdOnTQgQMH9MMPP9isX7lypSwWi80Mdvk8PT3VtWtXTZ06VVlZWdq/f3+BNkX1hcIsWbJE3t7e2rRpU4FrnTNnjjIzMwv8zEti+PDhCgoK0sSJEwsNQGaY6QvF7Yv53nvvPZs//ydOnNCOHTts+vfV6tSpo+eff16NGzcu8HME4Bj4HikAdvXpp5/K2dlZnTp10v79+zVt2jQ1bdpUffv2tbZp27atZs6cWeD7cebNm6d7771XrVq10qRJk3TnnXfq7NmzWrdund566y15e3tr+vTp+s9//qN27drphRdeUKVKlbR69Wp99tlniomJka+vr+maGzdurE8//VSLFy/WPffcowoVKlx3dKdChQqKiYnRwIED1b17dz3xxBPKzMzUnDlzdOnSJb3yyis3POe+ffuUnp5e6Afgwly6dEnffvutpD8D26FDh/T+++/r66+/Vt++fW/4RbqtWrVS9+7d1aRJE/n7++vgwYNatWqVTehr3LixJOnVV19V165d5eTkpCZNmhT52/8b2bVrl4YPH64+ffro1KlTmjp1qqpWraqRI0da2wwePFiDBg3SyJEj9fDDD+vEiROKiYkp8JzcHXfcIXd3d61evVr169eXl5eXQkNDC72dsW7duvqf//kfLViwQBUqVFDXrl11/PhxTZs2TWFhYRo/fnyJrudaS5Yskb+/v5555plCQ+yQIUM0b948/fjjj2ratKmmTJmiF198URkZGerfv798fX114MABnT9//oY/v/Hjx2vlypV64IEHNHPmTIWHh+uzzz7TokWL9OSTT6pOnTqSpMcff1zu7u5q06aNQkJClJCQoNmzZ8vX19c6hXxx+sK1fv75Z33//fd68sknC/3uszZt2mju3LlasmSJzSyCJeHn56e1a9eqR48eatq0qZ588kn97W9/k5eXly5cuKBt27YpISFBERERNzyWmb5Q3L6YLzExUQ899JAef/xxJScna/r06XJzc9PkyZMl/flnfPTo0erTp49q166tihUravPmzdq3b58mTZr0l94jADeJHSe6AHAby5+pbPfu3UaPHj0MLy8vw9vb2+jfv79x9uxZm7ZHjhwxLBaL8eGHHxY4zoEDB4w+ffoYAQEBRsWKFY3q1asbUVFRxpUrV6xtfvrpJ6NHjx6Gr6+vUbFiRaNp06YFZgLLn1nro48+sllf2MxhFy9eNB555BHDz8/PsFgs1hng8tvOmTOn0Gteu3at0apVK8PNzc3w9PQ0OnToYHzzzTc2bYqatW/atGlG5cqVba6rKOHh4YYkQ5JhsVgMLy8vo27dusbgwYONL774otB9dM1MepMmTTKaN29u+Pv7G66urkatWrWM8ePHG+fPn7e2yczMNIYPH25UqVLF+j7k1y3JGDVqVLHOlX/NGzduNAYPHmz4+fkZ7u7uRrdu3Yxff/3VZt+8vDwjJibGqFWrluHm5mY0b97c2Lx5c4GZ0gzDMN577z2jXr16houLi805r521zzD+nOHt1VdfNerUqWO4uLgYlStXNgYNGmScOnXKpl1kZKTRsGHDAtc0dOjQQmdyzPfjjz8akoxx48YV2eaXX34xJBljxoyxrlu5cqXRokULw83NzfDy8jLuuusum75YVD2GYRgnTpwwBgwYYAQEBBguLi5G3bp1jTlz5tjMXrdixQqjXbt2RlBQkFGxYkUjNDTU6Nu3r7Fv3z5rm+L0hWuNGzfOkGTs3bu3yDb5Mwvu3r3bMIySz9qXLyEhwZg8ebLRpEkTw9PT03BxcTFCQ0ONHj16GCtXrjSys7OtbfP7XHx8fIHjFLcvFLcv5v/dsmrVKmPs2LFGlSpVDFdXV+O+++4zdu3aZW139uxZIyoqyqhXr57h6elpeHl5GU2aNDFee+016wyPAByLxTCKMX0TAJSy6OhozZgxQ+fOnSvWMyg9evRQTk6OPv/88zKozrHk5ubqzjvv1IABA/Tyyy/buxwAJmzZskXt2rXTRx99ZP3uNQC3Bp6RAlAuzJ49W19++aXi4+PtXUqZe/fdd5WWlsYD5wAAOBCCFIByoVGjRlq2bFmhM1/d6vLy8rR69Wr5+fnZuxQAAPD/cWsfAAAAAJjEiBQAAAAAmESQAgAAAACTCFIAAAAAYBJfyKs/H+Q+ffq0vL29ZbFY7F0OAAAAADsxDEOpqakKDQ1VhQpFjzsRpCSdPn1aYWFh9i4DAAAAgIM4deqUqlWrVuR2gpQkb29vSX++WT4+PnauBgAAAIC9pKSkKCwszJoRikKQkqy38/n4+BCkAAAAANzwkR8mmwAAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkHFBycrKSk5PtXQYAAACAIhCkHExycrJmzZulWfNmEaYAAAAAB+Vs7wJgKz09XRcvX7T+v6+vr50rAgAAAHAtRqQAAAAAwCSCFAAAAACYRJACAAAAAJPsGqS2bdumHj16KDQ0VBaLRWvXrrVuy87O1nPPPafGjRvL09NToaGhGjJkiE6fPm1zjMzMTI0ZM0aVK1eWp6enevbsqd9//72MrwQAAADA7cSuQery5ctq2rSpFi5cWGBbenq6fvjhB02bNk0//PCDPv30Ux0+fFg9e/a0aTdu3DitWbNG77//vrZv3660tDR1795dubm5ZXUZAAAAAG4zdp21r2vXruratWuh23x9fRUXF2ezbsGCBWrZsqVOnjyp6tWrKzk5WUuWLNGqVavUsWNHSdK7776rsLAwffnll+rSpctNvwYAAAAAt59y9YxUcnKyLBaL/Pz8JEm7d+9Wdna2OnfubG0TGhqqRo0aaceOHUUeJzMzUykpKTYvAAAAACiuchOkrly5okmTJmnAgAHy8fGRJCUkJKhixYry9/e3aRsUFKSEhIQijzV79mz5+vpaX2FhYTe1dgAAAAC3lnIRpLKzs/WPf/xDeXl5WrRo0Q3bG4Yhi8VS5PbJkycrOTnZ+jp16lRplgsAAADgFufwQSo7O1t9+/bVsWPHFBcXZx2NkqTg4GBlZWUpKSnJZp/ExEQFBQUVeUxXV1f5+PjYvAAAAACguBw6SOWHqF9//VVffvmlAgICbLbfc889cnFxsZmU4syZM/r5558VERFR1uUCAAAAuE3Ydda+tLQ0HTlyxLp87Ngx7d27V5UqVVJoaKgeeeQR/fDDD/rPf/6j3Nxc63NPlSpVUsWKFeXr66vHHntMTz/9tAICAlSpUiU988wzaty4sXUWPwAAAAAobXYNUrt27VK7du2syxMmTJAkDR06VNHR0Vq3bp0kqVmzZjb7ffXVV2rbtq0k6bXXXpOzs7P69u2rjIwMdejQQcuXL5eTk1OZXAMAAACA249dg1Tbtm1lGEaR26+3LZ+bm5sWLFigBQsWlGZpAAAAAFAkh35GCgAAAAAcEUEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAA7Co1NVVbtmxRamqqvUspNoIUAAAAALtKS0vTli1blJaWZu9Sio0gBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEl2DVLbtm1Tjx49FBoaKovForVr19psNwxD0dHRCg0Nlbu7u9q2bav9+/fbtMnMzNSYMWNUuXJleXp6qmfPnvr999/L8CoAAAAA3G7sGqQuX76spk2bauHChYVuj4mJ0bx587Rw4ULFx8crODhYnTp1UmpqqrXNuHHjtGbNGr3//vvavn270tLS1L17d+Xm5pbVZQAAAAC4zTjb8+Rdu3ZV165dC91mGIbmz5+vqVOnqnfv3pKkFStWKCgoSLGxsXriiSeUnJysJUuWaNWqVerYsaMk6d1331VYWJi+/PJLdenSpcyuBQAAAMDtw2GfkTp27JgSEhLUuXNn6zpXV1dFRkZqx44dkqTdu3crOzvbpk1oaKgaNWpkbVOYzMxMpaSk2LwAAAAAoLgcNkglJCRIkoKCgmzWBwUFWbclJCSoYsWK8vf3L7JNYWbPni1fX1/rKywsrJSrBwAAAHArc9gglc9isdgsG4ZRYN21btRm8uTJSk5Otr5OnTpVKrUCAAAAuD04bJAKDg6WpAIjS4mJidZRquDgYGVlZSkpKanINoVxdXWVj4+PzQsAAAAAisthg1TNmjUVHBysuLg467qsrCxt3bpVERERkqR77rlHLi4uNm3OnDmjn3/+2doGAAAAAEqbXWftS0tL05EjR6zLx44d0969e1WpUiVVr15d48aN06xZs1S7dm3Vrl1bs2bNkoeHhwYMGCBJ8vX11WOPPaann35aAQEBqlSpkp555hk1btzYOosfAAAAAJQ2uwapXbt2qV27dtblCRMmSJKGDh2q5cuXa+LEicrIyNDIkSOVlJSkVq1aaePGjfL29rbu89prr8nZ2Vl9+/ZVRkaGOnTooOXLl8vJyanMrwcAAADA7cGuQapt27YyDKPI7RaLRdHR0YqOji6yjZubmxYsWKAFCxbchAoBAAAAoCCHfUYKAAAAABwVQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkxw6SOXk5Oj5559XzZo15e7urlq1amnmzJnKy8uztjEMQ9HR0QoNDZW7u7vatm2r/fv327FqAAAAALc6hw5Sr776qt58800tXLhQBw8eVExMjObMmaMFCxZY28TExGjevHlauHCh4uPjFRwcrE6dOik1NdWOlQMAAAC4lTl0kNq5c6cefPBBPfDAA6pRo4YeeeQRde7cWbt27ZL052jU/PnzNXXqVPXu3VuNGjXSihUrlJ6ertjYWDtXDwAAAOBW5dBB6t5779WmTZt0+PBhSdKPP/6o7du3q1u3bpKkY8eOKSEhQZ07d7bu4+rqqsjISO3YsaPI42ZmZiolJcXmBQAAAADF5WzvAq7nueeeU3JysurVqycnJyfl5ubq5ZdfVv/+/SVJCQkJkqSgoCCb/YKCgnTixIkijzt79mzNmDHj5hUOAAAA4Jbm0CNSH3zwgd59913Fxsbqhx9+0IoVK/TPf/5TK1assGlnsVhslg3DKLDuapMnT1ZycrL1derUqZtSPwAAAIBbk0OPSD377LOaNGmS/vGPf0iSGjdurBMnTmj27NkaOnSogoODJf05MhUSEmLdLzExscAo1dVcXV3l6up6c4sHAAAAcMty6BGp9PR0VahgW6KTk5N1+vOaNWsqODhYcXFx1u1ZWVnaunWrIiIiyrRWAAAAALcPhx6R6tGjh15++WVVr15dDRs21J49ezRv3jwNGzZM0p+39I0bN06zZs1S7dq1Vbt2bc2aNUseHh4aMGCAnasHAAAAcKty6CC1YMECTZs2TSNHjlRiYqJCQ0P1xBNP6IUXXrC2mThxojIyMjRy5EglJSWpVatW2rhxo7y9ve1YOQAAAIBbmUMHKW9vb82fP1/z588vso3FYlF0dLSio6PLrC4AAAAAtzeHfkYKAAAAABwRQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACaVKEjVqlVLFy5cKLD+0qVLqlWr1l8uCgAAAAAcWYmC1PHjx5Wbm1tgfWZmpv7444+/XBQAAAAAODJnM43XrVtn/f8vvvhCvr6+1uXc3Fxt2rRJNWrUKLXiAAAAAMARmQpSvXr1kiRZLBYNHTrUZpuLi4tq1KihuXPnllpxAAAAAOCITAWpvLw8SVLNmjUVHx+vypUr35SiAAAAAMCRmQpS+Y4dO1badQAAAABAuVGiICVJmzZt0qZNm5SYmGgdqcq3dOnSv1wYAAAAADiqEgWpGTNmaObMmWrevLlCQkJksVhKuy4AAAAAcFglClJvvvmmli9frsGDB5d2PQAAAADg8Er0PVJZWVmKiIgo7VoAAAAAoFwoUZAaPny4YmNjS7sWAAAAACgXSnRr35UrV/T222/ryy+/VJMmTeTi4mKzfd68eaVSHAAAAAA4ohIFqX379qlZs2aSpJ9//tlmGxNPAAAAALjVlShIffXVV6VdBwAAAACUGyV6RgoAAAAAbmclGpFq167ddW/h27x5c4kLAgAAAABHV6Iglf98VL7s7Gzt3btXP//8s4YOHVoadQEAAACAwypRkHrttdcKXR8dHa20tLS/VBAAAAAAOLpSfUZq0KBBWrp0aWkeEgAAAAAcTqkGqZ07d8rNza00DwkAAAAADqdEt/b17t3bZtkwDJ05c0a7du3StGnTSqUwAAAAAHBUJQpSvr6+NssVKlRQ3bp1NXPmTHXu3LlUCgMAAAAAR1WiILVs2bLSrgMAAAAAyo0SBal8u3fv1sGDB2WxWNSgQQPdddddpVUXAAAAADisEgWpxMRE/eMf/9CWLVvk5+cnwzCUnJysdu3a6f3331eVKlVKu04AAAAAcBglmrVvzJgxSklJ0f79+3Xx4kUlJSXp559/VkpKisaOHVvaNQIAAACAQynRiNSGDRv05Zdfqn79+tZ1DRo00BtvvMFkEwAAAABueSUakcrLy5OLi0uB9S4uLsrLy/vLRQEAAACAIytRkGrfvr2eeuopnT592rrujz/+0Pjx49WhQ4dSKy7/uIMGDVJAQIA8PDzUrFkz7d6927rdMAxFR0crNDRU7u7uatu2rfbv31+qNQAAAADA1UoUpBYuXKjU1FTVqFFDd9xxh+68807VrFlTqampWrBgQakVl5SUpDZt2sjFxUWff/65Dhw4oLlz58rPz8/aJiYmRvPmzdPChQsVHx+v4OBgderUSampqaVWBwAAAABcrUTPSIWFhemHH35QXFycfvnlFxmGoQYNGqhjx46lWtyrr76qsLAwm++tqlGjhvX/DcPQ/PnzNXXqVPXu3VuStGLFCgUFBSk2NlZPPPFEqdYDAAAAAJLJEanNmzerQYMGSklJkSR16tRJY8aM0dixY9WiRQs1bNhQX3/9dakVt27dOjVv3lx9+vRRYGCg7rrrLr3zzjvW7ceOHVNCQoLNBBeurq6KjIzUjh07ijxuZmamUlJSbF4AAAAAUFymgtT8+fP1+OOPy8fHp8A2X19fPfHEE5o3b16pFXf06FEtXrxYtWvX1hdffKERI0Zo7NixWrlypSQpISFBkhQUFGSzX1BQkHVbYWbPni1fX1/rKywsrNRqBgAAAHDrMxWkfvzxR91///1Fbu/cubPNRBB/VV5enu6++27NmjVLd911l5544gk9/vjjWrx4sU07i8Vis2wYRoF1V5s8ebKSk5Otr1OnTpVazQAAAABufaaC1NmzZwud9jyfs7Ozzp0795eLyhcSEqIGDRrYrKtfv75OnjwpSQoODpakAqNPiYmJBUaprubq6iofHx+bFwAAAAAUl6kgVbVqVf30009Fbt+3b59CQkL+clH52rRpo0OHDtmsO3z4sMLDwyVJNWvWVHBwsOLi4qzbs7KytHXrVkVERJRaHQAAAABwNVNBqlu3bnrhhRd05cqVAtsyMjI0ffp0de/evdSKGz9+vL799lvNmjVLR44cUWxsrN5++22NGjVK0p+39I0bN06zZs3SmjVr9PPPPysqKkoeHh4aMGBAqdUBAAAAAFczNf35888/r08//VR16tTR6NGjVbduXVksFh08eFBvvPGGcnNzNXXq1FIrrkWLFlqzZo0mT56smTNnqmbNmpo/f74GDhxobTNx4kRlZGRo5MiRSkpKUqtWrbRx40Z5e3uXWh0AAAAAcDVTQSooKEg7duzQk08+qcmTJ8swDEl/jgx16dJFixYtuu6zSSXRvXv3645yWSwWRUdHKzo6ulTPCwAAAABFMf2FvOHh4Vq/fr2SkpJ05MgRGYah2rVry9/f/2bUBwAAAAAOx3SQyufv768WLVqUZi0AAAAAUC6YmmwCAAAAAECQAgAAAADTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJpWrIDV79mxZLBaNGzfOus4wDEVHRys0NFTu7u5q27at9u/fb78iAQAAANzyyk2Qio+P19tvv60mTZrYrI+JidG8efO0cOFCxcfHKzg4WJ06dVJqaqqdKgUAAABwqysXQSotLU0DBw7UO++8I39/f+t6wzA0f/58TZ06Vb1791ajRo20YsUKpaenKzY2tsjjZWZmKiUlxeYFAAAAAMVVLoLUqFGj9MADD6hjx442648dO6aEhAR17tzZus7V1VWRkZHasWNHkcebPXu2fH19ra+wsLCbVjsAAACAW4/DB6n3339fP/zwg2bPnl1gW0JCgiQpKCjIZn1QUJB1W2EmT56s5ORk6+vUqVOlWzQAAACAW5qzvQu4nlOnTumpp57Sxo0b5ebmVmQ7i8Vis2wYRoF1V3N1dZWrq2up1QkAAADg9uLQI1K7d+9WYmKi7rnnHjk7O8vZ2Vlbt27V66+/LmdnZ+tI1LWjT4mJiQVGqQAAAACgtDh0kOrQoYN++ukn7d271/pq3ry5Bg4cqL1796pWrVoKDg5WXFycdZ+srCxt3bpVERERdqwcAAAAwK3MoW/t8/b2VqNGjWzWeXp6KiAgwLp+3LhxmjVrlmrXrq3atWtr1qxZ8vDw0IABA+xRMgAAAIDbgEMHqeKYOHGiMjIyNHLkSCUlJalVq1bauHGjvL297V0aAAAAgFtUuQtSW7ZssVm2WCyKjo5WdHS0XeoBAAAAcPtx6GekAAAAAMAREaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTCFIAAAAAYBJBCgAAAABMIkgBAAAAgEkEKQAAAAAwiSAFAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAAACASQQpAAAAADCJIAUAAAAAJhGkAAAAAMAkghQAAAAAmESQAgAAAACTnO1dAADAseTm5io7O9veZcAOXFxc5OTkZO8yAKBcIEgBACRJhmEoISFBly5dsncpsCM/Pz8FBwfLYrHYuxQAcGgEKQCAJFlDVGBgoDw8PPggfZsxDEPp6elKTEyUJIWEhNi5IgBwbAQpAIByc3OtISogIMDe5cBO3N3dJUmJiYkKDAzkNj8AuA4mmwAAWJ+J8vDwsHMlsLf8PsBzcgBwfQQpAIAVt/OBPgAAxUOQAgAAAACTeEYKAFCk5ORkpaenl9n5PDw85OvrW2bnAwCgpAhSAIBCJScn6+WY13QhteyCVIC3h6ZOHO/wYapGjRoaN26cxo0bZ+9SAAB2QpACABQqPT1dF1LTVanhvfLyrXTTz5eWfFEX9m9Xenq6wwepqx0/flw1a9YsdNuHH36oPn36lHFFAICyQJACAFyXl28l+QQElsm5LpbJWUpXWFiYzpw5Y7Pu7bffVkxMjLp27WqnqgAANxuTTQAAyrW8vDy9+uqruvPOO+Xq6qrq1avr5ZdfliT99NNPat++vdzd3RUQEKD/+Z//UVpamnXfqKgo9erVS//85z8VEhKigIAAjRo1ymbq78TERPXo0UPu7u6qWbOmVq9ebXN+JycnBQcH27zWrFmjfv36ycvLq2zeBABAmXPoIDV79my1aNFC3t7eCgwMVK9evXTo0CGbNoZhKDo6WqGhoXJ3d1fbtm21f/9+O1UMAChrkydP1quvvqpp06bpwIEDio2NVVBQkNLT03X//ffL399f8fHx+uijj/Tll19q9OjRNvt/9dVX+u233/TVV19pxYoVWr58uZYvX27dHhUVpePHj2vz5s36+OOPtWjRIiUmJhZZz+7du7V371499thjN+uSAQAOwKGD1NatWzVq1Ch9++23iouLU05Ojjp37qzLly9b28TExGjevHlauHCh4uPjFRwcrE6dOik1NdWOlQMAykJqaqr+93//VzExMRo6dKjuuOMO3XvvvRo+fLhWr16tjIwMrVy5Uo0aNVL79u21cOFCrVq1SmfPnrUew9/fXwsXLlS9evXUvXt3PfDAA9q0aZMk6fDhw/r888/1r3/9S61bt9Y999yjJUuWKCMjo8ialixZovr16ysiIuKmXz8AwH4cOkht2LBBUVFRatiwoZo2baply5bp5MmT2r17t6Q/R6Pmz5+vqVOnqnfv3mrUqJFWrFih9PR0xcbG2rl6AMDNdvDgQWVmZqpDhw6FbmvatKk8PT2t69q0aaO8vDybuxsaNmwoJycn63JISIh1xOngwYNydnZW8+bNrdvr1asnPz+/QuvJyMhQbGwso1EAcBtw6CB1reTkZElSpUp/zh517NgxJSQkqHPnztY2rq6uioyM1I4dO4o8TmZmplJSUmxeAIDyx93dvchthmHIYrEUuu3q9S4uLgW25eXlWY9xbfvr+fjjj5Wenq4hQ4YUqz0AoPwqN0HKMAxNmDBB9957rxo1aiRJSkhIkCQFBQXZtA0KCrJuK8zs2bPl6+trfYWFhd28wgEAN03t2rXl7u5uvRXvag0aNNDevXttbgf/5ptvVKFCBdWpU6dYx69fv75ycnK0a9cu67pDhw7p0qVLhbZfsmSJevbsqSpVqpi7EABAuVNupj8fPXq09u3bp+3btxfYdu1vCq/3W0jpzweTJ0yYYF1OSUkhTAFAEdKSy2ZS8pKcx83NTc8995wmTpyoihUrqk2bNjp37pz279+vgQMHavr06Ro6dKiio6N17tw5jRkzRoMHDy7wC7ii1K1bV/fff78ef/xxvf3223J2dta4ceMKHQk7cuSItm3bpvXr15u+DgBA+VMugtSYMWO0bt06bdu2TdWqVbOuDw4OlvTnyFRISIh1fWJi4nX/kXR1dZWrq+vNKxgAbgEeHh4K8PbQhf3by+z7nQK8PeTh4WFqn2nTpsnZ2VkvvPCCTp8+rZCQEI0YMUIeHh764osv9NRTT6lFixby8PDQww8/rHnz5pk6/rJlyzR8+HBFRkYqKChIL730kqZNm1ag3dKlS1W1alWb280BALcui5F/A7gDMgxDY8aM0Zo1a7RlyxbVrl27wPbQ0FCNHz9eEydOlCRlZWUpMDBQr776qp544olinSclJUW+vr5KTk6Wj49PqV+HGWfOnNELc1+QJM18eqZNQASAm+XKlSs6duyYatasKTc3N+v65ORkpaenl1kdHh4e8vX1LbPzoaCi+gIA3ExnzpzRW2+9pSeeeMLun3+Lmw0cekRq1KhRio2N1f/93//J29vb+tyTr6+v3N3dZbFYNG7cOM2aNUu1a9dW7dq1NWvWLHl4eGjAgAF2rh4Ayr/8Z0kBAIAthw5SixcvliS1bdvWZv2yZcsUFRUlSZo4caIyMjI0cuRIJSUlqVWrVtq4caO8vb3LuFoAAAAAtwuHDlLFuevQYrEoOjpa0dHRN78gAAAAAFA5mv4cAAAAABwFQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgBQAAAAAmOfSsfQAA++ILeQEAKBxBCgBQqOTkZC2c85KyU8+X2TldvCtr9LPPE6YAAA6PIAUAKFR6erqyU8+rd2NvVfHzvOnnO3fpsj796bzS09MdLkhduHBBTZs21R9//KGkpCT5+flZt/30008aPXq0vv/+e1WqVElPPPGEpk2bJovFYr+CAQA3HUEKAHBdVfw8FRLgU0ZnSy2j85jz2GOPqUmTJvrjjz9s1qekpKhTp05q166d4uPjdfjwYUVFRcnT01NPP/20naoFAJQFJpsAAJRrhmEoJiZGtWrVkru7u5o2baqPP/5YhmGoY8eOuv/++2UYhiTp0qVLql69uqZOnVrs4y9evFiXLl3SM888U2Db6tWrdeXKFS1fvlyNGjVS7969NWXKFM2bN896TgDArYkgBQAo155//nktW7ZMixcv1v79+zV+/HgNGjRI27Zt04oVK/T999/r9ddflySNGDFCQUFBio6OLtaxDxw4oJkzZ2rlypWqUKHgP5k7d+5UZGSkXF1dreu6dOmi06dP6/jx46VxeQAAB8WtfQCAcuvy5cuaN2+eNm/erNatW0uSatWqpe3bt+utt95SbGys3nrrLQ0ePFhnz57Vv//9b+3Zs0cuLi43PHZmZqb69++vOXPmqHr16jp69GiBNgkJCapRo4bNuqCgIOu2mjVr/vWLBAA4JIIUAKDcOnDggK5cuaJOnTrZrM/KytJdd90lSerTp4/WrFmj2bNna/HixapTp06xjj158mTVr19fgwYNum67ayeVyL+lj8kmAODWRpACAJRbeXl5kqTPPvtMVatWtdmWf7tdenq6du/eLScnJ/3666/FPvbmzZv1008/6eOPP5b034BUuXJlTZ06VTNmzFBwcLASEhJs9ktMTJT035EpAMCtiSAFACi3GjRoIFdXV508eVKRkZGFtnn66adVoUIFff755+rWrZseeOABtW/f/obH/uSTT5SRkWFdjo+P17Bhw/T111/rjjvukCS1bt1aU6ZMUVZWlipWrChJ2rhxo0JDQwvc8gcAuLUQpAAA13Xu0mWHPY+3t7eeeeYZjR8/Xnl5ebr33nuVkpKiHTt2yMvLS5UrV9bSpUu1c+dO3X333Zo0aZKGDh2qffv2yd/f/7rHzg9L+c6f//OLievXr2/9HqkBAwZoxowZioqK0pQpU/Trr79q1qxZeuGFF7i1DwBucQQpAEChPDw85OJdWZ/+dF5l9f1OLt6V5eHhYWqfF198UYGBgZo9e7aOHj0qPz8/3X333Zo8ebL69eun6Oho3X333ZKk6dOna+PGjRoxYoQ++OCDv1yvr6+v4uLiNGrUKDVv3lz+/v6aMGGCJkyY8JePDQA3W3JystLT0+1dhiTp7NmzunLlir3LMIUgBQAolK+vr0Y/+3yZ/iPr4eEhX19fU/tYLBaNHTtWY8eOLbDt2ueXnJ2d9d1335WotrZt2xb63VCNGzfWtm3bSnRMALCX5ORkLZzzkrJTz9u7FElSekaG9h85pZSURxUSEmLvcoqFIAUAKJKvr6/pYAMAcHzp6enKTj2v3o29VcXP097l6Pjpczp8ON3m2VRHR5ACANyWRowYoXfffbfQbYMGDdKbb75ZxhUBQNmr4uepkAAfe5ehtMtl8zxuaSJIAQBuSzNnztQzzzxT6DYfH/t/qAAAODaCFADgthQYGKjAwEB7lwEAKKcq2LsAAAAAAChvCFIAAAAAYBJBCgAAAABMIkgBAAAAgElMNgEAKFJZf+t9Sb6QFwAAeyBIAQAKlZycrFnzZuni5Ytlds5KnpU0ZcKUUglTUVFRunTpktauXfvXC/v/jh8/rpo1a2rPnj1q1qxZqR33am3btlWzZs00f/78m3J8AEDpIEgBAAqVnp6ui5cvKrBloLz8vW76+dKS0pT4faLS09NLJUj97//+rwzDKIXKAAAoiCAFALguL38v+VYpm9vtEpVYasfiFkEAwM3EZBMAgHLt448/VuPGjeXu7q6AgAB17NhRly9fVlRUlHr16mVt17ZtW40dO1YTJ05UpUqVFBwcrOjoaJtj/fLLL7r33nvl5uamBg0a6Msvv5TFYrnu7YEHDhxQt27d5OXlpaCgIA0ePFjnz58vVu2XL1/WkCFD5OXlpZCQEM2dO7dAm6SkJA0ZMkT+/v7y8PBQ165d9euvv1q3nzhxQj169JC/v788PT3VsGFDrV+/vlTqAwAUjSAFACi3zpw5o/79+2vYsGE6ePCgtmzZot69exd5S9+KFSvk6emp7777TjExMZo5c6bi4uIkSXl5eerVq5c8PDz03Xff6e2339bUqVNveP7IyEg1a9ZMu3bt0oYNG3T27Fn17du3WPU/++yz+uqrr7RmzRpt3LhRW7Zs0e7du23aREVFadeuXVq3bp127twpwzDUrVs3ZWdnS5JGjRqlzMxMbdu2TT/99JNeffVVeXl5lUp9AICicWsfAKDcOnPmjHJyctS7d2+Fh4dLkho3blxk+yZNmmj69OmSpNq1a2vhwoXatGmTOnXqpI0bN+q3337Tli1bFBwcLEl6+eWX1alTpyKPt3jxYt19992aNWuWdd3SpUsVFhamw4cPq06dOkXum5aWpiVLlmjlypXWc6xYsULVqlWztvn111+1bt06ffPNN4qIiJAkrV69WmFhYVq7dq369OmjkydP6uGHH7Zed61atUqlPgDA9TEiBQAot5o2baoOHTqocePG6tOnj9555x0lJSUV2b5JkyY2yyEhIUpM/PO5rEOHDiksLMwaoiSpZcuW1z3/7t279dVXX8nLy8v6qlevniTpt99+u+6+v/32m7KystS6dWvrukqVKqlu3brW5YMHD8rZ2VmtWrWyrgsICFDdunV18OBBSdLYsWP10ksvqU2bNpo+fbr27dtXKvUBAK6PESkAQLnl5OSkuLg47dixQxs3btSCBQs0depUfffdd4W2d3FxsVm2WCzKy8uTJBmGIYvFYur8eXl56tGjh1599dUC20JCQq67b3FmFCyqzdW1Dh8+XF26dNFnn32mjRs3avbs2Zo7d67GjBnzl+oDbiVl/Z1418P35d06CFIAgHLNYrGoTZs2atOmjV544QWFh4drzZo1po9Tr149nTx5UmfPnlVQUJAkKT4+/rr73H333frkk09Uo0YNOTub+yf1zjvvlIuLi7799ltVr15d0p8TSxw+fFiRkZGSpAYNGignJ0ffffed9da+Cxcu6PDhw6pfv771WGFhYRoxYoRGjBihyZMn65133tGYMWP+Un3ArSI5OVkL57yk7FTHmGTFxbuyRj/7PGHqGlnZWUpLS9Ply5ftXUqx8bcqAOC60pLSHPY83333nTZt2qTOnTsrMDBQ3333nc6dO6f69evb3OJWHJ06ddIdd9yhoUOHKiYmRqmpqdbJJooaqRo1apTeeecd9e/fX88++6wqV66sI0eO6P3339c777wjJyenIs/n5eWlxx57TM8++6wCAgIUFBSkqVOnqkKF/951X7t2bT344IN6/PHH9dZbb8nb21uTJk1S1apV9eCDD0qSxo0bp65du6pOnTpKSkrS5s2brSHrr9QH3CrS09OVnXpevRt7q4qfp11rOXfpsj796XypfV/erSQnK0dpaWkOM3JYHAQpB5aSkmLvEqwYhgZuPx4eHqrkWUmJ3yeW6vc7XU8lz0ry8PAodnsfHx9t27ZN8+fPV0pKisLDwzV37lx17dpVH3zwgalzOzk5ae3atRo+fLhatGihWrVqac6cOerRo4fc3NwK3Sc0NFTffPONnnvuOXXp0kWZmZkKDw/X/fffbxOIijJnzhylpaWpZ8+e8vb21tNPP63k5GSbNsuWLdNTTz2l7t27KysrS3//+9+1fv16622Kubm5GjVqlH7//Xf5+Pjo/vvv12uvvVYq9QG3kip+ngoJ8LF3GZJS7V0ASglBykFlZWVp2aL5ctMVe5ciiWFo4Hbk6+urKROmlOlvB83+0qZ+/frasGFDoduWL19us7xly5YCba79fqh69epp+/bt1uVvvvlG0p+34UlSjRo1Cjy3VLt2bX366afFrvlqXl5eWrVqlVatWmVd9+yzz9q08ff318qVK4s8xoIFC657jr9SHwCgaAQpB5Wbk6vsrIsa8LcghqEB2I2vr+9t9ed+zZo18vLyUu3atXXkyBE99dRTatOmje644w57lwYAcDAEKQfHMDQAlJ3U1FRNnDhRp06dUuXKldWxY0fNnTu3RMc6efKkGjRoUOT2AwcOWCeZAACUPwQpAAD+vyFDhmjIkCGlcqzQ0FDt3bv3utsBAOUXQQoAgJvA2dnZ+mwVAODWQ5BCsVzJzNLZs2ftXYYkKTs7u8CXatoLsxniVlOcL4nFrY0+ANxcjvKZ6uzZs8rKzrZ3GeUaQQo3lHL5in76aZ/yFr0iD3d3u9ZyJTNL+3/5VY0b1FFFBwhTzGaIW0X+LyfS09Plbuc/57Cv/FkaHeUXVsCtxJE+U6VeTtfRwwd05d5Au9aRLysnS1lZWXyPFG4tGVk5csnL1EONvFQjtIpdazlwPFG//HhJPeq52b0WZjPErcTJyUl+fn5KTPzz+6I8PDyK/BJa3JoMw1B6eroSExPl5+fHl/UCN4GjfaZasD9TOdk5dq0jX052jrKyspSRkWHvUoqNIIViq+zrYfcZBM8mpTlMLZJ0JfOCQwzPS9xmiL8uODhYkqxhCrcnPz8/a18AcHM4wueY/M9UKDmCFFBCjjQ8L3GbIf46i8WikJAQBQYGKpv75m9LLi4ujEQBQDERpIAScqTheW4zRGlycnLiwzQAADdwywSpRYsWac6cOTpz5owaNmyo+fPn67777rN3WaUiOe2KJMnXy61Uj5memSUP14qletzbkSMMz0uOdZuh5Fi3GiYnJzvMw6uO9L44Ekf6GTEzKMxypP7rSH3GUd4XZqfDzXJLBKkPPvhA48aN06JFi9SmTRu99dZb6tq16y3xrfEpl69o/mc7JUlTekeWSuhJTruiWZ9u1cWsK6pU0a3Ujgv7cbTbDCXHudUwOTlZC+e8pOzU83atI5+jvC+OxJF+RswMCrMcqf9KjtNnHOl9cbTZ6VC4pKQkZWRc0dGjR+1dSrHdEkFq3rx5euyxxzR8+HBJ0vz58/XFF19o8eLFmj17tp2r+2sysnJ0MevPEan0zKxSCTzpmVm6mHVFHnU9dPFQeqkdF/bjSLcZSo51q2F6erqyU8+rd2NvVfHztGstjvS+OBJH+hkxMyjMcqT+60h9xpHeF0ebnQ6FS0tLU25urhISEuxdSrGV+yCVlZWl3bt3a9KkSTbrO3furB07dhS6T2ZmpjIzM63LycnJkqSUlJSbV2gxpaamKiszS+lp6bqYkaE9R3J0IfmylGfou4OnFODjYW1rsVhsvjixuMvnUy7rQvJlZaVYdCUtQ7+dvqjU9P++H9c6efaSsnNydeLsJRkW+3YZarl+LZevZF33Z1lW0jKylJKWrt9++02pqal2rSUxMVFp6elKy3CVW0X7/pwc6X2R/pzu2hGmOHekn9HlK1kO82fJ0fqL5Dh9RnKcWhyp/zpSn3Gk9yX/z7Uj/XtNLQUlXMpQnmEoKyvL7p/J889/oy8otxjl/CvMT58+rapVq+qbb75RRESEdf2sWbO0YsUKHTp0qMA+0dHRmjFjRlmWCQAAAKAcOXXqlKpVq1bkdvvHz1Jy7W+lrvebqsmTJ2vChAnW5by8PF28eFEBAQF2/+1WSkqKwsLCdOrUKfn42H8CAzg++gzMos/ALPoMzKLPwCxH6jOGYSg1NVWhoaHXbVfug1TlypXl5ORU4H7KxMREBQUFFbqPq6urXF1dbdb5+fndrBJLxMfHx+6dCOULfQZm0WdgFn0GZtFnYJaj9JniPGdYoQzquKkqVqyoe+65R3FxcTbr4+LibG71AwAAAIDSUu5HpCRpwoQJGjx4sJo3b67WrVvr7bff1smTJzVixAh7lwYAAADgFnRLBKl+/frpwoULmjlzps6cOaNGjRpp/fr1Cg8Pt3dpprm6umr69OkFbj0EikKfgVn0GZhFn4FZ9BmYVR77TLmftQ8AAAAAylq5f0YKAAAAAMoaQQoAAAAATCJIAQAAAIBJBCkAAAAAMIkgZQeLFi1SzZo15ebmpnvuuUdff/31ddtv3bpV99xzj9zc3FSrVi29+eabZVQpHIWZPvPpp5+qU6dOqlKlinx8fNS6dWt98cUXZVgtHIHZv2fyffPNN3J2dlazZs1uboFwOGb7TGZmpqZOnarw8HC5urrqjjvu0NKlS8uoWjgCs31m9erVatq0qTw8PBQSEqJHH31UFy5cKKNqYU/btm1Tjx49FBoaKovForVr195wn/Lw+ZcgVcY++OADjRs3TlOnTtWePXt03333qWvXrjp58mSh7Y8dO6Zu3brpvvvu0549ezRlyhSNHTtWn3zySRlXDnsx22e2bdumTp06af369dq9e7fatWunHj16aM+ePWVcOezFbJ/Jl5ycrCFDhqhDhw5lVCkcRUn6TN++fbVp0yYtWbJEhw4d0nvvvad69eqVYdWwJ7N9Zvv27RoyZIgee+wx7d+/Xx999JHi4+M1fPjwMq4c9nD58mU1bdpUCxcuLFb7cvP510CZatmypTFixAibdfXq1TMmTZpUaPuJEyca9erVs1n3xBNPGH/7299uWo1wLGb7TGEaNGhgzJgxo7RLg4MqaZ/p16+f8fzzzxvTp083mjZtehMrhKMx22c+//xzw9fX17hw4UJZlAcHZLbPzJkzx6hVq5bNutdff92oVq3aTasRjkmSsWbNmuu2KS+ffxmRKkNZWVnavXu3OnfubLO+c+fO2rFjR6H77Ny5s0D7Ll26aNeuXcrOzr5ptcIxlKTPXCsvL0+pqamqVKnSzSgRDqakfWbZsmX67bffNH369JtdIhxMSfrMunXr1Lx5c8XExKhq1aqqU6eOnnnmGWVkZJRFybCzkvSZiIgI/f7771q/fr0Mw9DZs2f18ccf64EHHiiLklHOlJfPv872LuB2cv78eeXm5iooKMhmfVBQkBISEgrdJyEhodD2OTk5On/+vEJCQm5avbC/kvSZa82dO1eXL19W3759b0aJcDAl6TO//vqrJk2apK+//lrOzvyzcLspSZ85evSotm/fLjc3N61Zs0bnz5/XyJEjdfHiRZ6Tug2UpM9ERERo9erV6tevn65cuaKcnBz17NlTCxYsKIuSUc6Ul8+/jEjZgcVisVk2DKPAuhu1L2w9bl1m+0y+9957T9HR0frggw8UGBh4s8qDAypun8nNzdWAAQM0Y8YM1alTp6zKgwMy8/dMXl6eLBaLVq9erZYtW6pbt26aN2+eli9fzqjUbcRMnzlw4IDGjh2rF154Qbt379aGDRt07NgxjRgxoixKRTlUHj7/8qvHMlS5cmU5OTkV+G1NYmJigdSdLzg4uND2zs7OCggIuGm1wjGUpM/k++CDD/TYY4/po48+UseOHW9mmXAgZvtMamqqdu3apT179mj06NGS/vyQbBiGnJ2dtXHjRrVv375Maod9lOTvmZCQEFWtWlW+vr7WdfXr15dhGPr9999Vu3btm1oz7KskfWb27Nlq06aNnn32WUlSkyZN5Onpqfvuu08vvfSSw4wwwDGUl8+/jEiVoYoVK+qee+5RXFyczfq4uDhFREQUuk/r1q0LtN+4caOaN28uFxeXm1YrHENJ+oz050hUVFSUYmNjuf/8NmO2z/j4+Oinn37S3r17ra8RI0aobt262rt3r1q1alVWpcNOSvL3TJs2bXT69GmlpaVZ1x0+fFgVKlRQtWrVbmq9sL+S9Jn09HRVqGD7sdPJyUnSf0cagHzl5vOvnSa5uG29//77houLi7FkyRLjwIEDxrhx4wxPT0/j+PHjhmEYxqRJk4zBgwdb2x89etTw8PAwxo8fbxw4cMBYsmSJ4eLiYnz88cf2ugSUMbN9JjY21nB2djbeeOMN48yZM9bXpUuX7HUJKGNm+8y1mLXv9mO2z6SmphrVqlUzHnnkEWP//v3G1q1bjdq1axvDhw+31yWgjJntM8uWLTOcnZ2NRYsWGb/99puxfft2o3nz5kbLli3tdQkoQ6mpqcaePXuMPXv2GJKMefPmGXv27DFOnDhhGEb5/fxLkLKDN954wwgPDzcqVqxo3H333cbWrVut24YOHWpERkbatN+yZYtx1113GRUrVjRq1KhhLF68uIwrhr2Z6TORkZGGpAKvoUOHln3hsBuzf89cjSB1ezLbZw4ePGh07NjRcHd3N6pVq2ZMmDDBSE9PL+OqYU9m+8zrr79uNGjQwHB3dzdCQkKMgQMHGr///nsZVw17+Oqrr6772aS8fv61GAbjqQAAAABgBs9IAQAAAIBJBCkAAAAAMIkgBQAAAAAmEaQAAAAAwCSCFAAAAACYRJACAAAAAJMIUgAAAABgEkEKAAAAAEwiSAEAbjnR0dFq1qzZXz6OxWLR2rVri9x+/PhxWSwW7d27V5K0ZcsWWSwWXbp0SZK0fPly+fn5/eU6AACOhyAFALCrqKgoWSwWWSwWubi4qFatWnrmmWd0+fJle5d2Q2FhYTpz5owaNWpU6PZ+/frp8OHD1uXSCngAAPtztncBAADcf//9WrZsmbKzs/X1119r+PDhunz5shYvXmzTLjs7Wy4uLnaqsiAnJycFBwcXud3d3V3u7u5lWBEAoKwwIgUAsDtXV1cFBwcrLCxMAwYM0MCBA7V27VrrCM7SpUtVq1Ytubq6yjAMnTx5Ug8++KC8vLzk4+Ojvn376uzZswWO+9ZbbyksLEweHh7q06eP9ZY7SYqPj1enTp1UuXJl+fr6KjIyUj/88EOBY5w5c0Zdu3aVu7u7atasqY8++si67dpb+6519a19y5cv14wZM/Tjjz9aR+CWL1+uYcOGqXv37jb75eTkKDg4WEuXLjX/ZgIAygRBCgDgcNzd3ZWdnS1JOnLkiD788EN98skn1sDSq1cvXbx4UVu3blVcXJx+++039evXz+YY+fv9+9//1oYNG7R3716NGjXKuj01NVVDhw7V119/rW+//Va1a9dWt27dlJqaanOcadOm6eGHH9aPP/6oQYMGqX///jp48KDpa+rXr5+efvppNWzYUGfOnNGZM2fUr18/DR8+XBs2bNCZM2esbdevX6+0tDT17dvX9HkAAGWDW/sAAA7l+++/V2xsrDp06CBJysrK0qpVq1SlShVJUlxcnPbt26djx44pLCxMkrRq1So1bNhQ8fHxatGihSTpypUrWrFihapVqyZJWrBggR544AHNnTtXwcHBat++vc1533rrLfn7+2vr1q02I0R9+vTR8OHDJUkvvvii4uLitGDBAi1atMjUdbm7u8vLy0vOzs42twNGRESobt26WrVqlSZOnChJWrZsmfr06SMvLy9T5wAAlB1GpAAAdvef//xHXl5ecnNzU+vWrfX3v/9dCxYskCSFh4dbQ5QkHTx4UGFhYdYQJUkNGjSQn5+fzUhR9erVrSFKklq3bq28vDwdOnRIkpSYmKgRI0aoTp068vX1la+vr9LS0nTy5Emb2lq3bl1guSQjUtczfPhwLVu2zFrXZ599pmHDhpXqOQAApYsRKQCA3bVr106LFy+Wi4uLQkNDbSaU8PT0tGlrGIYsFkuBYxS1Pl/+tvz/RkVF6dy5c5o/f77Cw8Pl6uqq1q1bKysr64b1Xu88JTFkyBBNmjRJO3fu1M6dO1WjRg3dd999pXoOAEDpYkQKAGB3np6euvPOOxUeHn7DWfkaNGigkydP6tSpU9Z1Bw4cUHJysurXr29dd/LkSZ0+fdq6vHPnTlWoUEF16tSRJH399dcaO3asunXrpoYNG8rV1VXnz58vcL5vv/22wHK9evVKdJ0VK1ZUbm5ugfUBAQHq1auXli1bpmXLlunRRx8t0fEBAGWHESkAQLnSsWNHNWnSRAMHDtT8+fOVk5OjkSNHKjIyUs2bN7e2c3Nz09ChQ/XPf/5TKSkpGjt2rPr27Wt9PunOO+/UqlWr1Lx5c6WkpOjZZ58tdKryjz76SM2bN9e9996r1atX6/vvv9eSJUtKVHuNGjV07Ngx7d27V9WqVZO3t7dcXV0l/Xl7X/fu3ZWbm6uhQ4eW6PgAgLLDiBQAoFyxWCxau3at/P399fe//10dO3ZUrVq19MEHH9i0u/POO9W7d29169ZNnTt3VqNGjWwmiFi6dKmSkpJ01113afDgwRo7dqwCAwMLnG/GjBl6//331aRJE61YsUKrV69WgwYNSlT7ww8/rPvvv1/t2rVTlSpV9N5771m3dezYUSEhIerSpYtCQ0NLdHwAQNmxGIZh2LsIAABud+np6QoNDdXSpUvVu3dve5cDALgBbu0DAMCO8vLylJCQoLlz58rX11c9e/a0d0kAgGIgSAEAYEcnT55UzZo1Va1aNS1fvlzOzvzTDADlAbf2AQAAAIBJTDYBAAAAACYRpAAAAADAJIIUAAAAAJhEkAIAAAAAkwhSAAAAAGASQQoAAAAATCJIAQAAAIBJBCkAAAAAMOn/ARkljVYzTzo0AAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sorted by p(treated) in ascending order:\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B03-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C07-T01.tiff: 0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B08-T01.tiff: 0.0026\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B11-T01.tiff: 0.0026\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C11-T01.tiff: 0.0029\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F03-T01.tiff: 0.0030\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F02-T01.tiff: 0.0064\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C8.tif: 0.0159\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F06-T01.tiff: 0.0187\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C09-T01.tiff: 0.0214\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B10-T01.tiff: 0.0224\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B07-T01.tiff: 0.0307\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C10-T01.tiff: 0.0334\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C11.tif: 0.0508\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C08-T01.tiff: 0.0639\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C7.tif: 0.0672\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B10-T01.tiff: 0.1001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B09-T01.tiff: 0.1057\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B09-T01.tiff: 0.1087\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C04-T01.tiff: 0.1193\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F05-T01.tiff: 0.1277\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C9.tif: 0.1413\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F04-T01.tiff: 0.1888\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_c10.tif: 0.2812\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C10-T01.tiff: 0.4880\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C11-T01.tiff: 0.5236\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C02-T01.tiff: 0.6887\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C04-T01.tiff: 0.7544\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C08-T01.tiff: 0.7985\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C05-T01.tiff: 0.8027\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C03-T01.tiff: 0.8507\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B07-T01.tiff: 0.8660\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C07-T01.tiff: 0.8945\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C03-T01.tiff: 0.8987\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B11-T01.tiff: 0.9060\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C06-T01.tiff: 0.9433\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C06-T01.tiff: 0.9522\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G10-T01.tiff: 0.9622\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C02-T01.tiff: 0.9674\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C09-T01.tiff: 0.9685\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C05-T01.tiff: 0.9733\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E05-T01.tiff: 0.9933\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g9_C10-T01.tiff: 0.9974\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B04-T01.tiff: 0.9994\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B06-T01.tiff: 0.9995\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E5.tif: 0.9997\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E04-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B05-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E03-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B03-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E09-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C07-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B02-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E02-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E4.tif: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E2.tif: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E3.tif: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E05-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B03-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B03-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D09-T01.tiff: 1.0000\n"
     ]
    }
   ],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending ordergroups_data[group_name]\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sorted by p(treated) in ascending order:\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B03-T01.tiff: p(treated)=0.0001, p(control)=0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C07-T01.tiff: p(treated)=0.0002, p(control)=0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B08-T01.tiff: p(treated)=0.0026, p(control)=0.9974\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B11-T01.tiff: p(treated)=0.0026, p(control)=0.9974\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C11-T01.tiff: p(treated)=0.0029, p(control)=0.9971\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F03-T01.tiff: p(treated)=0.0030, p(control)=0.9970\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F02-T01.tiff: p(treated)=0.0064, p(control)=0.9936\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C8.tif: p(treated)=0.0159, p(control)=0.9841\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F06-T01.tiff: p(treated)=0.0187, p(control)=0.9813\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C09-T01.tiff: p(treated)=0.0214, p(control)=0.9786\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B10-T01.tiff: p(treated)=0.0224, p(control)=0.9776\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B07-T01.tiff: p(treated)=0.0307, p(control)=0.9693\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C10-T01.tiff: p(treated)=0.0334, p(control)=0.9666\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C11.tif: p(treated)=0.0508, p(control)=0.9492\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C08-T01.tiff: p(treated)=0.0639, p(control)=0.9361\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C7.tif: p(treated)=0.0672, p(control)=0.9328\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B10-T01.tiff: p(treated)=0.1001, p(control)=0.8999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B09-T01.tiff: p(treated)=0.1057, p(control)=0.8943\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B09-T01.tiff: p(treated)=0.1087, p(control)=0.8913\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C04-T01.tiff: p(treated)=0.1193, p(control)=0.8807\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F05-T01.tiff: p(treated)=0.1277, p(control)=0.8723\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C9.tif: p(treated)=0.1413, p(control)=0.8587\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F04-T01.tiff: p(treated)=0.1888, p(control)=0.8112\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_c10.tif: p(treated)=0.2812, p(control)=0.7188\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C10-T01.tiff: p(treated)=0.4880, p(control)=0.5120\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C11-T01.tiff: p(treated)=0.5236, p(control)=0.4764\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C02-T01.tiff: p(treated)=0.6887, p(control)=0.3113\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C04-T01.tiff: p(treated)=0.7544, p(control)=0.2456\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C08-T01.tiff: p(treated)=0.7985, p(control)=0.2015\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C05-T01.tiff: p(treated)=0.8027, p(control)=0.1973\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C03-T01.tiff: p(treated)=0.8507, p(control)=0.1493\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B07-T01.tiff: p(treated)=0.8660, p(control)=0.1340\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C07-T01.tiff: p(treated)=0.8945, p(control)=0.1055\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C03-T01.tiff: p(treated)=0.8987, p(control)=0.1013\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B11-T01.tiff: p(treated)=0.9060, p(control)=0.0940\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C06-T01.tiff: p(treated)=0.9433, p(control)=0.0567\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C06-T01.tiff: p(treated)=0.9522, p(control)=0.0478\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G10-T01.tiff: p(treated)=0.9622, p(control)=0.0378\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C02-T01.tiff: p(treated)=0.9674, p(control)=0.0326\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C09-T01.tiff: p(treated)=0.9685, p(control)=0.0315\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C05-T01.tiff: p(treated)=0.9733, p(control)=0.0267\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E05-T01.tiff: p(treated)=0.9933, p(control)=0.0067\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g9_C10-T01.tiff: p(treated)=0.9974, p(control)=0.0026\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B04-T01.tiff: p(treated)=0.9994, p(control)=0.0006\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B06-T01.tiff: p(treated)=0.9995, p(control)=0.0005\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E5.tif: p(treated)=0.9997, p(control)=0.0003\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E04-T01.tiff: p(treated)=0.9998, p(control)=0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B05-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E03-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B03-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E09-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C07-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B02-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E06-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E06-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E02-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E4.tif: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E2.tif: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E3.tif: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E05-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B03-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B03-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B06-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "\n",
      "Group-Wise Ranking Accuracy:\n",
      "Correct Transitions: 1\n",
      "Total Possible Transitions: 2\n",
      "Ranking Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1], entry[0]) for entry in all_images_data]\n",
    "\n",
    "# Print sorted images\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr, p_ctrl in sorted_by_treated:\n",
    "    print(f\"{img_path}: p(treated)={p_tr:.4f}, p(control)={p_ctrl:.4f}\")\n",
    "\n",
    "# Initialize group-wise data\n",
    "grouped_data = {group: [] for group in groups}\n",
    "for group in groups:\n",
    "    grouped_data[group].extend(groups_data[group])\n",
    "\n",
    "# Step 1: Sort distances and keep track of group membership\n",
    "sorted_distances = []\n",
    "for group, data in grouped_data.items():\n",
    "    for _, p_treated, _ in data:\n",
    "        sorted_distances.append((p_treated, group))\n",
    "\n",
    "sorted_distances.sort(key=lambda x: x[0])  # Sort by p(treated)\n",
    "\n",
    "# Step 2: Check for correct transitions between groups\n",
    "correct_transitions = 0\n",
    "total_transitions = len(groups) - 1  # Total possible adjacent group transitions\n",
    "\n",
    "for i in range(total_transitions):\n",
    "    group_i = groups[i]\n",
    "    group_j = groups[i + 1]\n",
    "\n",
    "    # Get all distances for groups i and j\n",
    "    distances_i = [dist for dist, grp in sorted_distances if grp == group_i]\n",
    "    distances_j = [dist for dist, grp in sorted_distances if grp == group_j]\n",
    "\n",
    "    # Check the condition: all d in G_i < all d in G_j\n",
    "    if all(d_i < d_j for d_i in distances_i for d_j in distances_j):\n",
    "        correct_transitions += 1\n",
    "\n",
    "# Step 3: Calculate ranking accuracy\n",
    "ranking_accuracy = correct_transitions / total_transitions if total_transitions > 0 else 1.0\n",
    "\n",
    "# Step 4: Print the group-wise ranking accuracy\n",
    "print(\"\\nGroup-Wise Ranking Accuracy:\")\n",
    "print(f\"Correct Transitions: {correct_transitions}\")\n",
    "print(f\"Total Possible Transitions: {total_transitions}\")\n",
    "print(f\"Ranking Accuracy: {ranking_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Assuming 'sorted_by_treated' is already defined as:\n",
    "# sorted_by_treated = [(img_path, p_tr), ...] sorted in ascending order by p_tr\n",
    "\n",
    "new_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\sorted_explodall\"\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "for i, (img_path, p_tr) in enumerate(sorted_by_treated, start=1):\n",
    "    # Extract the parent directory name and the original filename\n",
    "    parent_dir_name = os.path.basename(os.path.dirname(img_path))  # e.g. \"cond7\"\n",
    "    base_filename = os.path.basename(img_path)  # e.g. \"ds_41.tif\"\n",
    "    \n",
    "    # Combine them to get \"cond7_ds_41.tif\"\n",
    "    original_filename = f\"{parent_dir_name}_{base_filename}\"\n",
    "\n",
    "    # Format the probability score\n",
    "    formatted_score = f\"{p_tr:.4f}\"\n",
    "    \n",
    "    # Construct the new filename with index and score\n",
    "    new_filename = f\"{i}_{formatted_score}_{original_filename}\"\n",
    "    new_path = os.path.join(new_dir, new_filename)\n",
    "    \n",
    "    shutil.copy2(img_path, new_path)\n",
    "\n",
    "print(\"Images copied and renamed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Assuming 'sorted_by_treated' is already defined as:\n",
    "# sorted_by_treated = [(img_path, p_tr), ...] sorted in ascending order by p_tr\n",
    "\n",
    "new_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\sorted_cond10\"\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "for i, (img_path, p_tr) in enumerate(sorted_by_treated, start=1):\n",
    "    # Extract the parent directory name and the original filename\n",
    "    parent_dir_name = os.path.basename(os.path.dirname(img_path))  # e.g. \"cond7\"\n",
    "    base_filename = os.path.basename(img_path)  # e.g. \"ds_41.tif\"\n",
    "    \n",
    "    # Combine them to get \"cond7_ds_41.tif\"\n",
    "    original_filename = f\"{parent_dir_name}_{base_filename}\"\n",
    "\n",
    "    # Format the probability score\n",
    "    formatted_score = f\"{p_tr:.4f}\"\n",
    "    \n",
    "    # Construct the new filename with index and score\n",
    "    new_filename = f\"{i}_{formatted_score}_{original_filename}\"\n",
    "    new_path = os.path.join(new_dir, new_filename)\n",
    "    \n",
    "    shutil.copy2(img_path, new_path)\n",
    "\n",
    "print(\"Images copied and renamed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#500 epochs, one outlier of exploder in ds closer to sd: which is ds41_g9_C10-T01   inbetween 4 ds closer\n",
    "# 100 epochs, one outlier of exploder also one outlier from ds_clos_tosd ds41_g5_E04-T01\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "#from helper import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model definition\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, feature_dim, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Recreate the model structure\n",
    "feature_dim = 512 # Set this to the same dimension used during training\n",
    "num_classes = 2   # Since you trained for 2 classes\n",
    "logreg_model = LogisticRegression(feature_dim, num_classes).to(device)\n",
    "\n",
    "# Load the saved weights\n",
    "logreg_model.load_state_dict(torch.load(\"best_loss_model.pth\", map_location=device))\n",
    "logreg_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in descending order (highest p(treated) first)\n",
    "all_images_data.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Now all_images_data is sorted by p(treated)\n",
    "# Extract (img_path, p_treated)\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "# Print or handle as needed\n",
    "print(\"Images sorted by p(treated) in descending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup for inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess_Image(image_path):\n",
    "    # Load the image\n",
    "    image = tiff.imread(image_path)\n",
    "    \n",
    "    # Ensure the image has 3 layers (channels)\n",
    "    if image.shape[0] != 3:\n",
    "        raise ValueError(f\"Image at {image_path} does not have exactly 3 layers.\")\n",
    "    \n",
    "    # Normalize the 16-bit image to [0, 1]\n",
    "    image = image.astype(np.float32) / 65535.0\n",
    "    \n",
    "    # Convert to a torch tensor\n",
    "    image = torch.tensor(image, dtype=torch.float32)\n",
    "    \n",
    "    # Resize to (96, 96)\n",
    "    image = TF.resize(image, (96, 96))\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_of_image = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B07-T01.tiff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = Preprocess_Image(path_of_image)\n",
    "print(first_image.shape)\n",
    "prep_first_image = first_image.unsqueeze(0)\n",
    "print(prep_first_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image_np = first_image.numpy().transpose(1, 2, 0)  # (C, H, W) -> (H, W, C)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(first_image_np, cmap='gray')  # Use `cmap='gray'` if it's grayscale\n",
    "plt.title('First Image')\n",
    "plt.axis('off')  # Optional: turn off the axis for a cleaner look\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathimage = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B08-T01.tiff'\n",
    "second_image = Preprocess_Image(pathimage)\n",
    "print(second_image.shape)\n",
    "prep_second_image = second_image.unsqueeze(0)\n",
    "print(prep_second_image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_image_np = second_image.numpy().transpose(1, 2, 0)  # (C, H, W) -> (H, W, C)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(second_image_np, cmap='gray')  # Use `cmap='gray'` if it's grayscale\n",
    "plt.title('second Image')\n",
    "plt.axis('off')  # Optional: turn off the axis for a cleaner look\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extract_features(model, image_tensor):\n",
    "    # prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "    \n",
    "    # Move image tensor to device\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    # Extract features\n",
    "    features = network(image_tensor)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"simclr_model: {simclr_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for both images\n",
    "first_image_feats = extract_features(simclr_model, prep_first_image)\n",
    "second_image_feats = extract_features(simclr_model, prep_second_image)\n",
    "print(first_image_feats.shape)\n",
    "print(second_image_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSINE FROM NEWDATA CROP VAL&INFER\n",
    "# Compute cosine similarity between the feature vectors\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats, second_image_feats, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSINE old data crop\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats, second_image_feats, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\untreated\\D08-T01.tiff'\n",
    "untreated_image = Preprocess_Image(im_path)\n",
    "print(untreated_image.shape)\n",
    "prep_untreated_image = untreated_image.unsqueeze(0)\n",
    "print(prep_untreated_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_image_np = untreated_image.numpy().transpose(1, 2, 0)  # (C, H, W) -> (H, W, C)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(untreated_image_np, cmap='gray')  # Use `cmap='gray'` if it's grayscale\n",
    "plt.title('untreated Image')\n",
    "plt.axis('off')  # Optional: turn off the axis for a cleaner look\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_image_feats = extract_features(simclr_model, prep_untreated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSINE NEW DATA CROP\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats, untreated_image_feats, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine old data crop\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats, untreated_image_feats, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference after projection head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def features_after_projection(model, image_tensor):\n",
    "    # prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    #network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "    \n",
    "    # Move image tensor to device\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    # Extract features\n",
    "    features = network(image_tensor)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for both images\n",
    "first_image_feats_after = features_after_projection(simclr_model, prep_first_image)\n",
    "second_image_feats_after = features_after_projection(simclr_model, prep_second_image)\n",
    "print(first_image_feats_after.shape)\n",
    "print(second_image_feats_after.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine newdata crop \n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats_after, second_image_feats_after, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine old data crop\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats_after, second_image_feats_after, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")\n",
    "\n",
    "#Cosine similarity between features: 0.8507535457611084\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as expected after projection head cosine similarity is higher this leads to the question that maybe for ranking images with time series, this after projection maybe better option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_image_feats_after = features_after_projection(simclr_model, prep_untreated_image)\n",
    "print(untreated_image_feats_after.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between the feature vectors\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats_after, untreated_image_feats_after, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between the feature vectors\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats_after, untreated_image_feats_after, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as expected after projection head cosine similarity is lower for different class images this leads to the question that maybe for ranking images with time series, this after projection maybe better option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orig images (without simclr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_image)\n",
    "first_image.view(-1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(second_image)\n",
    "second_image.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_flat = first_image.view(-1)\n",
    "second_flat = second_image.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_flat.unsqueeze(0).shape == untreated_flat.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "similarity = F.cosine_similarity(first_flat.unsqueeze(0), second_flat.unsqueeze(0))\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_flat = untreated_image.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = F.cosine_similarity(first_flat.unsqueeze(0), untreated_flat.unsqueeze(0))\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_flat == untreated_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "orig without resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Load and normalize both images\n",
    "im1 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B07-T01.tiff')\n",
    "im2 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B08-T01.tiff')\n",
    "\n",
    "# Ensure each image has 3 layers (channels)\n",
    "if im1.shape[0] != 3 or im2.shape[0] != 3:\n",
    "    raise ValueError(\"Each image must have exactly 3 layers.\")\n",
    "\n",
    "# Normalize the 16-bit images to [0, 1]\n",
    "im1 = im1.astype(np.float32) / 65535.0\n",
    "im2 = im2.astype(np.float32) / 65535.0\n",
    "print(im2.shape)\n",
    "\n",
    "# Flatten the 3D images to 1D vectors\n",
    "im1_flattened = im1.flatten()\n",
    "im2_flattened = im2.flatten()\n",
    "print(im2_flattened.shape)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_similarity = np.dot(im1_flattened, im2_flattened) / (norm(im1_flattened) * norm(im2_flattened))\n",
    "\n",
    "print(f\"Cosine Similarity between the two images: {cosine_similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B07-T01.tiff')\n",
    "im2 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\untreated\\D08-T01.tiff')\n",
    "\n",
    "# Ensure each image has 3 layers (channels)\n",
    "if im1.shape[0] != 3 or im2.shape[0] != 3:\n",
    "    raise ValueError(\"Each image must have exactly 3 layers.\")\n",
    "\n",
    "# Normalize the 16-bit images to [0, 1]\n",
    "im1 = im1.astype(np.float32) / 65535.0\n",
    "im2 = im2.astype(np.float32) / 65535.0\n",
    "print(im2.shape)\n",
    "\n",
    "# Flatten the 3D images to 1D vectors\n",
    "im1_flattened = im1.flatten()\n",
    "im2_flattened = im2.flatten()\n",
    "print(im2_flattened.shape)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_similarity = np.dot(im1_flattened, im2_flattened) / (norm(im1_flattened) * norm(im2_flattened))\n",
    "\n",
    "print(f\"Cosine Similarity between the two images: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAS IST DAS?\n",
    "Mach kein Sinn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B07-T01.tiff')\n",
    "img2 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B08-T01.tiff')\n",
    "img3 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\untreated\\D08-T01.tiff')\n",
    "img1_flattened = img1.flatten()\n",
    "img2_flattened = img2.flatten()\n",
    "img3_flattened = img3.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = np.dot(img1_flattened, img2_flattened) / (norm(img1_flattened) * norm(img2_flattened))\n",
    "print(f\"Cosine Similarity between the two images: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = np.dot(img1_flattened, img3_flattened) / (norm(img1_flattened) * norm(img3_flattened))\n",
    "print(f\"Cosine Similarity between the two images: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, if we didn't use simclr and just try to find the cosine similarity between orig images: it doesn't deviate too  much not good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
