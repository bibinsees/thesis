{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "#from helper import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Now you can use the `device` variable\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay,max_epochs):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        # Load the pretrained ResNet-18 model\n",
    "        self.convnet = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "        \n",
    "        # Modify the fully connected layer\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4 * hidden_dim),  # Linear layer with 4*hidden_dim output\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * hidden_dim, 20)  # Output layer with hidden_dim output\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.AdamW(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        self.lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=max_epochs, eta_min=lr / 50)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convnet(x)\n",
    "\n",
    "    def info_nce_loss(self, imgs1, imgs2, device):\n",
    "\n",
    "        imgs = torch.cat((imgs1, imgs2), dim=0)  # Concatenate along the batch dimension\n",
    "        imgs = imgs.to(device)  # Move images to the device\n",
    "\n",
    "        # Encode all images\n",
    "        feats = self.forward(imgs)\n",
    "    \n",
    "        # Calculate cosine similarity\n",
    "        cos_sim = nn.functional.cosine_similarity(feats[:, None, :], feats[None, :, :], dim=-1)\n",
    "    \n",
    "        # Mask out cosine similarity to itself\n",
    "        self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "        cos_sim.masked_fill_(self_mask, -9e15)\n",
    "    \n",
    "        # Find positive example -> batch_size//2 away from the original example\n",
    "        pos_mask = self_mask.roll(shifts=cos_sim.shape[0] // 2, dims=0)\n",
    "    \n",
    "        # Normalize similarity scores by temperature\n",
    "        cos_sim = cos_sim / self.temperature\n",
    "\n",
    "        # InfoNCE loss\n",
    "        nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "        nll = nll.mean()\n",
    "\n",
    "        # Accuracy calculations\n",
    "        # Create a combination of positive and negative similarities for ranking\n",
    "        comb_sim = torch.cat([cos_sim[pos_mask][:, None],  # Positive example in first position\n",
    "                          cos_sim.masked_fill(pos_mask, -9e15)], dim=-1)\n",
    "    \n",
    "        # Sort and get the ranking position of the positive example\n",
    "        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
    "    \n",
    "        # Compute accuracy metrics\n",
    "        top1_acc = (sim_argsort == 0).float().mean()  # Top-1 accuracy\n",
    "        top5_acc = (sim_argsort < 5).float().mean()   # Top-5 accuracy\n",
    "        mean_pos = 1 + sim_argsort.float().mean()     # Mean position of the positive example\n",
    "\n",
    "        return nll, top1_acc, top5_acc, mean_pos\n",
    "\n",
    "    def train_epoch(self, train_loader, device):\n",
    "        self.train()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            imgs1, imgs2, _ = batch\n",
    "            imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "        \n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Calculate loss and accuracy metrics\n",
    "            loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            #self.lr_scheduler.step()\n",
    "\n",
    "            # Accumulate metrics\n",
    "            total_loss += loss.item()\n",
    "            total_top1_acc += top1_acc.item()\n",
    "            total_top5_acc += top5_acc.item()\n",
    "            total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(train_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(train_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(train_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos\n",
    "\n",
    "    def validate_epoch(self, val_loader, device):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "                imgs1, imgs2, _ = batch\n",
    "                imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "\n",
    "                # Calculate loss and accuracy metrics\n",
    "                loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "                # Accumulate metrics\n",
    "                total_loss += loss.item()\n",
    "                total_top1_acc += top1_acc.item()\n",
    "                total_top5_acc += top5_acc.item()\n",
    "                total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(val_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(val_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(val_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(val_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos\n",
    "    \n",
    "\n",
    "    def inference_epoch(self, inference_loader, device):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(inference_loader, desc=\"Inferencing\", leave=False):\n",
    "                imgs1, imgs2, _ = batch\n",
    "                imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "\n",
    "                # Calculate loss and accuracy metrics\n",
    "                loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "                # Accumulate metrics\n",
    "                total_loss += loss.item()\n",
    "                total_top1_acc += top1_acc.item()\n",
    "                total_top5_acc += top5_acc.item()\n",
    "                total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(inference_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(inference_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(inference_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(inference_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "model_path = r'C:\\Users\\k54739\\Bibi_new_thesis\\saved_model\\sweetcrop_simclr_model_epoch_245.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_25724\\3778111997.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  simclr_model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (convnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=512, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simclr_model = SimCLR(hidden_dim=128, lr=5e-4, temperature=0.07, weight_decay=1e-4,max_epochs=245)\n",
    "simclr_model.load_state_dict(torch.load(model_path))\n",
    "simclr_model.to(device)\n",
    "simclr_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference before projection head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledImageDataset(Dataset):\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "\n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Convert to a torch tensor and add channel dimension\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        \n",
    "        # Apply resize transform\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def load_and_split_data(root_dir, test_size=0.2):\n",
    "    #classes = ['untreated', 'single_dose', 'drug_screened']\n",
    "    classes = ['sd', 'ex_40']\n",
    "    image_files = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(root_dir, class_name)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir) if file.endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        labels.extend([idx] * len(files))\n",
    "    \n",
    "    # Check if the labels correctly reflect the classes\n",
    "    #print(\"Label distribution:\", {classes[i]: labels.count(i) for i in range(len(classes))})\n",
    "    \n",
    "    # Split data into training and test sets\n",
    "    train_files, test_files, train_labels, test_labels = train_test_split(\n",
    "        image_files, labels, test_size=test_size, stratify=labels, random_state=42)\n",
    "\n",
    "    return train_files, test_files, train_labels, test_labels\n",
    "\n",
    "\n",
    "# Directories for labeled data\n",
    "image_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\train_ex_vs_sd\"\n",
    "\n",
    "# Load and split the data\n",
    "train_files, test_files, train_labels, test_labels = load_and_split_data(image_dir, test_size=0.2)\n",
    "\n",
    "# Create the labeled datasets\n",
    "train_labeled_dataset = LabeledImageDataset(train_files, train_labels)\n",
    "test_labeled_dataset = LabeledImageDataset(test_files, test_labels)\n",
    "\n",
    "# Define DataLoaders\n",
    "batch_size = 16\n",
    "train_loader_labeled = DataLoader(train_labeled_dataset, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=0)\n",
    "test_loader_labeled = DataLoader(test_labeled_dataset, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 96, 96]) torch.Size([16]) torch.float32\n",
      "tensor([1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0])\n"
     ]
    }
   ],
   "source": [
    "for anchor,label in train_loader_labeled:\n",
    "    print(anchor.shape, label.shape, anchor.dtype)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in train_loader_labeled: 114\n"
     ]
    }
   ],
   "source": [
    "# Initialize a counter\n",
    "total_images = 0\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for anchor, label in train_loader_labeled:\n",
    "    total_images += anchor.size(0)  # Increment by the batch size (number of images in the current batch)\n",
    "\n",
    "# Print the total number of images\n",
    "print(f\"Total number of images in train_loader_labeled: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images in test_loader_labeled: 29\n"
     ]
    }
   ],
   "source": [
    "# Initialize a counter\n",
    "total_images = 0\n",
    "\n",
    "# Iterate through the DataLoader\n",
    "for anchor, label in test_loader_labeled:\n",
    "    total_images += anchor.size(0)  # Increment by the batch size (number of images in the current batch)\n",
    "\n",
    "# Print the total number of images\n",
    "print(f\"Total number of images in test_loader_labeled: {total_images}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_data_features(model, dataloader):\n",
    "    # Prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    # Encode all images\n",
    "    feats, labels = [], []\n",
    "    for batch_imgs, batch_labels in tqdm(dataloader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        print(f\"Batch features shape: {batch_feats.shape}\")\n",
    "        print(f\"Batch labels shape: {batch_labels.shape}\")\n",
    "        \n",
    "        feats.append(batch_feats.detach().cpu())\n",
    "        labels.append(batch_labels)\n",
    "\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    \n",
    "    print(f\"Features shape after concatenation: {feats.shape}\")\n",
    "    print(f\"Labels shape after concatenation: {labels.shape}\")\n",
    "\n",
    "    return torch.utils.data.TensorDataset(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 12%|█▎        | 1/8 [00:01<00:07,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 2/8 [00:01<00:05,  1.15it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 3/8 [00:02<00:04,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 4/8 [00:03<00:03,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▎   | 5/8 [00:03<00:02,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 6/8 [00:04<00:01,  1.37it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 8/8 [00:05<00:00,  1.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n",
      "Batch features shape: torch.Size([2, 512])\n",
      "Batch labels shape: torch.Size([2])\n",
      "Features shape after concatenation: torch.Size([114, 512])\n",
      "Labels shape after concatenation: torch.Size([114])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:00<00:00,  1.58it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 512])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.71it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([13, 512])\n",
      "Batch labels shape: torch.Size([13])\n",
      "Features shape after concatenation: torch.Size([29, 512])\n",
      "Labels shape after concatenation: torch.Size([29])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract features for train and test datasets\n",
    "train_feats_simclr = prepare_data_features(simclr_model, train_loader_labeled)\n",
    "test_feats_simclr = prepare_data_features(simclr_model, test_loader_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model definition\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, feature_dim, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_logistic_regression(model, train_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch_feats, batch_labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        batch_feats, batch_labels = batch_feats.to(device), batch_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_feats)\n",
    "        loss = nn.functional.cross_entropy(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_logistic_regression(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_feats, batch_labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            batch_feats, batch_labels = batch_feats.to(device), batch_labels.to(device)\n",
    "            \n",
    "            outputs = model(batch_feats)\n",
    "            loss = nn.functional.cross_entropy(outputs, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logreg_simplified(batch_size, train_feats_data, test_feats_data, feature_dim, num_classes, lr=5e-4, weight_decay=1e-4, max_epochs=50):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_feats_data, batch_size=batch_size, shuffle=True,\n",
    "                              drop_last=False, pin_memory=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_feats_data, batch_size=batch_size, shuffle=False,\n",
    "                             drop_last=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "    # Model, loss, and optimizer\n",
    "    model = LogisticRegression(feature_dim, num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                               milestones=[int(max_epochs * 0.6), int(max_epochs * 0.8)],\n",
    "                                               gamma=0.1)\n",
    "\n",
    "    # Store metrics for plotting\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    # Track best by accuracy\n",
    "    best_test_acc = -1.0\n",
    "    best_model_state_acc = None\n",
    "\n",
    "    # Track best by loss (with accuracy as a tiebreaker)\n",
    "    best_test_loss = float('inf')\n",
    "    best_test_loss_acc = -1.0\n",
    "    best_model_state_loss = None\n",
    "\n",
    "    for epoch in range(max_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{max_epochs}\")\n",
    "\n",
    "        train_loss, train_acc = train_logistic_regression(model, train_loader, optimizer, scheduler, device)\n",
    "        test_loss, test_acc = evaluate_logistic_regression(model, test_loader, criterion, device)\n",
    "\n",
    "        print(f\"Training loss: {train_loss:.4f}, Training accuracy: {train_acc:.4f}\")\n",
    "        print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        test_accuracies.append(test_acc)\n",
    "\n",
    "        # Check for best accuracy model\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            best_model_state_acc = model.state_dict()\n",
    "\n",
    "        # Check for best loss model\n",
    "        # Condition: strictly lower loss OR equal loss but higher accuracy\n",
    "        if (test_loss < best_test_loss) or (test_loss == best_test_loss and test_acc > best_test_loss_acc):\n",
    "            best_test_loss = test_loss\n",
    "            best_test_loss_acc = test_acc\n",
    "            best_model_state_loss = model.state_dict()\n",
    "\n",
    "    # Now we have two best states: best_model_state_acc and best_model_state_loss\n",
    "    # Create two separate model instances for them\n",
    "    best_acc_model = LogisticRegression(feature_dim, num_classes).to(device)\n",
    "    best_acc_model.load_state_dict(best_model_state_acc)\n",
    "    best_acc_model.eval()\n",
    "\n",
    "    best_loss_model = LogisticRegression(feature_dim, num_classes).to(device)\n",
    "    best_loss_model.load_state_dict(best_model_state_loss)\n",
    "    best_loss_model.eval()\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Loss curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(max_epochs), train_losses, label='Train Loss')\n",
    "    plt.plot(range(max_epochs), test_losses, label='Test Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(max_epochs), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(max_epochs), test_accuracies, label='Test Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Return both models and the final results (e.g., last train_acc and test_acc recorded)\n",
    "    return best_acc_model, best_loss_model, {\"train_acc\": train_acc, \"test_acc\": test_acc}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 205.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.1296, Training accuracy: 0.9737\n",
      "Test loss: 0.0561, Test accuracy: 1.0000\n",
      "Epoch 2/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0402, Training accuracy: 1.0000\n",
      "Test loss: 0.0226, Test accuracy: 1.0000\n",
      "Epoch 3/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0206, Training accuracy: 1.0000\n",
      "Test loss: 0.0132, Test accuracy: 1.0000\n",
      "Epoch 4/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 893.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0125, Training accuracy: 1.0000\n",
      "Test loss: 0.0094, Test accuracy: 1.0000\n",
      "Epoch 5/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 896.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0092, Training accuracy: 1.0000\n",
      "Test loss: 0.0073, Test accuracy: 1.0000\n",
      "Epoch 6/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 891.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0074, Training accuracy: 1.0000\n",
      "Test loss: 0.0061, Test accuracy: 1.0000\n",
      "Epoch 7/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 886.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0061, Training accuracy: 1.0000\n",
      "Test loss: 0.0051, Test accuracy: 1.0000\n",
      "Epoch 8/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 923.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0052, Training accuracy: 1.0000\n",
      "Test loss: 0.0044, Test accuracy: 1.0000\n",
      "Epoch 9/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 844.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0045, Training accuracy: 1.0000\n",
      "Test loss: 0.0039, Test accuracy: 1.0000\n",
      "Epoch 10/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 933.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0041, Training accuracy: 1.0000\n",
      "Test loss: 0.0034, Test accuracy: 1.0000\n",
      "Epoch 11/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 927.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0035, Training accuracy: 1.0000\n",
      "Test loss: 0.0030, Test accuracy: 1.0000\n",
      "Epoch 12/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 800.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0031, Training accuracy: 1.0000\n",
      "Test loss: 0.0027, Test accuracy: 1.0000\n",
      "Epoch 13/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 1014.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0028, Training accuracy: 1.0000\n",
      "Test loss: 0.0025, Test accuracy: 1.0000\n",
      "Epoch 14/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 883.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0023, Test accuracy: 1.0000\n",
      "Epoch 15/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 887.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3921.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0021, Test accuracy: 1.0000\n",
      "Epoch 16/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 3785.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0019, Test accuracy: 1.0000\n",
      "Epoch 17/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 896.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0020, Training accuracy: 1.0000\n",
      "Test loss: 0.0017, Test accuracy: 1.0000\n",
      "Epoch 18/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 911.78it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0016, Test accuracy: 1.0000\n",
      "Epoch 19/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 871.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0015, Test accuracy: 1.0000\n",
      "Epoch 20/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0014, Test accuracy: 1.0000\n",
      "Epoch 21/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0013, Test accuracy: 1.0000\n",
      "Epoch 22/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0013, Test accuracy: 1.0000\n",
      "Epoch 23/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 876.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0013, Training accuracy: 1.0000\n",
      "Test loss: 0.0012, Test accuracy: 1.0000\n",
      "Epoch 24/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 919.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0012, Training accuracy: 1.0000\n",
      "Test loss: 0.0011, Test accuracy: 1.0000\n",
      "Epoch 25/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 785.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0011, Test accuracy: 1.0000\n",
      "Epoch 26/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 1072.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0011, Training accuracy: 1.0000\n",
      "Test loss: 0.0010, Test accuracy: 1.0000\n",
      "Epoch 27/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 885.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 28/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 960.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 29/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2240.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 30/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 31/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 32/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 895.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 33/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 901.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 34/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 901.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 35/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 857.99it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 36/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 959.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 37/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 8811.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 38/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 39/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 40/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 787.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 41/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 1063.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 42/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 892.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 43/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 905.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 44/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 853.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 45/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 959.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 46/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2117.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 47/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 301.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 48/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 50/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 884.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 51/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 914.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 52/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 895.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 53/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 898.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 54/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 858.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 55/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 960.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 56/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2501.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 57/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 251.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 58/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 59/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 904.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 60/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 890.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 61/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 894.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 62/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 719.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3984.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 63/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 1605.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 64/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 883.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 65/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 66/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2187.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 67/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 68/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 69/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 905.70it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 70/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 899.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 71/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 881.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 72/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 910.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 73/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 818.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 74/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 960.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 75/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 925.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 76/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 825.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 77/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 959.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 78/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 805.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 79/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 1052.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 80/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 911.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 81/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 82/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 83/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 84/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 25216.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 85/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 874.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 86/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 914.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 87/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 895.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 88/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 901.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 89/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 879.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 90/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 960.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 91/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 860.23it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 92/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<?, ?it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2143.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 93/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 954.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 223.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 94/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 462.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 95/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 299.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 96/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 459.66it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 97/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 432.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 98/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 430.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 99/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 416.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 284.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 100/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 451.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 101/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 443.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 102/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 349.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 103/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 371.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 104/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 430.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 105/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 448.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 106/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 428.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 107/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 453.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 108/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 446.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 109/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 441.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0010, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 110/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 398.53it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 111/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 322.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 112/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 374.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 113/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 513.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 114/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 435.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 115/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 319.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 10076.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 116/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 467.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 117/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 349.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 118/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 358.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 119/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 442.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 120/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 439.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 121/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 433.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 122/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 438.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 123/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 432.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 124/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 441.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 125/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 445.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 6096.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 126/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 479.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 127/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 430.19it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 128/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 443.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 129/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 446.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 130/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 803.66it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 131/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 445.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 132/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 434.16it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 133/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 457.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 134/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 295.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 135/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 355.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 478.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 136/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 281.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1541.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 137/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 321.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 449.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 138/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 335.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 139/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 221.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 140/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 445.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 141/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 479.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 206.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 142/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 311.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 143/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 456.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 144/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 293.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 145/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 287.50it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 146/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 457.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 147/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 431.54it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 148/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 426.90it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 149/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 437.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 150/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 438.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 151/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 442.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 152/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 454.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 153/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 432.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 225.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 154/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 425.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 290.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 155/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 446.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 156/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 443.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 157/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 461.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 158/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 434.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 159/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 439.70it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 160/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 435.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 161/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 430.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 162/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 292.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 163/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 441.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 164/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 446.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 165/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 409.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 193.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 166/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 349.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 167/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 454.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 168/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 288.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 169/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 314.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 170/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 421.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 171/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 438.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 172/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 436.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0009, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 173/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 426.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 174/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 314.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 4067.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 175/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 453.16it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 176/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 297.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 177/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 305.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 225.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 178/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 441.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 179/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 413.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 262.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 180/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 461.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 181/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 438.19it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 259.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 182/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 316.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 447.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 183/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 374.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 467.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 184/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 350.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 517.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 185/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 353.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 571.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 186/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 374.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 499.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 187/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 382.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 506.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 188/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 388.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 590.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 189/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 365.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 452.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 190/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 390.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 468.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 191/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 373.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 477.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 192/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 376.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 492.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 193/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 354.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 575.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 194/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 371.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 195/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 283.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 571.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 196/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 395.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 571.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 197/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 347.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 571.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 198/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 363.70it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 524.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 199/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 421.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 200/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 479.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1626.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 201/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 460.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 202/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 318.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1732.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 203/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 303.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 204/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 298.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 205/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 268.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 500.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 206/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 375.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 571.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 207/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 459.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 208/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 432.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 209/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 437.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 176.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 210/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 364.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 211/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 290.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 326.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 212/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 422.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 213/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 428.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 214/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 431.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 258.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 215/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 446.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 216/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 457.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 245.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 217/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 445.53it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 248.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 218/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 324.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1752.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 219/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 428.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 220/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 427.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 221/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 304.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 222/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 308.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 223/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 296.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 224/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 426.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 225/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 298.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 226/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 442.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 227/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 439.44it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 228/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 450.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 229/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 427.19it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 230/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 427.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 247.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 231/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 426.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 232/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 297.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 233/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 275.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 514.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 234/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 370.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 566.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 235/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 369.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 522.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 236/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 371.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 363.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 237/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 238/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 153.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 239/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 207.16it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 240/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 225.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 241/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 187.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 210.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 242/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.94it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 243/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 218.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 244/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 245/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 180.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 246/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 198.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 245.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 247/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 248/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 249/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 250/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 223.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 251/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 252/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.94it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 253/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 215.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 127.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 254/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 132.66it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 255/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 160.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 277.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 256/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 231.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 257/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 415.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 258/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 296.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 259/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 299.50it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 247.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 260/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 295.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 261/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 303.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 262/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 292.16it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 263/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 296.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 264/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 304.44it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 265/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 300.70it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 266/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 304.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 267/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 451.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 268/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 293.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 269/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 298.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 261.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0008, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 270/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 454.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 271/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 450.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0007, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 272/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 434.78it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 251.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 273/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 384.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 274/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 309.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 275/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 405.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 276/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 304.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 277/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 440.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 278/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 435.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 279/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 440.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2202.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 280/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 423.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 281/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 306.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 282/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 304.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 283/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 449.78it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 284/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 445.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 285/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 445.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 286/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 424.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 269.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 287/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 416.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 288/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 479.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3075.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 289/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 319.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 290/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 453.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 541.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 291/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 354.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 292/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 315.02it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 293/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 403.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 294/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 450.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 295/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 445.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 296/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 412.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 297/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 309.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 298/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 440.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 299/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 436.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 300/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 448.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 301/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 420.73it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 302/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 292.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 303/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 299.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 304/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 305/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 227.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2123.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 306/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 221.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 307/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 308/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 194.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 309/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 310/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 214.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 311/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 131.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 312/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 207.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 313/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 314/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 251.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 315/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 227.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 316/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 317/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 318/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 319/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.13it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 320/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 224.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1357.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 321/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 152.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 211.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 322/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 323/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 218.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 324/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 325/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 326/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 217.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 327/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 152.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0005, Test accuracy: 1.0000\n",
      "Epoch 328/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 329/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 330/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 331/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 173.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 332/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 333/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 334/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 221.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 245.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 335/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 166.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 336/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 202.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 337/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 338/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 172.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 339/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 206.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 340/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 341/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 204.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 342/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 343/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0006, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 344/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 345/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 167.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 346/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 198.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 347/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 175.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 348/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 349/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 220.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 350/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.02it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 351/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 221.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 352/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 175.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 353/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 176.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 354/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 355/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 213.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 356/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 210.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 357/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 358/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 221.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 359/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 360/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.50it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 128.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 361/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 215.16it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 362/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.66it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 363/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 160.99it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 364/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 198.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 365/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 146.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 227.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 366/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 154.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 367/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 253.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 368/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.94it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 369/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 172.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 370/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 216.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 127.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 371/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 372/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 172.99it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 251.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 373/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 374/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 200.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 424.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 375/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 154.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 376/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 209.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 257.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 377/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 175.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 168.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 378/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 199.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 122.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 379/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 380/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 251.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 381/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 382/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.76it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 383/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 174.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 222.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 384/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 190.23it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 215.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 385/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 217.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 386/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 154.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 212.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 387/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 219.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 388/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0005, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 389/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 390/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 172.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3955.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 391/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 196.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 218.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 392/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 393/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 161.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 394/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 395/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 205.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0004, Test accuracy: 1.0000\n",
      "Epoch 396/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 397/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 398/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 251.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 399/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 400/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 221.69it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 401/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 224.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 219.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 402/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 152.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 403/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 462.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 404/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 162.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 405/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 227.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 406/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 227.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 407/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 152.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 408/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 229.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 409/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 410/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 228.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 411/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 227.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 247.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 412/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.16it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 166.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 413/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 156.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 344.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 414/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 155.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 415/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 195.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 712.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 416/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 144.69it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 406.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 417/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 418/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 229.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 419/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 420/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.10it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 421/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 422/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 423/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 424/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 223.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 124.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 425/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 227.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 426/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.90it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 427/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 230.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 428/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 429/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 430/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 431/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 432/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 223.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 433/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 219.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 434/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 435/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 436/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 225.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.36it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 437/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 226.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 438/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 109.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 439/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 190.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 128.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 440/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 441/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 269.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 442/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 159.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1482.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 443/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 225.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 444/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 186.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 230.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 445/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 446/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 112.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 447/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 118.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 448/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 449/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 450/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 451/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.99it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 452/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 453/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 225.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 454/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 455/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 117.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 456/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.51it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 245.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 457/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0004, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 458/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 459/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 460/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 461/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.02it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 462/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 463/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 221.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 558.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 464/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 465/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 466/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 467/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.09it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 468/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.19it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 469/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 210.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 470/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 185.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 471/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 121.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 472/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 248.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0003, Test accuracy: 1.0000\n",
      "Epoch 473/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.54it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 119.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 474/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 475/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 248.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 476/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 148.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 477/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 478/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 479/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.78it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 480/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 165.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 426.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 481/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 120.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 482/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 483/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 484/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 485/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 196.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 486/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 187.88it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 487/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 119.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 488/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 489/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 224.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 120.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 490/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 491/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 227.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 492/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 248.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 493/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 170.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 494/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 201.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 131.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 495/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 496/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.23it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 226.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 497/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 118.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 498/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.41it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 499/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 221.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 500/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.66it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 501/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 502/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.23it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 503/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 250.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 504/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 158.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 505/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 208.94it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 138.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 506/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 145.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 507/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.03it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 508/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 118.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 509/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0003, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 510/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 511/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 512/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 513/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 514/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 225.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 515/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 226.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2868.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 516/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 223.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 517/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.52it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 518/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 143.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 391.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 519/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.98it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 520/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 247.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 521/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 224.40it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 522/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 164.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 523/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 169.56it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 524/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 153.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 525/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 245.32it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 526/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.44it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 527/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 528/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 223.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 529/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.67it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 530/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 531/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 532/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 533/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 534/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 535/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 152.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 536/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 537/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 165.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 534.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 538/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 153.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 539/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 229.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 540/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 541/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3090.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 542/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 224.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 543/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 118.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 544/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 545/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 546/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 224.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 547/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 224.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3275.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 548/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.58it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 549/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.19it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 550/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 184.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 133.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 551/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 147.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 552/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.69it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 553/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.94it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 554/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 128.03it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 555/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.14it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.33it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 556/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 557/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 558/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 230.39it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 559/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 226.08it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 560/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 122.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 561/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 562/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 563/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 245.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 564/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 225.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 256.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 565/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 566/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.53it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 567/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 568/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 152.72it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 569/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 570/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 571/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.28it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 572/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 226.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 573/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 574/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 173.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 575/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 195.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 576/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 577/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 578/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3000.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 579/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.19it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 580/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 581/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 171.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 393.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 582/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 251.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 583/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 584/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 224.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0002, Test accuracy: 1.0000\n",
      "Epoch 585/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.47it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 226.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 586/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.70it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 587/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.90it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 588/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 213.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 589/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 185.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 590/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 591/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 592/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 593/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 245.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 594/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 158.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 595/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 175.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 1309.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 596/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 161.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 667.38it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 597/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 123.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 598/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 226.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 229.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 599/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.79it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 600/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 601/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 602/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3482.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 603/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 223.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 5401.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 604/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 223.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 605/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.70it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 606/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.93it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 607/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.42it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 168.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 608/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 163.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 609/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 610/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 224.51it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 611/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.26it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 247.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 612/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 613/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.26it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 614/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 227.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 615/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 616/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 222.99it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 126.19it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 617/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.11it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 618/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 154.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 619/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 205.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 130.16it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 620/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 172.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 307.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 621/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 159.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 788.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 622/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 155.69it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 230.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 623/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 187.97it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 214.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 624/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.80it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 625/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 626/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.93it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 627/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.55it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 628/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 140.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 629/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 171.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0002, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 630/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 240.48it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 631/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 632/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 224.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 633/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 148.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 252.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 634/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.91it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 635/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.18it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 251.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 636/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 637/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 638/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.23it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 122.77it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 639/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 640/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.31it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 641/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 642/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 249.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 643/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 644/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 225.43it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2895.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 645/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 646/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.87it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 122.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 647/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.49it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 648/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 128.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 649/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.54it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 650/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 651/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 652/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.63it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 653/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 654/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 655/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 128.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 656/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 657/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.69it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 658/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 659/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.28it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 245.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 660/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.51it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 230.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 661/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.50it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 662/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 663/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 664/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.53it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 665/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.66it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 666/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.89it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.66it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 667/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 668/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.66it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 669/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 670/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 120.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 671/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 170.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 386.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 672/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.52it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 673/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 163.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 548.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 674/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 152.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 675/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 187.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 227.22it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 676/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 677/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.30it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 227.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 678/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.34it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 679/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.85it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 229.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 680/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 681/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 682/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 234.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 683/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 235.35it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 684/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.12it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 685/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 223.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 686/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.04it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 687/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.15it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 688/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.59it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 689/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.86it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 118.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 690/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 225.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 255.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 691/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.74it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.23it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 692/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 693/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.32it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 197.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 694/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 193.07it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 133.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 695/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 161.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 440.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 696/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 155.21it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 3482.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 697/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 177.68it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 698/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 236.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 699/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 148.77it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 251.34it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 700/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 231.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 701/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.90it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 250.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 702/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.51it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 116.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 703/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.27it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 243.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 704/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 245.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 705/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 167.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 706/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 164.09it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 266.53it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 707/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 152.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 708/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 183.57it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 709.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 709/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 143.24it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 350.06it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 710/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 160.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 820.40it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 711/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.95it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 226.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 712/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.94it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.42it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 713/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 254.71it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 714/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.75it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 715/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.48it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 247.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 716/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.67it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 717/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 225.92it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 718/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.70it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 719/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.00it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 720/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.20it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 242.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 721/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.44it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.02it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 722/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.45it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 224.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 723/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.05it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.56it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 724/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 229.16it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 2422.00it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 725/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 225.65it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 726/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.08it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 239.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 727/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.17it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 246.14it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 728/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.37it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 729/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.36it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 202.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 730/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 189.96it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 141.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 731/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 163.61it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 376.41it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 732/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 178.71it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 733/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.84it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 232.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 734/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 128.46it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 121.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 735/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 182.64it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 186.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 736/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 192.82it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 155.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 737/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 151.50it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 178.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 738/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.01it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 230.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 739/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.35it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 244.30it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 740/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 179.33it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 120.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 741/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.29it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.75it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 742/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 149.62it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 233.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 743/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.39it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 230.55it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 744/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.25it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 241.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 745/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 150.06it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 248.05it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 746/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 146.83it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 289.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 747/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.22it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 230.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 748/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.60it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 238.78it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 749/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 180.81it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 237.98it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n",
      "Epoch 750/750\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 15/15 [00:00<00:00, 181.38it/s]\n",
      "Evaluating: 100%|██████████| 4/4 [00:00<00:00, 228.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0001, Training accuracy: 1.0000\n",
      "Test loss: 0.0001, Test accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the logistic regression model\n",
    "# Example usage:\n",
    "best_acc_model, best_loss_model, results = train_logreg_simplified(\n",
    "    batch_size=8,\n",
    "    train_feats_data=train_feats_simclr,\n",
    "    test_feats_data=test_feats_simclr,\n",
    "    feature_dim=train_feats_simclr.tensors[0].shape[1],\n",
    "    num_classes=2,\n",
    "    lr=5e-4,\n",
    "    weight_decay=1e-4,\n",
    "    max_epochs=750\n",
    ")\n",
    "#print(f\"Final Train Accuracy: {results['train_acc']:.4f}, Final Test Accuracy: {results['test_acc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (linear): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg_model= best_loss_model\n",
    "logreg_model\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the logistic regression model\n",
    "# Example usage:\n",
    "best_acc_model, best_loss_model, results = train_logreg_simplified(\n",
    "    batch_size=8,\n",
    "    train_feats_data=train_feats_simclr,\n",
    "    test_feats_data=test_feats_simclr,\n",
    "    feature_dim=train_feats_simclr.tensors[0].shape[1],\n",
    "    num_classes=2,\n",
    "    lr=5e-4,\n",
    "    weight_decay=1e-4,\n",
    "    max_epochs=100\n",
    ")\n",
    "#print(f\"Final Train Accuracy: {results['train_acc']:.4f}, Final Test Accuracy: {results['test_acc']:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the best models by accuracy and loss\n",
    "torch.save(best_acc_model.state_dict(), \"1000epoch_best_acc_model.pth\")\n",
    "torch.save(best_loss_model.state_dict(), \"1000epoch_best_loss_model.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg_model = LogisticRegression(512,2)\n",
    "logreg_model = logreg_model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_22448\\4036842466.py:8: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  state_dict = torch.load(\"1000epoch_best_loss_model.pth\")  # Load weights from the file\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(\n",
       "  (linear): Linear(in_features=512, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "# Step 2: Load the saved state dict\n",
    "state_dict = torch.load(\"1000epoch_best_loss_model.pth\")  # Load weights from the file\n",
    "logreg_model.load_state_dict(state_dict)  # Load state dict into the model\n",
    "\n",
    "# Step 3: Set the model to evaluation mode (if not training)\n",
    "logreg_model.eval()  # This disables dropout and batchnorm for inference\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 512= feature_dim = train_feats_simclr.tensors[0].shape[1] =  before projection head"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Save model state_dict\n",
    "torch.save(logreg_model.state_dict(), \"logreg_model_best.pth\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 1000 epochs: no outlier amoung exploded, control7, single dose\n",
    "#500 epochs, one outlier of exploder in ds closer to sd: which is ds41_g9_C10-T01   inbetween 4 ds closer\n",
    "# 100 epochs, one outlier of exploder also one outlier from ds_clos_tosd ds41_g5_E04-T01\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# we got 100 % down checking whether we will get it by repeating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 18/18 [00:12<00:00,  1.43it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sorted by p(treated) in ascending order:\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E3.tif: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E2.tif: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E4.tif: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E5.tif: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B11-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E08-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D09-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C07-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G07-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E10-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G10-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E09-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C07-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B03-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E09-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B03-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G08-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E10-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B02-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B09-T01.tiff: 0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B11-T01.tiff: 0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D08-T01.tiff: 0.0003\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F08-T01.tiff: 0.0007\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E06-T01.tiff: 0.0008\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F07-T01.tiff: 0.0008\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B06-T01.tiff: 0.0011\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E04-T01.tiff: 0.0016\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E03-T01.tiff: 0.0025\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B04-T01.tiff: 0.0026\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E04-T01.tiff: 0.0030\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E05-T01.tiff: 0.0030\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E05-T01.tiff: 0.0031\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E02-T01.tiff: 0.0040\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E10-T01.tiff: 0.0054\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E06-T01.tiff: 0.0070\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B05-T01.tiff: 0.0224\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B11-T01.tiff: 0.0584\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D02-T01.tiff: 0.0597\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B09-T01.tiff: 0.0674\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C04-T01.tiff: 0.0776\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D09-T01.tiff: 0.0984\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D06-T01.tiff: 0.1055\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G04-T01.tiff: 0.1574\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C07-T01.tiff: 0.1662\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B08-T01.tiff: 0.1710\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F09-T01.tiff: 0.2206\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F07-T01.tiff: 0.3078\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F11-T01.tiff: 0.3645\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D03-T01.tiff: 0.3822\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E03-T01.tiff: 0.3830\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F10-T01.tiff: 0.3944\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E08-T01.tiff: 0.3997\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E11-T01.tiff: 0.4431\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E05-T01.tiff: 0.4536\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B10-T01.tiff: 0.4549\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B02-T01.tiff: 0.4696\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B10-T01.tiff: 0.4954\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C11-T01.tiff: 0.5016\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C04-T01.tiff: 0.5030\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G07-T01.tiff: 0.5414\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C10-T01.tiff: 0.5591\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F02-T01.tiff: 0.5743\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G02-T01.tiff: 0.6085\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G05-T01.tiff: 0.6192\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G07-T01.tiff: 0.6319\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E09-T01.tiff: 0.6519\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B03-T01.tiff: 0.6525\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D02-T01.tiff: 0.6601\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G08-T01.tiff: 0.6798\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C07-T01.tiff: 0.6859\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E02-T01.tiff: 0.7082\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G03-T01.tiff: 0.7104\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D07-T01.tiff: 0.7117\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F05-T01.tiff: 0.7260\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D10-T01.tiff: 0.7431\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E08-T01.tiff: 0.7550\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F06-T01.tiff: 0.7722\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D04-T01.tiff: 0.7793\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E05-T01.tiff: 0.7833\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F04-T01.tiff: 0.7911\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G11-T01.tiff: 0.8025\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E10-T01.tiff: 0.8284\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B06-T01.tiff: 0.8367\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B07-T01.tiff: 0.8442\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C08-T01.tiff: 0.8559\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G10-T01.tiff: 0.8574\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B06-T01.tiff: 0.8624\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G05-T01.tiff: 0.8647\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C02-T01.tiff: 0.8744\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B05-T01.tiff: 0.8803\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F03-T01.tiff: 0.8890\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E06-T01.tiff: 0.8911\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D07-T01.tiff: 0.8914\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F08-T01.tiff: 0.8988\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E03-T01.tiff: 0.9154\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D11-T01.tiff: 0.9178\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F08-T01.tiff: 0.9179\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E07-T01.tiff: 0.9200\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D08-T01.tiff: 0.9244\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B05-T01.tiff: 0.9294\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B08-T01.tiff: 0.9299\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B04-T01.tiff: 0.9325\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G09-T01.tiff: 0.9408\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C02-T01.tiff: 0.9415\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E02-T01.tiff: 0.9422\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D06-T01.tiff: 0.9472\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D09-T01.tiff: 0.9484\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C11-T01.tiff: 0.9502\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G02-T01.tiff: 0.9549\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B11-T01.tiff: 0.9552\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E04-T01.tiff: 0.9554\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F10-T01.tiff: 0.9581\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F05-T01.tiff: 0.9619\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D05-T01.tiff: 0.9630\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B09-T01.tiff: 0.9653\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G03-T01.tiff: 0.9654\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D03-T01.tiff: 0.9654\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D10-T01.tiff: 0.9667\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E11-T01.tiff: 0.9676\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F04-T01.tiff: 0.9682\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C03-T01.tiff: 0.9697\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C09-T01.tiff: 0.9735\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F11-T01.tiff: 0.9737\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E04-T01.tiff: 0.9766\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G10-T01.tiff: 0.9786\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F02-T01.tiff: 0.9795\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F09-T01.tiff: 0.9802\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D11-T01.tiff: 0.9814\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F06-T01.tiff: 0.9816\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C05-T01.tiff: 0.9817\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F07-T01.tiff: 0.9823\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D08-T01.tiff: 0.9839\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E07-T01.tiff: 0.9855\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G08-T01.tiff: 0.9862\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E06-T01.tiff: 0.9862\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C05-T01.tiff: 0.9868\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G11-T01.tiff: 0.9870\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B04-T01.tiff: 0.9874\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C03-T01.tiff: 0.9874\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C06-T01.tiff: 0.9883\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E09-T01.tiff: 0.9890\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D05-T01.tiff: 0.9899\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C10-T01.tiff: 0.9912\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D04-T01.tiff: 0.9912\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F03-T01.tiff: 0.9919\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G09-T01.tiff: 0.9923\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G06-T01.tiff: 0.9944\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B02-T01.tiff: 0.9946\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G06-T01.tiff: 0.9952\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B03-T01.tiff: 0.9958\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G04-T01.tiff: 0.9963\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C09-T01.tiff: 0.9976\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B07-T01.tiff: 0.9983\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_c10.tif: 0.9990\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C06-T01.tiff: 0.9992\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C08-T01.tiff: 0.9992\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C9.tif: 0.9992\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C06-T01.tiff: 0.9993\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C7.tif: 0.9994\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C09-T01.tiff: 0.9995\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C03-T01.tiff: 0.9996\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g9_C10-T01.tiff: 0.9996\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C10-T01.tiff: 0.9997\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C11.tif: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C05-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C8.tif: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C06-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C05-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C02-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C02-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C03-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F03-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F05-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F02-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B09-T01.tiff: 1.0000\n"
     ]
    }
   ],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending ordergroups_data[group_name]\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images copied and renamed successfully!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Assuming 'sorted_by_treated' is already defined as:\n",
    "# sorted_by_treated = [(img_path, p_tr), ...] sorted in ascending order by p_tr\n",
    "\n",
    "new_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\sort_ex_85\"\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "for i, (img_path, p_tr) in enumerate(sorted_by_treated, start=1):\n",
    "    # Extract the parent directory name and the original filename\n",
    "    parent_dir_name = os.path.basename(os.path.dirname(img_path))  # e.g. \"cond7\"\n",
    "    base_filename = os.path.basename(img_path)  # e.g. \"ds_41.tif\"\n",
    "    \n",
    "    # Combine them to get \"cond7_ds_41.tif\"\n",
    "    original_filename = f\"{parent_dir_name}_{base_filename}\"\n",
    "\n",
    "    # Format the probability score\n",
    "    formatted_score = f\"{p_tr:.4f}\"\n",
    "    \n",
    "    # Construct the new filename with index and score\n",
    "    new_filename = f\"{i}_{formatted_score}_{original_filename}\"\n",
    "    new_path = os.path.join(new_dir, new_filename)\n",
    "    \n",
    "    shutil.copy2(img_path, new_path)\n",
    "\n",
    "print(\"Images copied and renamed successfully!\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 100 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Extracting Features: 100%|██████████| 18/18 [00:12<00:00,  1.42it/s]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x1200 with 6 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x500 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sorted by p(treated) in ascending order:\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C03-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B04-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E07-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D02-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C11-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D09-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E05-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D06-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G10-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E08-T01.tiff: 0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B03-T01.tiff: 0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C07-T01.tiff: 0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B08-T01.tiff: 0.0026\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B11-T01.tiff: 0.0026\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C11-T01.tiff: 0.0029\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F03-T01.tiff: 0.0030\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F02-T01.tiff: 0.0064\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C8.tif: 0.0159\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F06-T01.tiff: 0.0187\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C09-T01.tiff: 0.0214\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B10-T01.tiff: 0.0224\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B07-T01.tiff: 0.0307\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C10-T01.tiff: 0.0334\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C11.tif: 0.0508\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C08-T01.tiff: 0.0639\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C7.tif: 0.0672\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B10-T01.tiff: 0.1001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B09-T01.tiff: 0.1057\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B09-T01.tiff: 0.1087\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C04-T01.tiff: 0.1193\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F05-T01.tiff: 0.1277\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C9.tif: 0.1413\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F04-T01.tiff: 0.1888\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_c10.tif: 0.2812\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C10-T01.tiff: 0.4880\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C11-T01.tiff: 0.5236\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C02-T01.tiff: 0.6887\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C04-T01.tiff: 0.7544\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C08-T01.tiff: 0.7985\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C05-T01.tiff: 0.8027\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C03-T01.tiff: 0.8507\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B07-T01.tiff: 0.8660\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C07-T01.tiff: 0.8945\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C03-T01.tiff: 0.8987\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B11-T01.tiff: 0.9060\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C06-T01.tiff: 0.9433\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C06-T01.tiff: 0.9522\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G10-T01.tiff: 0.9622\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C02-T01.tiff: 0.9674\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C09-T01.tiff: 0.9685\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C05-T01.tiff: 0.9733\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E05-T01.tiff: 0.9933\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g9_C10-T01.tiff: 0.9974\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B04-T01.tiff: 0.9994\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B06-T01.tiff: 0.9995\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E5.tif: 0.9997\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E04-T01.tiff: 0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B05-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E03-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B03-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E09-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C07-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B02-T01.tiff: 0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E02-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E4.tif: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E2.tif: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E3.tif: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E05-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B03-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B03-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B04-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B06-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E09-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F10-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G11-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C08-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D07-T01.tiff: 1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D09-T01.tiff: 1.0000\n"
     ]
    }
   ],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending ordergroups_data[group_name]\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Images sorted by p(treated) in ascending order:\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_B11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C03-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_G02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_C04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B04-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_E11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E07-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_F09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_F05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_D02-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_C11-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D09-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E05-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_D06-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_G10-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBT_01.04_Day7_E08-T01.tiff: p(treated)=0.0000, p(control)=1.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\cond7\\RBTDS1B_Day_7_B03-T01.tiff: p(treated)=0.0001, p(control)=0.9999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C07-T01.tiff: p(treated)=0.0002, p(control)=0.9998\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B08-T01.tiff: p(treated)=0.0026, p(control)=0.9974\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B11-T01.tiff: p(treated)=0.0026, p(control)=0.9974\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C11-T01.tiff: p(treated)=0.0029, p(control)=0.9971\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F03-T01.tiff: p(treated)=0.0030, p(control)=0.9970\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F02-T01.tiff: p(treated)=0.0064, p(control)=0.9936\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C8.tif: p(treated)=0.0159, p(control)=0.9841\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F06-T01.tiff: p(treated)=0.0187, p(control)=0.9813\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C09-T01.tiff: p(treated)=0.0214, p(control)=0.9786\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B10-T01.tiff: p(treated)=0.0224, p(control)=0.9776\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B07-T01.tiff: p(treated)=0.0307, p(control)=0.9693\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C10-T01.tiff: p(treated)=0.0334, p(control)=0.9666\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C11.tif: p(treated)=0.0508, p(control)=0.9492\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g9_C08-T01.tiff: p(treated)=0.0639, p(control)=0.9361\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C7.tif: p(treated)=0.0672, p(control)=0.9328\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B10-T01.tiff: p(treated)=0.1001, p(control)=0.8999\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B09-T01.tiff: p(treated)=0.1057, p(control)=0.8943\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g8_B09-T01.tiff: p(treated)=0.1087, p(control)=0.8913\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C04-T01.tiff: p(treated)=0.1193, p(control)=0.8807\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F05-T01.tiff: p(treated)=0.1277, p(control)=0.8723\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_C9.tif: p(treated)=0.1413, p(control)=0.8587\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g6_F04-T01.tiff: p(treated)=0.1888, p(control)=0.8112\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds1B_g9_c10.tif: p(treated)=0.2812, p(control)=0.7188\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C10-T01.tiff: p(treated)=0.4880, p(control)=0.5120\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C11-T01.tiff: p(treated)=0.5236, p(control)=0.4764\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C02-T01.tiff: p(treated)=0.6887, p(control)=0.3113\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C04-T01.tiff: p(treated)=0.7544, p(control)=0.2456\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C08-T01.tiff: p(treated)=0.7985, p(control)=0.2015\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C05-T01.tiff: p(treated)=0.8027, p(control)=0.1973\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C03-T01.tiff: p(treated)=0.8507, p(control)=0.1493\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B07-T01.tiff: p(treated)=0.8660, p(control)=0.1340\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C07-T01.tiff: p(treated)=0.8945, p(control)=0.1055\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C03-T01.tiff: p(treated)=0.8987, p(control)=0.1013\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g8_B11-T01.tiff: p(treated)=0.9060, p(control)=0.0940\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C06-T01.tiff: p(treated)=0.9433, p(control)=0.0567\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g3_C06-T01.tiff: p(treated)=0.9522, p(control)=0.0478\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G10-T01.tiff: p(treated)=0.9622, p(control)=0.0378\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C02-T01.tiff: p(treated)=0.9674, p(control)=0.0326\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds62_g9_C09-T01.tiff: p(treated)=0.9685, p(control)=0.0315\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds61_g3_C05-T01.tiff: p(treated)=0.9733, p(control)=0.0267\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E05-T01.tiff: p(treated)=0.9933, p(control)=0.0067\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\ex_40\\ds41_g9_C10-T01.tiff: p(treated)=0.9974, p(control)=0.0026\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B04-T01.tiff: p(treated)=0.9994, p(control)=0.0006\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B06-T01.tiff: p(treated)=0.9995, p(control)=0.0005\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E5.tif: p(treated)=0.9997, p(control)=0.0003\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E04-T01.tiff: p(treated)=0.9998, p(control)=0.0002\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B05-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E03-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B03-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E09-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C07-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds62_g2_B02-T01.tiff: p(treated)=0.9999, p(control)=0.0001\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E06-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E06-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g5_E02-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E4.tif: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E2.tif: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds1b_g5_E3.tif: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g5_E05-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B03-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds41_g2_B03-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B04-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\ds42_g2_B06-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_B10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_C10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_D11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_E11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_F11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.04_Day10_G11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_B11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_C10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_D11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_E11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_F11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.09_Day10_G11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_B08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_C07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_D09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_E11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_F10-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.10_Day10_G11-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_B07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_C08-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D07-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference_for_accuracy\\single_dose\\sd_RBT_01.14_Day10_D09-T01.tiff: p(treated)=1.0000, p(control)=0.0000\n",
      "\n",
      "Group-Wise Ranking Accuracy:\n",
      "Correct Transitions: 1\n",
      "Total Possible Transitions: 2\n",
      "Ranking Accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1], entry[0]) for entry in all_images_data]\n",
    "\n",
    "# Print sorted images\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr, p_ctrl in sorted_by_treated:\n",
    "    print(f\"{img_path}: p(treated)={p_tr:.4f}, p(control)={p_ctrl:.4f}\")\n",
    "\n",
    "# Initialize group-wise data\n",
    "grouped_data = {group: [] for group in groups}\n",
    "for group in groups:\n",
    "    grouped_data[group].extend(groups_data[group])\n",
    "\n",
    "# Step 1: Sort distances and keep track of group membership\n",
    "sorted_distances = []\n",
    "for group, data in grouped_data.items():\n",
    "    for _, p_treated, _ in data:\n",
    "        sorted_distances.append((p_treated, group))\n",
    "\n",
    "sorted_distances.sort(key=lambda x: x[0])  # Sort by p(treated)\n",
    "\n",
    "# Step 2: Check for correct transitions between groups\n",
    "correct_transitions = 0\n",
    "total_transitions = len(groups) - 1  # Total possible adjacent group transitions\n",
    "\n",
    "for i in range(total_transitions):\n",
    "    group_i = groups[i]\n",
    "    group_j = groups[i + 1]\n",
    "\n",
    "    # Get all distances for groups i and j\n",
    "    distances_i = [dist for dist, grp in sorted_distances if grp == group_i]\n",
    "    distances_j = [dist for dist, grp in sorted_distances if grp == group_j]\n",
    "\n",
    "    # Check the condition: all d in G_i < all d in G_j\n",
    "    if all(d_i < d_j for d_i in distances_i for d_j in distances_j):\n",
    "        correct_transitions += 1\n",
    "\n",
    "# Step 3: Calculate ranking accuracy\n",
    "ranking_accuracy = correct_transitions / total_transitions if total_transitions > 0 else 1.0\n",
    "\n",
    "# Step 4: Print the group-wise ranking accuracy\n",
    "print(\"\\nGroup-Wise Ranking Accuracy:\")\n",
    "print(f\"Correct Transitions: {correct_transitions}\")\n",
    "print(f\"Total Possible Transitions: {total_transitions}\")\n",
    "print(f\"Ranking Accuracy: {ranking_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Assuming 'sorted_by_treated' is already defined as:\n",
    "# sorted_by_treated = [(img_path, p_tr), ...] sorted in ascending order by p_tr\n",
    "\n",
    "new_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\sorted_explodall\"\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "for i, (img_path, p_tr) in enumerate(sorted_by_treated, start=1):\n",
    "    # Extract the parent directory name and the original filename\n",
    "    parent_dir_name = os.path.basename(os.path.dirname(img_path))  # e.g. \"cond7\"\n",
    "    base_filename = os.path.basename(img_path)  # e.g. \"ds_41.tif\"\n",
    "    \n",
    "    # Combine them to get \"cond7_ds_41.tif\"\n",
    "    original_filename = f\"{parent_dir_name}_{base_filename}\"\n",
    "\n",
    "    # Format the probability score\n",
    "    formatted_score = f\"{p_tr:.4f}\"\n",
    "    \n",
    "    # Construct the new filename with index and score\n",
    "    new_filename = f\"{i}_{formatted_score}_{original_filename}\"\n",
    "    new_path = os.path.join(new_dir, new_filename)\n",
    "    \n",
    "    shutil.copy2(img_path, new_path)\n",
    "\n",
    "print(\"Images copied and renamed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import shutil\n",
    "\n",
    "# Assuming 'sorted_by_treated' is already defined as:\n",
    "# sorted_by_treated = [(img_path, p_tr), ...] sorted in ascending order by p_tr\n",
    "\n",
    "new_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\sorted_cond10\"\n",
    "os.makedirs(new_dir, exist_ok=True)\n",
    "\n",
    "for i, (img_path, p_tr) in enumerate(sorted_by_treated, start=1):\n",
    "    # Extract the parent directory name and the original filename\n",
    "    parent_dir_name = os.path.basename(os.path.dirname(img_path))  # e.g. \"cond7\"\n",
    "    base_filename = os.path.basename(img_path)  # e.g. \"ds_41.tif\"\n",
    "    \n",
    "    # Combine them to get \"cond7_ds_41.tif\"\n",
    "    original_filename = f\"{parent_dir_name}_{base_filename}\"\n",
    "\n",
    "    # Format the probability score\n",
    "    formatted_score = f\"{p_tr:.4f}\"\n",
    "    \n",
    "    # Construct the new filename with index and score\n",
    "    new_filename = f\"{i}_{formatted_score}_{original_filename}\"\n",
    "    new_path = os.path.join(new_dir, new_filename)\n",
    "    \n",
    "    shutil.copy2(img_path, new_path)\n",
    "\n",
    "print(\"Images copied and renamed successfully!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\2_class\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#500 epochs, one outlier of exploder in ds closer to sd: which is ds41_g9_C10-T01   inbetween 4 ds closer\n",
    "# 100 epochs, one outlier of exploder also one outlier from ds_clos_tosd ds41_g5_E04-T01\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "#from helper import set_seed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model definition\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, feature_dim, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Recreate the model structure\n",
    "feature_dim = 512 # Set this to the same dimension used during training\n",
    "num_classes = 2   # Since you trained for 2 classes\n",
    "logreg_model = LogisticRegression(feature_dim, num_classes).to(device)\n",
    "\n",
    "# Load the saved weights\n",
    "logreg_model.load_state_dict(torch.load(\"best_loss_model.pth\", map_location=device))\n",
    "logreg_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "import tifffile as tiff\n",
    "from torchvision import transforms\n",
    "\n",
    "# Assume simclr_model, logreg_model, device are already defined and loaded.\n",
    "# simclr_model: the feature extractor model\n",
    "# logreg_model: the logistic regression model for control vs treated classification.\n",
    "\n",
    "def get_all_groups(root_dir):\n",
    "    # All directories in root_dir are considered different groups\n",
    "    groups = []\n",
    "    for d in os.listdir(root_dir):\n",
    "        dir_path = os.path.join(root_dir, d)\n",
    "        if os.path.isdir(dir_path):\n",
    "            groups.append(d)\n",
    "    return groups\n",
    "\n",
    "def load_inference_data(root_dir):\n",
    "    groups = get_all_groups(root_dir)\n",
    "    \n",
    "    image_files = []\n",
    "    group_names = []\n",
    "    \n",
    "    # We won't use numeric labels for correctness here since our model is only binary.\n",
    "    # However, we still need a label tensor. We'll just assign a dummy label (e.g. 0) \n",
    "    # because we only need to run inference. The label doesn't affect inference.\n",
    "    dummy_labels = []\n",
    "\n",
    "    for group in groups:\n",
    "        class_dir = os.path.join(root_dir, group)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir)\n",
    "                 if file.lower().endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        group_names.extend([group] * len(files))\n",
    "        dummy_labels.extend([0]*len(files))  # dummy label\n",
    "\n",
    "    return image_files, dummy_labels, group_names, groups\n",
    "\n",
    "# Dataset that returns image, a dummy label, path, and keeps track of group name externally\n",
    "class LabeledImageDatasetWithPath:\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Handle shape: ensure CxHxW\n",
    "        if image.ndim == 3 and image.shape[2] == 3:\n",
    "            image = np.transpose(image, (2, 0, 1))\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} doesn't have 3 channels.\")\n",
    "\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "        return image, label, img_path\n",
    "\n",
    "@torch.no_grad()\n",
    "def extract_features(model, dataloader, device):\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    all_features = []\n",
    "    all_labels = []\n",
    "    all_paths = []\n",
    "    for batch_imgs, batch_labels, batch_paths in tqdm(dataloader, desc=\"Extracting Features\"):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        all_features.append(batch_feats.cpu())\n",
    "        all_labels.append(batch_labels)\n",
    "        all_paths.extend(batch_paths)\n",
    "    all_features = torch.cat(all_features, dim=0)\n",
    "    all_labels = torch.cat(all_labels, dim=0)\n",
    "    return all_features, all_labels, all_paths\n",
    "\n",
    "@torch.no_grad()\n",
    "def predict_with_probs(model, features, device):\n",
    "    model.eval()\n",
    "    features = features.to(device)\n",
    "    logits = model(features)  # shape: [N, 2]\n",
    "    probs = F.softmax(logits, dim=1)  # Convert logits to probabilities\n",
    "    return probs.cpu().numpy()\n",
    "\n",
    "# --------------------\n",
    "# MAIN INFERENCE FLOW\n",
    "# --------------------\n",
    "\n",
    "root_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\softmax_dataset\\inference\"\n",
    "\n",
    "# 1. Load data from all groups\n",
    "image_files, dummy_labels, group_names, groups = load_inference_data(root_dir)\n",
    "\n",
    "# 2. Create dataset and dataloader for inference\n",
    "inference_dataset = LabeledImageDatasetWithPath(image_files, dummy_labels)\n",
    "inference_loader = DataLoader(inference_dataset, batch_size=16, shuffle=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "# 3. Extract features\n",
    "inference_feats, inference_true_labels, inference_paths = extract_features(simclr_model, inference_loader, device)\n",
    "\n",
    "# 4. Get probabilities from logistic regression model\n",
    "probs = predict_with_probs(logreg_model, inference_feats, device)  # shape [N, 2]\n",
    "# probs[:, 0] = probability of control\n",
    "# probs[:, 1] = probability of treated\n",
    "\n",
    "# Let's store results in a dictionary keyed by group name\n",
    "# groups_data[group_name] = list of [p_control, p_treated, img_path]\n",
    "groups_data = {g: [] for g in groups}\n",
    "\n",
    "# Since group_names aligns with inference_paths and probs, we can pair them up\n",
    "for p_control, p_treated, grp, path in zip(probs[:,0], probs[:,1], group_names, inference_paths):\n",
    "    groups_data[grp].append([p_control, p_treated, path])\n",
    "\n",
    "# Now we have groups_data with each group having a list of probabilities and paths.\n",
    "\n",
    "# 5. Plot distributions\n",
    "\n",
    "# Individual distributions per group:\n",
    "# We'll create subplots dynamically based on how many groups we have.\n",
    "num_groups = len(groups)\n",
    "fig, axs = plt.subplots(num_groups, 2, figsize=(10, 4*num_groups))\n",
    "# axs[i,0] -> p(control) distribution for group i\n",
    "# axs[i,1] -> p(treated) distribution for group i\n",
    "\n",
    "if num_groups == 1:\n",
    "    # If there's only one group, axs is not a 2D array\n",
    "    axs = np.array([axs])  # make it 2D for consistency\n",
    "\n",
    "for i, grp in enumerate(groups):\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "\n",
    "    axs[i, 0].hist(p_control_list, bins=20, alpha=0.7, edgecolor='black')\n",
    "    axs[i, 0].set_title(f\"{grp} Group p(control)\")\n",
    "    axs[i, 0].set_xlabel(\"Probability\")\n",
    "    axs[i, 0].set_ylabel(\"Count\")\n",
    "\n",
    "    axs[i, 1].hist(p_treated_list, bins=20, alpha=0.7, edgecolor='black', color='orange')\n",
    "    axs[i, 1].set_title(f\"{grp} Group p(treated)\")\n",
    "    axs[i, 1].set_xlabel(\"Probability\")\n",
    "    axs[i, 1].set_ylabel(\"Count\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# 6. Plot combined distributions\n",
    "# 6.1: Compare all groups p(control) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_control_list = [item[0] for item in groups_data[grp]]\n",
    "    plt.hist(p_control_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(control) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# 6.2: Compare all groups p(treated) together\n",
    "plt.figure(figsize=(10, 5))\n",
    "for grp in groups:\n",
    "    p_treated_list = [item[1] for item in groups_data[grp]]\n",
    "    plt.hist(p_treated_list, bins=20, alpha=0.5, edgecolor='black', label=grp)\n",
    "plt.title(\"p(treated) Distribution Across All Groups\")\n",
    "plt.xlabel(\"Probability\")\n",
    "plt.ylabel(\"Count\")\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# At this point:\n",
    "# - We've dynamically handled any number of groups in the directory.\n",
    "# - We plotted individual probability distributions for each group.\n",
    "# - We also plotted combined distributions comparing all groups together for both p(control) and p(treated).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# descending order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in descending order (highest p(treated) first)\n",
    "all_images_data.sort(key=lambda x: x[1], reverse=True)\n",
    "\n",
    "# Now all_images_data is sorted by p(treated)\n",
    "# Extract (img_path, p_treated)\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "# Print or handle as needed\n",
    "print(\"Images sorted by p(treated) in descending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ascending order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_images_data = []\n",
    "for grp in groups:\n",
    "    # each entry is [p_control, p_treated, img_path]\n",
    "    all_images_data.extend(groups_data[grp])\n",
    "\n",
    "# Sort by p(treated) in ascending order\n",
    "all_images_data.sort(key=lambda x: x[1])  # No reverse=True\n",
    "\n",
    "# Now all_images_data is sorted by p(treated) in ascending order\n",
    "sorted_by_treated = [(entry[2], entry[1]) for entry in all_images_data]\n",
    "\n",
    "print(\"Images sorted by p(treated) in ascending order:\")\n",
    "for img_path, p_tr in sorted_by_treated:\n",
    "    print(f\"{img_path}: {p_tr:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Device setup for inference\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Preprocess_Image(image_path):\n",
    "    # Load the image\n",
    "    image = tiff.imread(image_path)\n",
    "    \n",
    "    # Ensure the image has 3 layers (channels)\n",
    "    if image.shape[0] != 3:\n",
    "        raise ValueError(f\"Image at {image_path} does not have exactly 3 layers.\")\n",
    "    \n",
    "    # Normalize the 16-bit image to [0, 1]\n",
    "    image = image.astype(np.float32) / 65535.0\n",
    "    \n",
    "    # Convert to a torch tensor\n",
    "    image = torch.tensor(image, dtype=torch.float32)\n",
    "    \n",
    "    # Resize to (96, 96)\n",
    "    image = TF.resize(image, (96, 96))\n",
    "    \n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_of_image = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B07-T01.tiff'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image = Preprocess_Image(path_of_image)\n",
    "print(first_image.shape)\n",
    "prep_first_image = first_image.unsqueeze(0)\n",
    "print(prep_first_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_image_np = first_image.numpy().transpose(1, 2, 0)  # (C, H, W) -> (H, W, C)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(first_image_np, cmap='gray')  # Use `cmap='gray'` if it's grayscale\n",
    "plt.title('First Image')\n",
    "plt.axis('off')  # Optional: turn off the axis for a cleaner look\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pathimage = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B08-T01.tiff'\n",
    "second_image = Preprocess_Image(pathimage)\n",
    "print(second_image.shape)\n",
    "prep_second_image = second_image.unsqueeze(0)\n",
    "print(prep_second_image.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "second_image_np = second_image.numpy().transpose(1, 2, 0)  # (C, H, W) -> (H, W, C)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(second_image_np, cmap='gray')  # Use `cmap='gray'` if it's grayscale\n",
    "plt.title('second Image')\n",
    "plt.axis('off')  # Optional: turn off the axis for a cleaner look\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def extract_features(model, image_tensor):\n",
    "    # prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "    \n",
    "    # Move image tensor to device\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    # Extract features\n",
    "    features = network(image_tensor)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"simclr_model: {simclr_model}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for both images\n",
    "first_image_feats = extract_features(simclr_model, prep_first_image)\n",
    "second_image_feats = extract_features(simclr_model, prep_second_image)\n",
    "print(first_image_feats.shape)\n",
    "print(second_image_feats.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSINE FROM NEWDATA CROP VAL&INFER\n",
    "# Compute cosine similarity between the feature vectors\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats, second_image_feats, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSINE old data crop\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats, second_image_feats, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im_path = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\untreated\\D08-T01.tiff'\n",
    "untreated_image = Preprocess_Image(im_path)\n",
    "print(untreated_image.shape)\n",
    "prep_untreated_image = untreated_image.unsqueeze(0)\n",
    "print(prep_untreated_image.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_image_np = untreated_image.numpy().transpose(1, 2, 0)  # (C, H, W) -> (H, W, C)\n",
    "\n",
    "# Display the image\n",
    "plt.figure(figsize=(5, 5))\n",
    "plt.imshow(untreated_image_np, cmap='gray')  # Use `cmap='gray'` if it's grayscale\n",
    "plt.title('untreated Image')\n",
    "plt.axis('off')  # Optional: turn off the axis for a cleaner look\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_image_feats = extract_features(simclr_model, prep_untreated_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# COSINE NEW DATA CROP\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats, untreated_image_feats, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cosine old data crop\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats, untreated_image_feats, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference after projection head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def features_after_projection(model, image_tensor):\n",
    "    # prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    #network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "    \n",
    "    # Move image tensor to device\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    \n",
    "    # Extract features\n",
    "    features = network(image_tensor)\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extract features for both images\n",
    "first_image_feats_after = features_after_projection(simclr_model, prep_first_image)\n",
    "second_image_feats_after = features_after_projection(simclr_model, prep_second_image)\n",
    "print(first_image_feats_after.shape)\n",
    "print(second_image_feats_after.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine newdata crop \n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats_after, second_image_feats_after, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cosine old data crop\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats_after, second_image_feats_after, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")\n",
    "\n",
    "#Cosine similarity between features: 0.8507535457611084\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as expected after projection head cosine similarity is higher this leads to the question that maybe for ranking images with time series, this after projection maybe better option."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_image_feats_after = features_after_projection(simclr_model, prep_untreated_image)\n",
    "print(untreated_image_feats_after.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between the feature vectors\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats_after, untreated_image_feats_after, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute cosine similarity between the feature vectors\n",
    "cosine_similarity = nn.functional.cosine_similarity(first_image_feats_after, untreated_image_feats_after, dim=1)\n",
    "print(f\"Cosine similarity between features: {cosine_similarity.item()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "as expected after projection head cosine similarity is lower for different class images this leads to the question that maybe for ranking images with time series, this after projection maybe better option."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Orig images (without simclr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(first_image)\n",
    "first_image.view(-1).shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(second_image)\n",
    "second_image.view(-1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_flat = first_image.view(-1)\n",
    "second_flat = second_image.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_flat.unsqueeze(0).shape == untreated_flat.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "similarity = F.cosine_similarity(first_flat.unsqueeze(0), second_flat.unsqueeze(0))\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "untreated_flat = untreated_image.view(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "similarity = F.cosine_similarity(first_flat.unsqueeze(0), untreated_flat.unsqueeze(0))\n",
    "similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_flat == untreated_flat"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "orig without resizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from numpy.linalg import norm\n",
    "\n",
    "# Load and normalize both images\n",
    "im1 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B07-T01.tiff')\n",
    "im2 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B08-T01.tiff')\n",
    "\n",
    "# Ensure each image has 3 layers (channels)\n",
    "if im1.shape[0] != 3 or im2.shape[0] != 3:\n",
    "    raise ValueError(\"Each image must have exactly 3 layers.\")\n",
    "\n",
    "# Normalize the 16-bit images to [0, 1]\n",
    "im1 = im1.astype(np.float32) / 65535.0\n",
    "im2 = im2.astype(np.float32) / 65535.0\n",
    "print(im2.shape)\n",
    "\n",
    "# Flatten the 3D images to 1D vectors\n",
    "im1_flattened = im1.flatten()\n",
    "im2_flattened = im2.flatten()\n",
    "print(im2_flattened.shape)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_similarity = np.dot(im1_flattened, im2_flattened) / (norm(im1_flattened) * norm(im2_flattened))\n",
    "\n",
    "print(f\"Cosine Similarity between the two images: {cosine_similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "im1 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B07-T01.tiff')\n",
    "im2 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\untreated\\D08-T01.tiff')\n",
    "\n",
    "# Ensure each image has 3 layers (channels)\n",
    "if im1.shape[0] != 3 or im2.shape[0] != 3:\n",
    "    raise ValueError(\"Each image must have exactly 3 layers.\")\n",
    "\n",
    "# Normalize the 16-bit images to [0, 1]\n",
    "im1 = im1.astype(np.float32) / 65535.0\n",
    "im2 = im2.astype(np.float32) / 65535.0\n",
    "print(im2.shape)\n",
    "\n",
    "# Flatten the 3D images to 1D vectors\n",
    "im1_flattened = im1.flatten()\n",
    "im2_flattened = im2.flatten()\n",
    "print(im2_flattened.shape)\n",
    "\n",
    "# Calculate cosine similarity\n",
    "cosine_similarity = np.dot(im1_flattened, im2_flattened) / (norm(im1_flattened) * norm(im2_flattened))\n",
    "\n",
    "print(f\"Cosine Similarity between the two images: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "WAS IST DAS?\n",
    "Mach kein Sinn!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B07-T01.tiff')\n",
    "img2 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\single_dose\\B08-T01.tiff')\n",
    "img3 = tiff.imread(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Data_supervised\\untreated\\D08-T01.tiff')\n",
    "img1_flattened = img1.flatten()\n",
    "img2_flattened = img2.flatten()\n",
    "img3_flattened = img3.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = np.dot(img1_flattened, img2_flattened) / (norm(img1_flattened) * norm(img2_flattened))\n",
    "print(f\"Cosine Similarity between the two images: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_similarity = np.dot(img1_flattened, img3_flattened) / (norm(img1_flattened) * norm(img3_flattened))\n",
    "print(f\"Cosine Similarity between the two images: {cosine_similarity}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "so, if we didn't use simclr and just try to find the cosine similarity between orig images: it doesn't deviate too  much not good."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
