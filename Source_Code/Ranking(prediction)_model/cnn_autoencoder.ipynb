{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "import tifffile as tiff\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Size of input images\n",
    "SIZE = 128\n",
    "batch_size = 64"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define transformations similar to rescaling in Keras\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((SIZE, SIZE)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5,), (0.5,))  # Normalizing to [-1, 1] range\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.tiff')]\n",
    "        #we don't need to resize into 96*96 because we are doing that in below contrastive transform (self.resize_transform = transforms.resize((96,96)))\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "        \n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        \n",
    "        # Convert to a torch tensor\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image\n",
    "\n",
    "# Data augmentation similar to the tutorial\n",
    "contrast_transforms = transforms.Compose([\n",
    "    #transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomResizedCrop(size=96),\n",
    "    #transforms.RandomApply([transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1)], p=0.8),\n",
    "    #transforms.RandomGrayscale(p=0.2),\n",
    "   #transforms.GaussianBlur(kernel_size=9),\n",
    "])\n",
    "\n",
    "# Create the dataset\n",
    "image_dir = r\"../../Day10_drugscreened&singledose_untreated\"\n",
    "\n",
    "\n",
    "dataset = ImageDataset(image_dir=image_dir, transform=contrast_transforms)\n",
    "batch_size = 16\n",
    "\n",
    "# Function to split dataset with explicit percentage\n",
    "def split_dataset(dataset, val_percentage):\n",
    "    val_size = int(len(dataset) * val_percentage)\n",
    "    train_size = len(dataset) - val_size\n",
    "    return random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Split the dataset with 20% for validation\n",
    "val_percentage = 0.2\n",
    "train_dataset, val_dataset = split_dataset(dataset, val_percentage)\n",
    "\n",
    "# Define DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=0) #num_workers=os.cpu count() using cluster gpu\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "  image: torch.Size([16, 3, 96, 96])\n"
     ]
    }
   ],
   "source": [
    "for i, image in enumerate(train_loader):\n",
    "    print(f\"Batch {i}:\")\n",
    "    print(f\"  image: {image.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#anomaly_dataset = datasets.ImageFolder('cell_images2/parasitized/', transform=transform)\n",
    "#anomaly_loader = DataLoader(anomaly_dataset, batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the autoencoder model in PyTorch\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, padding=1),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, padding=1),\n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, padding=1)\n",
    "        )\n",
    "        \n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),\n",
    "            nn.Conv2d(64, 3, kernel_size=3, padding=1),\n",
    "            nn.Sigmoid()\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Autoencoder(\n",
       "  (encoder): Sequential(\n",
       "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (3): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (6): Conv2d(32, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): MaxPool2d(kernel_size=2, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "  )\n",
       "  (decoder): Sequential(\n",
       "    (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (1): ReLU()\n",
       "    (2): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (3): Conv2d(16, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (4): ReLU()\n",
       "    (5): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (7): ReLU()\n",
       "    (8): Upsample(scale_factor=2.0, mode='nearest')\n",
       "    (9): Conv2d(64, 3, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
       "    (10): Sigmoid()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "auto = Autoencoder()\n",
    "auto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model, loss function, and optimizer\n",
    "model = Autoencoder()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training the model\n",
    "num_epochs = 1000\n",
    "train_losses = []\n",
    "val_losses = []\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    for images, _ in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, images)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "    \n",
    "    train_loss /= len(train_loader)\n",
    "    train_losses.append(train_loss)\n",
    "\n",
    "    # Validation\n",
    "    model.eval()\n",
    "    val_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, _ in validation_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, images)\n",
    "            val_loss += loss.item()\n",
    "    val_loss /= len(validation_loader)\n",
    "    val_losses.append(val_loss)\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot training and validation loss\n",
    "epochs = range(1, num_epochs + 1)\n",
    "plt.plot(epochs, train_losses, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_losses, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Testing on a batch of images\n",
    "data_batch = next(iter(train_loader))\n",
    "images, _ = data_batch\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    outputs = model(images)\n",
    "\n",
    "# Display original and reconstructed images\n",
    "image_number = random.randint(0, outputs.shape[0] - 1)\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(np.transpose(images[image_number].numpy(), (1, 2, 0)))\n",
    "plt.subplot(122)\n",
    "plt.imshow(np.transpose(outputs[image_number].numpy(), (1, 2, 0)))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate reconstruction error for validation and anomaly datasets\n",
    "def evaluate_reconstruction_error(data_loader):\n",
    "    model.eval()\n",
    "    total_loss = 0\n",
    "    with torch.no_grad():\n",
    "        for images, _ in data_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, images)\n",
    "            total_loss += loss.item()\n",
    "    return total_loss / len(data_loader)\n",
    "\n",
    "validation_error = evaluate_reconstruction_error(validation_loader)\n",
    "anomaly_error = evaluate_reconstruction_error(anomaly_loader)\n",
    "\n",
    "print(\"Recon. error for the validation (normal) data is: \", validation_error)\n",
    "print(\"Recon. error for the anomaly data is: \", anomaly_error)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#Fit the model. \n",
    "history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch= 500 // batch_size,\n",
    "        epochs=1000,\n",
    "        validation_data=validation_generator,\n",
    "        validation_steps=75 // batch_size,\n",
    "        shuffle = True)\n",
    "\n",
    "\n",
    "#plot the training and validation accuracy and loss at each epoch\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(1, len(loss) + 1)\n",
    "plt.plot(epochs, loss, 'y', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "\n",
    "# Get all batches generated by the datagen and pick a batch for prediction\n",
    "#Just to test the model. \n",
    "data_batch = []  #Capture all training batches as a numpy array\n",
    "img_num = 0\n",
    "while img_num <= train_generator.batch_index:   #gets each generated batch of size batch_size\n",
    "    data = train_generator.next()\n",
    "    data_batch.append(data[0])\n",
    "    img_num = img_num + 1\n",
    "\n",
    "predicted = model.predict(data_batch[0])  #Predict on the first batch of images\n",
    "\n",
    "\n",
    "#Sanity check, view few images and corresponding reconstructions\n",
    "image_number = random.randint(0, predicted.shape[0])\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.subplot(121)\n",
    "plt.imshow(data_batch[0][image_number])\n",
    "plt.subplot(122)\n",
    "plt.imshow(predicted[image_number])\n",
    "plt.show()\n",
    "\n",
    "#Let us examine the reconstruction error between our validation data (good/normal images)\n",
    "# and the anomaly images\n",
    "validation_error = model.evaluate_generator(validation_generator)\n",
    "anomaly_error = model.evaluate_generator(anomaly_generator)\n",
    "\n",
    "print(\"Recon. error for the validation (normal) data is: \", validation_error)\n",
    "print(\"Recon. error for the anomaly data is: \", anomaly_error)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#We use these mean and sigma to set thresholds. \n",
    "def calc_recon_error(batch_images):\n",
    "    \n",
    "    density_list=[]\n",
    "    recon_error_list=[]\n",
    "    for im in range(0, batch_images.shape[0]-1):\n",
    "        \n",
    "        img  = batch_images[im]\n",
    "        img = img[np.newaxis, :,:,:]\n",
    "        encoded_img = encoder_model.predict([[img]]) # Create a compressed version of the image using the encoder\n",
    "        encoded_img = [np.reshape(img, (out_vector_shape)) for img in encoded_img] # Flatten the compressed image\n",
    "        \n",
    "        reconstruction = model.predict([[img]])\n",
    "        reconstruction_error = model.evaluate([reconstruction],[[img]], batch_size = 1)[0]\n",
    "        \n",
    "        recon_error_list.append(reconstruction_error)\n",
    "        \n",
    "   \n",
    "    \n",
    "    average_recon_error = np.mean(np.array(recon_error_list))  \n",
    "    stdev_recon_error = np.std(np.array(recon_error_list)) \n",
    "    \n",
    "    return  average_recon_error, stdev_recon_error\n",
    "\n",
    "#Get average and std dev. of density and recon. error for uninfected and anomaly (parasited) images. \n",
    "#For this let us generate a batch of images for each. \n",
    "train_batch = train_generator.next()[0]\n",
    "anomaly_batch = anomaly_generator.next()[0]\n",
    "\n",
    "uninfected_values = calc_recon_error(train_batch)\n",
    "anomaly_values = calc_recon_error(anomaly_batch)\n",
    "\n",
    "\n",
    "#Now, input unknown images and sort as Good or Anomaly\n",
    "def check_anomaly(img_path):\n",
    "     #Set this value based on the above exercise\n",
    "    reconstruction_error_threshold = 0.004 # Set this value based on the above exercise\n",
    "    img  = Image.open(img_path)\n",
    "    img = np.array(img.resize((128,128), Image.ANTIALIAS))\n",
    "    plt.imshow(img)\n",
    "    img = img / 255.\n",
    "    img = img[np.newaxis, :,:,:]\n",
    "    encoded_img = encoder_model.predict([[img]]) \n",
    "    encoded_img = [np.reshape(img, (out_vector_shape)) for img in encoded_img] \n",
    "    \n",
    "\n",
    "    reconstruction = model.predict([[img]])\n",
    "    reconstruction_error = model.evaluate([reconstruction],[[img]], batch_size = 1)[0]\n",
    "\n",
    "    if reconstruction_error > reconstruction_error_threshold:\n",
    "        print(\"The image is an anomaly\")\n",
    "        \n",
    "    else:\n",
    "        print(\"The image is NOT an anomaly\")\n",
    "        \n",
    "        \n",
    "#Load a couple of test images and verify whether they are reported as anomalies.\n",
    "import glob\n",
    "para_file_paths = glob.glob('cell_images2/parasitized/images/*')\n",
    "uninfected_file_paths = glob.glob('cell_images2/uninfected_train/images/*')\n",
    "\n",
    "#Anomaly image verification\n",
    "num=random.randint(0,len(para_file_paths)-1)\n",
    "check_anomaly(para_file_paths[num])\n",
    "\n",
    "#Good/normal image verification\n",
    "num=random.randint(0,len(para_file_paths)-1)\n",
    "check_anomaly(uninfected_file_paths[num])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
