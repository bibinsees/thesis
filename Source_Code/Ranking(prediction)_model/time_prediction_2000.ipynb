{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision import datasets, transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "\n",
    "\n",
    "\n",
    "import torch.nn.functional as F\n",
    "from torchvision.transforms import functional as Func\n",
    "\n",
    "import tifffile as tiff\n",
    "import os\n",
    "import time\n",
    "\n",
    "from torchvision.transforms import RandomResizedCrop\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Huge change from previous implementations since we are using target day10 images,we need to give same transform to day10 image as same as day7. hence we removed transform.compose instead we used from torchvision.transforms import functional as Func"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, day7_dir, day10_dir): \n",
    "        self.day7_files = {os.path.basename(file): os.path.join(day7_dir, file) for file in os.listdir(day7_dir) if file.endswith('.tiff')}\n",
    "        self.day10_files = {os.path.basename(file): os.path.join(day10_dir, file) for file in os.listdir(day10_dir) if file.endswith('.tiff')}\n",
    "      \n",
    "\n",
    "        # Ensure all day7 files have a corresponding day10 file\n",
    "        self.common_files = list(self.day7_files.keys())\n",
    "        assert set(self.common_files) <= set(self.day10_files.keys()), \"Mismatch between day7 and day10 filenames.\"\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.common_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        filename = self.common_files[idx]\n",
    "        day7_img_path = self.day7_files[filename]\n",
    "        day10_img_path = self.day10_files[filename]\n",
    "\n",
    "        # Load the images\n",
    "        day7_img = tiff.imread(day7_img_path)\n",
    "        day10_img = tiff.imread(day10_img_path)\n",
    "\n",
    "         # Ensure the images have 3 layers (channels)\n",
    "        if day7_img.shape[0] != 3:\n",
    "            raise ValueError(f\"Day7 image at {day7_img_path} does not have exactly 3 layers. Found shape: {day7_img.shape}.\")\n",
    "        if day10_img.shape[0] != 3:\n",
    "            raise ValueError(f\"Day10 image at {day10_img_path} does not have exactly 3 layers. Found shape: {day10_img.shape}.\")\n",
    "        \n",
    "        # Normalize and convert both images\n",
    "        day7_img = day7_img.astype(np.float32) / 65535.0\n",
    "        day10_img = day10_img.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Convert to tensors\n",
    "        day7_img = torch.tensor(day7_img, dtype=torch.float32)\n",
    "        day10_img = torch.tensor(day10_img, dtype=torch.float32)\n",
    "\n",
    "        # Apply transforms \n",
    "\n",
    "        # RandomHorizontalFlip\n",
    "        if torch.rand(1) < 0.5:\n",
    "            day7_img = Func.hflip(day7_img)\n",
    "            day10_img = Func.hflip(day10_img)\n",
    "        # RandomVerticalFlip\n",
    "        if torch.rand(1) < 0.5:\n",
    "            day7_img = Func.vflip(day7_img)\n",
    "            day10_img = Func.vflip(day10_img)\n",
    "\n",
    "        # RandomRotation\n",
    "        angle = torch.randint(-10, 10, (1,)).item()  # Generate a random angle\n",
    "        day7_img = Func.rotate(day7_img, angle)\n",
    "        day10_img = Func.rotate(day10_img, angle)\n",
    "\n",
    "        # RandomResizedCrop\n",
    "        crop_transform = RandomResizedCrop(size=256)\n",
    "        i, j, h, w = crop_transform.get_params(day7_img, scale=(0.08, 1.0), ratio=(3 / 4, 4 / 3))\n",
    "        day7_img = Func.resized_crop(day7_img, i, j, h, w, size=(256, 256))\n",
    "        day10_img = Func.resized_crop(day10_img, i, j, h, w, size=(256, 256))\n",
    "\n",
    "        return day7_img, day10_img\n",
    "    \n",
    "# Specify paths for both day7 and day10 folders\n",
    "day7_dir = r'C:\\Users\\k54739\\Bibin\\thesis\\control_day7_day10\\day7'\n",
    "day10_dir = r'C:\\Users\\k54739\\Bibin\\thesis\\control_day7_day10\\day10'\n",
    "\n",
    "# Create the dataset\n",
    "dataset = ImageDataset(day7_dir=day7_dir, day10_dir=day10_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Image Shape: torch.Size([3, 256, 256]), Day 10 Image Shape: torch.Size([3, 256, 256])\n",
      "Day 7 Image Shape: torch.Size([3, 256, 256]), Day 10 Image Shape: torch.Size([3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "for i, (day7_img, day10_img) in enumerate(dataset):\n",
    "    print(f\"Day 7 Image Shape: {day7_img.shape}, Day 10 Image Shape: {day10_img.shape}\")\n",
    "    if i == 1:  # Check just a couple of samples\n",
    "        break\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to split dataset with explicit percentage\n",
    "def split_dataset(dataset, val_percentage):\n",
    "    val_size = int(len(dataset) * val_percentage)\n",
    "    train_size = len(dataset) - val_size\n",
    "    return random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Split the dataset with 20% for validation\n",
    "val_percentage = 0.2\n",
    "train_dataset, val_dataset = split_dataset(dataset, val_percentage)\n",
    "\n",
    "batch_size = 16\n",
    "# Define DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=0) #num_workers=os.cpu count() using cluster gpu\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 104\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of images in the training dataset\n",
    "total_images_in_train = len(train_loader.dataset)\n",
    "print(f\"Total number of images: {total_images_in_train}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of images: 26\n"
     ]
    }
   ],
   "source": [
    "# Calculate the total number of images in the training dataset\n",
    "total_images_in_val = len(val_loader.dataset)\n",
    "print(f\"Total number of images: {total_images_in_val}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "  Input image (day7): torch.Size([16, 3, 256, 256])\n",
      "  Target image (day10): torch.Size([16, 3, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "# Print the shape of both pairs and total number of images in one epoch\n",
    "for i, (input_image, target_image) in enumerate(train_loader):\n",
    "    print(f\"Batch {i}:\")\n",
    "    print(f\"  Input image (day7): {input_image.shape}\")\n",
    "    print(f\"  Target image (day10): {target_image.shape}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Autoencod_fituning(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencod_fituning, self).__init__()\n",
    "        \n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding='same'),  # Input: (3, 96, 96) Output: (64, 96, 96)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, padding=1),        # Output: (64, 48, 48)\n",
    "            \n",
    "            nn.Conv2d(16, 32, kernel_size=3, padding='same'), # Output: (32, 48, 48)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, padding=1),        # Output: (32, 24, 24)\n",
    "            \n",
    "            nn.Conv2d(32, 64, kernel_size=3, padding='same'), # Output: (16, 24, 24)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, stride=2, padding=0)         # Output: (16, 12, 12)\n",
    "        )\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding='same'), # Output: (32, 12, 12)\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),      # Output: (32, 24, 24)\n",
    "    \n",
    "            nn.Conv2d(32, 16, kernel_size=3, padding='same'), # Output: (16, 24, 24)\n",
    "            nn.ReLU(),\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),      # Output: (16, 48, 48)\n",
    "    \n",
    "            nn.Conv2d(16, 3, kernel_size=3, padding='same'),  # Output: (3, 48, 48)\n",
    "            nn.Upsample(scale_factor=2, mode='nearest'),      # Output: (3, 96, 96)\n",
    "            nn.Sigmoid()                                      # Ensures output values are in [0, 1] range\n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        #print(\"Input:\", x.shape)\n",
    "        \n",
    "        # Encoder\n",
    "        for layer in self.encoder:\n",
    "            x = layer(x)\n",
    "            #print(f\"After {layer}: {x.shape}\")\n",
    "        \n",
    "        # Decoder\n",
    "        for layer in self.decoder:\n",
    "            x = layer(x)\n",
    "            #print(f\"After {layer}: {x.shape}\")\n",
    "        \n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "modi = Autoencod_fituning()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(modi.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "modi = modi.to(device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_validate(modi, train_loader, val_loader, optimizer, criterion, num_epochs=1):\n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        start_time = time.time()  # Start time for the epoch\n",
    "        \n",
    "        # Training phase\n",
    "        modi.train()\n",
    "        train_loss = 0\n",
    "        for input_images, target_images in train_loader:\n",
    "            input_images, target_images = input_images.to(device), target_images.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            outputs = modi(input_images)\n",
    "            loss = criterion(outputs, target_images)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            train_loss += loss.item()\n",
    "\n",
    "        train_loss /= len(train_loader)\n",
    "        train_losses.append(train_loss)\n",
    "\n",
    "        # Validation phase\n",
    "        modi.eval()\n",
    "        val_loss = 0\n",
    "        with torch.no_grad():\n",
    "            for input_images, target_images in val_loader:\n",
    "                input_images, target_images = input_images.to(device), target_images.to(device)\n",
    "                outputs = modi(input_images)\n",
    "                loss = criterion(outputs, target_images)\n",
    "                val_loss += loss.item()\n",
    "        val_loss /= len(val_loader)\n",
    "        val_losses.append(val_loss)\n",
    "\n",
    "        end_time = time.time()  # End time for the epoch\n",
    "        epoch_time = end_time - start_time  # Calculate epoch duration\n",
    "\n",
    "        print(f'Epoch [{epoch+1}/{num_epochs}], Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}, Time: {epoch_time:.2f} seconds')\n",
    "\n",
    "    return train_losses, val_losses\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1], Train Loss: 0.0424, Validation Loss: 0.0419, Time: 21.49 seconds\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train_and_validate(modi, train_loader, val_loader, optimizer, criterion, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train Loss: 0.0389, Validation Loss: 0.0273, Time: 21.56 seconds\n",
      "Epoch [2/10], Train Loss: 0.0290, Validation Loss: 0.0251, Time: 22.33 seconds\n",
      "Epoch [3/10], Train Loss: 0.0256, Validation Loss: 0.0231, Time: 22.50 seconds\n",
      "Epoch [4/10], Train Loss: 0.0238, Validation Loss: 0.0233, Time: 22.85 seconds\n",
      "Epoch [5/10], Train Loss: 0.0266, Validation Loss: 0.0216, Time: 22.47 seconds\n",
      "Epoch [6/10], Train Loss: 0.0240, Validation Loss: 0.0204, Time: 23.15 seconds\n",
      "Epoch [7/10], Train Loss: 0.0233, Validation Loss: 0.0200, Time: 23.13 seconds\n",
      "Epoch [8/10], Train Loss: 0.0239, Validation Loss: 0.0192, Time: 22.91 seconds\n",
      "Epoch [9/10], Train Loss: 0.0243, Validation Loss: 0.0217, Time: 21.73 seconds\n",
      "Epoch [10/10], Train Loss: 0.0246, Validation Loss: 0.0214, Time: 21.83 seconds\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train_and_validate(modi, train_loader, val_loader, optimizer, criterion, num_epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/100], Train Loss: 0.0222, Validation Loss: 0.0182, Time: 22.77 seconds\n",
      "Epoch [2/100], Train Loss: 0.0233, Validation Loss: 0.0247, Time: 22.28 seconds\n",
      "Epoch [3/100], Train Loss: 0.0237, Validation Loss: 0.0205, Time: 21.37 seconds\n",
      "Epoch [4/100], Train Loss: 0.0232, Validation Loss: 0.0218, Time: 21.61 seconds\n",
      "Epoch [5/100], Train Loss: 0.0226, Validation Loss: 0.0193, Time: 21.93 seconds\n",
      "Epoch [6/100], Train Loss: 0.0229, Validation Loss: 0.0205, Time: 22.19 seconds\n",
      "Epoch [7/100], Train Loss: 0.0239, Validation Loss: 0.0222, Time: 31.80 seconds\n",
      "Epoch [8/100], Train Loss: 0.0230, Validation Loss: 0.0186, Time: 40.98 seconds\n",
      "Epoch [9/100], Train Loss: 0.0223, Validation Loss: 0.0192, Time: 28.48 seconds\n",
      "Epoch [10/100], Train Loss: 0.0223, Validation Loss: 0.0219, Time: 22.52 seconds\n",
      "Epoch [11/100], Train Loss: 0.0220, Validation Loss: 0.0178, Time: 21.92 seconds\n",
      "Epoch [12/100], Train Loss: 0.0221, Validation Loss: 0.0185, Time: 21.85 seconds\n",
      "Epoch [13/100], Train Loss: 0.0229, Validation Loss: 0.0200, Time: 22.05 seconds\n",
      "Epoch [14/100], Train Loss: 0.0223, Validation Loss: 0.0196, Time: 22.21 seconds\n",
      "Epoch [15/100], Train Loss: 0.0222, Validation Loss: 0.0200, Time: 22.69 seconds\n",
      "Epoch [16/100], Train Loss: 0.0230, Validation Loss: 0.0197, Time: 27.97 seconds\n",
      "Epoch [17/100], Train Loss: 0.0219, Validation Loss: 0.0199, Time: 40.18 seconds\n",
      "Epoch [18/100], Train Loss: 0.0213, Validation Loss: 0.0209, Time: 34.47 seconds\n",
      "Epoch [19/100], Train Loss: 0.0225, Validation Loss: 0.0206, Time: 22.46 seconds\n",
      "Epoch [20/100], Train Loss: 0.0244, Validation Loss: 0.0196, Time: 22.07 seconds\n",
      "Epoch [21/100], Train Loss: 0.0231, Validation Loss: 0.0211, Time: 21.88 seconds\n",
      "Epoch [22/100], Train Loss: 0.0218, Validation Loss: 0.0196, Time: 24.95 seconds\n",
      "Epoch [23/100], Train Loss: 0.0227, Validation Loss: 0.0184, Time: 30.44 seconds\n",
      "Epoch [24/100], Train Loss: 0.0221, Validation Loss: 0.0204, Time: 22.44 seconds\n",
      "Epoch [25/100], Train Loss: 0.0216, Validation Loss: 0.0201, Time: 22.47 seconds\n",
      "Epoch [26/100], Train Loss: 0.0222, Validation Loss: 0.0192, Time: 22.40 seconds\n",
      "Epoch [27/100], Train Loss: 0.0226, Validation Loss: 0.0197, Time: 22.35 seconds\n",
      "Epoch [28/100], Train Loss: 0.0216, Validation Loss: 0.0224, Time: 22.49 seconds\n",
      "Epoch [29/100], Train Loss: 0.0223, Validation Loss: 0.0195, Time: 22.91 seconds\n",
      "Epoch [30/100], Train Loss: 0.0226, Validation Loss: 0.0206, Time: 22.26 seconds\n",
      "Epoch [31/100], Train Loss: 0.0222, Validation Loss: 0.0182, Time: 22.47 seconds\n",
      "Epoch [32/100], Train Loss: 0.0222, Validation Loss: 0.0199, Time: 22.65 seconds\n",
      "Epoch [33/100], Train Loss: 0.0211, Validation Loss: 0.0187, Time: 22.61 seconds\n",
      "Epoch [34/100], Train Loss: 0.0211, Validation Loss: 0.0177, Time: 22.85 seconds\n",
      "Epoch [35/100], Train Loss: 0.0208, Validation Loss: 0.0181, Time: 30.34 seconds\n",
      "Epoch [36/100], Train Loss: 0.0218, Validation Loss: 0.0217, Time: 20.15 seconds\n",
      "Epoch [37/100], Train Loss: 0.0208, Validation Loss: 0.0193, Time: 20.21 seconds\n",
      "Epoch [38/100], Train Loss: 0.0206, Validation Loss: 0.0170, Time: 20.42 seconds\n",
      "Epoch [39/100], Train Loss: 0.0213, Validation Loss: 0.0171, Time: 20.42 seconds\n",
      "Epoch [40/100], Train Loss: 0.0222, Validation Loss: 0.0184, Time: 19.83 seconds\n",
      "Epoch [41/100], Train Loss: 0.0213, Validation Loss: 0.0199, Time: 20.41 seconds\n",
      "Epoch [42/100], Train Loss: 0.0213, Validation Loss: 0.0200, Time: 20.40 seconds\n",
      "Epoch [43/100], Train Loss: 0.0212, Validation Loss: 0.0188, Time: 20.78 seconds\n",
      "Epoch [44/100], Train Loss: 0.0209, Validation Loss: 0.0170, Time: 20.49 seconds\n",
      "Epoch [45/100], Train Loss: 0.0215, Validation Loss: 0.0187, Time: 20.27 seconds\n",
      "Epoch [46/100], Train Loss: 0.0215, Validation Loss: 0.0185, Time: 21.19 seconds\n",
      "Epoch [47/100], Train Loss: 0.0220, Validation Loss: 0.0172, Time: 20.25 seconds\n",
      "Epoch [48/100], Train Loss: 0.0233, Validation Loss: 0.0200, Time: 20.22 seconds\n",
      "Epoch [49/100], Train Loss: 0.0215, Validation Loss: 0.0190, Time: 20.41 seconds\n",
      "Epoch [50/100], Train Loss: 0.0207, Validation Loss: 0.0176, Time: 21.28 seconds\n",
      "Epoch [51/100], Train Loss: 0.0207, Validation Loss: 0.0186, Time: 21.00 seconds\n",
      "Epoch [52/100], Train Loss: 0.0221, Validation Loss: 0.0195, Time: 20.11 seconds\n",
      "Epoch [53/100], Train Loss: 0.0201, Validation Loss: 0.0192, Time: 20.29 seconds\n",
      "Epoch [54/100], Train Loss: 0.0216, Validation Loss: 0.0163, Time: 20.25 seconds\n",
      "Epoch [55/100], Train Loss: 0.0202, Validation Loss: 0.0184, Time: 20.31 seconds\n",
      "Epoch [56/100], Train Loss: 0.0226, Validation Loss: 0.0200, Time: 21.69 seconds\n",
      "Epoch [57/100], Train Loss: 0.0204, Validation Loss: 0.0200, Time: 20.54 seconds\n",
      "Epoch [58/100], Train Loss: 0.0212, Validation Loss: 0.0188, Time: 20.44 seconds\n",
      "Epoch [59/100], Train Loss: 0.0209, Validation Loss: 0.0178, Time: 20.26 seconds\n",
      "Epoch [60/100], Train Loss: 0.0215, Validation Loss: 0.0210, Time: 20.46 seconds\n",
      "Epoch [61/100], Train Loss: 0.0207, Validation Loss: 0.0198, Time: 20.64 seconds\n",
      "Epoch [62/100], Train Loss: 0.0202, Validation Loss: 0.0193, Time: 20.27 seconds\n",
      "Epoch [63/100], Train Loss: 0.0215, Validation Loss: 0.0215, Time: 20.04 seconds\n",
      "Epoch [64/100], Train Loss: 0.0202, Validation Loss: 0.0191, Time: 20.39 seconds\n",
      "Epoch [65/100], Train Loss: 0.0206, Validation Loss: 0.0176, Time: 21.33 seconds\n",
      "Epoch [66/100], Train Loss: 0.0199, Validation Loss: 0.0170, Time: 21.21 seconds\n",
      "Epoch [67/100], Train Loss: 0.0217, Validation Loss: 0.0176, Time: 20.46 seconds\n",
      "Epoch [68/100], Train Loss: 0.0203, Validation Loss: 0.0216, Time: 20.53 seconds\n",
      "Epoch [69/100], Train Loss: 0.0203, Validation Loss: 0.0192, Time: 20.70 seconds\n",
      "Epoch [70/100], Train Loss: 0.0212, Validation Loss: 0.0194, Time: 20.50 seconds\n",
      "Epoch [71/100], Train Loss: 0.0220, Validation Loss: 0.0182, Time: 21.46 seconds\n",
      "Epoch [72/100], Train Loss: 0.0214, Validation Loss: 0.0190, Time: 20.99 seconds\n",
      "Epoch [73/100], Train Loss: 0.0221, Validation Loss: 0.0200, Time: 21.56 seconds\n",
      "Epoch [74/100], Train Loss: 0.0216, Validation Loss: 0.0216, Time: 21.74 seconds\n",
      "Epoch [75/100], Train Loss: 0.0214, Validation Loss: 0.0187, Time: 20.77 seconds\n",
      "Epoch [76/100], Train Loss: 0.0212, Validation Loss: 0.0204, Time: 20.26 seconds\n",
      "Epoch [77/100], Train Loss: 0.0222, Validation Loss: 0.0190, Time: 20.53 seconds\n",
      "Epoch [78/100], Train Loss: 0.0202, Validation Loss: 0.0165, Time: 20.38 seconds\n",
      "Epoch [79/100], Train Loss: 0.0208, Validation Loss: 0.0188, Time: 21.01 seconds\n",
      "Epoch [80/100], Train Loss: 0.0194, Validation Loss: 0.0193, Time: 20.59 seconds\n",
      "Epoch [81/100], Train Loss: 0.0218, Validation Loss: 0.0186, Time: 21.19 seconds\n",
      "Epoch [82/100], Train Loss: 0.0211, Validation Loss: 0.0164, Time: 21.99 seconds\n",
      "Epoch [83/100], Train Loss: 0.0214, Validation Loss: 0.0201, Time: 22.26 seconds\n",
      "Epoch [84/100], Train Loss: 0.0213, Validation Loss: 0.0189, Time: 21.62 seconds\n",
      "Epoch [85/100], Train Loss: 0.0215, Validation Loss: 0.0195, Time: 21.72 seconds\n",
      "Epoch [86/100], Train Loss: 0.0221, Validation Loss: 0.0200, Time: 21.81 seconds\n",
      "Epoch [87/100], Train Loss: 0.0244, Validation Loss: 0.0186, Time: 21.06 seconds\n",
      "Epoch [88/100], Train Loss: 0.0206, Validation Loss: 0.0203, Time: 21.31 seconds\n",
      "Epoch [89/100], Train Loss: 0.0209, Validation Loss: 0.0200, Time: 21.41 seconds\n",
      "Epoch [90/100], Train Loss: 0.0208, Validation Loss: 0.0170, Time: 21.82 seconds\n",
      "Epoch [91/100], Train Loss: 0.0214, Validation Loss: 0.0211, Time: 21.90 seconds\n",
      "Epoch [92/100], Train Loss: 0.0199, Validation Loss: 0.0213, Time: 21.80 seconds\n",
      "Epoch [93/100], Train Loss: 0.0205, Validation Loss: 0.0180, Time: 21.73 seconds\n",
      "Epoch [94/100], Train Loss: 0.0213, Validation Loss: 0.0182, Time: 21.67 seconds\n",
      "Epoch [95/100], Train Loss: 0.0207, Validation Loss: 0.0182, Time: 22.35 seconds\n",
      "Epoch [96/100], Train Loss: 0.0205, Validation Loss: 0.0182, Time: 20.84 seconds\n",
      "Epoch [97/100], Train Loss: 0.0209, Validation Loss: 0.0180, Time: 20.98 seconds\n",
      "Epoch [98/100], Train Loss: 0.0212, Validation Loss: 0.0184, Time: 21.07 seconds\n",
      "Epoch [99/100], Train Loss: 0.0217, Validation Loss: 0.0230, Time: 21.81 seconds\n",
      "Epoch [100/100], Train Loss: 0.0227, Validation Loss: 0.0170, Time: 21.13 seconds\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train_and_validate(modi, train_loader, val_loader, optimizer, criterion, num_epochs=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/500], Train Loss: 0.0214, Validation Loss: 0.0178, Time: 21.51 seconds\n",
      "Epoch [2/500], Train Loss: 0.0200, Validation Loss: 0.0215, Time: 21.13 seconds\n",
      "Epoch [3/500], Train Loss: 0.0204, Validation Loss: 0.0216, Time: 20.85 seconds\n",
      "Epoch [4/500], Train Loss: 0.0206, Validation Loss: 0.0194, Time: 21.62 seconds\n",
      "Epoch [5/500], Train Loss: 0.0211, Validation Loss: 0.0173, Time: 22.07 seconds\n",
      "Epoch [6/500], Train Loss: 0.0204, Validation Loss: 0.0140, Time: 22.86 seconds\n",
      "Epoch [7/500], Train Loss: 0.0205, Validation Loss: 0.0192, Time: 22.10 seconds\n",
      "Epoch [8/500], Train Loss: 0.0216, Validation Loss: 0.0190, Time: 21.60 seconds\n",
      "Epoch [9/500], Train Loss: 0.0220, Validation Loss: 0.0177, Time: 21.56 seconds\n",
      "Epoch [10/500], Train Loss: 0.0208, Validation Loss: 0.0177, Time: 21.82 seconds\n",
      "Epoch [11/500], Train Loss: 0.0200, Validation Loss: 0.0174, Time: 22.25 seconds\n",
      "Epoch [12/500], Train Loss: 0.0210, Validation Loss: 0.0195, Time: 22.11 seconds\n",
      "Epoch [13/500], Train Loss: 0.0216, Validation Loss: 0.0160, Time: 22.02 seconds\n",
      "Epoch [14/500], Train Loss: 0.0210, Validation Loss: 0.0179, Time: 21.83 seconds\n",
      "Epoch [15/500], Train Loss: 0.0204, Validation Loss: 0.0168, Time: 20.38 seconds\n",
      "Epoch [16/500], Train Loss: 0.0231, Validation Loss: 0.0198, Time: 20.74 seconds\n",
      "Epoch [17/500], Train Loss: 0.0207, Validation Loss: 0.0177, Time: 21.28 seconds\n",
      "Epoch [18/500], Train Loss: 0.0203, Validation Loss: 0.0173, Time: 21.54 seconds\n",
      "Epoch [19/500], Train Loss: 0.0212, Validation Loss: 0.0192, Time: 22.29 seconds\n",
      "Epoch [20/500], Train Loss: 0.0209, Validation Loss: 0.0176, Time: 22.61 seconds\n",
      "Epoch [21/500], Train Loss: 0.0203, Validation Loss: 0.0178, Time: 22.48 seconds\n",
      "Epoch [22/500], Train Loss: 0.0200, Validation Loss: 0.0146, Time: 22.40 seconds\n",
      "Epoch [23/500], Train Loss: 0.0205, Validation Loss: 0.0206, Time: 22.24 seconds\n",
      "Epoch [24/500], Train Loss: 0.0217, Validation Loss: 0.0191, Time: 21.39 seconds\n",
      "Epoch [25/500], Train Loss: 0.0197, Validation Loss: 0.0192, Time: 21.74 seconds\n",
      "Epoch [26/500], Train Loss: 0.0211, Validation Loss: 0.0186, Time: 22.15 seconds\n",
      "Epoch [27/500], Train Loss: 0.0216, Validation Loss: 0.0200, Time: 21.88 seconds\n",
      "Epoch [28/500], Train Loss: 0.0213, Validation Loss: 0.0207, Time: 21.99 seconds\n",
      "Epoch [29/500], Train Loss: 0.0194, Validation Loss: 0.0195, Time: 21.55 seconds\n",
      "Epoch [30/500], Train Loss: 0.0185, Validation Loss: 0.0178, Time: 21.60 seconds\n",
      "Epoch [31/500], Train Loss: 0.0202, Validation Loss: 0.0175, Time: 22.00 seconds\n",
      "Epoch [32/500], Train Loss: 0.0206, Validation Loss: 0.0172, Time: 21.59 seconds\n",
      "Epoch [33/500], Train Loss: 0.0197, Validation Loss: 0.0175, Time: 21.68 seconds\n",
      "Epoch [34/500], Train Loss: 0.0209, Validation Loss: 0.0184, Time: 22.59 seconds\n",
      "Epoch [35/500], Train Loss: 0.0214, Validation Loss: 0.0163, Time: 22.25 seconds\n",
      "Epoch [36/500], Train Loss: 0.0197, Validation Loss: 0.0198, Time: 21.94 seconds\n",
      "Epoch [37/500], Train Loss: 0.0205, Validation Loss: 0.0193, Time: 22.17 seconds\n",
      "Epoch [38/500], Train Loss: 0.0216, Validation Loss: 0.0186, Time: 21.89 seconds\n",
      "Epoch [39/500], Train Loss: 0.0215, Validation Loss: 0.0177, Time: 22.79 seconds\n",
      "Epoch [40/500], Train Loss: 0.0208, Validation Loss: 0.0191, Time: 22.37 seconds\n",
      "Epoch [41/500], Train Loss: 0.0188, Validation Loss: 0.0181, Time: 21.76 seconds\n",
      "Epoch [42/500], Train Loss: 0.0201, Validation Loss: 0.0176, Time: 22.01 seconds\n",
      "Epoch [43/500], Train Loss: 0.0220, Validation Loss: 0.0163, Time: 22.41 seconds\n",
      "Epoch [44/500], Train Loss: 0.0194, Validation Loss: 0.0177, Time: 22.77 seconds\n",
      "Epoch [45/500], Train Loss: 0.0220, Validation Loss: 0.0161, Time: 21.62 seconds\n",
      "Epoch [46/500], Train Loss: 0.0197, Validation Loss: 0.0204, Time: 21.72 seconds\n",
      "Epoch [47/500], Train Loss: 0.0201, Validation Loss: 0.0193, Time: 22.15 seconds\n",
      "Epoch [48/500], Train Loss: 0.0211, Validation Loss: 0.0168, Time: 22.07 seconds\n",
      "Epoch [49/500], Train Loss: 0.0198, Validation Loss: 0.0183, Time: 22.16 seconds\n",
      "Epoch [50/500], Train Loss: 0.0190, Validation Loss: 0.0167, Time: 22.57 seconds\n",
      "Epoch [51/500], Train Loss: 0.0191, Validation Loss: 0.0199, Time: 22.34 seconds\n",
      "Epoch [52/500], Train Loss: 0.0212, Validation Loss: 0.0185, Time: 22.44 seconds\n",
      "Epoch [53/500], Train Loss: 0.0210, Validation Loss: 0.0178, Time: 22.57 seconds\n",
      "Epoch [54/500], Train Loss: 0.0192, Validation Loss: 0.0188, Time: 22.58 seconds\n",
      "Epoch [55/500], Train Loss: 0.0209, Validation Loss: 0.0183, Time: 21.81 seconds\n",
      "Epoch [56/500], Train Loss: 0.0205, Validation Loss: 0.0191, Time: 21.40 seconds\n",
      "Epoch [57/500], Train Loss: 0.0193, Validation Loss: 0.0182, Time: 21.60 seconds\n",
      "Epoch [58/500], Train Loss: 0.0199, Validation Loss: 0.0210, Time: 21.62 seconds\n",
      "Epoch [59/500], Train Loss: 0.0207, Validation Loss: 0.0170, Time: 21.80 seconds\n",
      "Epoch [60/500], Train Loss: 0.0205, Validation Loss: 0.0192, Time: 22.31 seconds\n",
      "Epoch [61/500], Train Loss: 0.0197, Validation Loss: 0.0188, Time: 22.10 seconds\n",
      "Epoch [62/500], Train Loss: 0.0224, Validation Loss: 0.0174, Time: 21.61 seconds\n",
      "Epoch [63/500], Train Loss: 0.0205, Validation Loss: 0.0193, Time: 21.85 seconds\n",
      "Epoch [64/500], Train Loss: 0.0198, Validation Loss: 0.0174, Time: 22.33 seconds\n",
      "Epoch [65/500], Train Loss: 0.0203, Validation Loss: 0.0182, Time: 22.31 seconds\n",
      "Epoch [66/500], Train Loss: 0.0190, Validation Loss: 0.0159, Time: 22.18 seconds\n",
      "Epoch [67/500], Train Loss: 0.0199, Validation Loss: 0.0167, Time: 22.13 seconds\n",
      "Epoch [68/500], Train Loss: 0.0206, Validation Loss: 0.0168, Time: 21.84 seconds\n",
      "Epoch [69/500], Train Loss: 0.0210, Validation Loss: 0.0180, Time: 22.10 seconds\n",
      "Epoch [70/500], Train Loss: 0.0229, Validation Loss: 0.0205, Time: 22.00 seconds\n",
      "Epoch [71/500], Train Loss: 0.0206, Validation Loss: 0.0155, Time: 21.76 seconds\n",
      "Epoch [72/500], Train Loss: 0.0197, Validation Loss: 0.0168, Time: 21.88 seconds\n",
      "Epoch [73/500], Train Loss: 0.0208, Validation Loss: 0.0165, Time: 21.59 seconds\n",
      "Epoch [74/500], Train Loss: 0.0207, Validation Loss: 0.0179, Time: 22.27 seconds\n",
      "Epoch [75/500], Train Loss: 0.0202, Validation Loss: 0.0209, Time: 22.19 seconds\n",
      "Epoch [76/500], Train Loss: 0.0202, Validation Loss: 0.0169, Time: 22.68 seconds\n",
      "Epoch [77/500], Train Loss: 0.0198, Validation Loss: 0.0200, Time: 22.55 seconds\n",
      "Epoch [78/500], Train Loss: 0.0215, Validation Loss: 0.0188, Time: 22.42 seconds\n",
      "Epoch [79/500], Train Loss: 0.0218, Validation Loss: 0.0197, Time: 21.91 seconds\n",
      "Epoch [80/500], Train Loss: 0.0213, Validation Loss: 0.0187, Time: 22.16 seconds\n",
      "Epoch [81/500], Train Loss: 0.0210, Validation Loss: 0.0180, Time: 22.52 seconds\n",
      "Epoch [82/500], Train Loss: 0.0208, Validation Loss: 0.0172, Time: 22.72 seconds\n",
      "Epoch [83/500], Train Loss: 0.0195, Validation Loss: 0.0183, Time: 21.77 seconds\n",
      "Epoch [84/500], Train Loss: 0.0198, Validation Loss: 0.0185, Time: 21.92 seconds\n",
      "Epoch [85/500], Train Loss: 0.0195, Validation Loss: 0.0187, Time: 21.91 seconds\n",
      "Epoch [86/500], Train Loss: 0.0214, Validation Loss: 0.0173, Time: 22.08 seconds\n",
      "Epoch [87/500], Train Loss: 0.0205, Validation Loss: 0.0191, Time: 22.08 seconds\n",
      "Epoch [88/500], Train Loss: 0.0207, Validation Loss: 0.0203, Time: 22.38 seconds\n",
      "Epoch [89/500], Train Loss: 0.0210, Validation Loss: 0.0168, Time: 22.27 seconds\n",
      "Epoch [90/500], Train Loss: 0.0201, Validation Loss: 0.0181, Time: 22.62 seconds\n",
      "Epoch [91/500], Train Loss: 0.0212, Validation Loss: 0.0205, Time: 22.24 seconds\n",
      "Epoch [92/500], Train Loss: 0.0199, Validation Loss: 0.0158, Time: 22.70 seconds\n",
      "Epoch [93/500], Train Loss: 0.0191, Validation Loss: 0.0176, Time: 21.65 seconds\n",
      "Epoch [94/500], Train Loss: 0.0204, Validation Loss: 0.0180, Time: 21.69 seconds\n",
      "Epoch [95/500], Train Loss: 0.0209, Validation Loss: 0.0178, Time: 22.55 seconds\n",
      "Epoch [96/500], Train Loss: 0.0213, Validation Loss: 0.0209, Time: 21.74 seconds\n",
      "Epoch [97/500], Train Loss: 0.0205, Validation Loss: 0.0173, Time: 21.77 seconds\n",
      "Epoch [98/500], Train Loss: 0.0187, Validation Loss: 0.0193, Time: 21.54 seconds\n",
      "Epoch [99/500], Train Loss: 0.0199, Validation Loss: 0.0189, Time: 21.84 seconds\n",
      "Epoch [100/500], Train Loss: 0.0201, Validation Loss: 0.0199, Time: 21.76 seconds\n",
      "Epoch [101/500], Train Loss: 0.0208, Validation Loss: 0.0202, Time: 22.36 seconds\n",
      "Epoch [102/500], Train Loss: 0.0201, Validation Loss: 0.0180, Time: 22.32 seconds\n",
      "Epoch [103/500], Train Loss: 0.0207, Validation Loss: 0.0176, Time: 21.69 seconds\n",
      "Epoch [104/500], Train Loss: 0.0206, Validation Loss: 0.0174, Time: 21.84 seconds\n",
      "Epoch [105/500], Train Loss: 0.0214, Validation Loss: 0.0215, Time: 22.00 seconds\n",
      "Epoch [106/500], Train Loss: 0.0196, Validation Loss: 0.0173, Time: 21.96 seconds\n",
      "Epoch [107/500], Train Loss: 0.0215, Validation Loss: 0.0185, Time: 21.83 seconds\n",
      "Epoch [108/500], Train Loss: 0.0196, Validation Loss: 0.0178, Time: 22.33 seconds\n",
      "Epoch [109/500], Train Loss: 0.0208, Validation Loss: 0.0174, Time: 21.76 seconds\n",
      "Epoch [110/500], Train Loss: 0.0202, Validation Loss: 0.0163, Time: 21.65 seconds\n",
      "Epoch [111/500], Train Loss: 0.0196, Validation Loss: 0.0142, Time: 22.08 seconds\n",
      "Epoch [112/500], Train Loss: 0.0191, Validation Loss: 0.0178, Time: 21.94 seconds\n",
      "Epoch [113/500], Train Loss: 0.0226, Validation Loss: 0.0174, Time: 21.67 seconds\n",
      "Epoch [114/500], Train Loss: 0.0199, Validation Loss: 0.0193, Time: 22.33 seconds\n",
      "Epoch [115/500], Train Loss: 0.0190, Validation Loss: 0.0184, Time: 21.82 seconds\n",
      "Epoch [116/500], Train Loss: 0.0207, Validation Loss: 0.0169, Time: 21.93 seconds\n",
      "Epoch [117/500], Train Loss: 0.0195, Validation Loss: 0.0189, Time: 21.67 seconds\n",
      "Epoch [118/500], Train Loss: 0.0212, Validation Loss: 0.0179, Time: 21.95 seconds\n",
      "Epoch [119/500], Train Loss: 0.0211, Validation Loss: 0.0161, Time: 21.77 seconds\n",
      "Epoch [120/500], Train Loss: 0.0223, Validation Loss: 0.0167, Time: 22.52 seconds\n",
      "Epoch [121/500], Train Loss: 0.0198, Validation Loss: 0.0180, Time: 21.77 seconds\n",
      "Epoch [122/500], Train Loss: 0.0204, Validation Loss: 0.0185, Time: 21.51 seconds\n",
      "Epoch [123/500], Train Loss: 0.0204, Validation Loss: 0.0167, Time: 22.08 seconds\n",
      "Epoch [124/500], Train Loss: 0.0201, Validation Loss: 0.0168, Time: 21.55 seconds\n",
      "Epoch [125/500], Train Loss: 0.0200, Validation Loss: 0.0207, Time: 22.11 seconds\n",
      "Epoch [126/500], Train Loss: 0.0179, Validation Loss: 0.0170, Time: 21.31 seconds\n",
      "Epoch [127/500], Train Loss: 0.0201, Validation Loss: 0.0191, Time: 21.68 seconds\n",
      "Epoch [128/500], Train Loss: 0.0187, Validation Loss: 0.0175, Time: 22.67 seconds\n",
      "Epoch [129/500], Train Loss: 0.0219, Validation Loss: 0.0197, Time: 22.17 seconds\n",
      "Epoch [130/500], Train Loss: 0.0210, Validation Loss: 0.0178, Time: 22.39 seconds\n",
      "Epoch [131/500], Train Loss: 0.0204, Validation Loss: 0.0182, Time: 22.46 seconds\n",
      "Epoch [132/500], Train Loss: 0.0205, Validation Loss: 0.0194, Time: 21.49 seconds\n",
      "Epoch [133/500], Train Loss: 0.0200, Validation Loss: 0.0190, Time: 21.51 seconds\n",
      "Epoch [134/500], Train Loss: 0.0199, Validation Loss: 0.0188, Time: 22.16 seconds\n",
      "Epoch [135/500], Train Loss: 0.0189, Validation Loss: 0.0175, Time: 21.65 seconds\n",
      "Epoch [136/500], Train Loss: 0.0196, Validation Loss: 0.0178, Time: 22.38 seconds\n",
      "Epoch [137/500], Train Loss: 0.0207, Validation Loss: 0.0198, Time: 21.67 seconds\n",
      "Epoch [138/500], Train Loss: 0.0205, Validation Loss: 0.0176, Time: 21.67 seconds\n",
      "Epoch [139/500], Train Loss: 0.0210, Validation Loss: 0.0188, Time: 21.99 seconds\n",
      "Epoch [140/500], Train Loss: 0.0200, Validation Loss: 0.0180, Time: 21.54 seconds\n",
      "Epoch [141/500], Train Loss: 0.0201, Validation Loss: 0.0178, Time: 21.66 seconds\n",
      "Epoch [142/500], Train Loss: 0.0217, Validation Loss: 0.0181, Time: 22.31 seconds\n",
      "Epoch [143/500], Train Loss: 0.0205, Validation Loss: 0.0201, Time: 21.90 seconds\n",
      "Epoch [144/500], Train Loss: 0.0223, Validation Loss: 0.0176, Time: 21.83 seconds\n",
      "Epoch [145/500], Train Loss: 0.0203, Validation Loss: 0.0178, Time: 22.10 seconds\n",
      "Epoch [146/500], Train Loss: 0.0196, Validation Loss: 0.0169, Time: 22.78 seconds\n",
      "Epoch [147/500], Train Loss: 0.0211, Validation Loss: 0.0181, Time: 22.65 seconds\n",
      "Epoch [148/500], Train Loss: 0.0198, Validation Loss: 0.0180, Time: 21.70 seconds\n",
      "Epoch [149/500], Train Loss: 0.0215, Validation Loss: 0.0193, Time: 21.58 seconds\n",
      "Epoch [150/500], Train Loss: 0.0206, Validation Loss: 0.0166, Time: 22.16 seconds\n",
      "Epoch [151/500], Train Loss: 0.0195, Validation Loss: 0.0187, Time: 22.70 seconds\n",
      "Epoch [152/500], Train Loss: 0.0222, Validation Loss: 0.0186, Time: 22.69 seconds\n",
      "Epoch [153/500], Train Loss: 0.0196, Validation Loss: 0.0174, Time: 22.43 seconds\n",
      "Epoch [154/500], Train Loss: 0.0195, Validation Loss: 0.0178, Time: 22.39 seconds\n",
      "Epoch [155/500], Train Loss: 0.0193, Validation Loss: 0.0175, Time: 22.52 seconds\n",
      "Epoch [156/500], Train Loss: 0.0216, Validation Loss: 0.0182, Time: 21.89 seconds\n",
      "Epoch [157/500], Train Loss: 0.0212, Validation Loss: 0.0176, Time: 22.11 seconds\n",
      "Epoch [158/500], Train Loss: 0.0190, Validation Loss: 0.0218, Time: 22.48 seconds\n",
      "Epoch [159/500], Train Loss: 0.0190, Validation Loss: 0.0201, Time: 22.05 seconds\n",
      "Epoch [160/500], Train Loss: 0.0208, Validation Loss: 0.0184, Time: 21.64 seconds\n",
      "Epoch [161/500], Train Loss: 0.0202, Validation Loss: 0.0176, Time: 21.71 seconds\n",
      "Epoch [162/500], Train Loss: 0.0201, Validation Loss: 0.0181, Time: 21.83 seconds\n",
      "Epoch [163/500], Train Loss: 0.0206, Validation Loss: 0.0184, Time: 21.92 seconds\n",
      "Epoch [164/500], Train Loss: 0.0202, Validation Loss: 0.0175, Time: 22.02 seconds\n",
      "Epoch [165/500], Train Loss: 0.0213, Validation Loss: 0.0160, Time: 21.99 seconds\n",
      "Epoch [166/500], Train Loss: 0.0205, Validation Loss: 0.0190, Time: 22.47 seconds\n",
      "Epoch [167/500], Train Loss: 0.0208, Validation Loss: 0.0172, Time: 21.91 seconds\n",
      "Epoch [168/500], Train Loss: 0.0208, Validation Loss: 0.0176, Time: 22.86 seconds\n",
      "Epoch [169/500], Train Loss: 0.0200, Validation Loss: 0.0198, Time: 22.59 seconds\n",
      "Epoch [170/500], Train Loss: 0.0200, Validation Loss: 0.0173, Time: 21.86 seconds\n",
      "Epoch [171/500], Train Loss: 0.0205, Validation Loss: 0.0163, Time: 22.20 seconds\n",
      "Epoch [172/500], Train Loss: 0.0208, Validation Loss: 0.0185, Time: 22.14 seconds\n",
      "Epoch [173/500], Train Loss: 0.0207, Validation Loss: 0.0171, Time: 21.63 seconds\n",
      "Epoch [174/500], Train Loss: 0.0204, Validation Loss: 0.0176, Time: 22.15 seconds\n",
      "Epoch [175/500], Train Loss: 0.0200, Validation Loss: 0.0182, Time: 21.70 seconds\n",
      "Epoch [176/500], Train Loss: 0.0210, Validation Loss: 0.0187, Time: 22.01 seconds\n",
      "Epoch [177/500], Train Loss: 0.0196, Validation Loss: 0.0170, Time: 22.25 seconds\n",
      "Epoch [178/500], Train Loss: 0.0199, Validation Loss: 0.0181, Time: 22.58 seconds\n",
      "Epoch [179/500], Train Loss: 0.0186, Validation Loss: 0.0195, Time: 22.17 seconds\n",
      "Epoch [180/500], Train Loss: 0.0212, Validation Loss: 0.0175, Time: 22.33 seconds\n",
      "Epoch [181/500], Train Loss: 0.0209, Validation Loss: 0.0173, Time: 22.24 seconds\n",
      "Epoch [182/500], Train Loss: 0.0216, Validation Loss: 0.0166, Time: 22.30 seconds\n",
      "Epoch [183/500], Train Loss: 0.0203, Validation Loss: 0.0170, Time: 21.72 seconds\n",
      "Epoch [184/500], Train Loss: 0.0197, Validation Loss: 0.0198, Time: 21.68 seconds\n",
      "Epoch [185/500], Train Loss: 0.0208, Validation Loss: 0.0182, Time: 22.67 seconds\n",
      "Epoch [186/500], Train Loss: 0.0206, Validation Loss: 0.0181, Time: 22.36 seconds\n",
      "Epoch [187/500], Train Loss: 0.0205, Validation Loss: 0.0174, Time: 22.56 seconds\n",
      "Epoch [188/500], Train Loss: 0.0203, Validation Loss: 0.0191, Time: 21.86 seconds\n",
      "Epoch [189/500], Train Loss: 0.0209, Validation Loss: 0.0184, Time: 22.27 seconds\n",
      "Epoch [190/500], Train Loss: 0.0211, Validation Loss: 0.0185, Time: 22.78 seconds\n",
      "Epoch [191/500], Train Loss: 0.0199, Validation Loss: 0.0207, Time: 21.96 seconds\n",
      "Epoch [192/500], Train Loss: 0.0199, Validation Loss: 0.0208, Time: 21.93 seconds\n",
      "Epoch [193/500], Train Loss: 0.0208, Validation Loss: 0.0177, Time: 21.99 seconds\n",
      "Epoch [194/500], Train Loss: 0.0204, Validation Loss: 0.0197, Time: 22.27 seconds\n",
      "Epoch [195/500], Train Loss: 0.0188, Validation Loss: 0.0188, Time: 22.60 seconds\n",
      "Epoch [196/500], Train Loss: 0.0199, Validation Loss: 0.0184, Time: 22.67 seconds\n",
      "Epoch [197/500], Train Loss: 0.0197, Validation Loss: 0.0177, Time: 22.01 seconds\n",
      "Epoch [198/500], Train Loss: 0.0208, Validation Loss: 0.0203, Time: 22.65 seconds\n",
      "Epoch [199/500], Train Loss: 0.0193, Validation Loss: 0.0200, Time: 22.15 seconds\n",
      "Epoch [200/500], Train Loss: 0.0199, Validation Loss: 0.0181, Time: 21.88 seconds\n",
      "Epoch [201/500], Train Loss: 0.0202, Validation Loss: 0.0180, Time: 21.90 seconds\n",
      "Epoch [202/500], Train Loss: 0.0196, Validation Loss: 0.0183, Time: 21.66 seconds\n",
      "Epoch [203/500], Train Loss: 0.0196, Validation Loss: 0.0200, Time: 22.22 seconds\n",
      "Epoch [204/500], Train Loss: 0.0198, Validation Loss: 0.0177, Time: 21.79 seconds\n",
      "Epoch [205/500], Train Loss: 0.0189, Validation Loss: 0.0198, Time: 21.63 seconds\n",
      "Epoch [206/500], Train Loss: 0.0208, Validation Loss: 0.0176, Time: 22.54 seconds\n",
      "Epoch [207/500], Train Loss: 0.0184, Validation Loss: 0.0184, Time: 22.65 seconds\n",
      "Epoch [208/500], Train Loss: 0.0203, Validation Loss: 0.0177, Time: 22.97 seconds\n",
      "Epoch [209/500], Train Loss: 0.0199, Validation Loss: 0.0187, Time: 22.67 seconds\n",
      "Epoch [210/500], Train Loss: 0.0196, Validation Loss: 0.0164, Time: 21.77 seconds\n",
      "Epoch [211/500], Train Loss: 0.0198, Validation Loss: 0.0172, Time: 22.27 seconds\n",
      "Epoch [212/500], Train Loss: 0.0191, Validation Loss: 0.0191, Time: 22.47 seconds\n",
      "Epoch [213/500], Train Loss: 0.0214, Validation Loss: 0.0180, Time: 21.63 seconds\n",
      "Epoch [214/500], Train Loss: 0.0189, Validation Loss: 0.0182, Time: 22.19 seconds\n",
      "Epoch [215/500], Train Loss: 0.0209, Validation Loss: 0.0189, Time: 22.69 seconds\n",
      "Epoch [216/500], Train Loss: 0.0202, Validation Loss: 0.0151, Time: 22.12 seconds\n",
      "Epoch [217/500], Train Loss: 0.0192, Validation Loss: 0.0190, Time: 21.86 seconds\n",
      "Epoch [218/500], Train Loss: 0.0202, Validation Loss: 0.0185, Time: 21.91 seconds\n",
      "Epoch [219/500], Train Loss: 0.0182, Validation Loss: 0.0174, Time: 22.73 seconds\n",
      "Epoch [220/500], Train Loss: 0.0198, Validation Loss: 0.0178, Time: 21.98 seconds\n",
      "Epoch [221/500], Train Loss: 0.0201, Validation Loss: 0.0206, Time: 21.94 seconds\n",
      "Epoch [222/500], Train Loss: 0.0216, Validation Loss: 0.0171, Time: 22.06 seconds\n",
      "Epoch [223/500], Train Loss: 0.0191, Validation Loss: 0.0170, Time: 22.84 seconds\n",
      "Epoch [224/500], Train Loss: 0.0198, Validation Loss: 0.0181, Time: 21.87 seconds\n",
      "Epoch [225/500], Train Loss: 0.0197, Validation Loss: 0.0164, Time: 21.88 seconds\n",
      "Epoch [226/500], Train Loss: 0.0192, Validation Loss: 0.0180, Time: 22.08 seconds\n",
      "Epoch [227/500], Train Loss: 0.0207, Validation Loss: 0.0194, Time: 22.15 seconds\n",
      "Epoch [228/500], Train Loss: 0.0202, Validation Loss: 0.0202, Time: 21.86 seconds\n",
      "Epoch [229/500], Train Loss: 0.0195, Validation Loss: 0.0180, Time: 21.77 seconds\n",
      "Epoch [230/500], Train Loss: 0.0198, Validation Loss: 0.0170, Time: 22.26 seconds\n",
      "Epoch [231/500], Train Loss: 0.0196, Validation Loss: 0.0178, Time: 22.83 seconds\n",
      "Epoch [232/500], Train Loss: 0.0198, Validation Loss: 0.0163, Time: 22.02 seconds\n",
      "Epoch [233/500], Train Loss: 0.0192, Validation Loss: 0.0185, Time: 22.75 seconds\n",
      "Epoch [234/500], Train Loss: 0.0182, Validation Loss: 0.0202, Time: 23.10 seconds\n",
      "Epoch [235/500], Train Loss: 0.0202, Validation Loss: 0.0193, Time: 22.71 seconds\n",
      "Epoch [236/500], Train Loss: 0.0198, Validation Loss: 0.0181, Time: 22.49 seconds\n",
      "Epoch [237/500], Train Loss: 0.0187, Validation Loss: 0.0174, Time: 21.93 seconds\n",
      "Epoch [238/500], Train Loss: 0.0186, Validation Loss: 0.0143, Time: 22.22 seconds\n",
      "Epoch [239/500], Train Loss: 0.0188, Validation Loss: 0.0173, Time: 22.31 seconds\n",
      "Epoch [240/500], Train Loss: 0.0204, Validation Loss: 0.0174, Time: 22.14 seconds\n",
      "Epoch [241/500], Train Loss: 0.0194, Validation Loss: 0.0190, Time: 22.03 seconds\n",
      "Epoch [242/500], Train Loss: 0.0198, Validation Loss: 0.0182, Time: 22.63 seconds\n",
      "Epoch [243/500], Train Loss: 0.0191, Validation Loss: 0.0171, Time: 22.70 seconds\n",
      "Epoch [244/500], Train Loss: 0.0188, Validation Loss: 0.0180, Time: 22.59 seconds\n",
      "Epoch [245/500], Train Loss: 0.0194, Validation Loss: 0.0182, Time: 22.17 seconds\n",
      "Epoch [246/500], Train Loss: 0.0203, Validation Loss: 0.0184, Time: 22.52 seconds\n",
      "Epoch [247/500], Train Loss: 0.0200, Validation Loss: 0.0160, Time: 21.95 seconds\n",
      "Epoch [248/500], Train Loss: 0.0200, Validation Loss: 0.0196, Time: 22.16 seconds\n",
      "Epoch [249/500], Train Loss: 0.0198, Validation Loss: 0.0168, Time: 22.63 seconds\n",
      "Epoch [250/500], Train Loss: 0.0203, Validation Loss: 0.0198, Time: 22.46 seconds\n",
      "Epoch [251/500], Train Loss: 0.0195, Validation Loss: 0.0148, Time: 22.36 seconds\n",
      "Epoch [252/500], Train Loss: 0.0205, Validation Loss: 0.0192, Time: 22.60 seconds\n",
      "Epoch [253/500], Train Loss: 0.0195, Validation Loss: 0.0189, Time: 22.57 seconds\n",
      "Epoch [254/500], Train Loss: 0.0196, Validation Loss: 0.0197, Time: 22.28 seconds\n",
      "Epoch [255/500], Train Loss: 0.0208, Validation Loss: 0.0183, Time: 22.08 seconds\n",
      "Epoch [256/500], Train Loss: 0.0222, Validation Loss: 0.0199, Time: 21.96 seconds\n",
      "Epoch [257/500], Train Loss: 0.0196, Validation Loss: 0.0185, Time: 21.76 seconds\n",
      "Epoch [258/500], Train Loss: 0.0219, Validation Loss: 0.0175, Time: 22.17 seconds\n",
      "Epoch [259/500], Train Loss: 0.0201, Validation Loss: 0.0173, Time: 21.90 seconds\n",
      "Epoch [260/500], Train Loss: 0.0197, Validation Loss: 0.0194, Time: 22.14 seconds\n",
      "Epoch [261/500], Train Loss: 0.0204, Validation Loss: 0.0187, Time: 22.18 seconds\n",
      "Epoch [262/500], Train Loss: 0.0203, Validation Loss: 0.0160, Time: 22.66 seconds\n",
      "Epoch [263/500], Train Loss: 0.0201, Validation Loss: 0.0176, Time: 22.42 seconds\n",
      "Epoch [264/500], Train Loss: 0.0195, Validation Loss: 0.0189, Time: 22.44 seconds\n",
      "Epoch [265/500], Train Loss: 0.0191, Validation Loss: 0.0180, Time: 22.45 seconds\n",
      "Epoch [266/500], Train Loss: 0.0204, Validation Loss: 0.0175, Time: 22.34 seconds\n",
      "Epoch [267/500], Train Loss: 0.0194, Validation Loss: 0.0173, Time: 21.83 seconds\n",
      "Epoch [268/500], Train Loss: 0.0196, Validation Loss: 0.0178, Time: 22.19 seconds\n",
      "Epoch [269/500], Train Loss: 0.0198, Validation Loss: 0.0161, Time: 22.02 seconds\n",
      "Epoch [270/500], Train Loss: 0.0194, Validation Loss: 0.0174, Time: 22.43 seconds\n",
      "Epoch [271/500], Train Loss: 0.0192, Validation Loss: 0.0174, Time: 22.72 seconds\n",
      "Epoch [272/500], Train Loss: 0.0194, Validation Loss: 0.0166, Time: 22.44 seconds\n",
      "Epoch [273/500], Train Loss: 0.0200, Validation Loss: 0.0173, Time: 22.47 seconds\n",
      "Epoch [274/500], Train Loss: 0.0191, Validation Loss: 0.0181, Time: 22.35 seconds\n",
      "Epoch [275/500], Train Loss: 0.0223, Validation Loss: 0.0176, Time: 22.10 seconds\n",
      "Epoch [276/500], Train Loss: 0.0191, Validation Loss: 0.0168, Time: 22.07 seconds\n",
      "Epoch [277/500], Train Loss: 0.0217, Validation Loss: 0.0178, Time: 22.83 seconds\n",
      "Epoch [278/500], Train Loss: 0.0202, Validation Loss: 0.0167, Time: 21.87 seconds\n",
      "Epoch [279/500], Train Loss: 0.0195, Validation Loss: 0.0183, Time: 22.38 seconds\n",
      "Epoch [280/500], Train Loss: 0.0200, Validation Loss: 0.0186, Time: 22.01 seconds\n",
      "Epoch [281/500], Train Loss: 0.0201, Validation Loss: 0.0183, Time: 21.90 seconds\n",
      "Epoch [282/500], Train Loss: 0.0185, Validation Loss: 0.0178, Time: 22.48 seconds\n",
      "Epoch [283/500], Train Loss: 0.0209, Validation Loss: 0.0177, Time: 22.48 seconds\n",
      "Epoch [284/500], Train Loss: 0.0208, Validation Loss: 0.0164, Time: 22.26 seconds\n",
      "Epoch [285/500], Train Loss: 0.0196, Validation Loss: 0.0166, Time: 22.58 seconds\n",
      "Epoch [286/500], Train Loss: 0.0195, Validation Loss: 0.0189, Time: 22.61 seconds\n",
      "Epoch [287/500], Train Loss: 0.0190, Validation Loss: 0.0165, Time: 22.17 seconds\n",
      "Epoch [288/500], Train Loss: 0.0210, Validation Loss: 0.0183, Time: 22.81 seconds\n",
      "Epoch [289/500], Train Loss: 0.0209, Validation Loss: 0.0177, Time: 22.44 seconds\n",
      "Epoch [290/500], Train Loss: 0.0193, Validation Loss: 0.0161, Time: 21.87 seconds\n",
      "Epoch [291/500], Train Loss: 0.0210, Validation Loss: 0.0164, Time: 22.31 seconds\n",
      "Epoch [292/500], Train Loss: 0.0202, Validation Loss: 0.0173, Time: 21.99 seconds\n",
      "Epoch [293/500], Train Loss: 0.0186, Validation Loss: 0.0157, Time: 22.24 seconds\n",
      "Epoch [294/500], Train Loss: 0.0194, Validation Loss: 0.0184, Time: 21.78 seconds\n",
      "Epoch [295/500], Train Loss: 0.0204, Validation Loss: 0.0172, Time: 21.85 seconds\n",
      "Epoch [296/500], Train Loss: 0.0207, Validation Loss: 0.0180, Time: 22.51 seconds\n",
      "Epoch [297/500], Train Loss: 0.0192, Validation Loss: 0.0178, Time: 22.29 seconds\n",
      "Epoch [298/500], Train Loss: 0.0193, Validation Loss: 0.0184, Time: 22.20 seconds\n",
      "Epoch [299/500], Train Loss: 0.0201, Validation Loss: 0.0216, Time: 21.99 seconds\n",
      "Epoch [300/500], Train Loss: 0.0198, Validation Loss: 0.0193, Time: 22.54 seconds\n",
      "Epoch [301/500], Train Loss: 0.0195, Validation Loss: 0.0177, Time: 22.42 seconds\n",
      "Epoch [302/500], Train Loss: 0.0202, Validation Loss: 0.0180, Time: 23.02 seconds\n",
      "Epoch [303/500], Train Loss: 0.0185, Validation Loss: 0.0176, Time: 22.07 seconds\n",
      "Epoch [304/500], Train Loss: 0.0204, Validation Loss: 0.0175, Time: 22.25 seconds\n",
      "Epoch [305/500], Train Loss: 0.0194, Validation Loss: 0.0186, Time: 22.68 seconds\n",
      "Epoch [306/500], Train Loss: 0.0209, Validation Loss: 0.0164, Time: 22.36 seconds\n",
      "Epoch [307/500], Train Loss: 0.0209, Validation Loss: 0.0169, Time: 22.56 seconds\n",
      "Epoch [308/500], Train Loss: 0.0197, Validation Loss: 0.0176, Time: 22.76 seconds\n",
      "Epoch [309/500], Train Loss: 0.0206, Validation Loss: 0.0176, Time: 21.74 seconds\n",
      "Epoch [310/500], Train Loss: 0.0200, Validation Loss: 0.0180, Time: 22.25 seconds\n",
      "Epoch [311/500], Train Loss: 0.0199, Validation Loss: 0.0177, Time: 22.51 seconds\n",
      "Epoch [312/500], Train Loss: 0.0191, Validation Loss: 0.0176, Time: 22.00 seconds\n",
      "Epoch [313/500], Train Loss: 0.0198, Validation Loss: 0.0190, Time: 22.20 seconds\n",
      "Epoch [314/500], Train Loss: 0.0207, Validation Loss: 0.0195, Time: 22.25 seconds\n",
      "Epoch [315/500], Train Loss: 0.0197, Validation Loss: 0.0164, Time: 21.90 seconds\n",
      "Epoch [316/500], Train Loss: 0.0203, Validation Loss: 0.0155, Time: 22.23 seconds\n",
      "Epoch [317/500], Train Loss: 0.0200, Validation Loss: 0.0174, Time: 21.96 seconds\n",
      "Epoch [318/500], Train Loss: 0.0203, Validation Loss: 0.0173, Time: 22.02 seconds\n",
      "Epoch [319/500], Train Loss: 0.0194, Validation Loss: 0.0185, Time: 22.39 seconds\n",
      "Epoch [320/500], Train Loss: 0.0205, Validation Loss: 0.0178, Time: 21.97 seconds\n",
      "Epoch [321/500], Train Loss: 0.0208, Validation Loss: 0.0203, Time: 22.32 seconds\n",
      "Epoch [322/500], Train Loss: 0.0193, Validation Loss: 0.0156, Time: 21.72 seconds\n",
      "Epoch [323/500], Train Loss: 0.0196, Validation Loss: 0.0195, Time: 21.91 seconds\n",
      "Epoch [324/500], Train Loss: 0.0203, Validation Loss: 0.0162, Time: 21.90 seconds\n",
      "Epoch [325/500], Train Loss: 0.0204, Validation Loss: 0.0171, Time: 22.39 seconds\n",
      "Epoch [326/500], Train Loss: 0.0196, Validation Loss: 0.0169, Time: 22.14 seconds\n",
      "Epoch [327/500], Train Loss: 0.0196, Validation Loss: 0.0169, Time: 22.32 seconds\n",
      "Epoch [328/500], Train Loss: 0.0204, Validation Loss: 0.0186, Time: 21.89 seconds\n",
      "Epoch [329/500], Train Loss: 0.0194, Validation Loss: 0.0201, Time: 22.88 seconds\n",
      "Epoch [330/500], Train Loss: 0.0200, Validation Loss: 0.0166, Time: 22.13 seconds\n",
      "Epoch [331/500], Train Loss: 0.0201, Validation Loss: 0.0184, Time: 22.14 seconds\n",
      "Epoch [332/500], Train Loss: 0.0206, Validation Loss: 0.0183, Time: 21.86 seconds\n",
      "Epoch [333/500], Train Loss: 0.0215, Validation Loss: 0.0186, Time: 22.86 seconds\n",
      "Epoch [334/500], Train Loss: 0.0207, Validation Loss: 0.0155, Time: 22.55 seconds\n",
      "Epoch [335/500], Train Loss: 0.0193, Validation Loss: 0.0170, Time: 21.90 seconds\n",
      "Epoch [336/500], Train Loss: 0.0199, Validation Loss: 0.0207, Time: 22.35 seconds\n",
      "Epoch [337/500], Train Loss: 0.0209, Validation Loss: 0.0178, Time: 21.74 seconds\n",
      "Epoch [338/500], Train Loss: 0.0192, Validation Loss: 0.0183, Time: 22.06 seconds\n",
      "Epoch [339/500], Train Loss: 0.0198, Validation Loss: 0.0170, Time: 22.65 seconds\n",
      "Epoch [340/500], Train Loss: 0.0202, Validation Loss: 0.0168, Time: 22.20 seconds\n",
      "Epoch [341/500], Train Loss: 0.0197, Validation Loss: 0.0175, Time: 22.03 seconds\n",
      "Epoch [342/500], Train Loss: 0.0196, Validation Loss: 0.0184, Time: 21.87 seconds\n",
      "Epoch [343/500], Train Loss: 0.0195, Validation Loss: 0.0171, Time: 23.07 seconds\n",
      "Epoch [344/500], Train Loss: 0.0204, Validation Loss: 0.0160, Time: 22.20 seconds\n",
      "Epoch [345/500], Train Loss: 0.0189, Validation Loss: 0.0181, Time: 21.90 seconds\n",
      "Epoch [346/500], Train Loss: 0.0194, Validation Loss: 0.0156, Time: 22.62 seconds\n",
      "Epoch [347/500], Train Loss: 0.0214, Validation Loss: 0.0181, Time: 22.70 seconds\n",
      "Epoch [348/500], Train Loss: 0.0207, Validation Loss: 0.0197, Time: 22.74 seconds\n",
      "Epoch [349/500], Train Loss: 0.0209, Validation Loss: 0.0143, Time: 22.13 seconds\n",
      "Epoch [350/500], Train Loss: 0.0192, Validation Loss: 0.0178, Time: 22.47 seconds\n",
      "Epoch [351/500], Train Loss: 0.0191, Validation Loss: 0.0183, Time: 23.06 seconds\n",
      "Epoch [352/500], Train Loss: 0.0206, Validation Loss: 0.0179, Time: 23.12 seconds\n",
      "Epoch [353/500], Train Loss: 0.0195, Validation Loss: 0.0189, Time: 22.16 seconds\n",
      "Epoch [354/500], Train Loss: 0.0189, Validation Loss: 0.0186, Time: 22.56 seconds\n",
      "Epoch [355/500], Train Loss: 0.0200, Validation Loss: 0.0193, Time: 22.50 seconds\n",
      "Epoch [356/500], Train Loss: 0.0183, Validation Loss: 0.0183, Time: 22.49 seconds\n",
      "Epoch [357/500], Train Loss: 0.0191, Validation Loss: 0.0182, Time: 22.12 seconds\n",
      "Epoch [358/500], Train Loss: 0.0189, Validation Loss: 0.0178, Time: 22.75 seconds\n",
      "Epoch [359/500], Train Loss: 0.0190, Validation Loss: 0.0178, Time: 22.65 seconds\n",
      "Epoch [360/500], Train Loss: 0.0187, Validation Loss: 0.0153, Time: 22.42 seconds\n",
      "Epoch [361/500], Train Loss: 0.0206, Validation Loss: 0.0187, Time: 22.56 seconds\n",
      "Epoch [362/500], Train Loss: 0.0204, Validation Loss: 0.0169, Time: 22.54 seconds\n",
      "Epoch [363/500], Train Loss: 0.0196, Validation Loss: 0.0173, Time: 22.72 seconds\n",
      "Epoch [364/500], Train Loss: 0.0195, Validation Loss: 0.0184, Time: 22.49 seconds\n",
      "Epoch [365/500], Train Loss: 0.0193, Validation Loss: 0.0189, Time: 22.30 seconds\n",
      "Epoch [366/500], Train Loss: 0.0208, Validation Loss: 0.0183, Time: 22.02 seconds\n",
      "Epoch [367/500], Train Loss: 0.0209, Validation Loss: 0.0178, Time: 21.81 seconds\n",
      "Epoch [368/500], Train Loss: 0.0191, Validation Loss: 0.0167, Time: 22.08 seconds\n",
      "Epoch [369/500], Train Loss: 0.0195, Validation Loss: 0.0172, Time: 22.71 seconds\n",
      "Epoch [370/500], Train Loss: 0.0200, Validation Loss: 0.0163, Time: 22.40 seconds\n",
      "Epoch [371/500], Train Loss: 0.0190, Validation Loss: 0.0154, Time: 22.76 seconds\n",
      "Epoch [372/500], Train Loss: 0.0196, Validation Loss: 0.0176, Time: 21.88 seconds\n",
      "Epoch [373/500], Train Loss: 0.0200, Validation Loss: 0.0173, Time: 22.48 seconds\n",
      "Epoch [374/500], Train Loss: 0.0201, Validation Loss: 0.0168, Time: 22.26 seconds\n",
      "Epoch [375/500], Train Loss: 0.0194, Validation Loss: 0.0179, Time: 22.12 seconds\n",
      "Epoch [376/500], Train Loss: 0.0191, Validation Loss: 0.0177, Time: 22.31 seconds\n",
      "Epoch [377/500], Train Loss: 0.0217, Validation Loss: 0.0169, Time: 22.56 seconds\n",
      "Epoch [378/500], Train Loss: 0.0199, Validation Loss: 0.0179, Time: 21.72 seconds\n",
      "Epoch [379/500], Train Loss: 0.0205, Validation Loss: 0.0176, Time: 22.36 seconds\n",
      "Epoch [380/500], Train Loss: 0.0192, Validation Loss: 0.0170, Time: 22.41 seconds\n",
      "Epoch [381/500], Train Loss: 0.0204, Validation Loss: 0.0177, Time: 22.59 seconds\n",
      "Epoch [382/500], Train Loss: 0.0204, Validation Loss: 0.0197, Time: 21.88 seconds\n",
      "Epoch [383/500], Train Loss: 0.0197, Validation Loss: 0.0201, Time: 21.96 seconds\n",
      "Epoch [384/500], Train Loss: 0.0199, Validation Loss: 0.0189, Time: 22.10 seconds\n",
      "Epoch [385/500], Train Loss: 0.0204, Validation Loss: 0.0151, Time: 22.05 seconds\n",
      "Epoch [386/500], Train Loss: 0.0206, Validation Loss: 0.0169, Time: 21.92 seconds\n",
      "Epoch [387/500], Train Loss: 0.0208, Validation Loss: 0.0171, Time: 22.25 seconds\n",
      "Epoch [388/500], Train Loss: 0.0198, Validation Loss: 0.0175, Time: 22.20 seconds\n",
      "Epoch [389/500], Train Loss: 0.0222, Validation Loss: 0.0178, Time: 21.73 seconds\n",
      "Epoch [390/500], Train Loss: 0.0182, Validation Loss: 0.0171, Time: 21.84 seconds\n",
      "Epoch [391/500], Train Loss: 0.0210, Validation Loss: 0.0175, Time: 22.25 seconds\n",
      "Epoch [392/500], Train Loss: 0.0195, Validation Loss: 0.0165, Time: 22.18 seconds\n",
      "Epoch [393/500], Train Loss: 0.0197, Validation Loss: 0.0153, Time: 22.38 seconds\n",
      "Epoch [394/500], Train Loss: 0.0193, Validation Loss: 0.0171, Time: 21.88 seconds\n",
      "Epoch [395/500], Train Loss: 0.0199, Validation Loss: 0.0179, Time: 22.04 seconds\n",
      "Epoch [396/500], Train Loss: 0.0213, Validation Loss: 0.0180, Time: 22.77 seconds\n",
      "Epoch [397/500], Train Loss: 0.0183, Validation Loss: 0.0212, Time: 22.91 seconds\n",
      "Epoch [398/500], Train Loss: 0.0200, Validation Loss: 0.0168, Time: 23.53 seconds\n",
      "Epoch [399/500], Train Loss: 0.0195, Validation Loss: 0.0175, Time: 22.41 seconds\n",
      "Epoch [400/500], Train Loss: 0.0198, Validation Loss: 0.0155, Time: 21.92 seconds\n",
      "Epoch [401/500], Train Loss: 0.0197, Validation Loss: 0.0178, Time: 22.69 seconds\n",
      "Epoch [402/500], Train Loss: 0.0210, Validation Loss: 0.0181, Time: 21.76 seconds\n",
      "Epoch [403/500], Train Loss: 0.0188, Validation Loss: 0.0175, Time: 21.95 seconds\n",
      "Epoch [404/500], Train Loss: 0.0198, Validation Loss: 0.0152, Time: 22.58 seconds\n",
      "Epoch [405/500], Train Loss: 0.0206, Validation Loss: 0.0199, Time: 22.72 seconds\n",
      "Epoch [406/500], Train Loss: 0.0197, Validation Loss: 0.0170, Time: 22.26 seconds\n",
      "Epoch [407/500], Train Loss: 0.0202, Validation Loss: 0.0209, Time: 22.46 seconds\n",
      "Epoch [408/500], Train Loss: 0.0205, Validation Loss: 0.0168, Time: 22.68 seconds\n",
      "Epoch [409/500], Train Loss: 0.0189, Validation Loss: 0.0186, Time: 22.08 seconds\n",
      "Epoch [410/500], Train Loss: 0.0192, Validation Loss: 0.0176, Time: 22.43 seconds\n",
      "Epoch [411/500], Train Loss: 0.0193, Validation Loss: 0.0163, Time: 22.01 seconds\n",
      "Epoch [412/500], Train Loss: 0.0190, Validation Loss: 0.0174, Time: 21.96 seconds\n",
      "Epoch [413/500], Train Loss: 0.0195, Validation Loss: 0.0150, Time: 22.27 seconds\n",
      "Epoch [414/500], Train Loss: 0.0205, Validation Loss: 0.0178, Time: 21.93 seconds\n",
      "Epoch [415/500], Train Loss: 0.0193, Validation Loss: 0.0176, Time: 22.02 seconds\n",
      "Epoch [416/500], Train Loss: 0.0186, Validation Loss: 0.0163, Time: 22.39 seconds\n",
      "Epoch [417/500], Train Loss: 0.0212, Validation Loss: 0.0184, Time: 22.48 seconds\n",
      "Epoch [418/500], Train Loss: 0.0196, Validation Loss: 0.0196, Time: 22.26 seconds\n",
      "Epoch [419/500], Train Loss: 0.0201, Validation Loss: 0.0168, Time: 22.46 seconds\n",
      "Epoch [420/500], Train Loss: 0.0195, Validation Loss: 0.0177, Time: 22.35 seconds\n",
      "Epoch [421/500], Train Loss: 0.0202, Validation Loss: 0.0164, Time: 22.37 seconds\n",
      "Epoch [422/500], Train Loss: 0.0206, Validation Loss: 0.0171, Time: 22.47 seconds\n",
      "Epoch [423/500], Train Loss: 0.0192, Validation Loss: 0.0173, Time: 22.45 seconds\n",
      "Epoch [424/500], Train Loss: 0.0200, Validation Loss: 0.0151, Time: 22.98 seconds\n",
      "Epoch [425/500], Train Loss: 0.0202, Validation Loss: 0.0191, Time: 22.63 seconds\n",
      "Epoch [426/500], Train Loss: 0.0202, Validation Loss: 0.0164, Time: 22.05 seconds\n",
      "Epoch [427/500], Train Loss: 0.0202, Validation Loss: 0.0149, Time: 22.42 seconds\n",
      "Epoch [428/500], Train Loss: 0.0202, Validation Loss: 0.0193, Time: 22.65 seconds\n",
      "Epoch [429/500], Train Loss: 0.0199, Validation Loss: 0.0171, Time: 22.12 seconds\n",
      "Epoch [430/500], Train Loss: 0.0189, Validation Loss: 0.0173, Time: 22.34 seconds\n",
      "Epoch [431/500], Train Loss: 0.0197, Validation Loss: 0.0169, Time: 21.86 seconds\n",
      "Epoch [432/500], Train Loss: 0.0192, Validation Loss: 0.0229, Time: 22.63 seconds\n",
      "Epoch [433/500], Train Loss: 0.0203, Validation Loss: 0.0172, Time: 22.41 seconds\n",
      "Epoch [434/500], Train Loss: 0.0186, Validation Loss: 0.0172, Time: 21.82 seconds\n",
      "Epoch [435/500], Train Loss: 0.0215, Validation Loss: 0.0175, Time: 22.43 seconds\n",
      "Epoch [436/500], Train Loss: 0.0206, Validation Loss: 0.0157, Time: 22.10 seconds\n",
      "Epoch [437/500], Train Loss: 0.0207, Validation Loss: 0.0166, Time: 21.95 seconds\n",
      "Epoch [438/500], Train Loss: 0.0197, Validation Loss: 0.0170, Time: 21.92 seconds\n",
      "Epoch [439/500], Train Loss: 0.0203, Validation Loss: 0.0189, Time: 22.52 seconds\n",
      "Epoch [440/500], Train Loss: 0.0186, Validation Loss: 0.0161, Time: 22.34 seconds\n",
      "Epoch [441/500], Train Loss: 0.0213, Validation Loss: 0.0189, Time: 22.64 seconds\n",
      "Epoch [442/500], Train Loss: 0.0198, Validation Loss: 0.0196, Time: 22.38 seconds\n",
      "Epoch [443/500], Train Loss: 0.0195, Validation Loss: 0.0189, Time: 22.18 seconds\n",
      "Epoch [444/500], Train Loss: 0.0197, Validation Loss: 0.0175, Time: 22.33 seconds\n",
      "Epoch [445/500], Train Loss: 0.0195, Validation Loss: 0.0174, Time: 22.16 seconds\n",
      "Epoch [446/500], Train Loss: 0.0208, Validation Loss: 0.0170, Time: 22.09 seconds\n",
      "Epoch [447/500], Train Loss: 0.0198, Validation Loss: 0.0166, Time: 22.57 seconds\n",
      "Epoch [448/500], Train Loss: 0.0201, Validation Loss: 0.0174, Time: 22.03 seconds\n",
      "Epoch [449/500], Train Loss: 0.0195, Validation Loss: 0.0193, Time: 22.07 seconds\n",
      "Epoch [450/500], Train Loss: 0.0188, Validation Loss: 0.0187, Time: 22.35 seconds\n",
      "Epoch [451/500], Train Loss: 0.0186, Validation Loss: 0.0180, Time: 22.65 seconds\n",
      "Epoch [452/500], Train Loss: 0.0195, Validation Loss: 0.0170, Time: 22.37 seconds\n",
      "Epoch [453/500], Train Loss: 0.0195, Validation Loss: 0.0200, Time: 22.45 seconds\n",
      "Epoch [454/500], Train Loss: 0.0197, Validation Loss: 0.0187, Time: 22.57 seconds\n",
      "Epoch [455/500], Train Loss: 0.0193, Validation Loss: 0.0184, Time: 22.21 seconds\n",
      "Epoch [456/500], Train Loss: 0.0194, Validation Loss: 0.0159, Time: 21.83 seconds\n",
      "Epoch [457/500], Train Loss: 0.0196, Validation Loss: 0.0208, Time: 22.68 seconds\n",
      "Epoch [458/500], Train Loss: 0.0194, Validation Loss: 0.0164, Time: 22.79 seconds\n",
      "Epoch [459/500], Train Loss: 0.0199, Validation Loss: 0.0143, Time: 22.30 seconds\n",
      "Epoch [460/500], Train Loss: 0.0181, Validation Loss: 0.0193, Time: 21.85 seconds\n",
      "Epoch [461/500], Train Loss: 0.0178, Validation Loss: 0.0168, Time: 22.21 seconds\n",
      "Epoch [462/500], Train Loss: 0.0202, Validation Loss: 0.0176, Time: 22.50 seconds\n",
      "Epoch [463/500], Train Loss: 0.0194, Validation Loss: 0.0187, Time: 22.25 seconds\n",
      "Epoch [464/500], Train Loss: 0.0187, Validation Loss: 0.0169, Time: 22.16 seconds\n",
      "Epoch [465/500], Train Loss: 0.0199, Validation Loss: 0.0157, Time: 22.69 seconds\n",
      "Epoch [466/500], Train Loss: 0.0183, Validation Loss: 0.0172, Time: 22.20 seconds\n",
      "Epoch [467/500], Train Loss: 0.0193, Validation Loss: 0.0177, Time: 23.06 seconds\n",
      "Epoch [468/500], Train Loss: 0.0183, Validation Loss: 0.0167, Time: 22.21 seconds\n",
      "Epoch [469/500], Train Loss: 0.0196, Validation Loss: 0.0185, Time: 22.24 seconds\n",
      "Epoch [470/500], Train Loss: 0.0207, Validation Loss: 0.0196, Time: 22.01 seconds\n",
      "Epoch [471/500], Train Loss: 0.0202, Validation Loss: 0.0195, Time: 22.73 seconds\n",
      "Epoch [472/500], Train Loss: 0.0188, Validation Loss: 0.0196, Time: 22.32 seconds\n",
      "Epoch [473/500], Train Loss: 0.0193, Validation Loss: 0.0173, Time: 21.90 seconds\n",
      "Epoch [474/500], Train Loss: 0.0196, Validation Loss: 0.0178, Time: 21.90 seconds\n",
      "Epoch [475/500], Train Loss: 0.0191, Validation Loss: 0.0201, Time: 22.22 seconds\n",
      "Epoch [476/500], Train Loss: 0.0192, Validation Loss: 0.0164, Time: 22.29 seconds\n",
      "Epoch [477/500], Train Loss: 0.0201, Validation Loss: 0.0177, Time: 22.63 seconds\n",
      "Epoch [478/500], Train Loss: 0.0201, Validation Loss: 0.0151, Time: 22.38 seconds\n",
      "Epoch [479/500], Train Loss: 0.0199, Validation Loss: 0.0181, Time: 22.88 seconds\n",
      "Epoch [480/500], Train Loss: 0.0196, Validation Loss: 0.0198, Time: 22.52 seconds\n",
      "Epoch [481/500], Train Loss: 0.0216, Validation Loss: 0.0205, Time: 22.57 seconds\n",
      "Epoch [482/500], Train Loss: 0.0190, Validation Loss: 0.0173, Time: 22.50 seconds\n",
      "Epoch [483/500], Train Loss: 0.0196, Validation Loss: 0.0173, Time: 22.50 seconds\n",
      "Epoch [484/500], Train Loss: 0.0197, Validation Loss: 0.0184, Time: 22.59 seconds\n",
      "Epoch [485/500], Train Loss: 0.0196, Validation Loss: 0.0169, Time: 22.87 seconds\n",
      "Epoch [486/500], Train Loss: 0.0195, Validation Loss: 0.0165, Time: 22.30 seconds\n",
      "Epoch [487/500], Train Loss: 0.0188, Validation Loss: 0.0190, Time: 22.01 seconds\n",
      "Epoch [488/500], Train Loss: 0.0201, Validation Loss: 0.0196, Time: 21.89 seconds\n",
      "Epoch [489/500], Train Loss: 0.0189, Validation Loss: 0.0170, Time: 22.17 seconds\n",
      "Epoch [490/500], Train Loss: 0.0202, Validation Loss: 0.0165, Time: 22.59 seconds\n",
      "Epoch [491/500], Train Loss: 0.0206, Validation Loss: 0.0180, Time: 21.73 seconds\n",
      "Epoch [492/500], Train Loss: 0.0203, Validation Loss: 0.0166, Time: 22.10 seconds\n",
      "Epoch [493/500], Train Loss: 0.0197, Validation Loss: 0.0166, Time: 22.36 seconds\n",
      "Epoch [494/500], Train Loss: 0.0200, Validation Loss: 0.0177, Time: 22.52 seconds\n",
      "Epoch [495/500], Train Loss: 0.0186, Validation Loss: 0.0178, Time: 22.43 seconds\n",
      "Epoch [496/500], Train Loss: 0.0182, Validation Loss: 0.0153, Time: 21.76 seconds\n",
      "Epoch [497/500], Train Loss: 0.0202, Validation Loss: 0.0207, Time: 22.52 seconds\n",
      "Epoch [498/500], Train Loss: 0.0183, Validation Loss: 0.0172, Time: 22.79 seconds\n",
      "Epoch [499/500], Train Loss: 0.0193, Validation Loss: 0.0153, Time: 22.05 seconds\n",
      "Epoch [500/500], Train Loss: 0.0206, Validation Loss: 0.0167, Time: 21.87 seconds\n"
     ]
    }
   ],
   "source": [
    "train_losses, val_losses = train_and_validate(modi, train_loader, val_loader, optimizer, criterion, num_epochs=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the model parameters after training\n",
    "torch.save(modi.state_dict(), 'modi_time_pred.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the model parameters from the saved file\n",
    "modi = Autoencod_fituning()  # Reinitialize the model structure\n",
    "modi.load_state_dict(torch.load('modi_time_pred.pth',weights_only=True))  # Load saved weights\n",
    "modi = modi.to(device)  # Move the model to the same device as your data (if using GPU)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_3388\\2485854770.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  modi.load_state_dict(torch.load('modi_time_pred.pth'))  # Load saved weights\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/1500], Train Loss: 0.0193, Validation Loss: 0.0172, Time: 26.12 seconds\n",
      "Epoch [2/1500], Train Loss: 0.0190, Validation Loss: 0.0164, Time: 21.74 seconds\n",
      "Epoch [3/1500], Train Loss: 0.0193, Validation Loss: 0.0165, Time: 22.32 seconds\n",
      "Epoch [4/1500], Train Loss: 0.0192, Validation Loss: 0.0179, Time: 22.94 seconds\n",
      "Epoch [5/1500], Train Loss: 0.0182, Validation Loss: 0.0160, Time: 27.99 seconds\n",
      "Epoch [6/1500], Train Loss: 0.0194, Validation Loss: 0.0160, Time: 23.53 seconds\n",
      "Epoch [7/1500], Train Loss: 0.0192, Validation Loss: 0.0173, Time: 21.75 seconds\n",
      "Epoch [8/1500], Train Loss: 0.0201, Validation Loss: 0.0186, Time: 22.74 seconds\n",
      "Epoch [9/1500], Train Loss: 0.0206, Validation Loss: 0.0206, Time: 22.68 seconds\n",
      "Epoch [10/1500], Train Loss: 0.0194, Validation Loss: 0.0197, Time: 23.14 seconds\n",
      "Epoch [11/1500], Train Loss: 0.0204, Validation Loss: 0.0184, Time: 22.54 seconds\n",
      "Epoch [12/1500], Train Loss: 0.0183, Validation Loss: 0.0222, Time: 22.14 seconds\n",
      "Epoch [13/1500], Train Loss: 0.0196, Validation Loss: 0.0210, Time: 22.89 seconds\n",
      "Epoch [14/1500], Train Loss: 0.0191, Validation Loss: 0.0171, Time: 22.60 seconds\n",
      "Epoch [15/1500], Train Loss: 0.0182, Validation Loss: 0.0166, Time: 22.17 seconds\n",
      "Epoch [16/1500], Train Loss: 0.0186, Validation Loss: 0.0141, Time: 23.03 seconds\n",
      "Epoch [17/1500], Train Loss: 0.0207, Validation Loss: 0.0205, Time: 22.59 seconds\n",
      "Epoch [18/1500], Train Loss: 0.0204, Validation Loss: 0.0173, Time: 22.05 seconds\n",
      "Epoch [19/1500], Train Loss: 0.0187, Validation Loss: 0.0182, Time: 22.77 seconds\n",
      "Epoch [20/1500], Train Loss: 0.0197, Validation Loss: 0.0156, Time: 22.20 seconds\n",
      "Epoch [21/1500], Train Loss: 0.0202, Validation Loss: 0.0187, Time: 21.97 seconds\n",
      "Epoch [22/1500], Train Loss: 0.0189, Validation Loss: 0.0198, Time: 20.97 seconds\n",
      "Epoch [23/1500], Train Loss: 0.0182, Validation Loss: 0.0220, Time: 21.76 seconds\n",
      "Epoch [24/1500], Train Loss: 0.0201, Validation Loss: 0.0187, Time: 21.20 seconds\n",
      "Epoch [25/1500], Train Loss: 0.0197, Validation Loss: 0.0188, Time: 20.97 seconds\n",
      "Epoch [26/1500], Train Loss: 0.0188, Validation Loss: 0.0171, Time: 21.37 seconds\n",
      "Epoch [27/1500], Train Loss: 0.0185, Validation Loss: 0.0178, Time: 21.67 seconds\n",
      "Epoch [28/1500], Train Loss: 0.0190, Validation Loss: 0.0170, Time: 21.43 seconds\n",
      "Epoch [29/1500], Train Loss: 0.0193, Validation Loss: 0.0166, Time: 21.90 seconds\n",
      "Epoch [30/1500], Train Loss: 0.0209, Validation Loss: 0.0171, Time: 21.74 seconds\n",
      "Epoch [31/1500], Train Loss: 0.0191, Validation Loss: 0.0179, Time: 21.00 seconds\n",
      "Epoch [32/1500], Train Loss: 0.0184, Validation Loss: 0.0181, Time: 20.99 seconds\n",
      "Epoch [33/1500], Train Loss: 0.0197, Validation Loss: 0.0180, Time: 21.10 seconds\n",
      "Epoch [34/1500], Train Loss: 0.0181, Validation Loss: 0.0177, Time: 21.77 seconds\n",
      "Epoch [35/1500], Train Loss: 0.0198, Validation Loss: 0.0181, Time: 21.37 seconds\n",
      "Epoch [36/1500], Train Loss: 0.0182, Validation Loss: 0.0168, Time: 21.55 seconds\n",
      "Epoch [37/1500], Train Loss: 0.0189, Validation Loss: 0.0160, Time: 21.47 seconds\n",
      "Epoch [38/1500], Train Loss: 0.0196, Validation Loss: 0.0180, Time: 21.55 seconds\n",
      "Epoch [39/1500], Train Loss: 0.0194, Validation Loss: 0.0181, Time: 21.22 seconds\n",
      "Epoch [40/1500], Train Loss: 0.0196, Validation Loss: 0.0166, Time: 21.33 seconds\n",
      "Epoch [41/1500], Train Loss: 0.0196, Validation Loss: 0.0183, Time: 21.22 seconds\n",
      "Epoch [42/1500], Train Loss: 0.0191, Validation Loss: 0.0177, Time: 21.37 seconds\n",
      "Epoch [43/1500], Train Loss: 0.0212, Validation Loss: 0.0179, Time: 21.61 seconds\n",
      "Epoch [44/1500], Train Loss: 0.0194, Validation Loss: 0.0157, Time: 20.89 seconds\n",
      "Epoch [45/1500], Train Loss: 0.0180, Validation Loss: 0.0175, Time: 21.06 seconds\n",
      "Epoch [46/1500], Train Loss: 0.0196, Validation Loss: 0.0201, Time: 21.86 seconds\n",
      "Epoch [47/1500], Train Loss: 0.0183, Validation Loss: 0.0177, Time: 21.77 seconds\n",
      "Epoch [48/1500], Train Loss: 0.0203, Validation Loss: 0.0193, Time: 22.83 seconds\n",
      "Epoch [49/1500], Train Loss: 0.0202, Validation Loss: 0.0162, Time: 22.85 seconds\n",
      "Epoch [50/1500], Train Loss: 0.0181, Validation Loss: 0.0189, Time: 22.86 seconds\n",
      "Epoch [51/1500], Train Loss: 0.0187, Validation Loss: 0.0182, Time: 22.68 seconds\n",
      "Epoch [52/1500], Train Loss: 0.0179, Validation Loss: 0.0173, Time: 22.87 seconds\n",
      "Epoch [53/1500], Train Loss: 0.0186, Validation Loss: 0.0185, Time: 22.82 seconds\n",
      "Epoch [54/1500], Train Loss: 0.0197, Validation Loss: 0.0187, Time: 22.84 seconds\n",
      "Epoch [55/1500], Train Loss: 0.0188, Validation Loss: 0.0180, Time: 21.52 seconds\n",
      "Epoch [56/1500], Train Loss: 0.0190, Validation Loss: 0.0174, Time: 21.25 seconds\n",
      "Epoch [57/1500], Train Loss: 0.0192, Validation Loss: 0.0178, Time: 21.25 seconds\n",
      "Epoch [58/1500], Train Loss: 0.0214, Validation Loss: 0.0184, Time: 21.45 seconds\n",
      "Epoch [59/1500], Train Loss: 0.0195, Validation Loss: 0.0163, Time: 21.69 seconds\n",
      "Epoch [60/1500], Train Loss: 0.0191, Validation Loss: 0.0182, Time: 21.60 seconds\n",
      "Epoch [61/1500], Train Loss: 0.0201, Validation Loss: 0.0205, Time: 22.05 seconds\n",
      "Epoch [62/1500], Train Loss: 0.0202, Validation Loss: 0.0173, Time: 21.55 seconds\n",
      "Epoch [63/1500], Train Loss: 0.0182, Validation Loss: 0.0188, Time: 21.81 seconds\n",
      "Epoch [64/1500], Train Loss: 0.0193, Validation Loss: 0.0186, Time: 22.63 seconds\n",
      "Epoch [65/1500], Train Loss: 0.0190, Validation Loss: 0.0180, Time: 23.00 seconds\n",
      "Epoch [66/1500], Train Loss: 0.0195, Validation Loss: 0.0188, Time: 22.73 seconds\n",
      "Epoch [67/1500], Train Loss: 0.0191, Validation Loss: 0.0203, Time: 22.48 seconds\n",
      "Epoch [68/1500], Train Loss: 0.0194, Validation Loss: 0.0192, Time: 23.10 seconds\n",
      "Epoch [69/1500], Train Loss: 0.0180, Validation Loss: 0.0178, Time: 23.50 seconds\n",
      "Epoch [70/1500], Train Loss: 0.0181, Validation Loss: 0.0199, Time: 22.90 seconds\n",
      "Epoch [71/1500], Train Loss: 0.0202, Validation Loss: 0.0185, Time: 23.22 seconds\n",
      "Epoch [72/1500], Train Loss: 0.0198, Validation Loss: 0.0170, Time: 22.62 seconds\n",
      "Epoch [73/1500], Train Loss: 0.0186, Validation Loss: 0.0179, Time: 22.82 seconds\n",
      "Epoch [74/1500], Train Loss: 0.0198, Validation Loss: 0.0167, Time: 24.65 seconds\n",
      "Epoch [75/1500], Train Loss: 0.0184, Validation Loss: 0.0220, Time: 21.45 seconds\n",
      "Epoch [76/1500], Train Loss: 0.0192, Validation Loss: 0.0179, Time: 20.97 seconds\n",
      "Epoch [77/1500], Train Loss: 0.0202, Validation Loss: 0.0174, Time: 21.32 seconds\n",
      "Epoch [78/1500], Train Loss: 0.0200, Validation Loss: 0.0163, Time: 20.98 seconds\n",
      "Epoch [79/1500], Train Loss: 0.0188, Validation Loss: 0.0170, Time: 21.00 seconds\n",
      "Epoch [80/1500], Train Loss: 0.0191, Validation Loss: 0.0198, Time: 21.30 seconds\n",
      "Epoch [81/1500], Train Loss: 0.0190, Validation Loss: 0.0181, Time: 21.27 seconds\n",
      "Epoch [82/1500], Train Loss: 0.0193, Validation Loss: 0.0169, Time: 21.10 seconds\n",
      "Epoch [83/1500], Train Loss: 0.0184, Validation Loss: 0.0207, Time: 21.44 seconds\n",
      "Epoch [84/1500], Train Loss: 0.0201, Validation Loss: 0.0166, Time: 23.12 seconds\n",
      "Epoch [85/1500], Train Loss: 0.0194, Validation Loss: 0.0172, Time: 22.95 seconds\n",
      "Epoch [86/1500], Train Loss: 0.0194, Validation Loss: 0.0177, Time: 23.22 seconds\n",
      "Epoch [87/1500], Train Loss: 0.0186, Validation Loss: 0.0176, Time: 23.05 seconds\n",
      "Epoch [88/1500], Train Loss: 0.0189, Validation Loss: 0.0188, Time: 23.15 seconds\n",
      "Epoch [89/1500], Train Loss: 0.0185, Validation Loss: 0.0173, Time: 22.72 seconds\n",
      "Epoch [90/1500], Train Loss: 0.0198, Validation Loss: 0.0197, Time: 22.27 seconds\n",
      "Epoch [91/1500], Train Loss: 0.0198, Validation Loss: 0.0187, Time: 20.96 seconds\n",
      "Epoch [92/1500], Train Loss: 0.0197, Validation Loss: 0.0185, Time: 21.58 seconds\n",
      "Epoch [93/1500], Train Loss: 0.0194, Validation Loss: 0.0174, Time: 21.72 seconds\n",
      "Epoch [94/1500], Train Loss: 0.0205, Validation Loss: 0.0170, Time: 22.05 seconds\n",
      "Epoch [95/1500], Train Loss: 0.0194, Validation Loss: 0.0165, Time: 21.49 seconds\n",
      "Epoch [96/1500], Train Loss: 0.0192, Validation Loss: 0.0189, Time: 22.28 seconds\n",
      "Epoch [97/1500], Train Loss: 0.0192, Validation Loss: 0.0190, Time: 22.12 seconds\n",
      "Epoch [98/1500], Train Loss: 0.0187, Validation Loss: 0.0166, Time: 22.97 seconds\n",
      "Epoch [99/1500], Train Loss: 0.0187, Validation Loss: 0.0185, Time: 22.75 seconds\n",
      "Epoch [100/1500], Train Loss: 0.0202, Validation Loss: 0.0176, Time: 23.17 seconds\n",
      "Epoch [101/1500], Train Loss: 0.0203, Validation Loss: 0.0165, Time: 23.97 seconds\n",
      "Epoch [102/1500], Train Loss: 0.0199, Validation Loss: 0.0182, Time: 24.50 seconds\n",
      "Epoch [103/1500], Train Loss: 0.0200, Validation Loss: 0.0175, Time: 24.49 seconds\n",
      "Epoch [104/1500], Train Loss: 0.0189, Validation Loss: 0.0179, Time: 23.95 seconds\n",
      "Epoch [105/1500], Train Loss: 0.0195, Validation Loss: 0.0204, Time: 25.07 seconds\n",
      "Epoch [106/1500], Train Loss: 0.0190, Validation Loss: 0.0174, Time: 24.69 seconds\n",
      "Epoch [107/1500], Train Loss: 0.0194, Validation Loss: 0.0186, Time: 25.02 seconds\n",
      "Epoch [108/1500], Train Loss: 0.0186, Validation Loss: 0.0176, Time: 24.57 seconds\n",
      "Epoch [109/1500], Train Loss: 0.0191, Validation Loss: 0.0175, Time: 23.04 seconds\n",
      "Epoch [110/1500], Train Loss: 0.0199, Validation Loss: 0.0208, Time: 23.21 seconds\n",
      "Epoch [111/1500], Train Loss: 0.0187, Validation Loss: 0.0186, Time: 22.82 seconds\n",
      "Epoch [112/1500], Train Loss: 0.0185, Validation Loss: 0.0177, Time: 22.84 seconds\n",
      "Epoch [113/1500], Train Loss: 0.0197, Validation Loss: 0.0213, Time: 23.09 seconds\n",
      "Epoch [114/1500], Train Loss: 0.0208, Validation Loss: 0.0196, Time: 23.06 seconds\n",
      "Epoch [115/1500], Train Loss: 0.0183, Validation Loss: 0.0175, Time: 23.39 seconds\n",
      "Epoch [116/1500], Train Loss: 0.0193, Validation Loss: 0.0181, Time: 21.96 seconds\n",
      "Epoch [117/1500], Train Loss: 0.0198, Validation Loss: 0.0190, Time: 22.74 seconds\n",
      "Epoch [118/1500], Train Loss: 0.0185, Validation Loss: 0.0181, Time: 22.79 seconds\n",
      "Epoch [119/1500], Train Loss: 0.0184, Validation Loss: 0.0167, Time: 22.98 seconds\n",
      "Epoch [120/1500], Train Loss: 0.0191, Validation Loss: 0.0175, Time: 23.41 seconds\n",
      "Epoch [121/1500], Train Loss: 0.0203, Validation Loss: 0.0184, Time: 23.14 seconds\n",
      "Epoch [122/1500], Train Loss: 0.0185, Validation Loss: 0.0180, Time: 23.09 seconds\n",
      "Epoch [123/1500], Train Loss: 0.0193, Validation Loss: 0.0184, Time: 22.52 seconds\n",
      "Epoch [124/1500], Train Loss: 0.0183, Validation Loss: 0.0170, Time: 22.84 seconds\n",
      "Epoch [125/1500], Train Loss: 0.0198, Validation Loss: 0.0180, Time: 22.55 seconds\n",
      "Epoch [126/1500], Train Loss: 0.0194, Validation Loss: 0.0212, Time: 22.85 seconds\n",
      "Epoch [127/1500], Train Loss: 0.0205, Validation Loss: 0.0171, Time: 23.27 seconds\n",
      "Epoch [128/1500], Train Loss: 0.0196, Validation Loss: 0.0182, Time: 22.99 seconds\n",
      "Epoch [129/1500], Train Loss: 0.0189, Validation Loss: 0.0207, Time: 22.47 seconds\n",
      "Epoch [130/1500], Train Loss: 0.0195, Validation Loss: 0.0175, Time: 22.47 seconds\n",
      "Epoch [131/1500], Train Loss: 0.0188, Validation Loss: 0.0175, Time: 23.16 seconds\n",
      "Epoch [132/1500], Train Loss: 0.0200, Validation Loss: 0.0191, Time: 23.41 seconds\n",
      "Epoch [133/1500], Train Loss: 0.0189, Validation Loss: 0.0195, Time: 22.55 seconds\n",
      "Epoch [134/1500], Train Loss: 0.0195, Validation Loss: 0.0181, Time: 22.95 seconds\n",
      "Epoch [135/1500], Train Loss: 0.0189, Validation Loss: 0.0191, Time: 23.04 seconds\n",
      "Epoch [136/1500], Train Loss: 0.0196, Validation Loss: 0.0156, Time: 23.24 seconds\n",
      "Epoch [137/1500], Train Loss: 0.0191, Validation Loss: 0.0183, Time: 23.07 seconds\n",
      "Epoch [138/1500], Train Loss: 0.0194, Validation Loss: 0.0195, Time: 22.55 seconds\n",
      "Epoch [139/1500], Train Loss: 0.0198, Validation Loss: 0.0159, Time: 22.74 seconds\n",
      "Epoch [140/1500], Train Loss: 0.0186, Validation Loss: 0.0163, Time: 22.85 seconds\n",
      "Epoch [141/1500], Train Loss: 0.0197, Validation Loss: 0.0197, Time: 22.64 seconds\n",
      "Epoch [142/1500], Train Loss: 0.0194, Validation Loss: 0.0177, Time: 22.87 seconds\n",
      "Epoch [143/1500], Train Loss: 0.0185, Validation Loss: 0.0153, Time: 22.62 seconds\n",
      "Epoch [144/1500], Train Loss: 0.0209, Validation Loss: 0.0185, Time: 22.90 seconds\n",
      "Epoch [145/1500], Train Loss: 0.0194, Validation Loss: 0.0192, Time: 22.88 seconds\n",
      "Epoch [146/1500], Train Loss: 0.0193, Validation Loss: 0.0179, Time: 22.81 seconds\n",
      "Epoch [147/1500], Train Loss: 0.0205, Validation Loss: 0.0176, Time: 23.04 seconds\n",
      "Epoch [148/1500], Train Loss: 0.0187, Validation Loss: 0.0187, Time: 23.12 seconds\n",
      "Epoch [149/1500], Train Loss: 0.0209, Validation Loss: 0.0162, Time: 23.09 seconds\n",
      "Epoch [150/1500], Train Loss: 0.0195, Validation Loss: 0.0159, Time: 23.18 seconds\n",
      "Epoch [151/1500], Train Loss: 0.0198, Validation Loss: 0.0168, Time: 23.14 seconds\n",
      "Epoch [152/1500], Train Loss: 0.0189, Validation Loss: 0.0185, Time: 22.92 seconds\n",
      "Epoch [153/1500], Train Loss: 0.0198, Validation Loss: 0.0173, Time: 23.10 seconds\n",
      "Epoch [154/1500], Train Loss: 0.0196, Validation Loss: 0.0170, Time: 23.31 seconds\n",
      "Epoch [155/1500], Train Loss: 0.0190, Validation Loss: 0.0176, Time: 22.81 seconds\n",
      "Epoch [156/1500], Train Loss: 0.0198, Validation Loss: 0.0173, Time: 22.94 seconds\n",
      "Epoch [157/1500], Train Loss: 0.0188, Validation Loss: 0.0176, Time: 23.16 seconds\n",
      "Epoch [158/1500], Train Loss: 0.0180, Validation Loss: 0.0180, Time: 22.96 seconds\n",
      "Epoch [159/1500], Train Loss: 0.0210, Validation Loss: 0.0214, Time: 22.91 seconds\n",
      "Epoch [160/1500], Train Loss: 0.0187, Validation Loss: 0.0182, Time: 22.91 seconds\n",
      "Epoch [161/1500], Train Loss: 0.0180, Validation Loss: 0.0175, Time: 23.06 seconds\n",
      "Epoch [162/1500], Train Loss: 0.0201, Validation Loss: 0.0159, Time: 21.92 seconds\n",
      "Epoch [163/1500], Train Loss: 0.0204, Validation Loss: 0.0173, Time: 21.64 seconds\n",
      "Epoch [164/1500], Train Loss: 0.0186, Validation Loss: 0.0176, Time: 22.49 seconds\n",
      "Epoch [165/1500], Train Loss: 0.0178, Validation Loss: 0.0188, Time: 22.93 seconds\n",
      "Epoch [166/1500], Train Loss: 0.0208, Validation Loss: 0.0177, Time: 21.99 seconds\n",
      "Epoch [167/1500], Train Loss: 0.0188, Validation Loss: 0.0182, Time: 22.96 seconds\n",
      "Epoch [168/1500], Train Loss: 0.0195, Validation Loss: 0.0165, Time: 22.64 seconds\n",
      "Epoch [169/1500], Train Loss: 0.0209, Validation Loss: 0.0168, Time: 22.99 seconds\n",
      "Epoch [170/1500], Train Loss: 0.0191, Validation Loss: 0.0169, Time: 23.05 seconds\n",
      "Epoch [171/1500], Train Loss: 0.0190, Validation Loss: 0.0163, Time: 22.50 seconds\n",
      "Epoch [172/1500], Train Loss: 0.0188, Validation Loss: 0.0166, Time: 22.91 seconds\n",
      "Epoch [173/1500], Train Loss: 0.0195, Validation Loss: 0.0195, Time: 23.15 seconds\n",
      "Epoch [174/1500], Train Loss: 0.0195, Validation Loss: 0.0188, Time: 22.85 seconds\n",
      "Epoch [175/1500], Train Loss: 0.0193, Validation Loss: 0.0171, Time: 22.65 seconds\n",
      "Epoch [176/1500], Train Loss: 0.0192, Validation Loss: 0.0191, Time: 22.81 seconds\n",
      "Epoch [177/1500], Train Loss: 0.0183, Validation Loss: 0.0178, Time: 22.98 seconds\n",
      "Epoch [178/1500], Train Loss: 0.0196, Validation Loss: 0.0213, Time: 23.03 seconds\n",
      "Epoch [179/1500], Train Loss: 0.0191, Validation Loss: 0.0184, Time: 22.92 seconds\n",
      "Epoch [180/1500], Train Loss: 0.0190, Validation Loss: 0.0165, Time: 23.07 seconds\n",
      "Epoch [181/1500], Train Loss: 0.0200, Validation Loss: 0.0178, Time: 22.97 seconds\n",
      "Epoch [182/1500], Train Loss: 0.0189, Validation Loss: 0.0173, Time: 22.77 seconds\n",
      "Epoch [183/1500], Train Loss: 0.0202, Validation Loss: 0.0176, Time: 23.80 seconds\n",
      "Epoch [184/1500], Train Loss: 0.0181, Validation Loss: 0.0159, Time: 23.04 seconds\n",
      "Epoch [185/1500], Train Loss: 0.0191, Validation Loss: 0.0201, Time: 23.73 seconds\n",
      "Epoch [186/1500], Train Loss: 0.0186, Validation Loss: 0.0181, Time: 23.20 seconds\n",
      "Epoch [187/1500], Train Loss: 0.0206, Validation Loss: 0.0183, Time: 22.94 seconds\n",
      "Epoch [188/1500], Train Loss: 0.0192, Validation Loss: 0.0199, Time: 23.22 seconds\n",
      "Epoch [189/1500], Train Loss: 0.0197, Validation Loss: 0.0190, Time: 23.14 seconds\n",
      "Epoch [190/1500], Train Loss: 0.0178, Validation Loss: 0.0170, Time: 22.64 seconds\n",
      "Epoch [191/1500], Train Loss: 0.0203, Validation Loss: 0.0178, Time: 22.72 seconds\n",
      "Epoch [192/1500], Train Loss: 0.0186, Validation Loss: 0.0186, Time: 23.25 seconds\n",
      "Epoch [193/1500], Train Loss: 0.0194, Validation Loss: 0.0174, Time: 22.87 seconds\n",
      "Epoch [194/1500], Train Loss: 0.0200, Validation Loss: 0.0169, Time: 22.74 seconds\n",
      "Epoch [195/1500], Train Loss: 0.0189, Validation Loss: 0.0169, Time: 22.65 seconds\n",
      "Epoch [196/1500], Train Loss: 0.0194, Validation Loss: 0.0160, Time: 22.87 seconds\n",
      "Epoch [197/1500], Train Loss: 0.0197, Validation Loss: 0.0168, Time: 23.14 seconds\n",
      "Epoch [198/1500], Train Loss: 0.0188, Validation Loss: 0.0185, Time: 22.85 seconds\n",
      "Epoch [199/1500], Train Loss: 0.0195, Validation Loss: 0.0174, Time: 22.87 seconds\n",
      "Epoch [200/1500], Train Loss: 0.0195, Validation Loss: 0.0193, Time: 23.06 seconds\n",
      "Epoch [201/1500], Train Loss: 0.0199, Validation Loss: 0.0178, Time: 22.98 seconds\n",
      "Epoch [202/1500], Train Loss: 0.0194, Validation Loss: 0.0169, Time: 22.98 seconds\n",
      "Epoch [203/1500], Train Loss: 0.0196, Validation Loss: 0.0205, Time: 23.09 seconds\n",
      "Epoch [204/1500], Train Loss: 0.0181, Validation Loss: 0.0186, Time: 22.59 seconds\n",
      "Epoch [205/1500], Train Loss: 0.0193, Validation Loss: 0.0184, Time: 22.89 seconds\n",
      "Epoch [206/1500], Train Loss: 0.0196, Validation Loss: 0.0175, Time: 22.70 seconds\n",
      "Epoch [207/1500], Train Loss: 0.0187, Validation Loss: 0.0195, Time: 22.80 seconds\n",
      "Epoch [208/1500], Train Loss: 0.0195, Validation Loss: 0.0169, Time: 23.29 seconds\n",
      "Epoch [209/1500], Train Loss: 0.0191, Validation Loss: 0.0178, Time: 22.25 seconds\n",
      "Epoch [210/1500], Train Loss: 0.0196, Validation Loss: 0.0184, Time: 22.49 seconds\n",
      "Epoch [211/1500], Train Loss: 0.0190, Validation Loss: 0.0171, Time: 22.96 seconds\n",
      "Epoch [212/1500], Train Loss: 0.0191, Validation Loss: 0.0183, Time: 23.03 seconds\n",
      "Epoch [213/1500], Train Loss: 0.0191, Validation Loss: 0.0171, Time: 22.79 seconds\n",
      "Epoch [214/1500], Train Loss: 0.0197, Validation Loss: 0.0155, Time: 22.84 seconds\n",
      "Epoch [215/1500], Train Loss: 0.0186, Validation Loss: 0.0175, Time: 23.05 seconds\n",
      "Epoch [216/1500], Train Loss: 0.0198, Validation Loss: 0.0194, Time: 22.87 seconds\n",
      "Epoch [217/1500], Train Loss: 0.0192, Validation Loss: 0.0179, Time: 22.69 seconds\n",
      "Epoch [218/1500], Train Loss: 0.0192, Validation Loss: 0.0184, Time: 23.19 seconds\n",
      "Epoch [219/1500], Train Loss: 0.0192, Validation Loss: 0.0160, Time: 22.79 seconds\n",
      "Epoch [220/1500], Train Loss: 0.0197, Validation Loss: 0.0195, Time: 22.74 seconds\n",
      "Epoch [221/1500], Train Loss: 0.0188, Validation Loss: 0.0204, Time: 22.97 seconds\n",
      "Epoch [222/1500], Train Loss: 0.0187, Validation Loss: 0.0192, Time: 23.17 seconds\n",
      "Epoch [223/1500], Train Loss: 0.0204, Validation Loss: 0.0183, Time: 24.29 seconds\n",
      "Epoch [224/1500], Train Loss: 0.0194, Validation Loss: 0.0153, Time: 24.54 seconds\n",
      "Epoch [225/1500], Train Loss: 0.0192, Validation Loss: 0.0187, Time: 24.39 seconds\n",
      "Epoch [226/1500], Train Loss: 0.0185, Validation Loss: 0.0177, Time: 24.78 seconds\n",
      "Epoch [227/1500], Train Loss: 0.0192, Validation Loss: 0.0174, Time: 24.49 seconds\n",
      "Epoch [228/1500], Train Loss: 0.0190, Validation Loss: 0.0166, Time: 23.32 seconds\n",
      "Epoch [229/1500], Train Loss: 0.0211, Validation Loss: 0.0162, Time: 23.02 seconds\n",
      "Epoch [230/1500], Train Loss: 0.0198, Validation Loss: 0.0182, Time: 23.60 seconds\n",
      "Epoch [231/1500], Train Loss: 0.0184, Validation Loss: 0.0188, Time: 23.13 seconds\n",
      "Epoch [232/1500], Train Loss: 0.0190, Validation Loss: 0.0200, Time: 23.47 seconds\n",
      "Epoch [233/1500], Train Loss: 0.0190, Validation Loss: 0.0169, Time: 22.92 seconds\n",
      "Epoch [234/1500], Train Loss: 0.0182, Validation Loss: 0.0167, Time: 23.52 seconds\n",
      "Epoch [235/1500], Train Loss: 0.0184, Validation Loss: 0.0177, Time: 24.04 seconds\n",
      "Epoch [236/1500], Train Loss: 0.0183, Validation Loss: 0.0179, Time: 24.70 seconds\n",
      "Epoch [237/1500], Train Loss: 0.0181, Validation Loss: 0.0170, Time: 24.67 seconds\n",
      "Epoch [238/1500], Train Loss: 0.0186, Validation Loss: 0.0162, Time: 24.08 seconds\n",
      "Epoch [239/1500], Train Loss: 0.0213, Validation Loss: 0.0184, Time: 24.59 seconds\n",
      "Epoch [240/1500], Train Loss: 0.0187, Validation Loss: 0.0179, Time: 24.39 seconds\n",
      "Epoch [241/1500], Train Loss: 0.0217, Validation Loss: 0.0170, Time: 24.62 seconds\n",
      "Epoch [242/1500], Train Loss: 0.0177, Validation Loss: 0.0176, Time: 24.17 seconds\n",
      "Epoch [243/1500], Train Loss: 0.0207, Validation Loss: 0.0179, Time: 24.50 seconds\n",
      "Epoch [244/1500], Train Loss: 0.0202, Validation Loss: 0.0182, Time: 24.49 seconds\n",
      "Epoch [245/1500], Train Loss: 0.0199, Validation Loss: 0.0179, Time: 24.64 seconds\n",
      "Epoch [246/1500], Train Loss: 0.0190, Validation Loss: 0.0153, Time: 24.84 seconds\n",
      "Epoch [247/1500], Train Loss: 0.0198, Validation Loss: 0.0166, Time: 24.37 seconds\n",
      "Epoch [248/1500], Train Loss: 0.0181, Validation Loss: 0.0166, Time: 23.80 seconds\n",
      "Epoch [249/1500], Train Loss: 0.0190, Validation Loss: 0.0177, Time: 24.67 seconds\n",
      "Epoch [250/1500], Train Loss: 0.0195, Validation Loss: 0.0176, Time: 22.45 seconds\n",
      "Epoch [251/1500], Train Loss: 0.0183, Validation Loss: 0.0187, Time: 22.98 seconds\n",
      "Epoch [252/1500], Train Loss: 0.0192, Validation Loss: 0.0190, Time: 22.55 seconds\n",
      "Epoch [253/1500], Train Loss: 0.0199, Validation Loss: 0.0183, Time: 22.73 seconds\n",
      "Epoch [254/1500], Train Loss: 0.0199, Validation Loss: 0.0171, Time: 22.90 seconds\n",
      "Epoch [255/1500], Train Loss: 0.0190, Validation Loss: 0.0168, Time: 23.10 seconds\n",
      "Epoch [256/1500], Train Loss: 0.0190, Validation Loss: 0.0168, Time: 23.24 seconds\n",
      "Epoch [257/1500], Train Loss: 0.0185, Validation Loss: 0.0177, Time: 22.28 seconds\n",
      "Epoch [258/1500], Train Loss: 0.0186, Validation Loss: 0.0200, Time: 23.05 seconds\n",
      "Epoch [259/1500], Train Loss: 0.0186, Validation Loss: 0.0187, Time: 22.72 seconds\n",
      "Epoch [260/1500], Train Loss: 0.0201, Validation Loss: 0.0161, Time: 23.24 seconds\n",
      "Epoch [261/1500], Train Loss: 0.0181, Validation Loss: 0.0190, Time: 22.02 seconds\n",
      "Epoch [262/1500], Train Loss: 0.0186, Validation Loss: 0.0172, Time: 20.90 seconds\n",
      "Epoch [263/1500], Train Loss: 0.0186, Validation Loss: 0.0166, Time: 21.25 seconds\n",
      "Epoch [264/1500], Train Loss: 0.0188, Validation Loss: 0.0171, Time: 20.95 seconds\n",
      "Epoch [265/1500], Train Loss: 0.0200, Validation Loss: 0.0176, Time: 20.68 seconds\n",
      "Epoch [266/1500], Train Loss: 0.0202, Validation Loss: 0.0179, Time: 21.25 seconds\n",
      "Epoch [267/1500], Train Loss: 0.0200, Validation Loss: 0.0187, Time: 21.17 seconds\n",
      "Epoch [268/1500], Train Loss: 0.0189, Validation Loss: 0.0163, Time: 21.28 seconds\n",
      "Epoch [269/1500], Train Loss: 0.0196, Validation Loss: 0.0163, Time: 20.68 seconds\n",
      "Epoch [270/1500], Train Loss: 0.0199, Validation Loss: 0.0171, Time: 21.60 seconds\n",
      "Epoch [271/1500], Train Loss: 0.0204, Validation Loss: 0.0183, Time: 21.30 seconds\n",
      "Epoch [272/1500], Train Loss: 0.0188, Validation Loss: 0.0191, Time: 21.89 seconds\n",
      "Epoch [273/1500], Train Loss: 0.0183, Validation Loss: 0.0170, Time: 20.57 seconds\n",
      "Epoch [274/1500], Train Loss: 0.0196, Validation Loss: 0.0185, Time: 21.42 seconds\n",
      "Epoch [275/1500], Train Loss: 0.0190, Validation Loss: 0.0183, Time: 21.35 seconds\n",
      "Epoch [276/1500], Train Loss: 0.0189, Validation Loss: 0.0171, Time: 21.24 seconds\n",
      "Epoch [277/1500], Train Loss: 0.0185, Validation Loss: 0.0196, Time: 21.17 seconds\n",
      "Epoch [278/1500], Train Loss: 0.0185, Validation Loss: 0.0182, Time: 21.17 seconds\n",
      "Epoch [279/1500], Train Loss: 0.0195, Validation Loss: 0.0174, Time: 21.17 seconds\n",
      "Epoch [280/1500], Train Loss: 0.0179, Validation Loss: 0.0195, Time: 21.50 seconds\n",
      "Epoch [281/1500], Train Loss: 0.0207, Validation Loss: 0.0189, Time: 21.12 seconds\n",
      "Epoch [282/1500], Train Loss: 0.0193, Validation Loss: 0.0160, Time: 20.92 seconds\n",
      "Epoch [283/1500], Train Loss: 0.0190, Validation Loss: 0.0170, Time: 21.93 seconds\n",
      "Epoch [284/1500], Train Loss: 0.0198, Validation Loss: 0.0147, Time: 21.02 seconds\n",
      "Epoch [285/1500], Train Loss: 0.0187, Validation Loss: 0.0172, Time: 21.39 seconds\n",
      "Epoch [286/1500], Train Loss: 0.0181, Validation Loss: 0.0193, Time: 21.28 seconds\n",
      "Epoch [287/1500], Train Loss: 0.0199, Validation Loss: 0.0164, Time: 21.27 seconds\n",
      "Epoch [288/1500], Train Loss: 0.0186, Validation Loss: 0.0184, Time: 21.58 seconds\n",
      "Epoch [289/1500], Train Loss: 0.0188, Validation Loss: 0.0194, Time: 21.18 seconds\n",
      "Epoch [290/1500], Train Loss: 0.0185, Validation Loss: 0.0181, Time: 21.03 seconds\n",
      "Epoch [291/1500], Train Loss: 0.0190, Validation Loss: 0.0179, Time: 21.38 seconds\n",
      "Epoch [292/1500], Train Loss: 0.0179, Validation Loss: 0.0164, Time: 21.38 seconds\n",
      "Epoch [293/1500], Train Loss: 0.0189, Validation Loss: 0.0167, Time: 21.43 seconds\n",
      "Epoch [294/1500], Train Loss: 0.0191, Validation Loss: 0.0203, Time: 21.26 seconds\n",
      "Epoch [295/1500], Train Loss: 0.0190, Validation Loss: 0.0203, Time: 21.36 seconds\n",
      "Epoch [296/1500], Train Loss: 0.0189, Validation Loss: 0.0210, Time: 21.30 seconds\n",
      "Epoch [297/1500], Train Loss: 0.0196, Validation Loss: 0.0172, Time: 21.06 seconds\n",
      "Epoch [298/1500], Train Loss: 0.0190, Validation Loss: 0.0163, Time: 21.23 seconds\n",
      "Epoch [299/1500], Train Loss: 0.0194, Validation Loss: 0.0175, Time: 20.97 seconds\n",
      "Epoch [300/1500], Train Loss: 0.0195, Validation Loss: 0.0167, Time: 21.63 seconds\n",
      "Epoch [301/1500], Train Loss: 0.0196, Validation Loss: 0.0182, Time: 21.40 seconds\n",
      "Epoch [302/1500], Train Loss: 0.0200, Validation Loss: 0.0185, Time: 21.03 seconds\n",
      "Epoch [303/1500], Train Loss: 0.0191, Validation Loss: 0.0192, Time: 22.05 seconds\n",
      "Epoch [304/1500], Train Loss: 0.0186, Validation Loss: 0.0176, Time: 21.26 seconds\n",
      "Epoch [305/1500], Train Loss: 0.0191, Validation Loss: 0.0167, Time: 22.75 seconds\n",
      "Epoch [306/1500], Train Loss: 0.0192, Validation Loss: 0.0158, Time: 21.48 seconds\n",
      "Epoch [307/1500], Train Loss: 0.0196, Validation Loss: 0.0169, Time: 22.15 seconds\n",
      "Epoch [308/1500], Train Loss: 0.0195, Validation Loss: 0.0177, Time: 22.58 seconds\n",
      "Epoch [309/1500], Train Loss: 0.0183, Validation Loss: 0.0201, Time: 22.68 seconds\n",
      "Epoch [310/1500], Train Loss: 0.0190, Validation Loss: 0.0183, Time: 22.80 seconds\n",
      "Epoch [311/1500], Train Loss: 0.0202, Validation Loss: 0.0172, Time: 22.75 seconds\n",
      "Epoch [312/1500], Train Loss: 0.0189, Validation Loss: 0.0201, Time: 22.78 seconds\n",
      "Epoch [313/1500], Train Loss: 0.0207, Validation Loss: 0.0189, Time: 22.97 seconds\n",
      "Epoch [314/1500], Train Loss: 0.0189, Validation Loss: 0.0179, Time: 22.63 seconds\n",
      "Epoch [315/1500], Train Loss: 0.0197, Validation Loss: 0.0166, Time: 22.93 seconds\n",
      "Epoch [316/1500], Train Loss: 0.0182, Validation Loss: 0.0170, Time: 22.98 seconds\n",
      "Epoch [317/1500], Train Loss: 0.0196, Validation Loss: 0.0171, Time: 23.23 seconds\n",
      "Epoch [318/1500], Train Loss: 0.0186, Validation Loss: 0.0170, Time: 21.50 seconds\n",
      "Epoch [319/1500], Train Loss: 0.0197, Validation Loss: 0.0187, Time: 23.47 seconds\n",
      "Epoch [320/1500], Train Loss: 0.0182, Validation Loss: 0.0166, Time: 23.55 seconds\n",
      "Epoch [321/1500], Train Loss: 0.0188, Validation Loss: 0.0163, Time: 23.47 seconds\n",
      "Epoch [322/1500], Train Loss: 0.0190, Validation Loss: 0.0165, Time: 23.10 seconds\n",
      "Epoch [323/1500], Train Loss: 0.0191, Validation Loss: 0.0163, Time: 23.24 seconds\n",
      "Epoch [324/1500], Train Loss: 0.0188, Validation Loss: 0.0187, Time: 23.35 seconds\n",
      "Epoch [325/1500], Train Loss: 0.0197, Validation Loss: 0.0151, Time: 24.20 seconds\n",
      "Epoch [326/1500], Train Loss: 0.0183, Validation Loss: 0.0188, Time: 23.69 seconds\n",
      "Epoch [327/1500], Train Loss: 0.0187, Validation Loss: 0.0171, Time: 23.48 seconds\n",
      "Epoch [328/1500], Train Loss: 0.0189, Validation Loss: 0.0186, Time: 24.11 seconds\n",
      "Epoch [329/1500], Train Loss: 0.0196, Validation Loss: 0.0189, Time: 24.72 seconds\n",
      "Epoch [330/1500], Train Loss: 0.0191, Validation Loss: 0.0166, Time: 24.85 seconds\n",
      "Epoch [331/1500], Train Loss: 0.0200, Validation Loss: 0.0190, Time: 24.56 seconds\n",
      "Epoch [332/1500], Train Loss: 0.0192, Validation Loss: 0.0182, Time: 24.37 seconds\n",
      "Epoch [333/1500], Train Loss: 0.0206, Validation Loss: 0.0194, Time: 24.47 seconds\n",
      "Epoch [334/1500], Train Loss: 0.0201, Validation Loss: 0.0192, Time: 24.55 seconds\n",
      "Epoch [335/1500], Train Loss: 0.0202, Validation Loss: 0.0190, Time: 24.10 seconds\n",
      "Epoch [336/1500], Train Loss: 0.0189, Validation Loss: 0.0153, Time: 24.49 seconds\n",
      "Epoch [337/1500], Train Loss: 0.0189, Validation Loss: 0.0182, Time: 24.52 seconds\n",
      "Epoch [338/1500], Train Loss: 0.0201, Validation Loss: 0.0176, Time: 24.22 seconds\n",
      "Epoch [339/1500], Train Loss: 0.0189, Validation Loss: 0.0203, Time: 23.02 seconds\n",
      "Epoch [340/1500], Train Loss: 0.0208, Validation Loss: 0.0175, Time: 22.90 seconds\n",
      "Epoch [341/1500], Train Loss: 0.0191, Validation Loss: 0.0186, Time: 21.92 seconds\n",
      "Epoch [342/1500], Train Loss: 0.0195, Validation Loss: 0.0192, Time: 21.00 seconds\n",
      "Epoch [343/1500], Train Loss: 0.0195, Validation Loss: 0.0171, Time: 21.95 seconds\n",
      "Epoch [344/1500], Train Loss: 0.0186, Validation Loss: 0.0182, Time: 22.56 seconds\n",
      "Epoch [345/1500], Train Loss: 0.0197, Validation Loss: 0.0162, Time: 22.88 seconds\n",
      "Epoch [346/1500], Train Loss: 0.0205, Validation Loss: 0.0184, Time: 22.79 seconds\n",
      "Epoch [347/1500], Train Loss: 0.0195, Validation Loss: 0.0175, Time: 21.90 seconds\n",
      "Epoch [348/1500], Train Loss: 0.0202, Validation Loss: 0.0179, Time: 22.65 seconds\n",
      "Epoch [349/1500], Train Loss: 0.0207, Validation Loss: 0.0177, Time: 22.42 seconds\n",
      "Epoch [350/1500], Train Loss: 0.0200, Validation Loss: 0.0206, Time: 22.75 seconds\n",
      "Epoch [351/1500], Train Loss: 0.0197, Validation Loss: 0.0185, Time: 22.64 seconds\n",
      "Epoch [352/1500], Train Loss: 0.0198, Validation Loss: 0.0173, Time: 22.70 seconds\n",
      "Epoch [353/1500], Train Loss: 0.0199, Validation Loss: 0.0186, Time: 23.60 seconds\n",
      "Epoch [354/1500], Train Loss: 0.0201, Validation Loss: 0.0203, Time: 24.14 seconds\n",
      "Epoch [355/1500], Train Loss: 0.0199, Validation Loss: 0.0159, Time: 24.02 seconds\n",
      "Epoch [356/1500], Train Loss: 0.0189, Validation Loss: 0.0160, Time: 24.37 seconds\n",
      "Epoch [357/1500], Train Loss: 0.0194, Validation Loss: 0.0186, Time: 24.21 seconds\n",
      "Epoch [358/1500], Train Loss: 0.0186, Validation Loss: 0.0170, Time: 24.27 seconds\n",
      "Epoch [359/1500], Train Loss: 0.0205, Validation Loss: 0.0177, Time: 23.99 seconds\n",
      "Epoch [360/1500], Train Loss: 0.0194, Validation Loss: 0.0184, Time: 23.85 seconds\n",
      "Epoch [361/1500], Train Loss: 0.0197, Validation Loss: 0.0194, Time: 24.17 seconds\n",
      "Epoch [362/1500], Train Loss: 0.0197, Validation Loss: 0.0150, Time: 23.97 seconds\n",
      "Epoch [363/1500], Train Loss: 0.0206, Validation Loss: 0.0154, Time: 24.50 seconds\n",
      "Epoch [364/1500], Train Loss: 0.0204, Validation Loss: 0.0181, Time: 24.50 seconds\n",
      "Epoch [365/1500], Train Loss: 0.0201, Validation Loss: 0.0170, Time: 24.68 seconds\n",
      "Epoch [366/1500], Train Loss: 0.0201, Validation Loss: 0.0184, Time: 24.56 seconds\n",
      "Epoch [367/1500], Train Loss: 0.0192, Validation Loss: 0.0181, Time: 24.13 seconds\n",
      "Epoch [368/1500], Train Loss: 0.0195, Validation Loss: 0.0165, Time: 24.47 seconds\n",
      "Epoch [369/1500], Train Loss: 0.0192, Validation Loss: 0.0196, Time: 24.30 seconds\n",
      "Epoch [370/1500], Train Loss: 0.0200, Validation Loss: 0.0172, Time: 24.57 seconds\n",
      "Epoch [371/1500], Train Loss: 0.0192, Validation Loss: 0.0191, Time: 24.45 seconds\n",
      "Epoch [372/1500], Train Loss: 0.0194, Validation Loss: 0.0180, Time: 22.62 seconds\n",
      "Epoch [373/1500], Train Loss: 0.0190, Validation Loss: 0.0164, Time: 23.79 seconds\n",
      "Epoch [374/1500], Train Loss: 0.0200, Validation Loss: 0.0195, Time: 23.50 seconds\n",
      "Epoch [375/1500], Train Loss: 0.0187, Validation Loss: 0.0183, Time: 22.87 seconds\n",
      "Epoch [376/1500], Train Loss: 0.0190, Validation Loss: 0.0172, Time: 22.38 seconds\n",
      "Epoch [377/1500], Train Loss: 0.0196, Validation Loss: 0.0176, Time: 22.35 seconds\n",
      "Epoch [378/1500], Train Loss: 0.0206, Validation Loss: 0.0191, Time: 22.63 seconds\n",
      "Epoch [379/1500], Train Loss: 0.0188, Validation Loss: 0.0205, Time: 22.69 seconds\n",
      "Epoch [380/1500], Train Loss: 0.0208, Validation Loss: 0.0194, Time: 22.47 seconds\n",
      "Epoch [381/1500], Train Loss: 0.0189, Validation Loss: 0.0176, Time: 22.67 seconds\n",
      "Epoch [382/1500], Train Loss: 0.0213, Validation Loss: 0.0173, Time: 22.46 seconds\n",
      "Epoch [383/1500], Train Loss: 0.0183, Validation Loss: 0.0186, Time: 23.04 seconds\n",
      "Epoch [384/1500], Train Loss: 0.0191, Validation Loss: 0.0190, Time: 22.89 seconds\n",
      "Epoch [385/1500], Train Loss: 0.0191, Validation Loss: 0.0174, Time: 22.97 seconds\n",
      "Epoch [386/1500], Train Loss: 0.0193, Validation Loss: 0.0188, Time: 22.76 seconds\n",
      "Epoch [387/1500], Train Loss: 0.0189, Validation Loss: 0.0165, Time: 22.82 seconds\n",
      "Epoch [388/1500], Train Loss: 0.0172, Validation Loss: 0.0196, Time: 22.54 seconds\n",
      "Epoch [389/1500], Train Loss: 0.0182, Validation Loss: 0.0184, Time: 22.69 seconds\n",
      "Epoch [390/1500], Train Loss: 0.0192, Validation Loss: 0.0155, Time: 22.76 seconds\n",
      "Epoch [391/1500], Train Loss: 0.0196, Validation Loss: 0.0177, Time: 23.22 seconds\n",
      "Epoch [392/1500], Train Loss: 0.0189, Validation Loss: 0.0202, Time: 22.67 seconds\n",
      "Epoch [393/1500], Train Loss: 0.0192, Validation Loss: 0.0180, Time: 22.54 seconds\n",
      "Epoch [394/1500], Train Loss: 0.0183, Validation Loss: 0.0184, Time: 22.52 seconds\n",
      "Epoch [395/1500], Train Loss: 0.0180, Validation Loss: 0.0172, Time: 22.42 seconds\n",
      "Epoch [396/1500], Train Loss: 0.0185, Validation Loss: 0.0166, Time: 23.02 seconds\n",
      "Epoch [397/1500], Train Loss: 0.0197, Validation Loss: 0.0177, Time: 22.42 seconds\n",
      "Epoch [398/1500], Train Loss: 0.0197, Validation Loss: 0.0197, Time: 22.64 seconds\n",
      "Epoch [399/1500], Train Loss: 0.0193, Validation Loss: 0.0185, Time: 23.16 seconds\n",
      "Epoch [400/1500], Train Loss: 0.0195, Validation Loss: 0.0177, Time: 24.39 seconds\n",
      "Epoch [401/1500], Train Loss: 0.0192, Validation Loss: 0.0185, Time: 24.22 seconds\n",
      "Epoch [402/1500], Train Loss: 0.0189, Validation Loss: 0.0171, Time: 24.59 seconds\n",
      "Epoch [403/1500], Train Loss: 0.0192, Validation Loss: 0.0180, Time: 24.09 seconds\n",
      "Epoch [404/1500], Train Loss: 0.0185, Validation Loss: 0.0186, Time: 24.30 seconds\n",
      "Epoch [405/1500], Train Loss: 0.0191, Validation Loss: 0.0161, Time: 23.99 seconds\n",
      "Epoch [406/1500], Train Loss: 0.0199, Validation Loss: 0.0172, Time: 23.82 seconds\n",
      "Epoch [407/1500], Train Loss: 0.0187, Validation Loss: 0.0178, Time: 24.25 seconds\n",
      "Epoch [408/1500], Train Loss: 0.0198, Validation Loss: 0.0184, Time: 24.18 seconds\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[16], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m modi \u001b[38;5;241m=\u001b[39m modi\u001b[38;5;241m.\u001b[39mto(device)  \u001b[38;5;66;03m# Move the model to the same device as your data (if using GPU)\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;66;03m# Continue training for 1500 epochs\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m train_losses, val_losses \u001b[38;5;241m=\u001b[39m \u001b[43mtrain_and_validate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcriterion\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1500\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[15], line 11\u001b[0m, in \u001b[0;36mtrain_and_validate\u001b[1;34m(modi, train_loader, val_loader, optimizer, criterion, num_epochs)\u001b[0m\n\u001b[0;32m      9\u001b[0m modi\u001b[38;5;241m.\u001b[39mtrain()\n\u001b[0;32m     10\u001b[0m train_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m\n\u001b[1;32m---> 11\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minput_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_images\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m     12\u001b[0m \u001b[43m    \u001b[49m\u001b[43minput_images\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_images\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43minput_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_images\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\k54739\\.conda\\envs\\master\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    627\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sampler_iter \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    628\u001b[0m     \u001b[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    629\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_reset()  \u001b[38;5;66;03m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 630\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_next_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    631\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m    632\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dataset_kind \u001b[38;5;241m==\u001b[39m _DatasetKind\u001b[38;5;241m.\u001b[39mIterable \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    633\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \\\n\u001b[0;32m    634\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_num_yielded \u001b[38;5;241m>\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\k54739\\.conda\\envs\\master\\Lib\\site-packages\\torch\\utils\\data\\dataloader.py:673\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_next_data\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[0;32m    672\u001b[0m     index \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_next_index()  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 673\u001b[0m     data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dataset_fetcher\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfetch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mindex\u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    674\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory:\n\u001b[0;32m    675\u001b[0m         data \u001b[38;5;241m=\u001b[39m _utils\u001b[38;5;241m.\u001b[39mpin_memory\u001b[38;5;241m.\u001b[39mpin_memory(data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\k54739\\.conda\\envs\\master\\Lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:50\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mauto_collation:\n\u001b[0;32m     49\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m__getitems__\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__:\n\u001b[1;32m---> 50\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m__getitems__\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpossibly_batched_index\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     51\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     52\u001b[0m         data \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\k54739\\.conda\\envs\\master\\Lib\\site-packages\\torch\\utils\\data\\dataset.py:420\u001b[0m, in \u001b[0;36mSubset.__getitems__\u001b[1;34m(self, indices)\u001b[0m\n\u001b[0;32m    418\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdataset\u001b[38;5;241m.\u001b[39m__getitems__([\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindices[idx] \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices])  \u001b[38;5;66;03m# type: ignore[attr-defined]\u001b[39;00m\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 420\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdataset\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mindices\u001b[49m\u001b[43m[\u001b[49m\u001b[43midx\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m idx \u001b[38;5;129;01min\u001b[39;00m indices]\n",
      "Cell \u001b[1;32mIn[4], line 45\u001b[0m, in \u001b[0;36mImageDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     43\u001b[0m \u001b[38;5;66;03m# RandomVerticalFlip\u001b[39;00m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mrand(\u001b[38;5;241m1\u001b[39m) \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0.5\u001b[39m:\n\u001b[1;32m---> 45\u001b[0m     day7_img \u001b[38;5;241m=\u001b[39m \u001b[43mFunc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvflip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mday7_img\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     46\u001b[0m     day10_img \u001b[38;5;241m=\u001b[39m Func\u001b[38;5;241m.\u001b[39mvflip(day10_img)\n\u001b[0;32m     48\u001b[0m \u001b[38;5;66;03m# RandomRotation\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\k54739\\.conda\\envs\\master\\Lib\\site-packages\\torchvision\\transforms\\functional.py:774\u001b[0m, in \u001b[0;36mvflip\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(img, torch\u001b[38;5;241m.\u001b[39mTensor):\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F_pil\u001b[38;5;241m.\u001b[39mvflip(img)\n\u001b[1;32m--> 774\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF_t\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvflip\u001b[49m\u001b[43m(\u001b[49m\u001b[43mimg\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\k54739\\.conda\\envs\\master\\Lib\\site-packages\\torchvision\\transforms\\_functional_tensor.py:119\u001b[0m, in \u001b[0;36mvflip\u001b[1;34m(img)\u001b[0m\n\u001b[0;32m    116\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mvflip\u001b[39m(img: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m    117\u001b[0m     _assert_image_tensor(img)\n\u001b[1;32m--> 119\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflip\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m2\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Continue training for 1500 epochs\n",
    "train_losses, val_losses = train_and_validate(modi, train_loader, val_loader, optimizer, criterion, num_epochs=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the updated model parameters after continued training\n",
    "torch.save(modi.state_dict(), 'modi_time_pred_2000.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#check for whether pairing day7 with day 10 is working properly "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_D07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_D07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_D08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_D08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_D09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_D09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_D10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_D10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_D11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_D11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_E07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_E07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_E08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_E08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_E09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_E09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_E10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_E10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_E11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_E11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_F07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_F07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_F08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_F08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_F09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_F09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_F10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_F10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_F11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_F11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_G07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_G07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_G08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_G08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_G09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_G09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_G10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_G10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS1B_G11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS1B_G11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_D07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_D07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_D08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_D08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_D09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_D09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_D10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_D10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_D11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_D11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_E07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_E07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_E08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_E08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_E09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_E09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_E10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_E10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_E11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_E11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_F07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_F07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_F08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_F08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_F09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_F09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_F10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_F10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_F11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_F11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_G07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_G07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_G08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_G08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_G09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_G09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_G10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_G10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_4.2_G11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_4.2_G11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_D07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_D07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_D08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_D08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_D09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_D09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_D10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_D10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_D11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_D11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_E07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_E07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_E08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_E08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_E09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_E09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_E10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_E10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_E11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_E11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_F07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_F07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_F08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_F08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_F09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_F09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_F10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_F10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_F11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_F11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_G07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_G07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_G08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_G08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_G09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_G09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_G10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_G10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.1_G11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.1_G11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_D07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_D07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_D08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_D08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_D09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_D09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_D10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_D10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_D11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_D11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_E07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_E07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_E08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_E08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_E09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_E09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_E10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_E10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_E11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_E11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_F07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_F07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_F08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_F08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_F09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_F09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_F10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_F10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_F11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_F11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_G07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_G07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_G08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_G08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_G09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_G09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_G10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_G10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBTDS_6.2_G11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBTDS_6.2_G11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_B02-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_B02-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_B03-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_B03-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_B04-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_B04-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_B05-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_B05-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_B06-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_B06-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_C02-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_C02-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_C03-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_C03-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_C04-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_C04-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_C05-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_C05-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_C06-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_C06-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_D02-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_D02-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_D03-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_D03-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_D04-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_D04-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_D05-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_D05-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_D06-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_D06-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_E02-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_E02-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_E03-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_E03-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_E04-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_E04-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_E05-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_E05-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_E06-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_E06-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_F02-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_F02-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_F03-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_F03-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_F04-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_F04-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_F05-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_F05-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_F06-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_F06-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_G02-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_G02-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_G03-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_G03-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_G04-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_G04-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_G05-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_G05-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_01.04_G06-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_01.04_G06-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_D07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_D07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_D08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_D08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_D09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_D09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_D10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_D10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_D11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_D11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_E07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_E07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_E08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_E08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_E09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_E09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_E10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_E10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_E11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_E11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_F07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_F07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_F08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_F08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_F09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_F09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_F10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_F10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_F11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_F11-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_G07-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_G07-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_G08-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_G08-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_G09-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_G09-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_G10-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_G10-T01.tiff\n",
      "Day7: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7\\RBT_DS_4.1_G11-T01.tiff | Day10: C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10\\RBT_DS_4.1_G11-T01.tiff\n",
      "\n",
      "Total number of paired images: 130\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "class ImagePairingChecker:\n",
    "    def __init__(self, day7_dir, day10_dir):\n",
    "        self.day7_files = {os.path.basename(file): os.path.join(day7_dir, file) for file in os.listdir(day7_dir) if file.endswith('.tiff')}\n",
    "        self.day10_files = {os.path.basename(file): os.path.join(day10_dir, file) for file in os.listdir(day10_dir) if file.endswith('.tiff')}\n",
    "\n",
    "        # Ensure all day7 files have a corresponding day10 file\n",
    "        self.common_files = list(self.day7_files.keys())\n",
    "        assert set(self.common_files) <= set(self.day10_files.keys()), \"Mismatch between day7 and day10 filenames.\"\n",
    "\n",
    "    def print_paired_paths(self):\n",
    "        for filename in self.common_files:\n",
    "            day7_img_path = self.day7_files[filename]\n",
    "            day10_img_path = self.day10_files[filename]\n",
    "            print(f\"Day7: {day7_img_path} | Day10: {day10_img_path}\")\n",
    "        \n",
    "        # Print the total number of pairs\n",
    "        print(f\"\\nTotal number of paired images: {len(self.common_files)}\")\n",
    "\n",
    "\n",
    "# Example usage\n",
    "day7_dir = os.path.abspath(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day7')\n",
    "day10_dir = os.path.abspath(r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\control_day7_day10\\day10')\n",
    "\n",
    "\n",
    "pairing_checker = ImagePairingChecker(day7_dir, day10_dir)\n",
    "pairing_checker.print_paired_paths()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
