{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import random\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded Day 7 Features Shape: torch.Size([780, 512])\n",
      "Loaded Day 10 Features Shape: torch.Size([780, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_16800\\4239754175.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_day7_feats = torch.load('combined_con_d7.pt')\n",
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_16800\\4239754175.py:5: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  loaded_day10_feats = torch.load('combined_con_d10.pt')\n"
     ]
    }
   ],
   "source": [
    "# Load the saved day 7 features\n",
    "loaded_day7_feats = torch.load('combined_con_d7.pt')\n",
    "\n",
    "# Load the saved day 10 features\n",
    "loaded_day10_feats = torch.load('combined_con_d10.pt')\n",
    "\n",
    "# Verify the shapes\n",
    "print(f\"Loaded Day 7 Features Shape: {loaded_day7_feats.shape}\")\n",
    "print(f\"Loaded Day 10 Features Shape: {loaded_day10_feats.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_day7_feats = loaded_day7_feats \n",
    "train_day10_feats = loaded_day10_feats "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input (X): Mean=0.9252, Std=1.1999\n",
      "Target (Y): Mean=0.9463, Std=1.2446\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plot histograms for input (X) and target (Y)\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Flatten tensors to 1D for easier visualization\n",
    "train_day7_feats_flat = train_day7_feats.flatten().cpu().numpy()\n",
    "train_day10_feats_flat = train_day10_feats.flatten().cpu().numpy()\n",
    "\n",
    "# Input (X) histogram\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(train_day7_feats_flat, bins=50, color='blue', alpha=0.7, label='Input (X)')\n",
    "plt.title('Distribution of Input (X)')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Target (Y) histogram\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(train_day10_feats_flat, bins=50, color='green', alpha=0.7, label='Target (Y)')\n",
    "plt.title('Distribution of Target (Y)')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Print summary statistics\n",
    "print(f\"Input (X): Mean={train_day7_feats.mean():.4f}, Std={train_day7_feats.std():.4f}\")\n",
    "print(f\"Target (Y): Mean={train_day10_feats.mean():.4f}, Std={train_day10_feats.std():.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After Min-Max Scaling:\n",
      "Input (X): Min=0.0000, Max=1.0000\n",
      "Target (Y): Min=0.0000, Max=1.0000\n"
     ]
    }
   ],
   "source": [
    "# Min-Max Scaling for Input (X) and Target (Y)\n",
    "def min_max_scaling(data):\n",
    "    data_min = data.min()\n",
    "    data_max = data.max()\n",
    "    return (data - data_min) / (data_max - data_min), data_min, data_max  # Return scaled data and min/max for inverse scaling\n",
    "\n",
    "# Apply Min-Max Scaling\n",
    "train_day7_feats_minmaxed, day7_min, day7_max = min_max_scaling(train_day7_feats)\n",
    "train_day10_feats_minmaxed, day10_min, day10_max = min_max_scaling(train_day10_feats)\n",
    "\n",
    "# Print summary to confirm\n",
    "print(\"After Min-Max Scaling:\")\n",
    "print(f\"Input (X): Min={train_day7_feats_minmaxed.min():.4f}, Max={train_day7_feats_minmaxed.max():.4f}\")\n",
    "print(f\"Target (Y): Min={train_day10_feats_minmaxed.min():.4f}, Max={train_day10_feats_minmaxed.max():.4f}\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1200x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Flatten the tensors for easier visualization\n",
    "train_day7_feats_minmaxed_flat = train_day7_feats_minmaxed.flatten().cpu().numpy()\n",
    "train_day10_feats_minmaxed_flat = train_day10_feats_minmaxed.flatten().cpu().numpy()\n",
    "\n",
    "# Plot histograms\n",
    "plt.figure(figsize=(12, 6))\n",
    "\n",
    "# Input (X) histogram after Min-Max scaling\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.hist(train_day7_feats_minmaxed_flat, bins=50, color='blue', alpha=0.7, label='Min-Max Scaled Input (X)')\n",
    "plt.title('Min-Max Scaled Distribution of Input (X)')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "# Target (Y) histogram after Min-Max scaling\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.hist(train_day10_feats_minmaxed_flat, bins=50, color='green', alpha=0.7, label='Min-Max Scaled Target (Y)')\n",
    "plt.title('Min-Max Scaled Distribution of Target (Y)')\n",
    "plt.xlabel('Value')\n",
    "plt.ylabel('Frequency')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "class FeaturePredictor(nn.Module):\n",
    "    def __init__(self, input_size=512, output_size=512):\n",
    "        super(FeaturePredictor, self).__init__()\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,8),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(8, 16),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(16,32),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(32, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128,256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, output_size)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = FeaturePredictor()\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=1e-4)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, Subset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "optimizer_class = torch.optim.Adam\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import KFold\n",
    "from torch.utils.data import DataLoader, Subset\n",
    "import numpy as np\n",
    "import torch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class EarlyStopping:\n",
    "    def __init__(self, patience=10, delta=0.0):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            patience (int): How many epochs to wait after the last validation loss improvement.\n",
    "            delta (float): Minimum change in the validation loss to qualify as an improvement.\n",
    "        \"\"\"\n",
    "        self.patience = patience\n",
    "        self.delta = delta\n",
    "        self.best_loss = None\n",
    "        self.no_improvement_epochs = 0\n",
    "        self.early_stop = False\n",
    "\n",
    "    def __call__(self, val_loss):\n",
    "        if self.best_loss is None or val_loss < self.best_loss - self.delta:\n",
    "            self.best_loss = val_loss\n",
    "            self.no_improvement_epochs = 0\n",
    "        else:\n",
    "            self.no_improvement_epochs += 1\n",
    "            if self.no_improvement_epochs >= self.patience:\n",
    "                self.early_stop = True\n",
    "\n",
    "\n",
    "def cross_validate_with_early_stopping(\n",
    "    model_class, dataset, criterion, optimizer_class, num_epochs=50, n_splits=5, patience=10, device='cuda'\n",
    "):\n",
    "    kfold = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "    histories = []\n",
    "    best_models = []\n",
    "\n",
    "    for fold, (train_idx, val_idx) in enumerate(kfold.split(dataset)):\n",
    "        print(f\"Fold {fold + 1}/{n_splits}\")\n",
    "\n",
    "        # Create subsets for this fold\n",
    "        train_subset = Subset(dataset, train_idx)\n",
    "        val_subset = Subset(dataset, val_idx)\n",
    "\n",
    "        # Create DataLoaders\n",
    "        train_loader = DataLoader(train_subset, batch_size=32, shuffle=True)\n",
    "        val_loader = DataLoader(val_subset, batch_size=32, shuffle=False)\n",
    "\n",
    "        # Initialize the model, optimizer, and early stopping for this fold\n",
    "        model = model_class().to(device)\n",
    "        optimizer = optimizer_class(model.parameters(), lr=1e-4)\n",
    "        early_stopping = EarlyStopping(patience=patience)\n",
    "\n",
    "        # Training and validation loop\n",
    "        history = {'train_loss': [], 'val_loss': []}\n",
    "        for epoch in range(num_epochs):\n",
    "            # Training phase\n",
    "            model.train()\n",
    "            train_loss = 0.0\n",
    "            for batch_inputs, batch_targets in train_loader:\n",
    "                batch_inputs, batch_targets = batch_inputs.to(device), batch_targets.to(device)\n",
    "\n",
    "                # Forward pass\n",
    "                outputs = model(batch_inputs)\n",
    "                loss = criterion(outputs, batch_targets)\n",
    "                train_loss += loss.item()\n",
    "\n",
    "                # Backward pass and optimize\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "\n",
    "            train_loss /= len(train_loader)\n",
    "            history['train_loss'].append(train_loss)\n",
    "\n",
    "            # Validation phase\n",
    "            model.eval()\n",
    "            val_loss = 0.0\n",
    "            with torch.no_grad():\n",
    "                for batch_inputs, batch_targets in val_loader:\n",
    "                    batch_inputs, batch_targets = batch_inputs.to(device), batch_targets.to(device)\n",
    "                    outputs = model(batch_inputs)\n",
    "                    loss = criterion(outputs, batch_targets)\n",
    "                    val_loss += loss.item()\n",
    "\n",
    "            val_loss /= len(val_loader)\n",
    "            history['val_loss'].append(val_loss)\n",
    "\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}] Fold {fold + 1}, Train Loss: {train_loss:.4f}, Val Loss: {val_loss:.4f}\")\n",
    "\n",
    "            # Check early stopping\n",
    "            early_stopping(val_loss)\n",
    "            if early_stopping.early_stop:\n",
    "                print(f\"Early stopping at epoch {epoch + 1} for fold {fold + 1}\")\n",
    "                break\n",
    "\n",
    "        # Save the best model for this fold\n",
    "        best_models.append(model.state_dict())\n",
    "        histories.append(history)\n",
    "\n",
    "    return histories, best_models\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1/5\n",
      "Epoch [1/2000] Fold 1, Train Loss: 0.0264, Val Loss: 0.0241\n",
      "Epoch [2/2000] Fold 1, Train Loss: 0.0226, Val Loss: 0.0206\n",
      "Epoch [3/2000] Fold 1, Train Loss: 0.0191, Val Loss: 0.0172\n",
      "Epoch [4/2000] Fold 1, Train Loss: 0.0162, Val Loss: 0.0150\n",
      "Epoch [5/2000] Fold 1, Train Loss: 0.0146, Val Loss: 0.0140\n",
      "Epoch [6/2000] Fold 1, Train Loss: 0.0139, Val Loss: 0.0137\n",
      "Epoch [7/2000] Fold 1, Train Loss: 0.0137, Val Loss: 0.0136\n",
      "Epoch [8/2000] Fold 1, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [9/2000] Fold 1, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [10/2000] Fold 1, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [11/2000] Fold 1, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [12/2000] Fold 1, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [13/2000] Fold 1, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [14/2000] Fold 1, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [15/2000] Fold 1, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [16/2000] Fold 1, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [17/2000] Fold 1, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [18/2000] Fold 1, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [19/2000] Fold 1, Train Loss: 0.0135, Val Loss: 0.0134\n",
      "Epoch [20/2000] Fold 1, Train Loss: 0.0134, Val Loss: 0.0130\n",
      "Epoch [21/2000] Fold 1, Train Loss: 0.0128, Val Loss: 0.0122\n",
      "Epoch [22/2000] Fold 1, Train Loss: 0.0119, Val Loss: 0.0110\n",
      "Epoch [23/2000] Fold 1, Train Loss: 0.0109, Val Loss: 0.0102\n",
      "Epoch [24/2000] Fold 1, Train Loss: 0.0103, Val Loss: 0.0100\n",
      "Epoch [25/2000] Fold 1, Train Loss: 0.0101, Val Loss: 0.0099\n",
      "Epoch [26/2000] Fold 1, Train Loss: 0.0099, Val Loss: 0.0097\n",
      "Epoch [27/2000] Fold 1, Train Loss: 0.0098, Val Loss: 0.0096\n",
      "Epoch [28/2000] Fold 1, Train Loss: 0.0097, Val Loss: 0.0095\n",
      "Epoch [29/2000] Fold 1, Train Loss: 0.0095, Val Loss: 0.0094\n",
      "Epoch [30/2000] Fold 1, Train Loss: 0.0095, Val Loss: 0.0093\n",
      "Epoch [31/2000] Fold 1, Train Loss: 0.0093, Val Loss: 0.0093\n",
      "Epoch [32/2000] Fold 1, Train Loss: 0.0092, Val Loss: 0.0091\n",
      "Epoch [33/2000] Fold 1, Train Loss: 0.0090, Val Loss: 0.0089\n",
      "Epoch [34/2000] Fold 1, Train Loss: 0.0089, Val Loss: 0.0088\n",
      "Epoch [35/2000] Fold 1, Train Loss: 0.0088, Val Loss: 0.0088\n",
      "Epoch [36/2000] Fold 1, Train Loss: 0.0087, Val Loss: 0.0088\n",
      "Epoch [37/2000] Fold 1, Train Loss: 0.0087, Val Loss: 0.0087\n",
      "Epoch [38/2000] Fold 1, Train Loss: 0.0085, Val Loss: 0.0086\n",
      "Epoch [39/2000] Fold 1, Train Loss: 0.0085, Val Loss: 0.0086\n",
      "Epoch [40/2000] Fold 1, Train Loss: 0.0085, Val Loss: 0.0085\n",
      "Epoch [41/2000] Fold 1, Train Loss: 0.0084, Val Loss: 0.0085\n",
      "Epoch [42/2000] Fold 1, Train Loss: 0.0084, Val Loss: 0.0084\n",
      "Epoch [43/2000] Fold 1, Train Loss: 0.0084, Val Loss: 0.0084\n",
      "Epoch [44/2000] Fold 1, Train Loss: 0.0084, Val Loss: 0.0084\n",
      "Epoch [45/2000] Fold 1, Train Loss: 0.0083, Val Loss: 0.0084\n",
      "Epoch [46/2000] Fold 1, Train Loss: 0.0083, Val Loss: 0.0084\n",
      "Epoch [47/2000] Fold 1, Train Loss: 0.0083, Val Loss: 0.0083\n",
      "Epoch [48/2000] Fold 1, Train Loss: 0.0083, Val Loss: 0.0083\n",
      "Epoch [49/2000] Fold 1, Train Loss: 0.0082, Val Loss: 0.0083\n",
      "Epoch [50/2000] Fold 1, Train Loss: 0.0083, Val Loss: 0.0083\n",
      "Epoch [51/2000] Fold 1, Train Loss: 0.0082, Val Loss: 0.0082\n",
      "Epoch [52/2000] Fold 1, Train Loss: 0.0082, Val Loss: 0.0082\n",
      "Epoch [53/2000] Fold 1, Train Loss: 0.0081, Val Loss: 0.0082\n",
      "Epoch [54/2000] Fold 1, Train Loss: 0.0081, Val Loss: 0.0082\n",
      "Epoch [55/2000] Fold 1, Train Loss: 0.0081, Val Loss: 0.0081\n",
      "Epoch [56/2000] Fold 1, Train Loss: 0.0081, Val Loss: 0.0082\n",
      "Epoch [57/2000] Fold 1, Train Loss: 0.0081, Val Loss: 0.0082\n",
      "Epoch [58/2000] Fold 1, Train Loss: 0.0080, Val Loss: 0.0081\n",
      "Epoch [59/2000] Fold 1, Train Loss: 0.0080, Val Loss: 0.0081\n",
      "Epoch [60/2000] Fold 1, Train Loss: 0.0079, Val Loss: 0.0080\n",
      "Epoch [61/2000] Fold 1, Train Loss: 0.0080, Val Loss: 0.0080\n",
      "Epoch [62/2000] Fold 1, Train Loss: 0.0079, Val Loss: 0.0081\n",
      "Epoch [63/2000] Fold 1, Train Loss: 0.0079, Val Loss: 0.0080\n",
      "Epoch [64/2000] Fold 1, Train Loss: 0.0078, Val Loss: 0.0079\n",
      "Epoch [65/2000] Fold 1, Train Loss: 0.0078, Val Loss: 0.0079\n",
      "Epoch [66/2000] Fold 1, Train Loss: 0.0078, Val Loss: 0.0078\n",
      "Epoch [67/2000] Fold 1, Train Loss: 0.0077, Val Loss: 0.0078\n",
      "Epoch [68/2000] Fold 1, Train Loss: 0.0077, Val Loss: 0.0079\n",
      "Epoch [69/2000] Fold 1, Train Loss: 0.0077, Val Loss: 0.0078\n",
      "Epoch [70/2000] Fold 1, Train Loss: 0.0077, Val Loss: 0.0078\n",
      "Epoch [71/2000] Fold 1, Train Loss: 0.0076, Val Loss: 0.0078\n",
      "Epoch [72/2000] Fold 1, Train Loss: 0.0075, Val Loss: 0.0077\n",
      "Epoch [73/2000] Fold 1, Train Loss: 0.0075, Val Loss: 0.0077\n",
      "Epoch [74/2000] Fold 1, Train Loss: 0.0075, Val Loss: 0.0077\n",
      "Epoch [75/2000] Fold 1, Train Loss: 0.0075, Val Loss: 0.0077\n",
      "Epoch [76/2000] Fold 1, Train Loss: 0.0075, Val Loss: 0.0078\n",
      "Epoch [77/2000] Fold 1, Train Loss: 0.0075, Val Loss: 0.0077\n",
      "Epoch [78/2000] Fold 1, Train Loss: 0.0074, Val Loss: 0.0076\n",
      "Epoch [79/2000] Fold 1, Train Loss: 0.0074, Val Loss: 0.0076\n",
      "Epoch [80/2000] Fold 1, Train Loss: 0.0074, Val Loss: 0.0076\n",
      "Epoch [81/2000] Fold 1, Train Loss: 0.0074, Val Loss: 0.0075\n",
      "Epoch [82/2000] Fold 1, Train Loss: 0.0074, Val Loss: 0.0075\n",
      "Epoch [83/2000] Fold 1, Train Loss: 0.0073, Val Loss: 0.0075\n",
      "Epoch [84/2000] Fold 1, Train Loss: 0.0073, Val Loss: 0.0075\n",
      "Epoch [85/2000] Fold 1, Train Loss: 0.0073, Val Loss: 0.0075\n",
      "Epoch [86/2000] Fold 1, Train Loss: 0.0073, Val Loss: 0.0075\n",
      "Epoch [87/2000] Fold 1, Train Loss: 0.0072, Val Loss: 0.0074\n",
      "Epoch [88/2000] Fold 1, Train Loss: 0.0072, Val Loss: 0.0075\n",
      "Epoch [89/2000] Fold 1, Train Loss: 0.0072, Val Loss: 0.0075\n",
      "Epoch [90/2000] Fold 1, Train Loss: 0.0072, Val Loss: 0.0076\n",
      "Epoch [91/2000] Fold 1, Train Loss: 0.0072, Val Loss: 0.0074\n",
      "Epoch [92/2000] Fold 1, Train Loss: 0.0071, Val Loss: 0.0073\n",
      "Epoch [93/2000] Fold 1, Train Loss: 0.0071, Val Loss: 0.0073\n",
      "Epoch [94/2000] Fold 1, Train Loss: 0.0071, Val Loss: 0.0073\n",
      "Epoch [95/2000] Fold 1, Train Loss: 0.0071, Val Loss: 0.0073\n",
      "Epoch [96/2000] Fold 1, Train Loss: 0.0071, Val Loss: 0.0073\n",
      "Epoch [97/2000] Fold 1, Train Loss: 0.0070, Val Loss: 0.0073\n",
      "Epoch [98/2000] Fold 1, Train Loss: 0.0070, Val Loss: 0.0072\n",
      "Epoch [99/2000] Fold 1, Train Loss: 0.0070, Val Loss: 0.0072\n",
      "Epoch [100/2000] Fold 1, Train Loss: 0.0070, Val Loss: 0.0072\n",
      "Epoch [101/2000] Fold 1, Train Loss: 0.0069, Val Loss: 0.0072\n",
      "Epoch [102/2000] Fold 1, Train Loss: 0.0069, Val Loss: 0.0072\n",
      "Epoch [103/2000] Fold 1, Train Loss: 0.0069, Val Loss: 0.0072\n",
      "Epoch [104/2000] Fold 1, Train Loss: 0.0069, Val Loss: 0.0072\n",
      "Epoch [105/2000] Fold 1, Train Loss: 0.0068, Val Loss: 0.0072\n",
      "Epoch [106/2000] Fold 1, Train Loss: 0.0068, Val Loss: 0.0071\n",
      "Epoch [107/2000] Fold 1, Train Loss: 0.0069, Val Loss: 0.0071\n",
      "Epoch [108/2000] Fold 1, Train Loss: 0.0069, Val Loss: 0.0071\n",
      "Epoch [109/2000] Fold 1, Train Loss: 0.0068, Val Loss: 0.0070\n",
      "Epoch [110/2000] Fold 1, Train Loss: 0.0068, Val Loss: 0.0070\n",
      "Epoch [111/2000] Fold 1, Train Loss: 0.0067, Val Loss: 0.0070\n",
      "Epoch [112/2000] Fold 1, Train Loss: 0.0067, Val Loss: 0.0070\n",
      "Epoch [113/2000] Fold 1, Train Loss: 0.0067, Val Loss: 0.0071\n",
      "Epoch [114/2000] Fold 1, Train Loss: 0.0067, Val Loss: 0.0070\n",
      "Epoch [115/2000] Fold 1, Train Loss: 0.0067, Val Loss: 0.0070\n",
      "Epoch [116/2000] Fold 1, Train Loss: 0.0067, Val Loss: 0.0069\n",
      "Epoch [117/2000] Fold 1, Train Loss: 0.0067, Val Loss: 0.0070\n",
      "Epoch [118/2000] Fold 1, Train Loss: 0.0067, Val Loss: 0.0070\n",
      "Epoch [119/2000] Fold 1, Train Loss: 0.0066, Val Loss: 0.0069\n",
      "Epoch [120/2000] Fold 1, Train Loss: 0.0066, Val Loss: 0.0070\n",
      "Epoch [121/2000] Fold 1, Train Loss: 0.0066, Val Loss: 0.0070\n",
      "Epoch [122/2000] Fold 1, Train Loss: 0.0066, Val Loss: 0.0069\n",
      "Epoch [123/2000] Fold 1, Train Loss: 0.0066, Val Loss: 0.0069\n",
      "Epoch [124/2000] Fold 1, Train Loss: 0.0066, Val Loss: 0.0068\n",
      "Epoch [125/2000] Fold 1, Train Loss: 0.0066, Val Loss: 0.0069\n",
      "Epoch [126/2000] Fold 1, Train Loss: 0.0066, Val Loss: 0.0068\n",
      "Epoch [127/2000] Fold 1, Train Loss: 0.0065, Val Loss: 0.0069\n",
      "Epoch [128/2000] Fold 1, Train Loss: 0.0065, Val Loss: 0.0068\n",
      "Epoch [129/2000] Fold 1, Train Loss: 0.0065, Val Loss: 0.0069\n",
      "Epoch [130/2000] Fold 1, Train Loss: 0.0065, Val Loss: 0.0068\n",
      "Epoch [131/2000] Fold 1, Train Loss: 0.0065, Val Loss: 0.0068\n",
      "Epoch [132/2000] Fold 1, Train Loss: 0.0065, Val Loss: 0.0068\n",
      "Epoch [133/2000] Fold 1, Train Loss: 0.0065, Val Loss: 0.0068\n",
      "Epoch [134/2000] Fold 1, Train Loss: 0.0065, Val Loss: 0.0068\n",
      "Epoch [135/2000] Fold 1, Train Loss: 0.0065, Val Loss: 0.0068\n",
      "Epoch [136/2000] Fold 1, Train Loss: 0.0064, Val Loss: 0.0067\n",
      "Epoch [137/2000] Fold 1, Train Loss: 0.0064, Val Loss: 0.0068\n",
      "Epoch [138/2000] Fold 1, Train Loss: 0.0064, Val Loss: 0.0067\n",
      "Epoch [139/2000] Fold 1, Train Loss: 0.0064, Val Loss: 0.0067\n",
      "Epoch [140/2000] Fold 1, Train Loss: 0.0064, Val Loss: 0.0069\n",
      "Epoch [141/2000] Fold 1, Train Loss: 0.0064, Val Loss: 0.0068\n",
      "Epoch [142/2000] Fold 1, Train Loss: 0.0064, Val Loss: 0.0067\n",
      "Epoch [143/2000] Fold 1, Train Loss: 0.0064, Val Loss: 0.0068\n",
      "Epoch [144/2000] Fold 1, Train Loss: 0.0063, Val Loss: 0.0066\n",
      "Epoch [145/2000] Fold 1, Train Loss: 0.0062, Val Loss: 0.0067\n",
      "Epoch [146/2000] Fold 1, Train Loss: 0.0063, Val Loss: 0.0066\n",
      "Epoch [147/2000] Fold 1, Train Loss: 0.0062, Val Loss: 0.0066\n",
      "Epoch [148/2000] Fold 1, Train Loss: 0.0062, Val Loss: 0.0068\n",
      "Epoch [149/2000] Fold 1, Train Loss: 0.0062, Val Loss: 0.0066\n",
      "Epoch [150/2000] Fold 1, Train Loss: 0.0062, Val Loss: 0.0066\n",
      "Epoch [151/2000] Fold 1, Train Loss: 0.0062, Val Loss: 0.0066\n",
      "Epoch [152/2000] Fold 1, Train Loss: 0.0062, Val Loss: 0.0066\n",
      "Epoch [153/2000] Fold 1, Train Loss: 0.0062, Val Loss: 0.0066\n",
      "Epoch [154/2000] Fold 1, Train Loss: 0.0061, Val Loss: 0.0067\n",
      "Epoch [155/2000] Fold 1, Train Loss: 0.0061, Val Loss: 0.0065\n",
      "Epoch [156/2000] Fold 1, Train Loss: 0.0061, Val Loss: 0.0065\n",
      "Epoch [157/2000] Fold 1, Train Loss: 0.0061, Val Loss: 0.0066\n",
      "Epoch [158/2000] Fold 1, Train Loss: 0.0061, Val Loss: 0.0065\n",
      "Epoch [159/2000] Fold 1, Train Loss: 0.0061, Val Loss: 0.0065\n",
      "Epoch [160/2000] Fold 1, Train Loss: 0.0061, Val Loss: 0.0065\n",
      "Epoch [161/2000] Fold 1, Train Loss: 0.0061, Val Loss: 0.0065\n",
      "Epoch [162/2000] Fold 1, Train Loss: 0.0061, Val Loss: 0.0065\n",
      "Epoch [163/2000] Fold 1, Train Loss: 0.0060, Val Loss: 0.0065\n",
      "Epoch [164/2000] Fold 1, Train Loss: 0.0060, Val Loss: 0.0065\n",
      "Epoch [165/2000] Fold 1, Train Loss: 0.0060, Val Loss: 0.0064\n",
      "Epoch [166/2000] Fold 1, Train Loss: 0.0060, Val Loss: 0.0065\n",
      "Epoch [167/2000] Fold 1, Train Loss: 0.0060, Val Loss: 0.0064\n",
      "Epoch [168/2000] Fold 1, Train Loss: 0.0060, Val Loss: 0.0065\n",
      "Epoch [169/2000] Fold 1, Train Loss: 0.0060, Val Loss: 0.0065\n",
      "Epoch [170/2000] Fold 1, Train Loss: 0.0060, Val Loss: 0.0065\n",
      "Epoch [171/2000] Fold 1, Train Loss: 0.0059, Val Loss: 0.0064\n",
      "Epoch [172/2000] Fold 1, Train Loss: 0.0060, Val Loss: 0.0064\n",
      "Epoch [173/2000] Fold 1, Train Loss: 0.0059, Val Loss: 0.0064\n",
      "Epoch [174/2000] Fold 1, Train Loss: 0.0060, Val Loss: 0.0065\n",
      "Epoch [175/2000] Fold 1, Train Loss: 0.0059, Val Loss: 0.0064\n",
      "Epoch [176/2000] Fold 1, Train Loss: 0.0059, Val Loss: 0.0064\n",
      "Epoch [177/2000] Fold 1, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [178/2000] Fold 1, Train Loss: 0.0059, Val Loss: 0.0064\n",
      "Epoch [179/2000] Fold 1, Train Loss: 0.0059, Val Loss: 0.0064\n",
      "Epoch [180/2000] Fold 1, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [181/2000] Fold 1, Train Loss: 0.0059, Val Loss: 0.0064\n",
      "Epoch [182/2000] Fold 1, Train Loss: 0.0059, Val Loss: 0.0064\n",
      "Epoch [183/2000] Fold 1, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [184/2000] Fold 1, Train Loss: 0.0059, Val Loss: 0.0064\n",
      "Epoch [185/2000] Fold 1, Train Loss: 0.0058, Val Loss: 0.0063\n",
      "Epoch [186/2000] Fold 1, Train Loss: 0.0059, Val Loss: 0.0064\n",
      "Epoch [187/2000] Fold 1, Train Loss: 0.0059, Val Loss: 0.0064\n",
      "Epoch [188/2000] Fold 1, Train Loss: 0.0059, Val Loss: 0.0066\n",
      "Epoch [189/2000] Fold 1, Train Loss: 0.0059, Val Loss: 0.0063\n",
      "Epoch [190/2000] Fold 1, Train Loss: 0.0059, Val Loss: 0.0064\n",
      "Epoch [191/2000] Fold 1, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [192/2000] Fold 1, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [193/2000] Fold 1, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [194/2000] Fold 1, Train Loss: 0.0058, Val Loss: 0.0063\n",
      "Epoch [195/2000] Fold 1, Train Loss: 0.0058, Val Loss: 0.0063\n",
      "Epoch [196/2000] Fold 1, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [197/2000] Fold 1, Train Loss: 0.0058, Val Loss: 0.0063\n",
      "Epoch [198/2000] Fold 1, Train Loss: 0.0058, Val Loss: 0.0063\n",
      "Epoch [199/2000] Fold 1, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [200/2000] Fold 1, Train Loss: 0.0057, Val Loss: 0.0064\n",
      "Epoch [201/2000] Fold 1, Train Loss: 0.0057, Val Loss: 0.0063\n",
      "Epoch [202/2000] Fold 1, Train Loss: 0.0057, Val Loss: 0.0063\n",
      "Epoch [203/2000] Fold 1, Train Loss: 0.0057, Val Loss: 0.0063\n",
      "Epoch [204/2000] Fold 1, Train Loss: 0.0057, Val Loss: 0.0064\n",
      "Epoch [205/2000] Fold 1, Train Loss: 0.0057, Val Loss: 0.0064\n",
      "Epoch [206/2000] Fold 1, Train Loss: 0.0057, Val Loss: 0.0063\n",
      "Epoch [207/2000] Fold 1, Train Loss: 0.0057, Val Loss: 0.0063\n",
      "Epoch [208/2000] Fold 1, Train Loss: 0.0057, Val Loss: 0.0064\n",
      "Epoch [209/2000] Fold 1, Train Loss: 0.0057, Val Loss: 0.0065\n",
      "Epoch [210/2000] Fold 1, Train Loss: 0.0058, Val Loss: 0.0063\n",
      "Epoch [211/2000] Fold 1, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [212/2000] Fold 1, Train Loss: 0.0057, Val Loss: 0.0063\n",
      "Epoch [213/2000] Fold 1, Train Loss: 0.0057, Val Loss: 0.0063\n",
      "Epoch [214/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0064\n",
      "Epoch [215/2000] Fold 1, Train Loss: 0.0057, Val Loss: 0.0063\n",
      "Epoch [216/2000] Fold 1, Train Loss: 0.0057, Val Loss: 0.0063\n",
      "Epoch [217/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0063\n",
      "Epoch [218/2000] Fold 1, Train Loss: 0.0057, Val Loss: 0.0063\n",
      "Epoch [219/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0063\n",
      "Epoch [220/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0064\n",
      "Epoch [221/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0063\n",
      "Epoch [222/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0063\n",
      "Epoch [223/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0063\n",
      "Epoch [224/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0062\n",
      "Epoch [225/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0063\n",
      "Epoch [226/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0062\n",
      "Epoch [227/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0063\n",
      "Epoch [228/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0062\n",
      "Epoch [229/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0062\n",
      "Epoch [230/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0063\n",
      "Epoch [231/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0063\n",
      "Epoch [232/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0061\n",
      "Epoch [233/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0062\n",
      "Epoch [234/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0061\n",
      "Epoch [235/2000] Fold 1, Train Loss: 0.0055, Val Loss: 0.0062\n",
      "Epoch [236/2000] Fold 1, Train Loss: 0.0055, Val Loss: 0.0062\n",
      "Epoch [237/2000] Fold 1, Train Loss: 0.0055, Val Loss: 0.0062\n",
      "Epoch [238/2000] Fold 1, Train Loss: 0.0056, Val Loss: 0.0062\n",
      "Epoch [239/2000] Fold 1, Train Loss: 0.0055, Val Loss: 0.0061\n",
      "Epoch [240/2000] Fold 1, Train Loss: 0.0055, Val Loss: 0.0062\n",
      "Epoch [241/2000] Fold 1, Train Loss: 0.0055, Val Loss: 0.0062\n",
      "Epoch [242/2000] Fold 1, Train Loss: 0.0055, Val Loss: 0.0062\n",
      "Epoch [243/2000] Fold 1, Train Loss: 0.0055, Val Loss: 0.0061\n",
      "Epoch [244/2000] Fold 1, Train Loss: 0.0055, Val Loss: 0.0062\n",
      "Epoch [245/2000] Fold 1, Train Loss: 0.0055, Val Loss: 0.0061\n",
      "Epoch [246/2000] Fold 1, Train Loss: 0.0055, Val Loss: 0.0062\n",
      "Epoch [247/2000] Fold 1, Train Loss: 0.0054, Val Loss: 0.0062\n",
      "Epoch [248/2000] Fold 1, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [249/2000] Fold 1, Train Loss: 0.0054, Val Loss: 0.0062\n",
      "Epoch [250/2000] Fold 1, Train Loss: 0.0055, Val Loss: 0.0061\n",
      "Epoch [251/2000] Fold 1, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [252/2000] Fold 1, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [253/2000] Fold 1, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [254/2000] Fold 1, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [255/2000] Fold 1, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [256/2000] Fold 1, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [257/2000] Fold 1, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [258/2000] Fold 1, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [259/2000] Fold 1, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [260/2000] Fold 1, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [261/2000] Fold 1, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [262/2000] Fold 1, Train Loss: 0.0054, Val Loss: 0.0060\n",
      "Epoch [263/2000] Fold 1, Train Loss: 0.0053, Val Loss: 0.0061\n",
      "Epoch [264/2000] Fold 1, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [265/2000] Fold 1, Train Loss: 0.0054, Val Loss: 0.0060\n",
      "Epoch [266/2000] Fold 1, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [267/2000] Fold 1, Train Loss: 0.0053, Val Loss: 0.0061\n",
      "Epoch [268/2000] Fold 1, Train Loss: 0.0053, Val Loss: 0.0062\n",
      "Epoch [269/2000] Fold 1, Train Loss: 0.0053, Val Loss: 0.0061\n",
      "Epoch [270/2000] Fold 1, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [271/2000] Fold 1, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [272/2000] Fold 1, Train Loss: 0.0053, Val Loss: 0.0061\n",
      "Epoch [273/2000] Fold 1, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [274/2000] Fold 1, Train Loss: 0.0052, Val Loss: 0.0060\n",
      "Epoch [275/2000] Fold 1, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [276/2000] Fold 1, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [277/2000] Fold 1, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [278/2000] Fold 1, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [279/2000] Fold 1, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [280/2000] Fold 1, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [281/2000] Fold 1, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [282/2000] Fold 1, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [283/2000] Fold 1, Train Loss: 0.0052, Val Loss: 0.0061\n",
      "Epoch [284/2000] Fold 1, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [285/2000] Fold 1, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [286/2000] Fold 1, Train Loss: 0.0052, Val Loss: 0.0060\n",
      "Epoch [287/2000] Fold 1, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [288/2000] Fold 1, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [289/2000] Fold 1, Train Loss: 0.0051, Val Loss: 0.0059\n",
      "Epoch [290/2000] Fold 1, Train Loss: 0.0051, Val Loss: 0.0059\n",
      "Epoch [291/2000] Fold 1, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [292/2000] Fold 1, Train Loss: 0.0051, Val Loss: 0.0059\n",
      "Epoch [293/2000] Fold 1, Train Loss: 0.0051, Val Loss: 0.0059\n",
      "Epoch [294/2000] Fold 1, Train Loss: 0.0051, Val Loss: 0.0059\n",
      "Epoch [295/2000] Fold 1, Train Loss: 0.0051, Val Loss: 0.0059\n",
      "Epoch [296/2000] Fold 1, Train Loss: 0.0051, Val Loss: 0.0058\n",
      "Epoch [297/2000] Fold 1, Train Loss: 0.0051, Val Loss: 0.0058\n",
      "Epoch [298/2000] Fold 1, Train Loss: 0.0051, Val Loss: 0.0058\n",
      "Epoch [299/2000] Fold 1, Train Loss: 0.0051, Val Loss: 0.0059\n",
      "Epoch [300/2000] Fold 1, Train Loss: 0.0051, Val Loss: 0.0058\n",
      "Epoch [301/2000] Fold 1, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [302/2000] Fold 1, Train Loss: 0.0051, Val Loss: 0.0058\n",
      "Epoch [303/2000] Fold 1, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [304/2000] Fold 1, Train Loss: 0.0051, Val Loss: 0.0058\n",
      "Epoch [305/2000] Fold 1, Train Loss: 0.0051, Val Loss: 0.0058\n",
      "Epoch [306/2000] Fold 1, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [307/2000] Fold 1, Train Loss: 0.0051, Val Loss: 0.0058\n",
      "Epoch [308/2000] Fold 1, Train Loss: 0.0050, Val Loss: 0.0057\n",
      "Epoch [309/2000] Fold 1, Train Loss: 0.0050, Val Loss: 0.0057\n",
      "Epoch [310/2000] Fold 1, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [311/2000] Fold 1, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [312/2000] Fold 1, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [313/2000] Fold 1, Train Loss: 0.0050, Val Loss: 0.0057\n",
      "Epoch [314/2000] Fold 1, Train Loss: 0.0050, Val Loss: 0.0057\n",
      "Epoch [315/2000] Fold 1, Train Loss: 0.0050, Val Loss: 0.0059\n",
      "Epoch [316/2000] Fold 1, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [317/2000] Fold 1, Train Loss: 0.0050, Val Loss: 0.0057\n",
      "Epoch [318/2000] Fold 1, Train Loss: 0.0049, Val Loss: 0.0057\n",
      "Epoch [319/2000] Fold 1, Train Loss: 0.0049, Val Loss: 0.0057\n",
      "Epoch [320/2000] Fold 1, Train Loss: 0.0049, Val Loss: 0.0058\n",
      "Epoch [321/2000] Fold 1, Train Loss: 0.0049, Val Loss: 0.0057\n",
      "Epoch [322/2000] Fold 1, Train Loss: 0.0049, Val Loss: 0.0057\n",
      "Epoch [323/2000] Fold 1, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [324/2000] Fold 1, Train Loss: 0.0049, Val Loss: 0.0057\n",
      "Epoch [325/2000] Fold 1, Train Loss: 0.0049, Val Loss: 0.0056\n",
      "Epoch [326/2000] Fold 1, Train Loss: 0.0049, Val Loss: 0.0057\n",
      "Epoch [327/2000] Fold 1, Train Loss: 0.0049, Val Loss: 0.0056\n",
      "Epoch [328/2000] Fold 1, Train Loss: 0.0049, Val Loss: 0.0057\n",
      "Epoch [329/2000] Fold 1, Train Loss: 0.0048, Val Loss: 0.0057\n",
      "Epoch [330/2000] Fold 1, Train Loss: 0.0048, Val Loss: 0.0057\n",
      "Epoch [331/2000] Fold 1, Train Loss: 0.0049, Val Loss: 0.0058\n",
      "Epoch [332/2000] Fold 1, Train Loss: 0.0049, Val Loss: 0.0056\n",
      "Epoch [333/2000] Fold 1, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [334/2000] Fold 1, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [335/2000] Fold 1, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [336/2000] Fold 1, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [337/2000] Fold 1, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [338/2000] Fold 1, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [339/2000] Fold 1, Train Loss: 0.0048, Val Loss: 0.0057\n",
      "Epoch [340/2000] Fold 1, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [341/2000] Fold 1, Train Loss: 0.0047, Val Loss: 0.0056\n",
      "Epoch [342/2000] Fold 1, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [343/2000] Fold 1, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [344/2000] Fold 1, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [345/2000] Fold 1, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [346/2000] Fold 1, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [347/2000] Fold 1, Train Loss: 0.0047, Val Loss: 0.0056\n",
      "Epoch [348/2000] Fold 1, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [349/2000] Fold 1, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [350/2000] Fold 1, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [351/2000] Fold 1, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [352/2000] Fold 1, Train Loss: 0.0048, Val Loss: 0.0055\n",
      "Epoch [353/2000] Fold 1, Train Loss: 0.0047, Val Loss: 0.0056\n",
      "Epoch [354/2000] Fold 1, Train Loss: 0.0047, Val Loss: 0.0054\n",
      "Epoch [355/2000] Fold 1, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [356/2000] Fold 1, Train Loss: 0.0047, Val Loss: 0.0054\n",
      "Epoch [357/2000] Fold 1, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [358/2000] Fold 1, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [359/2000] Fold 1, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [360/2000] Fold 1, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [361/2000] Fold 1, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [362/2000] Fold 1, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [363/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [364/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [365/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [366/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [367/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [368/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [369/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [370/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [371/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [372/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [373/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [374/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0053\n",
      "Epoch [375/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [376/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0053\n",
      "Epoch [377/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [378/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [379/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [380/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [381/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0053\n",
      "Epoch [382/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [383/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [384/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [385/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [386/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [387/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [388/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [389/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [390/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [391/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [392/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [393/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [394/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [395/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [396/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [397/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [398/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [399/2000] Fold 1, Train Loss: 0.0046, Val Loss: 0.0053\n",
      "Epoch [400/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [401/2000] Fold 1, Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [402/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0052\n",
      "Epoch [403/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0053\n",
      "Epoch [404/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0052\n",
      "Epoch [405/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0052\n",
      "Epoch [406/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0053\n",
      "Epoch [407/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0054\n",
      "Epoch [408/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0054\n",
      "Epoch [409/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0054\n",
      "Epoch [410/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0053\n",
      "Epoch [411/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0052\n",
      "Epoch [412/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0052\n",
      "Epoch [413/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0052\n",
      "Epoch [414/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0052\n",
      "Epoch [415/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0052\n",
      "Epoch [416/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0052\n",
      "Epoch [417/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0053\n",
      "Epoch [418/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0052\n",
      "Epoch [419/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0053\n",
      "Epoch [420/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0053\n",
      "Epoch [421/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0052\n",
      "Epoch [422/2000] Fold 1, Train Loss: 0.0044, Val Loss: 0.0052\n",
      "Epoch [423/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0052\n",
      "Epoch [424/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0052\n",
      "Epoch [425/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0051\n",
      "Epoch [426/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0052\n",
      "Epoch [427/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0052\n",
      "Epoch [428/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0051\n",
      "Epoch [429/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0051\n",
      "Epoch [430/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0051\n",
      "Epoch [431/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0052\n",
      "Epoch [432/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0051\n",
      "Epoch [433/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0052\n",
      "Epoch [434/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0051\n",
      "Epoch [435/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0051\n",
      "Epoch [436/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0052\n",
      "Epoch [437/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0051\n",
      "Epoch [438/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0051\n",
      "Epoch [439/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0051\n",
      "Epoch [440/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0051\n",
      "Epoch [441/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0052\n",
      "Epoch [442/2000] Fold 1, Train Loss: 0.0043, Val Loss: 0.0051\n",
      "Epoch [443/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0051\n",
      "Epoch [444/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0051\n",
      "Epoch [445/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0051\n",
      "Epoch [446/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0050\n",
      "Epoch [447/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0051\n",
      "Epoch [448/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0050\n",
      "Epoch [449/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0051\n",
      "Epoch [450/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0050\n",
      "Epoch [451/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0050\n",
      "Epoch [452/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0051\n",
      "Epoch [453/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0051\n",
      "Epoch [454/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0050\n",
      "Epoch [455/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0051\n",
      "Epoch [456/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0050\n",
      "Epoch [457/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0051\n",
      "Epoch [458/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0052\n",
      "Epoch [459/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0051\n",
      "Epoch [460/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0051\n",
      "Epoch [461/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0050\n",
      "Epoch [462/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0050\n",
      "Epoch [463/2000] Fold 1, Train Loss: 0.0041, Val Loss: 0.0051\n",
      "Epoch [464/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0050\n",
      "Epoch [465/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0051\n",
      "Epoch [466/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0050\n",
      "Epoch [467/2000] Fold 1, Train Loss: 0.0041, Val Loss: 0.0049\n",
      "Epoch [468/2000] Fold 1, Train Loss: 0.0041, Val Loss: 0.0052\n",
      "Epoch [469/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0051\n",
      "Epoch [470/2000] Fold 1, Train Loss: 0.0042, Val Loss: 0.0050\n",
      "Epoch [471/2000] Fold 1, Train Loss: 0.0041, Val Loss: 0.0050\n",
      "Epoch [472/2000] Fold 1, Train Loss: 0.0041, Val Loss: 0.0050\n",
      "Epoch [473/2000] Fold 1, Train Loss: 0.0041, Val Loss: 0.0049\n",
      "Epoch [474/2000] Fold 1, Train Loss: 0.0041, Val Loss: 0.0050\n",
      "Epoch [475/2000] Fold 1, Train Loss: 0.0041, Val Loss: 0.0050\n",
      "Epoch [476/2000] Fold 1, Train Loss: 0.0041, Val Loss: 0.0050\n",
      "Epoch [477/2000] Fold 1, Train Loss: 0.0041, Val Loss: 0.0050\n",
      "Epoch [478/2000] Fold 1, Train Loss: 0.0041, Val Loss: 0.0049\n",
      "Epoch [479/2000] Fold 1, Train Loss: 0.0041, Val Loss: 0.0049\n",
      "Epoch [480/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [481/2000] Fold 1, Train Loss: 0.0041, Val Loss: 0.0049\n",
      "Epoch [482/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0050\n",
      "Epoch [483/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0050\n",
      "Epoch [484/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0050\n",
      "Epoch [485/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [486/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [487/2000] Fold 1, Train Loss: 0.0041, Val Loss: 0.0049\n",
      "Epoch [488/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [489/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [490/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [491/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [492/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [493/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [494/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0048\n",
      "Epoch [495/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [496/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [497/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [498/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [499/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [500/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [501/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [502/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0048\n",
      "Epoch [503/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [504/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0049\n",
      "Epoch [505/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0048\n",
      "Epoch [506/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0050\n",
      "Epoch [507/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0048\n",
      "Epoch [508/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [509/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [510/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [511/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0049\n",
      "Epoch [512/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [513/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0049\n",
      "Epoch [514/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [515/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0048\n",
      "Epoch [516/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [517/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [518/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [519/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [520/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [521/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0049\n",
      "Epoch [522/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0049\n",
      "Epoch [523/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [524/2000] Fold 1, Train Loss: 0.0040, Val Loss: 0.0048\n",
      "Epoch [525/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [526/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [527/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [528/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [529/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [530/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [531/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0047\n",
      "Epoch [532/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [533/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0048\n",
      "Epoch [534/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [535/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0049\n",
      "Epoch [536/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [537/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0048\n",
      "Epoch [538/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [539/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0048\n",
      "Epoch [540/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0048\n",
      "Epoch [541/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [542/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0048\n",
      "Epoch [543/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [544/2000] Fold 1, Train Loss: 0.0039, Val Loss: 0.0047\n",
      "Epoch [545/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [546/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [547/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0048\n",
      "Epoch [548/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [549/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [550/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [551/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [552/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0048\n",
      "Epoch [553/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0048\n",
      "Epoch [554/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [555/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0048\n",
      "Epoch [556/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [557/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [558/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0048\n",
      "Epoch [559/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0046\n",
      "Epoch [560/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [561/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0047\n",
      "Epoch [562/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0046\n",
      "Epoch [563/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [564/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0048\n",
      "Epoch [565/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [566/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0047\n",
      "Epoch [567/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0048\n",
      "Epoch [568/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [569/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0046\n",
      "Epoch [570/2000] Fold 1, Train Loss: 0.0038, Val Loss: 0.0047\n",
      "Epoch [571/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0047\n",
      "Epoch [572/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0047\n",
      "Epoch [573/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0047\n",
      "Epoch [574/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0047\n",
      "Epoch [575/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0047\n",
      "Epoch [576/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0047\n",
      "Epoch [577/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0047\n",
      "Epoch [578/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0046\n",
      "Epoch [579/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0047\n",
      "Epoch [580/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0046\n",
      "Epoch [581/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0047\n",
      "Epoch [582/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0046\n",
      "Epoch [583/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0046\n",
      "Epoch [584/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [585/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0047\n",
      "Epoch [586/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0046\n",
      "Epoch [587/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0046\n",
      "Epoch [588/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0046\n",
      "Epoch [589/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0046\n",
      "Epoch [590/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0047\n",
      "Epoch [591/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0049\n",
      "Epoch [592/2000] Fold 1, Train Loss: 0.0037, Val Loss: 0.0046\n",
      "Epoch [593/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [594/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [595/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [596/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [597/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [598/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0047\n",
      "Epoch [599/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [600/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [601/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [602/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [603/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [604/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [605/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0045\n",
      "Epoch [606/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [607/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [608/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [609/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [610/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0045\n",
      "Epoch [611/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [612/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [613/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0045\n",
      "Epoch [614/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0046\n",
      "Epoch [615/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0045\n",
      "Epoch [616/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [617/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0046\n",
      "Epoch [618/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [619/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0047\n",
      "Epoch [620/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [621/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0047\n",
      "Epoch [622/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0047\n",
      "Epoch [623/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [624/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [625/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [626/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0047\n",
      "Epoch [627/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [628/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0046\n",
      "Epoch [629/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [630/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0046\n",
      "Epoch [631/2000] Fold 1, Train Loss: 0.0036, Val Loss: 0.0046\n",
      "Epoch [632/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [633/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [634/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0046\n",
      "Epoch [635/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [636/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0046\n",
      "Epoch [637/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [638/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0046\n",
      "Epoch [639/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [640/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [641/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [642/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [643/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [644/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [645/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [646/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [647/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [648/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [649/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [650/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [651/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [652/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [653/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [654/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [655/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0046\n",
      "Epoch [656/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [657/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [658/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0047\n",
      "Epoch [659/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [660/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [661/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0044\n",
      "Epoch [662/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [663/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [664/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0044\n",
      "Epoch [665/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0044\n",
      "Epoch [666/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [667/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [668/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [669/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0044\n",
      "Epoch [670/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0046\n",
      "Epoch [671/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [672/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [673/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0046\n",
      "Epoch [674/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [675/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0045\n",
      "Epoch [676/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [677/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [678/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0044\n",
      "Epoch [679/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0044\n",
      "Epoch [680/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0044\n",
      "Epoch [681/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0045\n",
      "Epoch [682/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [683/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0045\n",
      "Epoch [684/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [685/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [686/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0044\n",
      "Epoch [687/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0044\n",
      "Epoch [688/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0044\n",
      "Epoch [689/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [690/2000] Fold 1, Train Loss: 0.0035, Val Loss: 0.0046\n",
      "Epoch [691/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0044\n",
      "Epoch [692/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [693/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [694/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [695/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [696/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0045\n",
      "Epoch [697/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0045\n",
      "Epoch [698/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [699/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [700/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0045\n",
      "Epoch [701/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [702/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0045\n",
      "Epoch [703/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [704/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [705/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [706/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [707/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0045\n",
      "Epoch [708/2000] Fold 1, Train Loss: 0.0034, Val Loss: 0.0045\n",
      "Epoch [709/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0045\n",
      "Epoch [710/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [711/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0047\n",
      "Epoch [712/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [713/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [714/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [715/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [716/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0043\n",
      "Epoch [717/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [718/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0045\n",
      "Epoch [719/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [720/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [721/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [722/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [723/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0043\n",
      "Epoch [724/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [725/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch [726/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0043\n",
      "Epoch [727/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0043\n",
      "Epoch [728/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch [729/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch [730/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch [731/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch [732/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [733/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch [734/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch [735/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0044\n",
      "Epoch [736/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch [737/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0043\n",
      "Epoch [738/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0043\n",
      "Epoch [739/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0043\n",
      "Epoch [740/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0043\n",
      "Epoch [741/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0043\n",
      "Epoch [742/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0045\n",
      "Epoch [743/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0045\n",
      "Epoch [744/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch [745/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0047\n",
      "Epoch [746/2000] Fold 1, Train Loss: 0.0033, Val Loss: 0.0043\n",
      "Epoch [747/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch [748/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch [749/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0043\n",
      "Epoch [750/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch [751/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch [752/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0043\n",
      "Epoch [753/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0043\n",
      "Epoch [754/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [755/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch [756/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [757/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [758/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [759/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch [760/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [761/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0044\n",
      "Epoch [762/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch [763/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [764/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [765/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0044\n",
      "Epoch [766/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0044\n",
      "Epoch [767/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [768/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0045\n",
      "Epoch [769/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0043\n",
      "Epoch [770/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0045\n",
      "Epoch [771/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0043\n",
      "Epoch [772/2000] Fold 1, Train Loss: 0.0032, Val Loss: 0.0044\n",
      "Epoch [773/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [774/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [775/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [776/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [777/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0044\n",
      "Epoch [778/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [779/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [780/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0044\n",
      "Epoch [781/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [782/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [783/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [784/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [785/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [786/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [787/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [788/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [789/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0042\n",
      "Epoch [790/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0042\n",
      "Epoch [791/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [792/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0042\n",
      "Epoch [793/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [794/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [795/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0044\n",
      "Epoch [796/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [797/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0042\n",
      "Epoch [798/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [799/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [800/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0042\n",
      "Epoch [801/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0042\n",
      "Epoch [802/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0042\n",
      "Epoch [803/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0046\n",
      "Epoch [804/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [805/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [806/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [807/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [808/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [809/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [810/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [811/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [812/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [813/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [814/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [815/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [816/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [817/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0042\n",
      "Epoch [818/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0042\n",
      "Epoch [819/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0044\n",
      "Epoch [820/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0044\n",
      "Epoch [821/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0043\n",
      "Epoch [822/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0044\n",
      "Epoch [823/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0042\n",
      "Epoch [824/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0042\n",
      "Epoch [825/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0043\n",
      "Epoch [826/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [827/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0043\n",
      "Epoch [828/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0042\n",
      "Epoch [829/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [830/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [831/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0045\n",
      "Epoch [832/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0042\n",
      "Epoch [833/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [834/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0042\n",
      "Epoch [835/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [836/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [837/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [838/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [839/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0043\n",
      "Epoch [840/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0043\n",
      "Epoch [841/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [842/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [843/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [844/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0041\n",
      "Epoch [845/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [846/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [847/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0043\n",
      "Epoch [848/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [849/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [850/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [851/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [852/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [853/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [854/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0043\n",
      "Epoch [855/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [856/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [857/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [858/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [859/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [860/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [861/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [862/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [863/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [864/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [865/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [866/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [867/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0043\n",
      "Epoch [868/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0043\n",
      "Epoch [869/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [870/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0046\n",
      "Epoch [871/2000] Fold 1, Train Loss: 0.0031, Val Loss: 0.0041\n",
      "Epoch [872/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0041\n",
      "Epoch [873/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [874/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [875/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0041\n",
      "Epoch [876/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0043\n",
      "Epoch [877/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0043\n",
      "Epoch [878/2000] Fold 1, Train Loss: 0.0030, Val Loss: 0.0043\n",
      "Epoch [879/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0043\n",
      "Epoch [880/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [881/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [882/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [883/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [884/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0041\n",
      "Epoch [885/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0043\n",
      "Epoch [886/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [887/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [888/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [889/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [890/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0043\n",
      "Epoch [891/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [892/2000] Fold 1, Train Loss: 0.0029, Val Loss: 0.0042\n",
      "Epoch [893/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0043\n",
      "Epoch [894/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0041\n",
      "Epoch [895/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [896/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [897/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [898/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0041\n",
      "Epoch [899/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [900/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0043\n",
      "Epoch [901/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [902/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [903/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [904/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [905/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [906/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [907/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [908/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [909/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [910/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [911/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0043\n",
      "Epoch [912/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0043\n",
      "Epoch [913/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [914/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [915/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [916/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [917/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [918/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [919/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [920/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [921/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [922/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [923/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [924/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [925/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [926/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [927/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [928/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [929/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [930/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [931/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [932/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [933/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [934/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [935/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0040\n",
      "Epoch [936/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [937/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [938/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [939/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0042\n",
      "Epoch [940/2000] Fold 1, Train Loss: 0.0028, Val Loss: 0.0041\n",
      "Epoch [941/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [942/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [943/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [944/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [945/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [946/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0042\n",
      "Epoch [947/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [948/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [949/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [950/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [951/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [952/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [953/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [954/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [955/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [956/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0040\n",
      "Epoch [957/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0042\n",
      "Epoch [958/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [959/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [960/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [961/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [962/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [963/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0042\n",
      "Epoch [964/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [965/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0040\n",
      "Epoch [966/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0042\n",
      "Epoch [967/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [968/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [969/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [970/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [971/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [972/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [973/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [974/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0040\n",
      "Epoch [975/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [976/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [977/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0040\n",
      "Epoch [978/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [979/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0042\n",
      "Epoch [980/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [981/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [982/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [983/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [984/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0041\n",
      "Epoch [985/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0040\n",
      "Epoch [986/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [987/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0040\n",
      "Epoch [988/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [989/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0041\n",
      "Epoch [990/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [991/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [992/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [993/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [994/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0040\n",
      "Epoch [995/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [996/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [997/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0040\n",
      "Epoch [998/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0040\n",
      "Epoch [999/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1000/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0042\n",
      "Epoch [1001/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0040\n",
      "Epoch [1002/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0041\n",
      "Epoch [1003/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1004/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1005/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1006/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0041\n",
      "Epoch [1007/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1008/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1009/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1010/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1011/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1012/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1013/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1014/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0039\n",
      "Epoch [1015/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1016/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0039\n",
      "Epoch [1017/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0039\n",
      "Epoch [1018/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0039\n",
      "Epoch [1019/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0041\n",
      "Epoch [1020/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1021/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1022/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1023/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0041\n",
      "Epoch [1024/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1025/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0040\n",
      "Epoch [1026/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1027/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0041\n",
      "Epoch [1028/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0039\n",
      "Epoch [1029/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1030/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1031/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1032/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1033/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1034/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0041\n",
      "Epoch [1035/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1036/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1037/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1038/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1039/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1040/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1041/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1042/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0042\n",
      "Epoch [1043/2000] Fold 1, Train Loss: 0.0027, Val Loss: 0.0042\n",
      "Epoch [1044/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0042\n",
      "Epoch [1045/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0039\n",
      "Epoch [1046/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0039\n",
      "Epoch [1047/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0039\n",
      "Epoch [1048/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1049/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1050/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1051/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1052/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1053/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0039\n",
      "Epoch [1054/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1055/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0039\n",
      "Epoch [1056/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1057/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1058/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0039\n",
      "Epoch [1059/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1060/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1061/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0041\n",
      "Epoch [1062/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0039\n",
      "Epoch [1063/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0039\n",
      "Epoch [1064/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0041\n",
      "Epoch [1065/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1066/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0039\n",
      "Epoch [1067/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1068/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0039\n",
      "Epoch [1069/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1070/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1071/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1072/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1073/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0039\n",
      "Epoch [1074/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0041\n",
      "Epoch [1075/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1076/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1077/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch [1078/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1079/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1080/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1081/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0039\n",
      "Epoch [1082/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1083/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1084/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1085/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1086/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1087/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1088/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1089/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0039\n",
      "Epoch [1090/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1091/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch [1092/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1093/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0042\n",
      "Epoch [1094/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0041\n",
      "Epoch [1095/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0040\n",
      "Epoch [1096/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1097/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1098/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0039\n",
      "Epoch [1099/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1100/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1101/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1102/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1103/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1104/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch [1105/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch [1106/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1107/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch [1108/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1109/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1110/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1111/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch [1112/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1113/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1114/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1115/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1116/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch [1117/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1118/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1119/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1120/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0041\n",
      "Epoch [1121/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch [1122/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1123/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch [1124/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0039\n",
      "Epoch [1125/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1126/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1127/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1128/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1129/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1130/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1131/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch [1132/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1133/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1134/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1135/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch [1136/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1137/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch [1138/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1139/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0039\n",
      "Epoch [1140/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0041\n",
      "Epoch [1141/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0039\n",
      "Epoch [1142/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0040\n",
      "Epoch [1143/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0039\n",
      "Epoch [1144/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1145/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0038\n",
      "Epoch [1146/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1147/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1148/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1149/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1150/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1151/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1152/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0040\n",
      "Epoch [1153/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1154/2000] Fold 1, Train Loss: 0.0024, Val Loss: 0.0043\n",
      "Epoch [1155/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0039\n",
      "Epoch [1156/2000] Fold 1, Train Loss: 0.0025, Val Loss: 0.0040\n",
      "Epoch [1157/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1158/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0038\n",
      "Epoch [1159/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1160/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1161/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1162/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1163/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch [1164/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0038\n",
      "Epoch [1165/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0040\n",
      "Epoch [1166/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1167/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1168/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0038\n",
      "Epoch [1169/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1170/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1171/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1172/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1173/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1174/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1175/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1176/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1177/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1178/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1179/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0040\n",
      "Epoch [1180/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1181/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1182/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0038\n",
      "Epoch [1183/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1184/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1185/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0038\n",
      "Epoch [1186/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1187/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1188/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1189/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch [1190/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1191/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1192/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1193/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1194/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0040\n",
      "Epoch [1195/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1196/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0038\n",
      "Epoch [1197/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1198/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1199/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1200/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1201/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1202/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1203/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1204/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0040\n",
      "Epoch [1205/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1206/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1207/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1208/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1209/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1210/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1211/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0038\n",
      "Epoch [1212/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1213/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1214/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1215/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1216/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1217/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1218/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1219/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1220/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0040\n",
      "Epoch [1221/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0038\n",
      "Epoch [1222/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1223/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0040\n",
      "Epoch [1224/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1225/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0038\n",
      "Epoch [1226/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1227/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1228/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1229/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1230/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1231/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1232/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1233/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1234/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1235/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1236/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1237/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1238/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1239/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0039\n",
      "Epoch [1240/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0039\n",
      "Epoch [1241/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1242/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1243/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0039\n",
      "Epoch [1244/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1245/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1246/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1247/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1248/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1249/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1250/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1251/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1252/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1253/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1254/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1255/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1256/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1257/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0039\n",
      "Epoch [1258/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1259/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1260/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1261/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0039\n",
      "Epoch [1262/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0039\n",
      "Epoch [1263/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0039\n",
      "Epoch [1264/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1265/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1266/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0039\n",
      "Epoch [1267/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1268/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0039\n",
      "Epoch [1269/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1270/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1271/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1272/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1273/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1274/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1275/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1276/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1277/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1278/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1279/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1280/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1281/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1282/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1283/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1284/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1285/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1286/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1287/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0039\n",
      "Epoch [1288/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1289/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1290/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1291/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1292/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1293/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0039\n",
      "Epoch [1294/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1295/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1296/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1297/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0039\n",
      "Epoch [1298/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0040\n",
      "Epoch [1299/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch [1300/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1301/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0037\n",
      "Epoch [1302/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0039\n",
      "Epoch [1303/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0038\n",
      "Epoch [1304/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0040\n",
      "Epoch [1305/2000] Fold 1, Train Loss: 0.0023, Val Loss: 0.0038\n",
      "Epoch [1306/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0037\n",
      "Epoch [1307/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1308/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1309/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1310/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1311/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1312/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1313/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1314/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1315/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1316/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1317/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1318/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1319/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1320/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1321/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1322/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1323/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1324/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1325/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1326/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1327/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1328/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1329/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1330/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1331/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1332/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0039\n",
      "Epoch [1333/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1334/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1335/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1336/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1337/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0039\n",
      "Epoch [1338/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1339/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1340/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1341/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1342/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1343/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0039\n",
      "Epoch [1344/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1345/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1346/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1347/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1348/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1349/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1350/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1351/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1352/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1353/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1354/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1355/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1356/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1357/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1358/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1359/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1360/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1361/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1362/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1363/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0036\n",
      "Epoch [1364/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1365/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1366/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1367/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1368/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1369/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1370/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1371/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0036\n",
      "Epoch [1372/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1373/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1374/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0039\n",
      "Epoch [1375/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1376/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1377/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1378/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1379/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1380/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1381/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1382/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1383/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1384/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1385/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1386/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1387/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1388/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0036\n",
      "Epoch [1389/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1390/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1391/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1392/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1393/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1394/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1395/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0041\n",
      "Epoch [1396/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1397/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0037\n",
      "Epoch [1398/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1399/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1400/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1401/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1402/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1403/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1404/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1405/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1406/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1407/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1408/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1409/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0036\n",
      "Epoch [1410/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1411/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1412/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1413/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1414/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1415/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1416/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1417/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0036\n",
      "Epoch [1418/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1419/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1420/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1421/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1422/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1423/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0036\n",
      "Epoch [1424/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1425/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0038\n",
      "Epoch [1426/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1427/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1428/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1429/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1430/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1431/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1432/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1433/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0038\n",
      "Epoch [1434/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1435/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1436/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0038\n",
      "Epoch [1437/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1438/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1439/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1440/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1441/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1442/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1443/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1444/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1445/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1446/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1447/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0038\n",
      "Epoch [1448/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1449/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1450/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1451/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1452/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1453/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1454/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1455/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1456/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1457/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1458/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1459/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1460/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0039\n",
      "Epoch [1461/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1462/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1463/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1464/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1465/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1466/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1467/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1468/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1469/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1470/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0038\n",
      "Epoch [1471/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1472/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0038\n",
      "Epoch [1473/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1474/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1475/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1476/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1477/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1478/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1479/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1480/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1481/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1482/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1483/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1484/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1485/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1486/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0038\n",
      "Epoch [1487/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1488/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1489/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1490/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1491/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1492/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1493/2000] Fold 1, Train Loss: 0.0026, Val Loss: 0.0043\n",
      "Epoch [1494/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1495/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1496/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1497/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1498/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1499/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1500/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1501/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1502/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1503/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1504/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1505/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0038\n",
      "Epoch [1506/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1507/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1508/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1509/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1510/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1511/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1512/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1513/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0038\n",
      "Epoch [1514/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1515/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1516/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1517/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1518/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1519/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1520/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1521/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1522/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1523/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1524/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1525/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1526/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1527/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1528/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1529/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1530/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1531/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1532/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1533/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1534/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1535/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0039\n",
      "Epoch [1536/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1537/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0038\n",
      "Epoch [1538/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1539/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1540/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1541/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1542/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1543/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1544/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1545/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1546/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1547/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1548/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1549/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1550/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0038\n",
      "Epoch [1551/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1552/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1553/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1554/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1555/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1556/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1557/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1558/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0038\n",
      "Epoch [1559/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1560/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1561/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0038\n",
      "Epoch [1562/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1563/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1564/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1565/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1566/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1567/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1568/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1569/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1570/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1571/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1572/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1573/2000] Fold 1, Train Loss: 0.0021, Val Loss: 0.0038\n",
      "Epoch [1574/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0042\n",
      "Epoch [1575/2000] Fold 1, Train Loss: 0.0022, Val Loss: 0.0038\n",
      "Epoch [1576/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1577/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1578/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1579/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1580/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0035\n",
      "Epoch [1581/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1582/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1583/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1584/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1585/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1586/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1587/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1588/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1589/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1590/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1591/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1592/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1593/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1594/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1595/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1596/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1597/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1598/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1599/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1600/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1601/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1602/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1603/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1604/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1605/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1606/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1607/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1608/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1609/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1610/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1611/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1612/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1613/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1614/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1615/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1616/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1617/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1618/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1619/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1620/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1621/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0038\n",
      "Epoch [1622/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1623/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1624/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1625/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1626/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1627/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1628/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1629/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1630/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1631/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1632/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1633/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1634/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1635/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1636/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1637/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1638/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1639/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1640/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1641/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1642/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0038\n",
      "Epoch [1643/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1644/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1645/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1646/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1647/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1648/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1649/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1650/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1651/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1652/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1653/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0038\n",
      "Epoch [1654/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1655/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0038\n",
      "Epoch [1656/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0036\n",
      "Epoch [1657/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1658/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1659/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1660/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1661/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1662/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1663/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1664/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1665/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1666/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1667/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1668/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1669/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1670/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1671/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1672/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1673/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1674/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1675/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1676/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1677/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1678/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1679/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1680/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1681/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1682/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1683/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1684/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1685/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0038\n",
      "Epoch [1686/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1687/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1688/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1689/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1690/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0043\n",
      "Epoch [1691/2000] Fold 1, Train Loss: 0.0020, Val Loss: 0.0037\n",
      "Epoch [1692/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1693/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1694/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1695/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1696/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1697/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1698/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1699/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1700/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1701/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1702/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1703/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1704/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1705/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1706/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1707/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1708/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1709/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1710/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1711/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1712/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1713/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0035\n",
      "Epoch [1714/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1715/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1716/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1717/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1718/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1719/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1720/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1721/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1722/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1723/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1724/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1725/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1726/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0038\n",
      "Epoch [1727/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1728/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1729/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1730/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1731/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0040\n",
      "Epoch [1732/2000] Fold 1, Train Loss: 0.0019, Val Loss: 0.0037\n",
      "Epoch [1733/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0037\n",
      "Epoch [1734/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0035\n",
      "Epoch [1735/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1736/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0035\n",
      "Epoch [1737/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1738/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1739/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1740/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1741/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1742/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1743/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1744/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1745/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1746/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1747/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1748/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1749/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1750/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1751/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1752/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0035\n",
      "Epoch [1753/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0035\n",
      "Epoch [1754/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1755/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1756/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0040\n",
      "Epoch [1757/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0038\n",
      "Epoch [1758/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0036\n",
      "Epoch [1759/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1760/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1761/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1762/2000] Fold 1, Train Loss: 0.0018, Val Loss: 0.0038\n",
      "Epoch [1763/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1764/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1765/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1766/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1767/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1768/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0035\n",
      "Epoch [1769/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1770/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1771/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1772/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1773/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1774/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1775/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0035\n",
      "Epoch [1776/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1777/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0035\n",
      "Epoch [1778/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1779/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1780/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1781/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1782/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0035\n",
      "Epoch [1783/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1784/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1785/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1786/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0035\n",
      "Epoch [1787/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1788/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0035\n",
      "Epoch [1789/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1790/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1791/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1792/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1793/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0035\n",
      "Epoch [1794/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1795/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1796/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1797/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1798/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1799/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1800/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1801/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1802/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1803/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1804/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1805/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1806/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1807/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1808/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1809/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1810/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1811/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1812/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1813/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1814/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1815/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1816/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1817/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1818/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1819/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1820/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1821/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1822/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1823/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1824/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0038\n",
      "Epoch [1825/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1826/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1827/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1828/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1829/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1830/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1831/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1832/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1833/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1834/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1835/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1836/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1837/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1838/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1839/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1840/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1841/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1842/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1843/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1844/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1845/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1846/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1847/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1848/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1849/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1850/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1851/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1852/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1853/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0035\n",
      "Epoch [1854/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1855/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1856/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0035\n",
      "Epoch [1857/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1858/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1859/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1860/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1861/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1862/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1863/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1864/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1865/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1866/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0037\n",
      "Epoch [1867/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1868/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0038\n",
      "Epoch [1869/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1870/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1871/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1872/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1873/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1874/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1875/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0037\n",
      "Epoch [1876/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1877/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1878/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1879/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1880/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1881/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1882/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1883/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1884/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1885/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1886/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1887/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1888/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1889/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1890/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1891/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1892/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1893/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1894/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0039\n",
      "Epoch [1895/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1896/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1897/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1898/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1899/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0037\n",
      "Epoch [1900/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1901/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1902/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1903/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1904/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0037\n",
      "Epoch [1905/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1906/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1907/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1908/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1909/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1910/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1911/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1912/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1913/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1914/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1915/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0035\n",
      "Epoch [1916/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1917/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1918/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0035\n",
      "Epoch [1919/2000] Fold 1, Train Loss: 0.0017, Val Loss: 0.0036\n",
      "Epoch [1920/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1921/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1922/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1923/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1924/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1925/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1926/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1927/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1928/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1929/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1930/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1931/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0035\n",
      "Epoch [1932/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1933/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1934/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1935/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1936/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0037\n",
      "Epoch [1937/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1938/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1939/2000] Fold 1, Train Loss: 0.0014, Val Loss: 0.0036\n",
      "Epoch [1940/2000] Fold 1, Train Loss: 0.0014, Val Loss: 0.0036\n",
      "Epoch [1941/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1942/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1943/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1944/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1945/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1946/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1947/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1948/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0036\n",
      "Epoch [1949/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0037\n",
      "Epoch [1950/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1951/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1952/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1953/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0037\n",
      "Epoch [1954/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1955/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1956/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1957/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1958/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1959/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1960/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0037\n",
      "Epoch [1961/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1962/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0037\n",
      "Epoch [1963/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1964/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0037\n",
      "Epoch [1965/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1966/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0037\n",
      "Epoch [1967/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1968/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1969/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1970/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1971/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1972/2000] Fold 1, Train Loss: 0.0014, Val Loss: 0.0036\n",
      "Epoch [1973/2000] Fold 1, Train Loss: 0.0014, Val Loss: 0.0036\n",
      "Epoch [1974/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1975/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0037\n",
      "Epoch [1976/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1977/2000] Fold 1, Train Loss: 0.0014, Val Loss: 0.0036\n",
      "Epoch [1978/2000] Fold 1, Train Loss: 0.0014, Val Loss: 0.0036\n",
      "Epoch [1979/2000] Fold 1, Train Loss: 0.0014, Val Loss: 0.0036\n",
      "Epoch [1980/2000] Fold 1, Train Loss: 0.0014, Val Loss: 0.0037\n",
      "Epoch [1981/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1982/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0037\n",
      "Epoch [1983/2000] Fold 1, Train Loss: 0.0014, Val Loss: 0.0036\n",
      "Epoch [1984/2000] Fold 1, Train Loss: 0.0014, Val Loss: 0.0036\n",
      "Epoch [1985/2000] Fold 1, Train Loss: 0.0014, Val Loss: 0.0036\n",
      "Epoch [1986/2000] Fold 1, Train Loss: 0.0014, Val Loss: 0.0036\n",
      "Epoch [1987/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1988/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1989/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0037\n",
      "Epoch [1990/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1991/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0038\n",
      "Epoch [1992/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0035\n",
      "Epoch [1993/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0037\n",
      "Epoch [1994/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1995/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0037\n",
      "Epoch [1996/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0035\n",
      "Epoch [1997/2000] Fold 1, Train Loss: 0.0016, Val Loss: 0.0037\n",
      "Epoch [1998/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [1999/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0036\n",
      "Epoch [2000/2000] Fold 1, Train Loss: 0.0015, Val Loss: 0.0037\n",
      "Fold 2/5\n",
      "Epoch [1/2000] Fold 2, Train Loss: 0.0263, Val Loss: 0.0240\n",
      "Epoch [2/2000] Fold 2, Train Loss: 0.0235, Val Loss: 0.0212\n",
      "Epoch [3/2000] Fold 2, Train Loss: 0.0203, Val Loss: 0.0181\n",
      "Epoch [4/2000] Fold 2, Train Loss: 0.0174, Val Loss: 0.0157\n",
      "Epoch [5/2000] Fold 2, Train Loss: 0.0152, Val Loss: 0.0143\n",
      "Epoch [6/2000] Fold 2, Train Loss: 0.0142, Val Loss: 0.0138\n",
      "Epoch [7/2000] Fold 2, Train Loss: 0.0138, Val Loss: 0.0136\n",
      "Epoch [8/2000] Fold 2, Train Loss: 0.0137, Val Loss: 0.0135\n",
      "Epoch [9/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [10/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [11/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [12/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [13/2000] Fold 2, Train Loss: 0.0137, Val Loss: 0.0135\n",
      "Epoch [14/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [15/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [16/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [17/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [18/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [19/2000] Fold 2, Train Loss: 0.0137, Val Loss: 0.0135\n",
      "Epoch [20/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [21/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [22/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [23/2000] Fold 2, Train Loss: 0.0137, Val Loss: 0.0135\n",
      "Epoch [24/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [25/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [26/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [27/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [28/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [29/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0135\n",
      "Epoch [30/2000] Fold 2, Train Loss: 0.0136, Val Loss: 0.0134\n",
      "Epoch [31/2000] Fold 2, Train Loss: 0.0134, Val Loss: 0.0132\n",
      "Epoch [32/2000] Fold 2, Train Loss: 0.0131, Val Loss: 0.0125\n",
      "Epoch [33/2000] Fold 2, Train Loss: 0.0119, Val Loss: 0.0110\n",
      "Epoch [34/2000] Fold 2, Train Loss: 0.0108, Val Loss: 0.0106\n",
      "Epoch [35/2000] Fold 2, Train Loss: 0.0102, Val Loss: 0.0099\n",
      "Epoch [36/2000] Fold 2, Train Loss: 0.0099, Val Loss: 0.0097\n",
      "Epoch [37/2000] Fold 2, Train Loss: 0.0098, Val Loss: 0.0096\n",
      "Epoch [38/2000] Fold 2, Train Loss: 0.0096, Val Loss: 0.0094\n",
      "Epoch [39/2000] Fold 2, Train Loss: 0.0094, Val Loss: 0.0093\n",
      "Epoch [40/2000] Fold 2, Train Loss: 0.0093, Val Loss: 0.0092\n",
      "Epoch [41/2000] Fold 2, Train Loss: 0.0091, Val Loss: 0.0091\n",
      "Epoch [42/2000] Fold 2, Train Loss: 0.0090, Val Loss: 0.0091\n",
      "Epoch [43/2000] Fold 2, Train Loss: 0.0089, Val Loss: 0.0089\n",
      "Epoch [44/2000] Fold 2, Train Loss: 0.0087, Val Loss: 0.0089\n",
      "Epoch [45/2000] Fold 2, Train Loss: 0.0088, Val Loss: 0.0089\n",
      "Epoch [46/2000] Fold 2, Train Loss: 0.0086, Val Loss: 0.0088\n",
      "Epoch [47/2000] Fold 2, Train Loss: 0.0085, Val Loss: 0.0088\n",
      "Epoch [48/2000] Fold 2, Train Loss: 0.0085, Val Loss: 0.0088\n",
      "Epoch [49/2000] Fold 2, Train Loss: 0.0085, Val Loss: 0.0088\n",
      "Epoch [50/2000] Fold 2, Train Loss: 0.0085, Val Loss: 0.0087\n",
      "Epoch [51/2000] Fold 2, Train Loss: 0.0085, Val Loss: 0.0087\n",
      "Epoch [52/2000] Fold 2, Train Loss: 0.0084, Val Loss: 0.0087\n",
      "Epoch [53/2000] Fold 2, Train Loss: 0.0084, Val Loss: 0.0087\n",
      "Epoch [54/2000] Fold 2, Train Loss: 0.0084, Val Loss: 0.0087\n",
      "Epoch [55/2000] Fold 2, Train Loss: 0.0085, Val Loss: 0.0087\n",
      "Epoch [56/2000] Fold 2, Train Loss: 0.0084, Val Loss: 0.0087\n",
      "Epoch [57/2000] Fold 2, Train Loss: 0.0084, Val Loss: 0.0086\n",
      "Epoch [58/2000] Fold 2, Train Loss: 0.0083, Val Loss: 0.0086\n",
      "Epoch [59/2000] Fold 2, Train Loss: 0.0083, Val Loss: 0.0086\n",
      "Epoch [60/2000] Fold 2, Train Loss: 0.0083, Val Loss: 0.0086\n",
      "Epoch [61/2000] Fold 2, Train Loss: 0.0083, Val Loss: 0.0086\n",
      "Epoch [62/2000] Fold 2, Train Loss: 0.0083, Val Loss: 0.0086\n",
      "Epoch [63/2000] Fold 2, Train Loss: 0.0082, Val Loss: 0.0086\n",
      "Epoch [64/2000] Fold 2, Train Loss: 0.0083, Val Loss: 0.0086\n",
      "Epoch [65/2000] Fold 2, Train Loss: 0.0083, Val Loss: 0.0085\n",
      "Epoch [66/2000] Fold 2, Train Loss: 0.0082, Val Loss: 0.0085\n",
      "Epoch [67/2000] Fold 2, Train Loss: 0.0082, Val Loss: 0.0085\n",
      "Epoch [68/2000] Fold 2, Train Loss: 0.0082, Val Loss: 0.0085\n",
      "Epoch [69/2000] Fold 2, Train Loss: 0.0082, Val Loss: 0.0085\n",
      "Epoch [70/2000] Fold 2, Train Loss: 0.0082, Val Loss: 0.0085\n",
      "Epoch [71/2000] Fold 2, Train Loss: 0.0082, Val Loss: 0.0085\n",
      "Epoch [72/2000] Fold 2, Train Loss: 0.0081, Val Loss: 0.0084\n",
      "Epoch [73/2000] Fold 2, Train Loss: 0.0081, Val Loss: 0.0084\n",
      "Epoch [74/2000] Fold 2, Train Loss: 0.0081, Val Loss: 0.0084\n",
      "Epoch [75/2000] Fold 2, Train Loss: 0.0081, Val Loss: 0.0084\n",
      "Epoch [76/2000] Fold 2, Train Loss: 0.0080, Val Loss: 0.0084\n",
      "Epoch [77/2000] Fold 2, Train Loss: 0.0080, Val Loss: 0.0084\n",
      "Epoch [78/2000] Fold 2, Train Loss: 0.0080, Val Loss: 0.0083\n",
      "Epoch [79/2000] Fold 2, Train Loss: 0.0080, Val Loss: 0.0083\n",
      "Epoch [80/2000] Fold 2, Train Loss: 0.0080, Val Loss: 0.0083\n",
      "Epoch [81/2000] Fold 2, Train Loss: 0.0080, Val Loss: 0.0083\n",
      "Epoch [82/2000] Fold 2, Train Loss: 0.0080, Val Loss: 0.0083\n",
      "Epoch [83/2000] Fold 2, Train Loss: 0.0079, Val Loss: 0.0083\n",
      "Epoch [84/2000] Fold 2, Train Loss: 0.0080, Val Loss: 0.0082\n",
      "Epoch [85/2000] Fold 2, Train Loss: 0.0079, Val Loss: 0.0082\n",
      "Epoch [86/2000] Fold 2, Train Loss: 0.0079, Val Loss: 0.0082\n",
      "Epoch [87/2000] Fold 2, Train Loss: 0.0079, Val Loss: 0.0082\n",
      "Epoch [88/2000] Fold 2, Train Loss: 0.0079, Val Loss: 0.0082\n",
      "Epoch [89/2000] Fold 2, Train Loss: 0.0078, Val Loss: 0.0081\n",
      "Epoch [90/2000] Fold 2, Train Loss: 0.0079, Val Loss: 0.0081\n",
      "Epoch [91/2000] Fold 2, Train Loss: 0.0078, Val Loss: 0.0081\n",
      "Epoch [92/2000] Fold 2, Train Loss: 0.0078, Val Loss: 0.0081\n",
      "Epoch [93/2000] Fold 2, Train Loss: 0.0078, Val Loss: 0.0081\n",
      "Epoch [94/2000] Fold 2, Train Loss: 0.0078, Val Loss: 0.0081\n",
      "Epoch [95/2000] Fold 2, Train Loss: 0.0079, Val Loss: 0.0081\n",
      "Epoch [96/2000] Fold 2, Train Loss: 0.0078, Val Loss: 0.0080\n",
      "Epoch [97/2000] Fold 2, Train Loss: 0.0077, Val Loss: 0.0080\n",
      "Epoch [98/2000] Fold 2, Train Loss: 0.0077, Val Loss: 0.0080\n",
      "Epoch [99/2000] Fold 2, Train Loss: 0.0077, Val Loss: 0.0080\n",
      "Epoch [100/2000] Fold 2, Train Loss: 0.0077, Val Loss: 0.0080\n",
      "Epoch [101/2000] Fold 2, Train Loss: 0.0077, Val Loss: 0.0079\n",
      "Epoch [102/2000] Fold 2, Train Loss: 0.0076, Val Loss: 0.0079\n",
      "Epoch [103/2000] Fold 2, Train Loss: 0.0077, Val Loss: 0.0079\n",
      "Epoch [104/2000] Fold 2, Train Loss: 0.0077, Val Loss: 0.0080\n",
      "Epoch [105/2000] Fold 2, Train Loss: 0.0077, Val Loss: 0.0079\n",
      "Epoch [106/2000] Fold 2, Train Loss: 0.0076, Val Loss: 0.0079\n",
      "Epoch [107/2000] Fold 2, Train Loss: 0.0076, Val Loss: 0.0079\n",
      "Epoch [108/2000] Fold 2, Train Loss: 0.0076, Val Loss: 0.0079\n",
      "Epoch [109/2000] Fold 2, Train Loss: 0.0076, Val Loss: 0.0078\n",
      "Epoch [110/2000] Fold 2, Train Loss: 0.0075, Val Loss: 0.0078\n",
      "Epoch [111/2000] Fold 2, Train Loss: 0.0075, Val Loss: 0.0078\n",
      "Epoch [112/2000] Fold 2, Train Loss: 0.0075, Val Loss: 0.0078\n",
      "Epoch [113/2000] Fold 2, Train Loss: 0.0075, Val Loss: 0.0078\n",
      "Epoch [114/2000] Fold 2, Train Loss: 0.0075, Val Loss: 0.0078\n",
      "Epoch [115/2000] Fold 2, Train Loss: 0.0074, Val Loss: 0.0077\n",
      "Epoch [116/2000] Fold 2, Train Loss: 0.0074, Val Loss: 0.0077\n",
      "Epoch [117/2000] Fold 2, Train Loss: 0.0074, Val Loss: 0.0077\n",
      "Epoch [118/2000] Fold 2, Train Loss: 0.0074, Val Loss: 0.0077\n",
      "Epoch [119/2000] Fold 2, Train Loss: 0.0074, Val Loss: 0.0077\n",
      "Epoch [120/2000] Fold 2, Train Loss: 0.0074, Val Loss: 0.0077\n",
      "Epoch [121/2000] Fold 2, Train Loss: 0.0074, Val Loss: 0.0077\n",
      "Epoch [122/2000] Fold 2, Train Loss: 0.0074, Val Loss: 0.0076\n",
      "Epoch [123/2000] Fold 2, Train Loss: 0.0073, Val Loss: 0.0076\n",
      "Epoch [124/2000] Fold 2, Train Loss: 0.0074, Val Loss: 0.0076\n",
      "Epoch [125/2000] Fold 2, Train Loss: 0.0073, Val Loss: 0.0076\n",
      "Epoch [126/2000] Fold 2, Train Loss: 0.0073, Val Loss: 0.0076\n",
      "Epoch [127/2000] Fold 2, Train Loss: 0.0073, Val Loss: 0.0076\n",
      "Epoch [128/2000] Fold 2, Train Loss: 0.0072, Val Loss: 0.0076\n",
      "Epoch [129/2000] Fold 2, Train Loss: 0.0072, Val Loss: 0.0076\n",
      "Epoch [130/2000] Fold 2, Train Loss: 0.0072, Val Loss: 0.0075\n",
      "Epoch [131/2000] Fold 2, Train Loss: 0.0072, Val Loss: 0.0075\n",
      "Epoch [132/2000] Fold 2, Train Loss: 0.0071, Val Loss: 0.0075\n",
      "Epoch [133/2000] Fold 2, Train Loss: 0.0072, Val Loss: 0.0075\n",
      "Epoch [134/2000] Fold 2, Train Loss: 0.0072, Val Loss: 0.0075\n",
      "Epoch [135/2000] Fold 2, Train Loss: 0.0072, Val Loss: 0.0075\n",
      "Epoch [136/2000] Fold 2, Train Loss: 0.0071, Val Loss: 0.0075\n",
      "Epoch [137/2000] Fold 2, Train Loss: 0.0071, Val Loss: 0.0075\n",
      "Epoch [138/2000] Fold 2, Train Loss: 0.0071, Val Loss: 0.0075\n",
      "Epoch [139/2000] Fold 2, Train Loss: 0.0071, Val Loss: 0.0075\n",
      "Epoch [140/2000] Fold 2, Train Loss: 0.0071, Val Loss: 0.0074\n",
      "Epoch [141/2000] Fold 2, Train Loss: 0.0071, Val Loss: 0.0074\n",
      "Epoch [142/2000] Fold 2, Train Loss: 0.0071, Val Loss: 0.0074\n",
      "Epoch [143/2000] Fold 2, Train Loss: 0.0070, Val Loss: 0.0074\n",
      "Epoch [144/2000] Fold 2, Train Loss: 0.0071, Val Loss: 0.0074\n",
      "Epoch [145/2000] Fold 2, Train Loss: 0.0070, Val Loss: 0.0074\n",
      "Epoch [146/2000] Fold 2, Train Loss: 0.0069, Val Loss: 0.0074\n",
      "Epoch [147/2000] Fold 2, Train Loss: 0.0070, Val Loss: 0.0074\n",
      "Epoch [148/2000] Fold 2, Train Loss: 0.0070, Val Loss: 0.0074\n",
      "Epoch [149/2000] Fold 2, Train Loss: 0.0069, Val Loss: 0.0073\n",
      "Epoch [150/2000] Fold 2, Train Loss: 0.0069, Val Loss: 0.0073\n",
      "Epoch [151/2000] Fold 2, Train Loss: 0.0069, Val Loss: 0.0073\n",
      "Epoch [152/2000] Fold 2, Train Loss: 0.0069, Val Loss: 0.0073\n",
      "Epoch [153/2000] Fold 2, Train Loss: 0.0069, Val Loss: 0.0073\n",
      "Epoch [154/2000] Fold 2, Train Loss: 0.0069, Val Loss: 0.0073\n",
      "Epoch [155/2000] Fold 2, Train Loss: 0.0070, Val Loss: 0.0073\n",
      "Epoch [156/2000] Fold 2, Train Loss: 0.0069, Val Loss: 0.0072\n",
      "Epoch [157/2000] Fold 2, Train Loss: 0.0069, Val Loss: 0.0073\n",
      "Epoch [158/2000] Fold 2, Train Loss: 0.0069, Val Loss: 0.0072\n",
      "Epoch [159/2000] Fold 2, Train Loss: 0.0068, Val Loss: 0.0072\n",
      "Epoch [160/2000] Fold 2, Train Loss: 0.0068, Val Loss: 0.0072\n",
      "Epoch [161/2000] Fold 2, Train Loss: 0.0068, Val Loss: 0.0072\n",
      "Epoch [162/2000] Fold 2, Train Loss: 0.0068, Val Loss: 0.0071\n",
      "Epoch [163/2000] Fold 2, Train Loss: 0.0068, Val Loss: 0.0072\n",
      "Epoch [164/2000] Fold 2, Train Loss: 0.0067, Val Loss: 0.0072\n",
      "Epoch [165/2000] Fold 2, Train Loss: 0.0067, Val Loss: 0.0071\n",
      "Epoch [166/2000] Fold 2, Train Loss: 0.0067, Val Loss: 0.0071\n",
      "Epoch [167/2000] Fold 2, Train Loss: 0.0067, Val Loss: 0.0071\n",
      "Epoch [168/2000] Fold 2, Train Loss: 0.0067, Val Loss: 0.0070\n",
      "Epoch [169/2000] Fold 2, Train Loss: 0.0066, Val Loss: 0.0070\n",
      "Epoch [170/2000] Fold 2, Train Loss: 0.0066, Val Loss: 0.0070\n",
      "Epoch [171/2000] Fold 2, Train Loss: 0.0066, Val Loss: 0.0070\n",
      "Epoch [172/2000] Fold 2, Train Loss: 0.0066, Val Loss: 0.0069\n",
      "Epoch [173/2000] Fold 2, Train Loss: 0.0065, Val Loss: 0.0069\n",
      "Epoch [174/2000] Fold 2, Train Loss: 0.0065, Val Loss: 0.0069\n",
      "Epoch [175/2000] Fold 2, Train Loss: 0.0065, Val Loss: 0.0069\n",
      "Epoch [176/2000] Fold 2, Train Loss: 0.0065, Val Loss: 0.0069\n",
      "Epoch [177/2000] Fold 2, Train Loss: 0.0064, Val Loss: 0.0068\n",
      "Epoch [178/2000] Fold 2, Train Loss: 0.0064, Val Loss: 0.0068\n",
      "Epoch [179/2000] Fold 2, Train Loss: 0.0064, Val Loss: 0.0068\n",
      "Epoch [180/2000] Fold 2, Train Loss: 0.0064, Val Loss: 0.0068\n",
      "Epoch [181/2000] Fold 2, Train Loss: 0.0064, Val Loss: 0.0067\n",
      "Epoch [182/2000] Fold 2, Train Loss: 0.0064, Val Loss: 0.0068\n",
      "Epoch [183/2000] Fold 2, Train Loss: 0.0064, Val Loss: 0.0067\n",
      "Epoch [184/2000] Fold 2, Train Loss: 0.0063, Val Loss: 0.0069\n",
      "Epoch [185/2000] Fold 2, Train Loss: 0.0063, Val Loss: 0.0067\n",
      "Epoch [186/2000] Fold 2, Train Loss: 0.0063, Val Loss: 0.0067\n",
      "Epoch [187/2000] Fold 2, Train Loss: 0.0063, Val Loss: 0.0067\n",
      "Epoch [188/2000] Fold 2, Train Loss: 0.0062, Val Loss: 0.0067\n",
      "Epoch [189/2000] Fold 2, Train Loss: 0.0062, Val Loss: 0.0067\n",
      "Epoch [190/2000] Fold 2, Train Loss: 0.0063, Val Loss: 0.0066\n",
      "Epoch [191/2000] Fold 2, Train Loss: 0.0062, Val Loss: 0.0066\n",
      "Epoch [192/2000] Fold 2, Train Loss: 0.0063, Val Loss: 0.0066\n",
      "Epoch [193/2000] Fold 2, Train Loss: 0.0062, Val Loss: 0.0066\n",
      "Epoch [194/2000] Fold 2, Train Loss: 0.0062, Val Loss: 0.0066\n",
      "Epoch [195/2000] Fold 2, Train Loss: 0.0061, Val Loss: 0.0066\n",
      "Epoch [196/2000] Fold 2, Train Loss: 0.0061, Val Loss: 0.0066\n",
      "Epoch [197/2000] Fold 2, Train Loss: 0.0061, Val Loss: 0.0066\n",
      "Epoch [198/2000] Fold 2, Train Loss: 0.0061, Val Loss: 0.0065\n",
      "Epoch [199/2000] Fold 2, Train Loss: 0.0061, Val Loss: 0.0065\n",
      "Epoch [200/2000] Fold 2, Train Loss: 0.0061, Val Loss: 0.0066\n",
      "Epoch [201/2000] Fold 2, Train Loss: 0.0061, Val Loss: 0.0066\n",
      "Epoch [202/2000] Fold 2, Train Loss: 0.0061, Val Loss: 0.0065\n",
      "Epoch [203/2000] Fold 2, Train Loss: 0.0061, Val Loss: 0.0066\n",
      "Epoch [204/2000] Fold 2, Train Loss: 0.0061, Val Loss: 0.0065\n",
      "Epoch [205/2000] Fold 2, Train Loss: 0.0060, Val Loss: 0.0065\n",
      "Epoch [206/2000] Fold 2, Train Loss: 0.0060, Val Loss: 0.0065\n",
      "Epoch [207/2000] Fold 2, Train Loss: 0.0060, Val Loss: 0.0065\n",
      "Epoch [208/2000] Fold 2, Train Loss: 0.0060, Val Loss: 0.0065\n",
      "Epoch [209/2000] Fold 2, Train Loss: 0.0060, Val Loss: 0.0066\n",
      "Epoch [210/2000] Fold 2, Train Loss: 0.0060, Val Loss: 0.0066\n",
      "Epoch [211/2000] Fold 2, Train Loss: 0.0060, Val Loss: 0.0065\n",
      "Epoch [212/2000] Fold 2, Train Loss: 0.0060, Val Loss: 0.0065\n",
      "Epoch [213/2000] Fold 2, Train Loss: 0.0060, Val Loss: 0.0065\n",
      "Epoch [214/2000] Fold 2, Train Loss: 0.0060, Val Loss: 0.0066\n",
      "Epoch [215/2000] Fold 2, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [216/2000] Fold 2, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [217/2000] Fold 2, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [218/2000] Fold 2, Train Loss: 0.0059, Val Loss: 0.0064\n",
      "Epoch [219/2000] Fold 2, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [220/2000] Fold 2, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [221/2000] Fold 2, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [222/2000] Fold 2, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [223/2000] Fold 2, Train Loss: 0.0059, Val Loss: 0.0064\n",
      "Epoch [224/2000] Fold 2, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [225/2000] Fold 2, Train Loss: 0.0059, Val Loss: 0.0064\n",
      "Epoch [226/2000] Fold 2, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [227/2000] Fold 2, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [228/2000] Fold 2, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [229/2000] Fold 2, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [230/2000] Fold 2, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [231/2000] Fold 2, Train Loss: 0.0058, Val Loss: 0.0065\n",
      "Epoch [232/2000] Fold 2, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [233/2000] Fold 2, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [234/2000] Fold 2, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [235/2000] Fold 2, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [236/2000] Fold 2, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [237/2000] Fold 2, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [238/2000] Fold 2, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [239/2000] Fold 2, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [240/2000] Fold 2, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [241/2000] Fold 2, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [242/2000] Fold 2, Train Loss: 0.0057, Val Loss: 0.0065\n",
      "Epoch [243/2000] Fold 2, Train Loss: 0.0058, Val Loss: 0.0065\n",
      "Epoch [244/2000] Fold 2, Train Loss: 0.0057, Val Loss: 0.0064\n",
      "Epoch [245/2000] Fold 2, Train Loss: 0.0057, Val Loss: 0.0064\n",
      "Epoch [246/2000] Fold 2, Train Loss: 0.0057, Val Loss: 0.0063\n",
      "Epoch [247/2000] Fold 2, Train Loss: 0.0057, Val Loss: 0.0064\n",
      "Epoch [248/2000] Fold 2, Train Loss: 0.0057, Val Loss: 0.0065\n",
      "Epoch [249/2000] Fold 2, Train Loss: 0.0057, Val Loss: 0.0064\n",
      "Epoch [250/2000] Fold 2, Train Loss: 0.0057, Val Loss: 0.0064\n",
      "Epoch [251/2000] Fold 2, Train Loss: 0.0057, Val Loss: 0.0064\n",
      "Epoch [252/2000] Fold 2, Train Loss: 0.0057, Val Loss: 0.0064\n",
      "Epoch [253/2000] Fold 2, Train Loss: 0.0057, Val Loss: 0.0065\n",
      "Epoch [254/2000] Fold 2, Train Loss: 0.0057, Val Loss: 0.0063\n",
      "Epoch [255/2000] Fold 2, Train Loss: 0.0056, Val Loss: 0.0063\n",
      "Epoch [256/2000] Fold 2, Train Loss: 0.0056, Val Loss: 0.0064\n",
      "Epoch [257/2000] Fold 2, Train Loss: 0.0056, Val Loss: 0.0064\n",
      "Epoch [258/2000] Fold 2, Train Loss: 0.0056, Val Loss: 0.0064\n",
      "Epoch [259/2000] Fold 2, Train Loss: 0.0056, Val Loss: 0.0064\n",
      "Epoch [260/2000] Fold 2, Train Loss: 0.0056, Val Loss: 0.0064\n",
      "Epoch [261/2000] Fold 2, Train Loss: 0.0056, Val Loss: 0.0063\n",
      "Epoch [262/2000] Fold 2, Train Loss: 0.0056, Val Loss: 0.0063\n",
      "Epoch [263/2000] Fold 2, Train Loss: 0.0056, Val Loss: 0.0064\n",
      "Epoch [264/2000] Fold 2, Train Loss: 0.0056, Val Loss: 0.0064\n",
      "Epoch [265/2000] Fold 2, Train Loss: 0.0056, Val Loss: 0.0063\n",
      "Epoch [266/2000] Fold 2, Train Loss: 0.0056, Val Loss: 0.0063\n",
      "Epoch [267/2000] Fold 2, Train Loss: 0.0056, Val Loss: 0.0063\n",
      "Epoch [268/2000] Fold 2, Train Loss: 0.0055, Val Loss: 0.0063\n",
      "Epoch [269/2000] Fold 2, Train Loss: 0.0055, Val Loss: 0.0063\n",
      "Epoch [270/2000] Fold 2, Train Loss: 0.0056, Val Loss: 0.0063\n",
      "Epoch [271/2000] Fold 2, Train Loss: 0.0055, Val Loss: 0.0063\n",
      "Epoch [272/2000] Fold 2, Train Loss: 0.0055, Val Loss: 0.0063\n",
      "Epoch [273/2000] Fold 2, Train Loss: 0.0056, Val Loss: 0.0062\n",
      "Epoch [274/2000] Fold 2, Train Loss: 0.0055, Val Loss: 0.0063\n",
      "Epoch [275/2000] Fold 2, Train Loss: 0.0055, Val Loss: 0.0063\n",
      "Epoch [276/2000] Fold 2, Train Loss: 0.0055, Val Loss: 0.0063\n",
      "Epoch [277/2000] Fold 2, Train Loss: 0.0055, Val Loss: 0.0063\n",
      "Epoch [278/2000] Fold 2, Train Loss: 0.0055, Val Loss: 0.0062\n",
      "Epoch [279/2000] Fold 2, Train Loss: 0.0054, Val Loss: 0.0063\n",
      "Epoch [280/2000] Fold 2, Train Loss: 0.0055, Val Loss: 0.0063\n",
      "Epoch [281/2000] Fold 2, Train Loss: 0.0054, Val Loss: 0.0062\n",
      "Epoch [282/2000] Fold 2, Train Loss: 0.0054, Val Loss: 0.0062\n",
      "Epoch [283/2000] Fold 2, Train Loss: 0.0054, Val Loss: 0.0063\n",
      "Epoch [284/2000] Fold 2, Train Loss: 0.0054, Val Loss: 0.0062\n",
      "Epoch [285/2000] Fold 2, Train Loss: 0.0054, Val Loss: 0.0062\n",
      "Epoch [286/2000] Fold 2, Train Loss: 0.0054, Val Loss: 0.0063\n",
      "Epoch [287/2000] Fold 2, Train Loss: 0.0054, Val Loss: 0.0062\n",
      "Epoch [288/2000] Fold 2, Train Loss: 0.0054, Val Loss: 0.0063\n",
      "Epoch [289/2000] Fold 2, Train Loss: 0.0054, Val Loss: 0.0063\n",
      "Epoch [290/2000] Fold 2, Train Loss: 0.0054, Val Loss: 0.0062\n",
      "Epoch [291/2000] Fold 2, Train Loss: 0.0054, Val Loss: 0.0062\n",
      "Epoch [292/2000] Fold 2, Train Loss: 0.0054, Val Loss: 0.0062\n",
      "Epoch [293/2000] Fold 2, Train Loss: 0.0054, Val Loss: 0.0062\n",
      "Epoch [294/2000] Fold 2, Train Loss: 0.0054, Val Loss: 0.0062\n",
      "Epoch [295/2000] Fold 2, Train Loss: 0.0053, Val Loss: 0.0063\n",
      "Epoch [296/2000] Fold 2, Train Loss: 0.0053, Val Loss: 0.0062\n",
      "Epoch [297/2000] Fold 2, Train Loss: 0.0054, Val Loss: 0.0063\n",
      "Epoch [298/2000] Fold 2, Train Loss: 0.0053, Val Loss: 0.0062\n",
      "Epoch [299/2000] Fold 2, Train Loss: 0.0053, Val Loss: 0.0062\n",
      "Epoch [300/2000] Fold 2, Train Loss: 0.0053, Val Loss: 0.0062\n",
      "Epoch [301/2000] Fold 2, Train Loss: 0.0053, Val Loss: 0.0062\n",
      "Epoch [302/2000] Fold 2, Train Loss: 0.0053, Val Loss: 0.0062\n",
      "Epoch [303/2000] Fold 2, Train Loss: 0.0053, Val Loss: 0.0063\n",
      "Epoch [304/2000] Fold 2, Train Loss: 0.0053, Val Loss: 0.0062\n",
      "Epoch [305/2000] Fold 2, Train Loss: 0.0053, Val Loss: 0.0062\n",
      "Epoch [306/2000] Fold 2, Train Loss: 0.0054, Val Loss: 0.0062\n",
      "Epoch [307/2000] Fold 2, Train Loss: 0.0053, Val Loss: 0.0062\n",
      "Epoch [308/2000] Fold 2, Train Loss: 0.0053, Val Loss: 0.0062\n",
      "Epoch [309/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [310/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [311/2000] Fold 2, Train Loss: 0.0053, Val Loss: 0.0062\n",
      "Epoch [312/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [313/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [314/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [315/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0063\n",
      "Epoch [316/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [317/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [318/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [319/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [320/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [321/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0061\n",
      "Epoch [322/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0061\n",
      "Epoch [323/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [324/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [325/2000] Fold 2, Train Loss: 0.0051, Val Loss: 0.0062\n",
      "Epoch [326/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [327/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [328/2000] Fold 2, Train Loss: 0.0051, Val Loss: 0.0061\n",
      "Epoch [329/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [330/2000] Fold 2, Train Loss: 0.0051, Val Loss: 0.0061\n",
      "Epoch [331/2000] Fold 2, Train Loss: 0.0051, Val Loss: 0.0062\n",
      "Epoch [332/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0061\n",
      "Epoch [333/2000] Fold 2, Train Loss: 0.0051, Val Loss: 0.0061\n",
      "Epoch [334/2000] Fold 2, Train Loss: 0.0052, Val Loss: 0.0061\n",
      "Epoch [335/2000] Fold 2, Train Loss: 0.0051, Val Loss: 0.0062\n",
      "Epoch [336/2000] Fold 2, Train Loss: 0.0051, Val Loss: 0.0061\n",
      "Epoch [337/2000] Fold 2, Train Loss: 0.0051, Val Loss: 0.0062\n",
      "Epoch [338/2000] Fold 2, Train Loss: 0.0051, Val Loss: 0.0061\n",
      "Epoch [339/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [340/2000] Fold 2, Train Loss: 0.0051, Val Loss: 0.0062\n",
      "Epoch [341/2000] Fold 2, Train Loss: 0.0051, Val Loss: 0.0061\n",
      "Epoch [342/2000] Fold 2, Train Loss: 0.0051, Val Loss: 0.0061\n",
      "Epoch [343/2000] Fold 2, Train Loss: 0.0051, Val Loss: 0.0061\n",
      "Epoch [344/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [345/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [346/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [347/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [348/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [349/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [350/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [351/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [352/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [353/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [354/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [355/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [356/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [357/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [358/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [359/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [360/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [361/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [362/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [363/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [364/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [365/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0062\n",
      "Epoch [366/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [367/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0062\n",
      "Epoch [368/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [369/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [370/2000] Fold 2, Train Loss: 0.0049, Val Loss: 0.0061\n",
      "Epoch [371/2000] Fold 2, Train Loss: 0.0049, Val Loss: 0.0061\n",
      "Epoch [372/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [373/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [374/2000] Fold 2, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [375/2000] Fold 2, Train Loss: 0.0049, Val Loss: 0.0061\n",
      "Epoch [376/2000] Fold 2, Train Loss: 0.0049, Val Loss: 0.0061\n",
      "Epoch [377/2000] Fold 2, Train Loss: 0.0049, Val Loss: 0.0061\n",
      "Epoch [378/2000] Fold 2, Train Loss: 0.0049, Val Loss: 0.0061\n",
      "Epoch [379/2000] Fold 2, Train Loss: 0.0049, Val Loss: 0.0061\n",
      "Epoch [380/2000] Fold 2, Train Loss: 0.0049, Val Loss: 0.0061\n",
      "Epoch [381/2000] Fold 2, Train Loss: 0.0049, Val Loss: 0.0061\n",
      "Epoch [382/2000] Fold 2, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [383/2000] Fold 2, Train Loss: 0.0049, Val Loss: 0.0061\n",
      "Epoch [384/2000] Fold 2, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [385/2000] Fold 2, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [386/2000] Fold 2, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [387/2000] Fold 2, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [388/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [389/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [390/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [391/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [392/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [393/2000] Fold 2, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [394/2000] Fold 2, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [395/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [396/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [397/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [398/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0061\n",
      "Epoch [399/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [400/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [401/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [402/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [403/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [404/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [405/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [406/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [407/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [408/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [409/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [410/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [411/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [412/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0061\n",
      "Epoch [413/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0061\n",
      "Epoch [414/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [415/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [416/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [417/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [418/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0061\n",
      "Epoch [419/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [420/2000] Fold 2, Train Loss: 0.0048, Val Loss: 0.0061\n",
      "Epoch [421/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [422/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [423/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [424/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [425/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [426/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [427/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [428/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [429/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [430/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [431/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [432/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [433/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [434/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [435/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [436/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [437/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [438/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [439/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [440/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [441/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [442/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [443/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0060\n",
      "Epoch [444/2000] Fold 2, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [445/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0060\n",
      "Epoch [446/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0060\n",
      "Epoch [447/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0059\n",
      "Epoch [448/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0059\n",
      "Epoch [449/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0059\n",
      "Epoch [450/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0059\n",
      "Epoch [451/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0060\n",
      "Epoch [452/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0060\n",
      "Epoch [453/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0059\n",
      "Epoch [454/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0060\n",
      "Epoch [455/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0060\n",
      "Epoch [456/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0059\n",
      "Epoch [457/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0060\n",
      "Epoch [458/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0060\n",
      "Epoch [459/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0060\n",
      "Epoch [460/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0060\n",
      "Epoch [461/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0059\n",
      "Epoch [462/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0059\n",
      "Epoch [463/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0059\n",
      "Epoch [464/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [465/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0059\n",
      "Epoch [466/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0059\n",
      "Epoch [467/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0060\n",
      "Epoch [468/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0059\n",
      "Epoch [469/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0061\n",
      "Epoch [470/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0059\n",
      "Epoch [471/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0059\n",
      "Epoch [472/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0059\n",
      "Epoch [473/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0060\n",
      "Epoch [474/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0059\n",
      "Epoch [475/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [476/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [477/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [478/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0060\n",
      "Epoch [479/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0058\n",
      "Epoch [480/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [481/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [482/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [483/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [484/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [485/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [486/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [487/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [488/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [489/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0060\n",
      "Epoch [490/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [491/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [492/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0058\n",
      "Epoch [493/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0060\n",
      "Epoch [494/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0058\n",
      "Epoch [495/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [496/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0059\n",
      "Epoch [497/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0059\n",
      "Epoch [498/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0059\n",
      "Epoch [499/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0058\n",
      "Epoch [500/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0058\n",
      "Epoch [501/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0059\n",
      "Epoch [502/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0059\n",
      "Epoch [503/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [504/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [505/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [506/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0061\n",
      "Epoch [507/2000] Fold 2, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch [508/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0058\n",
      "Epoch [509/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [510/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [511/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [512/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0058\n",
      "Epoch [513/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0058\n",
      "Epoch [514/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0059\n",
      "Epoch [515/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0058\n",
      "Epoch [516/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0059\n",
      "Epoch [517/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0059\n",
      "Epoch [518/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0058\n",
      "Epoch [519/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0059\n",
      "Epoch [520/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0058\n",
      "Epoch [521/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0059\n",
      "Epoch [522/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0059\n",
      "Epoch [523/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0058\n",
      "Epoch [524/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0059\n",
      "Epoch [525/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0058\n",
      "Epoch [526/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0058\n",
      "Epoch [527/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0060\n",
      "Epoch [528/2000] Fold 2, Train Loss: 0.0045, Val Loss: 0.0058\n",
      "Epoch [529/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0058\n",
      "Epoch [530/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0059\n",
      "Epoch [531/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0058\n",
      "Epoch [532/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0059\n",
      "Epoch [533/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0058\n",
      "Epoch [534/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [535/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [536/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [537/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0059\n",
      "Epoch [538/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0058\n",
      "Epoch [539/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0059\n",
      "Epoch [540/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0058\n",
      "Epoch [541/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [542/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [543/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0059\n",
      "Epoch [544/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [545/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0058\n",
      "Epoch [546/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [547/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [548/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [549/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0059\n",
      "Epoch [550/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0059\n",
      "Epoch [551/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0060\n",
      "Epoch [552/2000] Fold 2, Train Loss: 0.0044, Val Loss: 0.0058\n",
      "Epoch [553/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0059\n",
      "Epoch [554/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0057\n",
      "Epoch [555/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [556/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0059\n",
      "Epoch [557/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [558/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [559/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [560/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [561/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0059\n",
      "Epoch [562/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [563/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [564/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [565/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0058\n",
      "Epoch [566/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0058\n",
      "Epoch [567/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [568/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0057\n",
      "Epoch [569/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [570/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [571/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [572/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [573/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0058\n",
      "Epoch [574/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0058\n",
      "Epoch [575/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0057\n",
      "Epoch [576/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [577/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [578/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0058\n",
      "Epoch [579/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0058\n",
      "Epoch [580/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [581/2000] Fold 2, Train Loss: 0.0043, Val Loss: 0.0058\n",
      "Epoch [582/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [583/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [584/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [585/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0058\n",
      "Epoch [586/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [587/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0058\n",
      "Epoch [588/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [589/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [590/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [591/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0058\n",
      "Epoch [592/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0058\n",
      "Epoch [593/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [594/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0058\n",
      "Epoch [595/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [596/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [597/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [598/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [599/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0056\n",
      "Epoch [600/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0058\n",
      "Epoch [601/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0058\n",
      "Epoch [602/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [603/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [604/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [605/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0058\n",
      "Epoch [606/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [607/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [608/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [609/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0058\n",
      "Epoch [610/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0058\n",
      "Epoch [611/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [612/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [613/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [614/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0058\n",
      "Epoch [615/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [616/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [617/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0058\n",
      "Epoch [618/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0058\n",
      "Epoch [619/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0058\n",
      "Epoch [620/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0058\n",
      "Epoch [621/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0057\n",
      "Epoch [622/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [623/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [624/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [625/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [626/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [627/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [628/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [629/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [630/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0056\n",
      "Epoch [631/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [632/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [633/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [634/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [635/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [636/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [637/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [638/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [639/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0056\n",
      "Epoch [640/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [641/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [642/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [643/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [644/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [645/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [646/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0056\n",
      "Epoch [647/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [648/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [649/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [650/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [651/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0056\n",
      "Epoch [652/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [653/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0056\n",
      "Epoch [654/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0056\n",
      "Epoch [655/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [656/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [657/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [658/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [659/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [660/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0056\n",
      "Epoch [661/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0057\n",
      "Epoch [662/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0056\n",
      "Epoch [663/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [664/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0056\n",
      "Epoch [665/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [666/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [667/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0057\n",
      "Epoch [668/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [669/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [670/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [671/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [672/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0057\n",
      "Epoch [673/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [674/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [675/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0056\n",
      "Epoch [676/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0056\n",
      "Epoch [677/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0056\n",
      "Epoch [678/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [679/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0056\n",
      "Epoch [680/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0056\n",
      "Epoch [681/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [682/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0056\n",
      "Epoch [683/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [684/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [685/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [686/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0057\n",
      "Epoch [687/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [688/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [689/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0057\n",
      "Epoch [690/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0057\n",
      "Epoch [691/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0059\n",
      "Epoch [692/2000] Fold 2, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [693/2000] Fold 2, Train Loss: 0.0041, Val Loss: 0.0056\n",
      "Epoch [694/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [695/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [696/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0057\n",
      "Epoch [697/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0057\n",
      "Epoch [698/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [699/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [700/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [701/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [702/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [703/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [704/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [705/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [706/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [707/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0055\n",
      "Epoch [708/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [709/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [710/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [711/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [712/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [713/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [714/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [715/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [716/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [717/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0055\n",
      "Epoch [718/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [719/2000] Fold 2, Train Loss: 0.0040, Val Loss: 0.0056\n",
      "Epoch [720/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [721/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [722/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [723/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [724/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [725/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [726/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [727/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [728/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [729/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0055\n",
      "Epoch [730/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [731/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [732/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [733/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [734/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [735/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0055\n",
      "Epoch [736/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [737/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [738/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [739/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [740/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [741/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [742/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [743/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [744/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0055\n",
      "Epoch [745/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0055\n",
      "Epoch [746/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [747/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0055\n",
      "Epoch [748/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0055\n",
      "Epoch [749/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [750/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0055\n",
      "Epoch [751/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0055\n",
      "Epoch [752/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [753/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0056\n",
      "Epoch [754/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0055\n",
      "Epoch [755/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [756/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [757/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [758/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0055\n",
      "Epoch [759/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [760/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [761/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [762/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [763/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0056\n",
      "Epoch [764/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [765/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0056\n",
      "Epoch [766/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0056\n",
      "Epoch [767/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0055\n",
      "Epoch [768/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0056\n",
      "Epoch [769/2000] Fold 2, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [770/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0055\n",
      "Epoch [771/2000] Fold 2, Train Loss: 0.0038, Val Loss: 0.0054\n",
      "Epoch [772/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [773/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0056\n",
      "Epoch [774/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [775/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0054\n",
      "Epoch [776/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [777/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0054\n",
      "Epoch [778/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [779/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [780/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [781/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0054\n",
      "Epoch [782/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [783/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [784/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [785/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [786/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [787/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0055\n",
      "Epoch [788/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0055\n",
      "Epoch [789/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0055\n",
      "Epoch [790/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [791/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0054\n",
      "Epoch [792/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0054\n",
      "Epoch [793/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [794/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0055\n",
      "Epoch [795/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0055\n",
      "Epoch [796/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0054\n",
      "Epoch [797/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0056\n",
      "Epoch [798/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0055\n",
      "Epoch [799/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0054\n",
      "Epoch [800/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [801/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0055\n",
      "Epoch [802/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [803/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [804/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0055\n",
      "Epoch [805/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0055\n",
      "Epoch [806/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [807/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [808/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [809/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [810/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [811/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0055\n",
      "Epoch [812/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0055\n",
      "Epoch [813/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [814/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0056\n",
      "Epoch [815/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [816/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [817/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [818/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [819/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [820/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [821/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [822/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [823/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [824/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [825/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [826/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0055\n",
      "Epoch [827/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0055\n",
      "Epoch [828/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [829/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [830/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [831/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [832/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0055\n",
      "Epoch [833/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [834/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [835/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0054\n",
      "Epoch [836/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [837/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0055\n",
      "Epoch [838/2000] Fold 2, Train Loss: 0.0037, Val Loss: 0.0053\n",
      "Epoch [839/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [840/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0053\n",
      "Epoch [841/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0053\n",
      "Epoch [842/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [843/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [844/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0055\n",
      "Epoch [845/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [846/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [847/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [848/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [849/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [850/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0053\n",
      "Epoch [851/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [852/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [853/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [854/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [855/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [856/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [857/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [858/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [859/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0053\n",
      "Epoch [860/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [861/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0055\n",
      "Epoch [862/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0055\n",
      "Epoch [863/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [864/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [865/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [866/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [867/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [868/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [869/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [870/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [871/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [872/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [873/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [874/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [875/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [876/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [877/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0055\n",
      "Epoch [878/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0055\n",
      "Epoch [879/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0055\n",
      "Epoch [880/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [881/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [882/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [883/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [884/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [885/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [886/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [887/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [888/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [889/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [890/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [891/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0053\n",
      "Epoch [892/2000] Fold 2, Train Loss: 0.0036, Val Loss: 0.0054\n",
      "Epoch [893/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0053\n",
      "Epoch [894/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [895/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [896/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [897/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [898/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [899/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0053\n",
      "Epoch [900/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [901/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [902/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [903/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [904/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [905/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [906/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [907/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [908/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [909/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0055\n",
      "Epoch [910/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [911/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [912/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [913/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [914/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [915/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [916/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [917/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [918/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [919/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [920/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [921/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [922/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [923/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [924/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0053\n",
      "Epoch [925/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [926/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [927/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [928/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [929/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [930/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [931/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [932/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [933/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [934/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [935/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [936/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0054\n",
      "Epoch [937/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [938/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [939/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [940/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [941/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [942/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [943/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [944/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0054\n",
      "Epoch [945/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [946/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [947/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [948/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [949/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [950/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [951/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [952/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [953/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0054\n",
      "Epoch [954/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [955/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0054\n",
      "Epoch [956/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [957/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [958/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [959/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [960/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [961/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [962/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0054\n",
      "Epoch [963/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0053\n",
      "Epoch [964/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [965/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [966/2000] Fold 2, Train Loss: 0.0035, Val Loss: 0.0053\n",
      "Epoch [967/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [968/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0052\n",
      "Epoch [969/2000] Fold 2, Train Loss: 0.0034, Val Loss: 0.0053\n",
      "Epoch [970/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [971/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0052\n",
      "Epoch [972/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [973/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [974/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [975/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0053\n",
      "Epoch [976/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [977/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [978/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [979/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0053\n",
      "Epoch [980/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [981/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0052\n",
      "Epoch [982/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [983/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [984/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [985/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [986/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [987/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0052\n",
      "Epoch [988/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0052\n",
      "Epoch [989/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [990/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [991/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0052\n",
      "Epoch [992/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0053\n",
      "Epoch [993/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [994/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [995/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [996/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [997/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0052\n",
      "Epoch [998/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [999/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1000/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1001/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1002/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0053\n",
      "Epoch [1003/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1004/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0052\n",
      "Epoch [1005/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1006/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1007/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1008/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0053\n",
      "Epoch [1009/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0053\n",
      "Epoch [1010/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0053\n",
      "Epoch [1011/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0053\n",
      "Epoch [1012/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1013/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0053\n",
      "Epoch [1014/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1015/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1016/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1017/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [1018/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [1019/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0053\n",
      "Epoch [1020/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0053\n",
      "Epoch [1021/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1022/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1023/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1024/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0053\n",
      "Epoch [1025/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0053\n",
      "Epoch [1026/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1027/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1028/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0052\n",
      "Epoch [1029/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1030/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0052\n",
      "Epoch [1031/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0052\n",
      "Epoch [1032/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1033/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1034/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1035/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0051\n",
      "Epoch [1036/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0053\n",
      "Epoch [1037/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1038/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0052\n",
      "Epoch [1039/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1040/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1041/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1042/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1043/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1044/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1045/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0052\n",
      "Epoch [1046/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1047/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0052\n",
      "Epoch [1048/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1049/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0053\n",
      "Epoch [1050/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1051/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1052/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0052\n",
      "Epoch [1053/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1054/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1055/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0051\n",
      "Epoch [1056/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0051\n",
      "Epoch [1057/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1058/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1059/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1060/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0052\n",
      "Epoch [1061/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1062/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0053\n",
      "Epoch [1063/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0052\n",
      "Epoch [1064/2000] Fold 2, Train Loss: 0.0033, Val Loss: 0.0054\n",
      "Epoch [1065/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0051\n",
      "Epoch [1066/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1067/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0052\n",
      "Epoch [1068/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0052\n",
      "Epoch [1069/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1070/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1071/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1072/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1073/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1074/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1075/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1076/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1077/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1078/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1079/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1080/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0052\n",
      "Epoch [1081/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1082/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0051\n",
      "Epoch [1083/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1084/2000] Fold 2, Train Loss: 0.0032, Val Loss: 0.0052\n",
      "Epoch [1085/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1086/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1087/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1088/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1089/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1090/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1091/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1092/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1093/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1094/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1095/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0050\n",
      "Epoch [1096/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1097/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1098/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1099/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1100/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1101/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1102/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1103/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1104/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0050\n",
      "Epoch [1105/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0052\n",
      "Epoch [1106/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1107/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1108/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1109/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1110/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0052\n",
      "Epoch [1111/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0052\n",
      "Epoch [1112/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1113/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1114/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1115/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1116/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1117/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1118/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1119/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1120/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1121/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1122/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0052\n",
      "Epoch [1123/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1124/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1125/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1126/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1127/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1128/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1129/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1130/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1131/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1132/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1133/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1134/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1135/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1136/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1137/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1138/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0052\n",
      "Epoch [1139/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1140/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1141/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1142/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1143/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1144/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1145/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1146/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1147/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1148/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1149/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1150/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1151/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1152/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1153/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1154/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1155/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1156/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1157/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0051\n",
      "Epoch [1158/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1159/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1160/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0052\n",
      "Epoch [1161/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1162/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1163/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1164/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1165/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1166/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1167/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1168/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1169/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1170/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1171/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1172/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1173/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1174/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1175/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1176/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1177/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1178/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1179/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1180/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1181/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1182/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1183/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1184/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1185/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1186/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1187/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1188/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1189/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1190/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1191/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1192/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1193/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1194/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1195/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1196/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1197/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1198/2000] Fold 2, Train Loss: 0.0031, Val Loss: 0.0051\n",
      "Epoch [1199/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1200/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0051\n",
      "Epoch [1201/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [1202/2000] Fold 2, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [1203/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1204/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1205/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1206/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1207/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1208/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1209/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1210/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1211/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1212/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1213/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1214/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1215/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1216/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [1217/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1218/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [1219/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1220/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1221/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1222/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1223/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1224/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1225/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1226/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1227/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1228/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1229/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1230/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1231/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1232/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [1233/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1234/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1235/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1236/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1237/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1238/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1239/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1240/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [1241/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1242/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1243/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0051\n",
      "Epoch [1244/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1245/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [1246/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [1247/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [1248/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1249/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1250/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1251/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1252/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1253/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1254/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1255/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1256/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1257/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1258/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1259/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1260/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1261/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1262/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1263/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1264/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1265/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1266/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [1267/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0051\n",
      "Epoch [1268/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [1269/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [1270/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1271/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1272/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1273/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1274/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1275/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1276/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1277/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1278/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1279/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1280/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [1281/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [1282/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1283/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [1284/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0050\n",
      "Epoch [1285/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [1286/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1287/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1288/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1289/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1290/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1291/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1292/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1293/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0051\n",
      "Epoch [1294/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [1295/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1296/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1297/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1298/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1299/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1300/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1301/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1302/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1303/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1304/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1305/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1306/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1307/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1308/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1309/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1310/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1311/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1312/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1313/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1314/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1315/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1316/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1317/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1318/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1319/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1320/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1321/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1322/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1323/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0048\n",
      "Epoch [1324/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0051\n",
      "Epoch [1325/2000] Fold 2, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [1326/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1327/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1328/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1329/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1330/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1331/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1332/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1333/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1334/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1335/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1336/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1337/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1338/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1339/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1340/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1341/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1342/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1343/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1344/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1345/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1346/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1347/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1348/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0051\n",
      "Epoch [1349/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1350/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1351/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1352/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1353/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1354/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1355/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1356/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0050\n",
      "Epoch [1357/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1358/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1359/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1360/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0050\n",
      "Epoch [1361/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0050\n",
      "Epoch [1362/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1363/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0048\n",
      "Epoch [1364/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0050\n",
      "Epoch [1365/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1366/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1367/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1368/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1369/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1370/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1371/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1372/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1373/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1374/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1375/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1376/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0050\n",
      "Epoch [1377/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1378/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1379/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0050\n",
      "Epoch [1380/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1381/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1382/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1383/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0050\n",
      "Epoch [1384/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1385/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0050\n",
      "Epoch [1386/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0052\n",
      "Epoch [1387/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1388/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0048\n",
      "Epoch [1389/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1390/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0050\n",
      "Epoch [1391/2000] Fold 2, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [1392/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1393/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1394/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1395/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1396/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1397/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1398/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1399/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1400/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1401/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1402/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1403/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1404/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1405/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1406/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1407/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1408/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1409/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1410/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1411/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0048\n",
      "Epoch [1412/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1413/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1414/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1415/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1416/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1417/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1418/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1419/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0049\n",
      "Epoch [1420/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1421/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1422/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1423/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1424/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1425/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1426/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1427/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1428/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1429/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1430/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1431/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1432/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1433/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1434/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1435/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1436/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1437/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0050\n",
      "Epoch [1438/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1439/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1440/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1441/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1442/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1443/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1444/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1445/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1446/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0050\n",
      "Epoch [1447/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0050\n",
      "Epoch [1448/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1449/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1450/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0050\n",
      "Epoch [1451/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1452/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1453/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1454/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1455/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0048\n",
      "Epoch [1456/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1457/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1458/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1459/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1460/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1461/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1462/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1463/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1464/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1465/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1466/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1467/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1468/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1469/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0050\n",
      "Epoch [1470/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1471/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1472/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1473/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0050\n",
      "Epoch [1474/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1475/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1476/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1477/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1478/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0051\n",
      "Epoch [1479/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0052\n",
      "Epoch [1480/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0050\n",
      "Epoch [1481/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1482/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1483/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1484/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1485/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1486/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1487/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1488/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0048\n",
      "Epoch [1489/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1490/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1491/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1492/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1493/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1494/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0050\n",
      "Epoch [1495/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1496/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1497/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0048\n",
      "Epoch [1498/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1499/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0048\n",
      "Epoch [1500/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1501/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0048\n",
      "Epoch [1502/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1503/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1504/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1505/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1506/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1507/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0048\n",
      "Epoch [1508/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0048\n",
      "Epoch [1509/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0050\n",
      "Epoch [1510/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1511/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1512/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1513/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1514/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1515/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0050\n",
      "Epoch [1516/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0050\n",
      "Epoch [1517/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0048\n",
      "Epoch [1518/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1519/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1520/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0050\n",
      "Epoch [1521/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1522/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0048\n",
      "Epoch [1523/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0050\n",
      "Epoch [1524/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1525/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1526/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1527/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0048\n",
      "Epoch [1528/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1529/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1530/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1531/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0048\n",
      "Epoch [1532/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1533/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1534/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0050\n",
      "Epoch [1535/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1536/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1537/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1538/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1539/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1540/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1541/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1542/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1543/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1544/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1545/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1546/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1547/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1548/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1549/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1550/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1551/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1552/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0048\n",
      "Epoch [1553/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1554/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1555/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1556/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0050\n",
      "Epoch [1557/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1558/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1559/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0048\n",
      "Epoch [1560/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1561/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1562/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1563/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1564/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1565/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1566/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0051\n",
      "Epoch [1567/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0050\n",
      "Epoch [1568/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1569/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1570/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1571/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1572/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1573/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1574/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1575/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1576/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0048\n",
      "Epoch [1577/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1578/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1579/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1580/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1581/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1582/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1583/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1584/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0050\n",
      "Epoch [1585/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1586/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0048\n",
      "Epoch [1587/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1588/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1589/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1590/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1591/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1592/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1593/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0051\n",
      "Epoch [1594/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0050\n",
      "Epoch [1595/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0050\n",
      "Epoch [1596/2000] Fold 2, Train Loss: 0.0027, Val Loss: 0.0050\n",
      "Epoch [1597/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1598/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1599/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0048\n",
      "Epoch [1600/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1601/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1602/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0048\n",
      "Epoch [1603/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1604/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1605/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1606/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1607/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1608/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1609/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1610/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0048\n",
      "Epoch [1611/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1612/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1613/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1614/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1615/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1616/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1617/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1618/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1619/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1620/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1621/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1622/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1623/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1624/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1625/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1626/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0049\n",
      "Epoch [1627/2000] Fold 2, Train Loss: 0.0025, Val Loss: 0.0050\n",
      "Epoch [1628/2000] Fold 2, Train Loss: 0.0026, Val Loss: 0.0049\n",
      "Epoch [1629/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1630/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1631/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1632/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1633/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1634/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1635/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1636/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1637/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1638/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0050\n",
      "Epoch [1639/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1640/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0048\n",
      "Epoch [1641/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1642/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1643/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0048\n",
      "Epoch [1644/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1645/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1646/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1647/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1648/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1649/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1650/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1651/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1652/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1653/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1654/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1655/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1656/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1657/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1658/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1659/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0050\n",
      "Epoch [1660/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0048\n",
      "Epoch [1661/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1662/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1663/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1664/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1665/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1666/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1667/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1668/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1669/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1670/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1671/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0048\n",
      "Epoch [1672/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1673/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1674/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1675/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0050\n",
      "Epoch [1676/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1677/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1678/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1679/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1680/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1681/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1682/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1683/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1684/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1685/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1686/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1687/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1688/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1689/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1690/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1691/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1692/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1693/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1694/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1695/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1696/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0050\n",
      "Epoch [1697/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0048\n",
      "Epoch [1698/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0048\n",
      "Epoch [1699/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1700/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1701/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1702/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1703/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1704/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1705/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1706/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1707/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1708/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1709/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1710/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1711/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1712/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1713/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1714/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1715/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0048\n",
      "Epoch [1716/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1717/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1718/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1719/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1720/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1721/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1722/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0048\n",
      "Epoch [1723/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1724/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0048\n",
      "Epoch [1725/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1726/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1727/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1728/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1729/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1730/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1731/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1732/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1733/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1734/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1735/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1736/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1737/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1738/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1739/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1740/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0048\n",
      "Epoch [1741/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1742/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1743/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0049\n",
      "Epoch [1744/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1745/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1746/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1747/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1748/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1749/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1750/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1751/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1752/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1753/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1754/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1755/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1756/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1757/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1758/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1759/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1760/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1761/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1762/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1763/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1764/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1765/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1766/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1767/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1768/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1769/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1770/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1771/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1772/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1773/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1774/2000] Fold 2, Train Loss: 0.0024, Val Loss: 0.0048\n",
      "Epoch [1775/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1776/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1777/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1778/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1779/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1780/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1781/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0050\n",
      "Epoch [1782/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1783/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1784/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1785/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1786/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1787/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1788/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1789/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1790/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1791/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1792/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1793/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1794/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1795/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1796/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1797/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1798/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1799/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1800/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1801/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1802/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1803/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1804/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1805/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1806/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1807/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1808/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1809/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1810/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1811/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1812/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1813/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1814/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1815/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1816/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1817/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1818/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1819/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0050\n",
      "Epoch [1820/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1821/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1822/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1823/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1824/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1825/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1826/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1827/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1828/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1829/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1830/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1831/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1832/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1833/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1834/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1835/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1836/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1837/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0050\n",
      "Epoch [1838/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1839/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1840/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1841/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1842/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1843/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1844/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1845/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0050\n",
      "Epoch [1846/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1847/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1848/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1849/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1850/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1851/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1852/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1853/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1854/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1855/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1856/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0050\n",
      "Epoch [1857/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1858/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0050\n",
      "Epoch [1859/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1860/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0050\n",
      "Epoch [1861/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1862/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1863/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0050\n",
      "Epoch [1864/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1865/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1866/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1867/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1868/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0050\n",
      "Epoch [1869/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1870/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0050\n",
      "Epoch [1871/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1872/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0050\n",
      "Epoch [1873/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0051\n",
      "Epoch [1874/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1875/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1876/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1877/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1878/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1879/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1880/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1881/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1882/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1883/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1884/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1885/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1886/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1887/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1888/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0050\n",
      "Epoch [1889/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1890/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0048\n",
      "Epoch [1891/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1892/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1893/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1894/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1895/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1896/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1897/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1898/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1899/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0050\n",
      "Epoch [1900/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1901/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1902/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1903/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0050\n",
      "Epoch [1904/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1905/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1906/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1907/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1908/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1909/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1910/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1911/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1912/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1913/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1914/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1915/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1916/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1917/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1918/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1919/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1920/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1921/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1922/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1923/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0050\n",
      "Epoch [1924/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0050\n",
      "Epoch [1925/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1926/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1927/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1928/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1929/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1930/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1931/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1932/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0050\n",
      "Epoch [1933/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0050\n",
      "Epoch [1934/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1935/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1936/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1937/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0048\n",
      "Epoch [1938/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1939/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1940/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1941/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1942/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0051\n",
      "Epoch [1943/2000] Fold 2, Train Loss: 0.0023, Val Loss: 0.0049\n",
      "Epoch [1944/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1945/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0050\n",
      "Epoch [1946/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1947/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1948/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1949/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1950/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1951/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1952/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1953/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1954/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1955/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1956/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1957/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1958/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1959/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1960/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0049\n",
      "Epoch [1961/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1962/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1963/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1964/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0050\n",
      "Epoch [1965/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1966/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1967/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1968/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1969/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1970/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1971/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1972/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1973/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1974/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1975/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1976/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1977/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1978/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1979/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1980/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1981/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1982/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1983/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1984/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1985/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1986/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1987/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1988/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1989/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1990/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1991/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1992/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0048\n",
      "Epoch [1993/2000] Fold 2, Train Loss: 0.0020, Val Loss: 0.0048\n",
      "Epoch [1994/2000] Fold 2, Train Loss: 0.0020, Val Loss: 0.0048\n",
      "Epoch [1995/2000] Fold 2, Train Loss: 0.0020, Val Loss: 0.0049\n",
      "Epoch [1996/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0050\n",
      "Epoch [1997/2000] Fold 2, Train Loss: 0.0022, Val Loss: 0.0048\n",
      "Epoch [1998/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [1999/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Epoch [2000/2000] Fold 2, Train Loss: 0.0021, Val Loss: 0.0049\n",
      "Fold 3/5\n",
      "Epoch [1/2000] Fold 3, Train Loss: 0.0267, Val Loss: 0.0249\n",
      "Epoch [2/2000] Fold 3, Train Loss: 0.0237, Val Loss: 0.0218\n",
      "Epoch [3/2000] Fold 3, Train Loss: 0.0205, Val Loss: 0.0186\n",
      "Epoch [4/2000] Fold 3, Train Loss: 0.0175, Val Loss: 0.0158\n",
      "Epoch [5/2000] Fold 3, Train Loss: 0.0152, Val Loss: 0.0142\n",
      "Epoch [6/2000] Fold 3, Train Loss: 0.0142, Val Loss: 0.0136\n",
      "Epoch [7/2000] Fold 3, Train Loss: 0.0139, Val Loss: 0.0134\n",
      "Epoch [8/2000] Fold 3, Train Loss: 0.0137, Val Loss: 0.0133\n",
      "Epoch [9/2000] Fold 3, Train Loss: 0.0137, Val Loss: 0.0133\n",
      "Epoch [10/2000] Fold 3, Train Loss: 0.0137, Val Loss: 0.0133\n",
      "Epoch [11/2000] Fold 3, Train Loss: 0.0137, Val Loss: 0.0133\n",
      "Epoch [12/2000] Fold 3, Train Loss: 0.0137, Val Loss: 0.0133\n",
      "Epoch [13/2000] Fold 3, Train Loss: 0.0137, Val Loss: 0.0133\n",
      "Epoch [14/2000] Fold 3, Train Loss: 0.0136, Val Loss: 0.0133\n",
      "Epoch [15/2000] Fold 3, Train Loss: 0.0136, Val Loss: 0.0133\n",
      "Epoch [16/2000] Fold 3, Train Loss: 0.0137, Val Loss: 0.0133\n",
      "Epoch [17/2000] Fold 3, Train Loss: 0.0137, Val Loss: 0.0133\n",
      "Epoch [18/2000] Fold 3, Train Loss: 0.0136, Val Loss: 0.0133\n",
      "Epoch [19/2000] Fold 3, Train Loss: 0.0136, Val Loss: 0.0133\n",
      "Epoch [20/2000] Fold 3, Train Loss: 0.0136, Val Loss: 0.0132\n",
      "Epoch [21/2000] Fold 3, Train Loss: 0.0136, Val Loss: 0.0132\n",
      "Epoch [22/2000] Fold 3, Train Loss: 0.0134, Val Loss: 0.0129\n",
      "Epoch [23/2000] Fold 3, Train Loss: 0.0128, Val Loss: 0.0118\n",
      "Epoch [24/2000] Fold 3, Train Loss: 0.0115, Val Loss: 0.0107\n",
      "Epoch [25/2000] Fold 3, Train Loss: 0.0105, Val Loss: 0.0101\n",
      "Epoch [26/2000] Fold 3, Train Loss: 0.0101, Val Loss: 0.0098\n",
      "Epoch [27/2000] Fold 3, Train Loss: 0.0099, Val Loss: 0.0097\n",
      "Epoch [28/2000] Fold 3, Train Loss: 0.0097, Val Loss: 0.0095\n",
      "Epoch [29/2000] Fold 3, Train Loss: 0.0095, Val Loss: 0.0094\n",
      "Epoch [30/2000] Fold 3, Train Loss: 0.0094, Val Loss: 0.0092\n",
      "Epoch [31/2000] Fold 3, Train Loss: 0.0092, Val Loss: 0.0091\n",
      "Epoch [32/2000] Fold 3, Train Loss: 0.0091, Val Loss: 0.0090\n",
      "Epoch [33/2000] Fold 3, Train Loss: 0.0090, Val Loss: 0.0089\n",
      "Epoch [34/2000] Fold 3, Train Loss: 0.0090, Val Loss: 0.0088\n",
      "Epoch [35/2000] Fold 3, Train Loss: 0.0089, Val Loss: 0.0088\n",
      "Epoch [36/2000] Fold 3, Train Loss: 0.0089, Val Loss: 0.0088\n",
      "Epoch [37/2000] Fold 3, Train Loss: 0.0088, Val Loss: 0.0087\n",
      "Epoch [38/2000] Fold 3, Train Loss: 0.0088, Val Loss: 0.0086\n",
      "Epoch [39/2000] Fold 3, Train Loss: 0.0088, Val Loss: 0.0085\n",
      "Epoch [40/2000] Fold 3, Train Loss: 0.0087, Val Loss: 0.0085\n",
      "Epoch [41/2000] Fold 3, Train Loss: 0.0087, Val Loss: 0.0086\n",
      "Epoch [42/2000] Fold 3, Train Loss: 0.0087, Val Loss: 0.0085\n",
      "Epoch [43/2000] Fold 3, Train Loss: 0.0087, Val Loss: 0.0084\n",
      "Epoch [44/2000] Fold 3, Train Loss: 0.0087, Val Loss: 0.0084\n",
      "Epoch [45/2000] Fold 3, Train Loss: 0.0086, Val Loss: 0.0083\n",
      "Epoch [46/2000] Fold 3, Train Loss: 0.0085, Val Loss: 0.0083\n",
      "Epoch [47/2000] Fold 3, Train Loss: 0.0085, Val Loss: 0.0083\n",
      "Epoch [48/2000] Fold 3, Train Loss: 0.0084, Val Loss: 0.0083\n",
      "Epoch [49/2000] Fold 3, Train Loss: 0.0084, Val Loss: 0.0083\n",
      "Epoch [50/2000] Fold 3, Train Loss: 0.0084, Val Loss: 0.0082\n",
      "Epoch [51/2000] Fold 3, Train Loss: 0.0084, Val Loss: 0.0082\n",
      "Epoch [52/2000] Fold 3, Train Loss: 0.0083, Val Loss: 0.0082\n",
      "Epoch [53/2000] Fold 3, Train Loss: 0.0083, Val Loss: 0.0082\n",
      "Epoch [54/2000] Fold 3, Train Loss: 0.0082, Val Loss: 0.0082\n",
      "Epoch [55/2000] Fold 3, Train Loss: 0.0082, Val Loss: 0.0081\n",
      "Epoch [56/2000] Fold 3, Train Loss: 0.0081, Val Loss: 0.0081\n",
      "Epoch [57/2000] Fold 3, Train Loss: 0.0081, Val Loss: 0.0081\n",
      "Epoch [58/2000] Fold 3, Train Loss: 0.0081, Val Loss: 0.0082\n",
      "Epoch [59/2000] Fold 3, Train Loss: 0.0081, Val Loss: 0.0081\n",
      "Epoch [60/2000] Fold 3, Train Loss: 0.0080, Val Loss: 0.0080\n",
      "Epoch [61/2000] Fold 3, Train Loss: 0.0080, Val Loss: 0.0081\n",
      "Epoch [62/2000] Fold 3, Train Loss: 0.0080, Val Loss: 0.0080\n",
      "Epoch [63/2000] Fold 3, Train Loss: 0.0080, Val Loss: 0.0080\n",
      "Epoch [64/2000] Fold 3, Train Loss: 0.0079, Val Loss: 0.0080\n",
      "Epoch [65/2000] Fold 3, Train Loss: 0.0078, Val Loss: 0.0080\n",
      "Epoch [66/2000] Fold 3, Train Loss: 0.0078, Val Loss: 0.0080\n",
      "Epoch [67/2000] Fold 3, Train Loss: 0.0078, Val Loss: 0.0080\n",
      "Epoch [68/2000] Fold 3, Train Loss: 0.0078, Val Loss: 0.0080\n",
      "Epoch [69/2000] Fold 3, Train Loss: 0.0077, Val Loss: 0.0079\n",
      "Epoch [70/2000] Fold 3, Train Loss: 0.0077, Val Loss: 0.0079\n",
      "Epoch [71/2000] Fold 3, Train Loss: 0.0077, Val Loss: 0.0080\n",
      "Epoch [72/2000] Fold 3, Train Loss: 0.0077, Val Loss: 0.0078\n",
      "Epoch [73/2000] Fold 3, Train Loss: 0.0076, Val Loss: 0.0078\n",
      "Epoch [74/2000] Fold 3, Train Loss: 0.0076, Val Loss: 0.0078\n",
      "Epoch [75/2000] Fold 3, Train Loss: 0.0076, Val Loss: 0.0079\n",
      "Epoch [76/2000] Fold 3, Train Loss: 0.0075, Val Loss: 0.0078\n",
      "Epoch [77/2000] Fold 3, Train Loss: 0.0075, Val Loss: 0.0077\n",
      "Epoch [78/2000] Fold 3, Train Loss: 0.0075, Val Loss: 0.0077\n",
      "Epoch [79/2000] Fold 3, Train Loss: 0.0074, Val Loss: 0.0077\n",
      "Epoch [80/2000] Fold 3, Train Loss: 0.0074, Val Loss: 0.0078\n",
      "Epoch [81/2000] Fold 3, Train Loss: 0.0074, Val Loss: 0.0077\n",
      "Epoch [82/2000] Fold 3, Train Loss: 0.0074, Val Loss: 0.0077\n",
      "Epoch [83/2000] Fold 3, Train Loss: 0.0073, Val Loss: 0.0076\n",
      "Epoch [84/2000] Fold 3, Train Loss: 0.0073, Val Loss: 0.0077\n",
      "Epoch [85/2000] Fold 3, Train Loss: 0.0073, Val Loss: 0.0076\n",
      "Epoch [86/2000] Fold 3, Train Loss: 0.0073, Val Loss: 0.0076\n",
      "Epoch [87/2000] Fold 3, Train Loss: 0.0072, Val Loss: 0.0076\n",
      "Epoch [88/2000] Fold 3, Train Loss: 0.0073, Val Loss: 0.0076\n",
      "Epoch [89/2000] Fold 3, Train Loss: 0.0073, Val Loss: 0.0076\n",
      "Epoch [90/2000] Fold 3, Train Loss: 0.0072, Val Loss: 0.0075\n",
      "Epoch [91/2000] Fold 3, Train Loss: 0.0071, Val Loss: 0.0075\n",
      "Epoch [92/2000] Fold 3, Train Loss: 0.0072, Val Loss: 0.0075\n",
      "Epoch [93/2000] Fold 3, Train Loss: 0.0071, Val Loss: 0.0075\n",
      "Epoch [94/2000] Fold 3, Train Loss: 0.0070, Val Loss: 0.0075\n",
      "Epoch [95/2000] Fold 3, Train Loss: 0.0070, Val Loss: 0.0074\n",
      "Epoch [96/2000] Fold 3, Train Loss: 0.0070, Val Loss: 0.0075\n",
      "Epoch [97/2000] Fold 3, Train Loss: 0.0071, Val Loss: 0.0074\n",
      "Epoch [98/2000] Fold 3, Train Loss: 0.0070, Val Loss: 0.0074\n",
      "Epoch [99/2000] Fold 3, Train Loss: 0.0070, Val Loss: 0.0074\n",
      "Epoch [100/2000] Fold 3, Train Loss: 0.0069, Val Loss: 0.0074\n",
      "Epoch [101/2000] Fold 3, Train Loss: 0.0070, Val Loss: 0.0074\n",
      "Epoch [102/2000] Fold 3, Train Loss: 0.0069, Val Loss: 0.0073\n",
      "Epoch [103/2000] Fold 3, Train Loss: 0.0069, Val Loss: 0.0073\n",
      "Epoch [104/2000] Fold 3, Train Loss: 0.0069, Val Loss: 0.0073\n",
      "Epoch [105/2000] Fold 3, Train Loss: 0.0068, Val Loss: 0.0073\n",
      "Epoch [106/2000] Fold 3, Train Loss: 0.0068, Val Loss: 0.0074\n",
      "Epoch [107/2000] Fold 3, Train Loss: 0.0068, Val Loss: 0.0073\n",
      "Epoch [108/2000] Fold 3, Train Loss: 0.0068, Val Loss: 0.0072\n",
      "Epoch [109/2000] Fold 3, Train Loss: 0.0068, Val Loss: 0.0072\n",
      "Epoch [110/2000] Fold 3, Train Loss: 0.0068, Val Loss: 0.0072\n",
      "Epoch [111/2000] Fold 3, Train Loss: 0.0068, Val Loss: 0.0073\n",
      "Epoch [112/2000] Fold 3, Train Loss: 0.0067, Val Loss: 0.0072\n",
      "Epoch [113/2000] Fold 3, Train Loss: 0.0067, Val Loss: 0.0071\n",
      "Epoch [114/2000] Fold 3, Train Loss: 0.0067, Val Loss: 0.0072\n",
      "Epoch [115/2000] Fold 3, Train Loss: 0.0067, Val Loss: 0.0071\n",
      "Epoch [116/2000] Fold 3, Train Loss: 0.0067, Val Loss: 0.0071\n",
      "Epoch [117/2000] Fold 3, Train Loss: 0.0067, Val Loss: 0.0071\n",
      "Epoch [118/2000] Fold 3, Train Loss: 0.0066, Val Loss: 0.0071\n",
      "Epoch [119/2000] Fold 3, Train Loss: 0.0066, Val Loss: 0.0071\n",
      "Epoch [120/2000] Fold 3, Train Loss: 0.0066, Val Loss: 0.0071\n",
      "Epoch [121/2000] Fold 3, Train Loss: 0.0066, Val Loss: 0.0070\n",
      "Epoch [122/2000] Fold 3, Train Loss: 0.0066, Val Loss: 0.0071\n",
      "Epoch [123/2000] Fold 3, Train Loss: 0.0066, Val Loss: 0.0070\n",
      "Epoch [124/2000] Fold 3, Train Loss: 0.0065, Val Loss: 0.0071\n",
      "Epoch [125/2000] Fold 3, Train Loss: 0.0065, Val Loss: 0.0070\n",
      "Epoch [126/2000] Fold 3, Train Loss: 0.0065, Val Loss: 0.0070\n",
      "Epoch [127/2000] Fold 3, Train Loss: 0.0065, Val Loss: 0.0070\n",
      "Epoch [128/2000] Fold 3, Train Loss: 0.0065, Val Loss: 0.0070\n",
      "Epoch [129/2000] Fold 3, Train Loss: 0.0065, Val Loss: 0.0070\n",
      "Epoch [130/2000] Fold 3, Train Loss: 0.0065, Val Loss: 0.0070\n",
      "Epoch [131/2000] Fold 3, Train Loss: 0.0065, Val Loss: 0.0070\n",
      "Epoch [132/2000] Fold 3, Train Loss: 0.0065, Val Loss: 0.0069\n",
      "Epoch [133/2000] Fold 3, Train Loss: 0.0065, Val Loss: 0.0069\n",
      "Epoch [134/2000] Fold 3, Train Loss: 0.0064, Val Loss: 0.0069\n",
      "Epoch [135/2000] Fold 3, Train Loss: 0.0064, Val Loss: 0.0069\n",
      "Epoch [136/2000] Fold 3, Train Loss: 0.0064, Val Loss: 0.0068\n",
      "Epoch [137/2000] Fold 3, Train Loss: 0.0064, Val Loss: 0.0069\n",
      "Epoch [138/2000] Fold 3, Train Loss: 0.0064, Val Loss: 0.0069\n",
      "Epoch [139/2000] Fold 3, Train Loss: 0.0064, Val Loss: 0.0068\n",
      "Epoch [140/2000] Fold 3, Train Loss: 0.0063, Val Loss: 0.0068\n",
      "Epoch [141/2000] Fold 3, Train Loss: 0.0063, Val Loss: 0.0068\n",
      "Epoch [142/2000] Fold 3, Train Loss: 0.0063, Val Loss: 0.0069\n",
      "Epoch [143/2000] Fold 3, Train Loss: 0.0063, Val Loss: 0.0068\n",
      "Epoch [144/2000] Fold 3, Train Loss: 0.0063, Val Loss: 0.0068\n",
      "Epoch [145/2000] Fold 3, Train Loss: 0.0063, Val Loss: 0.0069\n",
      "Epoch [146/2000] Fold 3, Train Loss: 0.0064, Val Loss: 0.0068\n",
      "Epoch [147/2000] Fold 3, Train Loss: 0.0063, Val Loss: 0.0068\n",
      "Epoch [148/2000] Fold 3, Train Loss: 0.0063, Val Loss: 0.0068\n",
      "Epoch [149/2000] Fold 3, Train Loss: 0.0063, Val Loss: 0.0069\n",
      "Epoch [150/2000] Fold 3, Train Loss: 0.0063, Val Loss: 0.0067\n",
      "Epoch [151/2000] Fold 3, Train Loss: 0.0062, Val Loss: 0.0067\n",
      "Epoch [152/2000] Fold 3, Train Loss: 0.0062, Val Loss: 0.0068\n",
      "Epoch [153/2000] Fold 3, Train Loss: 0.0062, Val Loss: 0.0068\n",
      "Epoch [154/2000] Fold 3, Train Loss: 0.0062, Val Loss: 0.0067\n",
      "Epoch [155/2000] Fold 3, Train Loss: 0.0062, Val Loss: 0.0068\n",
      "Epoch [156/2000] Fold 3, Train Loss: 0.0062, Val Loss: 0.0067\n",
      "Epoch [157/2000] Fold 3, Train Loss: 0.0062, Val Loss: 0.0067\n",
      "Epoch [158/2000] Fold 3, Train Loss: 0.0062, Val Loss: 0.0067\n",
      "Epoch [159/2000] Fold 3, Train Loss: 0.0061, Val Loss: 0.0067\n",
      "Epoch [160/2000] Fold 3, Train Loss: 0.0062, Val Loss: 0.0067\n",
      "Epoch [161/2000] Fold 3, Train Loss: 0.0062, Val Loss: 0.0068\n",
      "Epoch [162/2000] Fold 3, Train Loss: 0.0061, Val Loss: 0.0067\n",
      "Epoch [163/2000] Fold 3, Train Loss: 0.0061, Val Loss: 0.0067\n",
      "Epoch [164/2000] Fold 3, Train Loss: 0.0061, Val Loss: 0.0067\n",
      "Epoch [165/2000] Fold 3, Train Loss: 0.0061, Val Loss: 0.0067\n",
      "Epoch [166/2000] Fold 3, Train Loss: 0.0061, Val Loss: 0.0066\n",
      "Epoch [167/2000] Fold 3, Train Loss: 0.0061, Val Loss: 0.0066\n",
      "Epoch [168/2000] Fold 3, Train Loss: 0.0060, Val Loss: 0.0067\n",
      "Epoch [169/2000] Fold 3, Train Loss: 0.0060, Val Loss: 0.0066\n",
      "Epoch [170/2000] Fold 3, Train Loss: 0.0060, Val Loss: 0.0066\n",
      "Epoch [171/2000] Fold 3, Train Loss: 0.0060, Val Loss: 0.0066\n",
      "Epoch [172/2000] Fold 3, Train Loss: 0.0060, Val Loss: 0.0066\n",
      "Epoch [173/2000] Fold 3, Train Loss: 0.0060, Val Loss: 0.0066\n",
      "Epoch [174/2000] Fold 3, Train Loss: 0.0060, Val Loss: 0.0066\n",
      "Epoch [175/2000] Fold 3, Train Loss: 0.0060, Val Loss: 0.0066\n",
      "Epoch [176/2000] Fold 3, Train Loss: 0.0060, Val Loss: 0.0066\n",
      "Epoch [177/2000] Fold 3, Train Loss: 0.0060, Val Loss: 0.0066\n",
      "Epoch [178/2000] Fold 3, Train Loss: 0.0059, Val Loss: 0.0066\n",
      "Epoch [179/2000] Fold 3, Train Loss: 0.0059, Val Loss: 0.0067\n",
      "Epoch [180/2000] Fold 3, Train Loss: 0.0060, Val Loss: 0.0066\n",
      "Epoch [181/2000] Fold 3, Train Loss: 0.0060, Val Loss: 0.0065\n",
      "Epoch [182/2000] Fold 3, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [183/2000] Fold 3, Train Loss: 0.0059, Val Loss: 0.0066\n",
      "Epoch [184/2000] Fold 3, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [185/2000] Fold 3, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [186/2000] Fold 3, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [187/2000] Fold 3, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [188/2000] Fold 3, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [189/2000] Fold 3, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [190/2000] Fold 3, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [191/2000] Fold 3, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [192/2000] Fold 3, Train Loss: 0.0059, Val Loss: 0.0066\n",
      "Epoch [193/2000] Fold 3, Train Loss: 0.0058, Val Loss: 0.0065\n",
      "Epoch [194/2000] Fold 3, Train Loss: 0.0059, Val Loss: 0.0065\n",
      "Epoch [195/2000] Fold 3, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [196/2000] Fold 3, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [197/2000] Fold 3, Train Loss: 0.0058, Val Loss: 0.0065\n",
      "Epoch [198/2000] Fold 3, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [199/2000] Fold 3, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [200/2000] Fold 3, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [201/2000] Fold 3, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [202/2000] Fold 3, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [203/2000] Fold 3, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [204/2000] Fold 3, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [205/2000] Fold 3, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [206/2000] Fold 3, Train Loss: 0.0057, Val Loss: 0.0064\n",
      "Epoch [207/2000] Fold 3, Train Loss: 0.0058, Val Loss: 0.0064\n",
      "Epoch [208/2000] Fold 3, Train Loss: 0.0058, Val Loss: 0.0065\n",
      "Epoch [209/2000] Fold 3, Train Loss: 0.0058, Val Loss: 0.0063\n",
      "Epoch [210/2000] Fold 3, Train Loss: 0.0057, Val Loss: 0.0063\n",
      "Epoch [211/2000] Fold 3, Train Loss: 0.0057, Val Loss: 0.0063\n",
      "Epoch [212/2000] Fold 3, Train Loss: 0.0057, Val Loss: 0.0063\n",
      "Epoch [213/2000] Fold 3, Train Loss: 0.0057, Val Loss: 0.0064\n",
      "Epoch [214/2000] Fold 3, Train Loss: 0.0057, Val Loss: 0.0064\n",
      "Epoch [215/2000] Fold 3, Train Loss: 0.0057, Val Loss: 0.0064\n",
      "Epoch [216/2000] Fold 3, Train Loss: 0.0057, Val Loss: 0.0063\n",
      "Epoch [217/2000] Fold 3, Train Loss: 0.0057, Val Loss: 0.0062\n",
      "Epoch [218/2000] Fold 3, Train Loss: 0.0056, Val Loss: 0.0062\n",
      "Epoch [219/2000] Fold 3, Train Loss: 0.0056, Val Loss: 0.0062\n",
      "Epoch [220/2000] Fold 3, Train Loss: 0.0056, Val Loss: 0.0062\n",
      "Epoch [221/2000] Fold 3, Train Loss: 0.0056, Val Loss: 0.0062\n",
      "Epoch [222/2000] Fold 3, Train Loss: 0.0056, Val Loss: 0.0062\n",
      "Epoch [223/2000] Fold 3, Train Loss: 0.0056, Val Loss: 0.0062\n",
      "Epoch [224/2000] Fold 3, Train Loss: 0.0056, Val Loss: 0.0062\n",
      "Epoch [225/2000] Fold 3, Train Loss: 0.0056, Val Loss: 0.0063\n",
      "Epoch [226/2000] Fold 3, Train Loss: 0.0055, Val Loss: 0.0062\n",
      "Epoch [227/2000] Fold 3, Train Loss: 0.0055, Val Loss: 0.0062\n",
      "Epoch [228/2000] Fold 3, Train Loss: 0.0055, Val Loss: 0.0061\n",
      "Epoch [229/2000] Fold 3, Train Loss: 0.0055, Val Loss: 0.0062\n",
      "Epoch [230/2000] Fold 3, Train Loss: 0.0055, Val Loss: 0.0062\n",
      "Epoch [231/2000] Fold 3, Train Loss: 0.0055, Val Loss: 0.0061\n",
      "Epoch [232/2000] Fold 3, Train Loss: 0.0055, Val Loss: 0.0061\n",
      "Epoch [233/2000] Fold 3, Train Loss: 0.0055, Val Loss: 0.0061\n",
      "Epoch [234/2000] Fold 3, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [235/2000] Fold 3, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [236/2000] Fold 3, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [237/2000] Fold 3, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [238/2000] Fold 3, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [239/2000] Fold 3, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [240/2000] Fold 3, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [241/2000] Fold 3, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [242/2000] Fold 3, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [243/2000] Fold 3, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [244/2000] Fold 3, Train Loss: 0.0054, Val Loss: 0.0060\n",
      "Epoch [245/2000] Fold 3, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [246/2000] Fold 3, Train Loss: 0.0054, Val Loss: 0.0060\n",
      "Epoch [247/2000] Fold 3, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [248/2000] Fold 3, Train Loss: 0.0054, Val Loss: 0.0061\n",
      "Epoch [249/2000] Fold 3, Train Loss: 0.0054, Val Loss: 0.0060\n",
      "Epoch [250/2000] Fold 3, Train Loss: 0.0054, Val Loss: 0.0060\n",
      "Epoch [251/2000] Fold 3, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [252/2000] Fold 3, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [253/2000] Fold 3, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [254/2000] Fold 3, Train Loss: 0.0053, Val Loss: 0.0061\n",
      "Epoch [255/2000] Fold 3, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [256/2000] Fold 3, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [257/2000] Fold 3, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [258/2000] Fold 3, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [259/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0060\n",
      "Epoch [260/2000] Fold 3, Train Loss: 0.0053, Val Loss: 0.0059\n",
      "Epoch [261/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [262/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [263/2000] Fold 3, Train Loss: 0.0053, Val Loss: 0.0060\n",
      "Epoch [264/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [265/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [266/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [267/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [268/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [269/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [270/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0060\n",
      "Epoch [271/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [272/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [273/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [274/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [275/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [276/2000] Fold 3, Train Loss: 0.0051, Val Loss: 0.0059\n",
      "Epoch [277/2000] Fold 3, Train Loss: 0.0051, Val Loss: 0.0059\n",
      "Epoch [278/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [279/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [280/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0058\n",
      "Epoch [281/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0058\n",
      "Epoch [282/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0059\n",
      "Epoch [283/2000] Fold 3, Train Loss: 0.0052, Val Loss: 0.0058\n",
      "Epoch [284/2000] Fold 3, Train Loss: 0.0051, Val Loss: 0.0059\n",
      "Epoch [285/2000] Fold 3, Train Loss: 0.0051, Val Loss: 0.0058\n",
      "Epoch [286/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [287/2000] Fold 3, Train Loss: 0.0051, Val Loss: 0.0058\n",
      "Epoch [288/2000] Fold 3, Train Loss: 0.0051, Val Loss: 0.0058\n",
      "Epoch [289/2000] Fold 3, Train Loss: 0.0051, Val Loss: 0.0058\n",
      "Epoch [290/2000] Fold 3, Train Loss: 0.0051, Val Loss: 0.0059\n",
      "Epoch [291/2000] Fold 3, Train Loss: 0.0051, Val Loss: 0.0059\n",
      "Epoch [292/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [293/2000] Fold 3, Train Loss: 0.0051, Val Loss: 0.0058\n",
      "Epoch [294/2000] Fold 3, Train Loss: 0.0051, Val Loss: 0.0058\n",
      "Epoch [295/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [296/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [297/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [298/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [299/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0059\n",
      "Epoch [300/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0059\n",
      "Epoch [301/2000] Fold 3, Train Loss: 0.0051, Val Loss: 0.0058\n",
      "Epoch [302/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0059\n",
      "Epoch [303/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [304/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [305/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [306/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [307/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [308/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [309/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [310/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0058\n",
      "Epoch [311/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0057\n",
      "Epoch [312/2000] Fold 3, Train Loss: 0.0049, Val Loss: 0.0057\n",
      "Epoch [313/2000] Fold 3, Train Loss: 0.0050, Val Loss: 0.0057\n",
      "Epoch [314/2000] Fold 3, Train Loss: 0.0049, Val Loss: 0.0057\n",
      "Epoch [315/2000] Fold 3, Train Loss: 0.0049, Val Loss: 0.0057\n",
      "Epoch [316/2000] Fold 3, Train Loss: 0.0049, Val Loss: 0.0057\n",
      "Epoch [317/2000] Fold 3, Train Loss: 0.0048, Val Loss: 0.0057\n",
      "Epoch [318/2000] Fold 3, Train Loss: 0.0049, Val Loss: 0.0056\n",
      "Epoch [319/2000] Fold 3, Train Loss: 0.0048, Val Loss: 0.0057\n",
      "Epoch [320/2000] Fold 3, Train Loss: 0.0049, Val Loss: 0.0057\n",
      "Epoch [321/2000] Fold 3, Train Loss: 0.0049, Val Loss: 0.0057\n",
      "Epoch [322/2000] Fold 3, Train Loss: 0.0049, Val Loss: 0.0057\n",
      "Epoch [323/2000] Fold 3, Train Loss: 0.0049, Val Loss: 0.0057\n",
      "Epoch [324/2000] Fold 3, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [325/2000] Fold 3, Train Loss: 0.0049, Val Loss: 0.0057\n",
      "Epoch [326/2000] Fold 3, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [327/2000] Fold 3, Train Loss: 0.0048, Val Loss: 0.0057\n",
      "Epoch [328/2000] Fold 3, Train Loss: 0.0048, Val Loss: 0.0057\n",
      "Epoch [329/2000] Fold 3, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [330/2000] Fold 3, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [331/2000] Fold 3, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [332/2000] Fold 3, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [333/2000] Fold 3, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [334/2000] Fold 3, Train Loss: 0.0047, Val Loss: 0.0056\n",
      "Epoch [335/2000] Fold 3, Train Loss: 0.0048, Val Loss: 0.0055\n",
      "Epoch [336/2000] Fold 3, Train Loss: 0.0048, Val Loss: 0.0055\n",
      "Epoch [337/2000] Fold 3, Train Loss: 0.0048, Val Loss: 0.0057\n",
      "Epoch [338/2000] Fold 3, Train Loss: 0.0048, Val Loss: 0.0056\n",
      "Epoch [339/2000] Fold 3, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [340/2000] Fold 3, Train Loss: 0.0047, Val Loss: 0.0056\n",
      "Epoch [341/2000] Fold 3, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [342/2000] Fold 3, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [343/2000] Fold 3, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [344/2000] Fold 3, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [345/2000] Fold 3, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [346/2000] Fold 3, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [347/2000] Fold 3, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [348/2000] Fold 3, Train Loss: 0.0047, Val Loss: 0.0056\n",
      "Epoch [349/2000] Fold 3, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [350/2000] Fold 3, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [351/2000] Fold 3, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [352/2000] Fold 3, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [353/2000] Fold 3, Train Loss: 0.0046, Val Loss: 0.0055\n",
      "Epoch [354/2000] Fold 3, Train Loss: 0.0046, Val Loss: 0.0055\n",
      "Epoch [355/2000] Fold 3, Train Loss: 0.0046, Val Loss: 0.0055\n",
      "Epoch [356/2000] Fold 3, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [357/2000] Fold 3, Train Loss: 0.0047, Val Loss: 0.0055\n",
      "Epoch [358/2000] Fold 3, Train Loss: 0.0046, Val Loss: 0.0055\n",
      "Epoch [359/2000] Fold 3, Train Loss: 0.0046, Val Loss: 0.0055\n",
      "Epoch [360/2000] Fold 3, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [361/2000] Fold 3, Train Loss: 0.0046, Val Loss: 0.0055\n",
      "Epoch [362/2000] Fold 3, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [363/2000] Fold 3, Train Loss: 0.0046, Val Loss: 0.0055\n",
      "Epoch [364/2000] Fold 3, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [365/2000] Fold 3, Train Loss: 0.0046, Val Loss: 0.0055\n",
      "Epoch [366/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0055\n",
      "Epoch [367/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [368/2000] Fold 3, Train Loss: 0.0046, Val Loss: 0.0054\n",
      "Epoch [369/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0055\n",
      "Epoch [370/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [371/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0055\n",
      "Epoch [372/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [373/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [374/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [375/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0055\n",
      "Epoch [376/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [377/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [378/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [379/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0055\n",
      "Epoch [380/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [381/2000] Fold 3, Train Loss: 0.0044, Val Loss: 0.0054\n",
      "Epoch [382/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [383/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [384/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [385/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [386/2000] Fold 3, Train Loss: 0.0044, Val Loss: 0.0054\n",
      "Epoch [387/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [388/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0053\n",
      "Epoch [389/2000] Fold 3, Train Loss: 0.0045, Val Loss: 0.0054\n",
      "Epoch [390/2000] Fold 3, Train Loss: 0.0044, Val Loss: 0.0053\n",
      "Epoch [391/2000] Fold 3, Train Loss: 0.0044, Val Loss: 0.0053\n",
      "Epoch [392/2000] Fold 3, Train Loss: 0.0044, Val Loss: 0.0054\n",
      "Epoch [393/2000] Fold 3, Train Loss: 0.0044, Val Loss: 0.0053\n",
      "Epoch [394/2000] Fold 3, Train Loss: 0.0044, Val Loss: 0.0054\n",
      "Epoch [395/2000] Fold 3, Train Loss: 0.0044, Val Loss: 0.0053\n",
      "Epoch [396/2000] Fold 3, Train Loss: 0.0044, Val Loss: 0.0053\n",
      "Epoch [397/2000] Fold 3, Train Loss: 0.0043, Val Loss: 0.0053\n",
      "Epoch [398/2000] Fold 3, Train Loss: 0.0043, Val Loss: 0.0053\n",
      "Epoch [399/2000] Fold 3, Train Loss: 0.0044, Val Loss: 0.0053\n",
      "Epoch [400/2000] Fold 3, Train Loss: 0.0043, Val Loss: 0.0053\n",
      "Epoch [401/2000] Fold 3, Train Loss: 0.0043, Val Loss: 0.0054\n",
      "Epoch [402/2000] Fold 3, Train Loss: 0.0044, Val Loss: 0.0054\n",
      "Epoch [403/2000] Fold 3, Train Loss: 0.0043, Val Loss: 0.0053\n",
      "Epoch [404/2000] Fold 3, Train Loss: 0.0043, Val Loss: 0.0054\n",
      "Epoch [405/2000] Fold 3, Train Loss: 0.0043, Val Loss: 0.0053\n",
      "Epoch [406/2000] Fold 3, Train Loss: 0.0043, Val Loss: 0.0053\n",
      "Epoch [407/2000] Fold 3, Train Loss: 0.0043, Val Loss: 0.0053\n",
      "Epoch [408/2000] Fold 3, Train Loss: 0.0043, Val Loss: 0.0054\n",
      "Epoch [409/2000] Fold 3, Train Loss: 0.0043, Val Loss: 0.0053\n",
      "Epoch [410/2000] Fold 3, Train Loss: 0.0043, Val Loss: 0.0053\n",
      "Epoch [411/2000] Fold 3, Train Loss: 0.0043, Val Loss: 0.0054\n",
      "Epoch [412/2000] Fold 3, Train Loss: 0.0043, Val Loss: 0.0053\n",
      "Epoch [413/2000] Fold 3, Train Loss: 0.0043, Val Loss: 0.0053\n",
      "Epoch [414/2000] Fold 3, Train Loss: 0.0043, Val Loss: 0.0053\n",
      "Epoch [415/2000] Fold 3, Train Loss: 0.0042, Val Loss: 0.0054\n",
      "Epoch [416/2000] Fold 3, Train Loss: 0.0042, Val Loss: 0.0054\n",
      "Epoch [417/2000] Fold 3, Train Loss: 0.0042, Val Loss: 0.0054\n",
      "Epoch [418/2000] Fold 3, Train Loss: 0.0042, Val Loss: 0.0053\n",
      "Epoch [419/2000] Fold 3, Train Loss: 0.0042, Val Loss: 0.0054\n",
      "Epoch [420/2000] Fold 3, Train Loss: 0.0042, Val Loss: 0.0053\n",
      "Epoch [421/2000] Fold 3, Train Loss: 0.0042, Val Loss: 0.0053\n",
      "Epoch [422/2000] Fold 3, Train Loss: 0.0042, Val Loss: 0.0053\n",
      "Epoch [423/2000] Fold 3, Train Loss: 0.0042, Val Loss: 0.0053\n",
      "Epoch [424/2000] Fold 3, Train Loss: 0.0042, Val Loss: 0.0053\n",
      "Epoch [425/2000] Fold 3, Train Loss: 0.0042, Val Loss: 0.0053\n",
      "Epoch [426/2000] Fold 3, Train Loss: 0.0042, Val Loss: 0.0052\n",
      "Epoch [427/2000] Fold 3, Train Loss: 0.0042, Val Loss: 0.0053\n",
      "Epoch [428/2000] Fold 3, Train Loss: 0.0042, Val Loss: 0.0054\n",
      "Epoch [429/2000] Fold 3, Train Loss: 0.0043, Val Loss: 0.0054\n",
      "Epoch [430/2000] Fold 3, Train Loss: 0.0042, Val Loss: 0.0053\n",
      "Epoch [431/2000] Fold 3, Train Loss: 0.0042, Val Loss: 0.0053\n",
      "Epoch [432/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0053\n",
      "Epoch [433/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [434/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0053\n",
      "Epoch [435/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0053\n",
      "Epoch [436/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0052\n",
      "Epoch [437/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0053\n",
      "Epoch [438/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0053\n",
      "Epoch [439/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0053\n",
      "Epoch [440/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [441/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0053\n",
      "Epoch [442/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0053\n",
      "Epoch [443/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0052\n",
      "Epoch [444/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0053\n",
      "Epoch [445/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0053\n",
      "Epoch [446/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0052\n",
      "Epoch [447/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0052\n",
      "Epoch [448/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0053\n",
      "Epoch [449/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0055\n",
      "Epoch [450/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0052\n",
      "Epoch [451/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0052\n",
      "Epoch [452/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0054\n",
      "Epoch [453/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0053\n",
      "Epoch [454/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0052\n",
      "Epoch [455/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0052\n",
      "Epoch [456/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0054\n",
      "Epoch [457/2000] Fold 3, Train Loss: 0.0041, Val Loss: 0.0053\n",
      "Epoch [458/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0052\n",
      "Epoch [459/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0053\n",
      "Epoch [460/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0053\n",
      "Epoch [461/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0052\n",
      "Epoch [462/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0052\n",
      "Epoch [463/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0054\n",
      "Epoch [464/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0052\n",
      "Epoch [465/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0053\n",
      "Epoch [466/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0052\n",
      "Epoch [467/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0052\n",
      "Epoch [468/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0052\n",
      "Epoch [469/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0052\n",
      "Epoch [470/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0052\n",
      "Epoch [471/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0052\n",
      "Epoch [472/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0053\n",
      "Epoch [473/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0051\n",
      "Epoch [474/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0052\n",
      "Epoch [475/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0052\n",
      "Epoch [476/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0052\n",
      "Epoch [477/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0053\n",
      "Epoch [478/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [479/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0052\n",
      "Epoch [480/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0052\n",
      "Epoch [481/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0052\n",
      "Epoch [482/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0052\n",
      "Epoch [483/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [484/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0052\n",
      "Epoch [485/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0052\n",
      "Epoch [486/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0051\n",
      "Epoch [487/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [488/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0052\n",
      "Epoch [489/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [490/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0051\n",
      "Epoch [491/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0052\n",
      "Epoch [492/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0052\n",
      "Epoch [493/2000] Fold 3, Train Loss: 0.0040, Val Loss: 0.0052\n",
      "Epoch [494/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [495/2000] Fold 3, Train Loss: 0.0039, Val Loss: 0.0052\n",
      "Epoch [496/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0051\n",
      "Epoch [497/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [498/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [499/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0051\n",
      "Epoch [500/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [501/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [502/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [503/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0051\n",
      "Epoch [504/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [505/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [506/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [507/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [508/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [509/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [510/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [511/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0051\n",
      "Epoch [512/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [513/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0051\n",
      "Epoch [514/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [515/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [516/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [517/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [518/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0051\n",
      "Epoch [519/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [520/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [521/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0051\n",
      "Epoch [522/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0054\n",
      "Epoch [523/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [524/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0051\n",
      "Epoch [525/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [526/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [527/2000] Fold 3, Train Loss: 0.0038, Val Loss: 0.0051\n",
      "Epoch [528/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0053\n",
      "Epoch [529/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [530/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0051\n",
      "Epoch [531/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0051\n",
      "Epoch [532/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0052\n",
      "Epoch [533/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [534/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [535/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [536/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [537/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0051\n",
      "Epoch [538/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0051\n",
      "Epoch [539/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0052\n",
      "Epoch [540/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0052\n",
      "Epoch [541/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0051\n",
      "Epoch [542/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0051\n",
      "Epoch [543/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [544/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0053\n",
      "Epoch [545/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [546/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [547/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [548/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0052\n",
      "Epoch [549/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0052\n",
      "Epoch [550/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [551/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0052\n",
      "Epoch [552/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [553/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [554/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [555/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [556/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [557/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [558/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [559/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0054\n",
      "Epoch [560/2000] Fold 3, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [561/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [562/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0052\n",
      "Epoch [563/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [564/2000] Fold 3, Train Loss: 0.0036, Val Loss: 0.0052\n",
      "Epoch [565/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [566/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0052\n",
      "Epoch [567/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [568/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [569/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0052\n",
      "Epoch [570/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0052\n",
      "Epoch [571/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [572/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [573/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [574/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [575/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0050\n",
      "Epoch [576/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [577/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [578/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0052\n",
      "Epoch [579/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0052\n",
      "Epoch [580/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0052\n",
      "Epoch [581/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [582/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [583/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [584/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [585/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0052\n",
      "Epoch [586/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0051\n",
      "Epoch [587/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [588/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0052\n",
      "Epoch [589/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0051\n",
      "Epoch [590/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [591/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0051\n",
      "Epoch [592/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0051\n",
      "Epoch [593/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0051\n",
      "Epoch [594/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [595/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0051\n",
      "Epoch [596/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [597/2000] Fold 3, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [598/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0051\n",
      "Epoch [599/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [600/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0051\n",
      "Epoch [601/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [602/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0051\n",
      "Epoch [603/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [604/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [605/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0052\n",
      "Epoch [606/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0052\n",
      "Epoch [607/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [608/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [609/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [610/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0050\n",
      "Epoch [611/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0050\n",
      "Epoch [612/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0051\n",
      "Epoch [613/2000] Fold 3, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [614/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0051\n",
      "Epoch [615/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0050\n",
      "Epoch [616/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0050\n",
      "Epoch [617/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [618/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0051\n",
      "Epoch [619/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [620/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0050\n",
      "Epoch [621/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0051\n",
      "Epoch [622/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [623/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0050\n",
      "Epoch [624/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [625/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0051\n",
      "Epoch [626/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0050\n",
      "Epoch [627/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0050\n",
      "Epoch [628/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [629/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [630/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0050\n",
      "Epoch [631/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0050\n",
      "Epoch [632/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0050\n",
      "Epoch [633/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [634/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0050\n",
      "Epoch [635/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0050\n",
      "Epoch [636/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0050\n",
      "Epoch [637/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0050\n",
      "Epoch [638/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0050\n",
      "Epoch [639/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0051\n",
      "Epoch [640/2000] Fold 3, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [641/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [642/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0050\n",
      "Epoch [643/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [644/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [645/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [646/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [647/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [648/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [649/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0050\n",
      "Epoch [650/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [651/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [652/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [653/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [654/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [655/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0048\n",
      "Epoch [656/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0048\n",
      "Epoch [657/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0048\n",
      "Epoch [658/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [659/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [660/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [661/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [662/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [663/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [664/2000] Fold 3, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [665/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [666/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [667/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [668/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [669/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [670/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [671/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [672/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [673/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [674/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [675/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [676/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [677/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [678/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [679/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [680/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [681/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [682/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [683/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [684/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [685/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [686/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [687/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0047\n",
      "Epoch [688/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [689/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [690/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [691/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [692/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [693/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0047\n",
      "Epoch [694/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0050\n",
      "Epoch [695/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [696/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [697/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0047\n",
      "Epoch [698/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0047\n",
      "Epoch [699/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0047\n",
      "Epoch [700/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0047\n",
      "Epoch [701/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [702/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0047\n",
      "Epoch [703/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [704/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [705/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [706/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [707/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [708/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [709/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [710/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [711/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [712/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0047\n",
      "Epoch [713/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0053\n",
      "Epoch [714/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0047\n",
      "Epoch [715/2000] Fold 3, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [716/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [717/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [718/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [719/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [720/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0046\n",
      "Epoch [721/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0046\n",
      "Epoch [722/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [723/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0047\n",
      "Epoch [724/2000] Fold 3, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [725/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [726/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [727/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [728/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0046\n",
      "Epoch [729/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [730/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [731/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [732/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [733/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [734/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [735/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [736/2000] Fold 3, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [737/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0046\n",
      "Epoch [738/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0046\n",
      "Epoch [739/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0046\n",
      "Epoch [740/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0046\n",
      "Epoch [741/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0046\n",
      "Epoch [742/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [743/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [744/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0046\n",
      "Epoch [745/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0046\n",
      "Epoch [746/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [747/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [748/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0046\n",
      "Epoch [749/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0046\n",
      "Epoch [750/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0046\n",
      "Epoch [751/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0046\n",
      "Epoch [752/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [753/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [754/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [755/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [756/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0046\n",
      "Epoch [757/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [758/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [759/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0046\n",
      "Epoch [760/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0046\n",
      "Epoch [761/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0049\n",
      "Epoch [762/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0046\n",
      "Epoch [763/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [764/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0046\n",
      "Epoch [765/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [766/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0046\n",
      "Epoch [767/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [768/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0046\n",
      "Epoch [769/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0046\n",
      "Epoch [770/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0046\n",
      "Epoch [771/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0046\n",
      "Epoch [772/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [773/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [774/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [775/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0045\n",
      "Epoch [776/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0046\n",
      "Epoch [777/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0046\n",
      "Epoch [778/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [779/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0046\n",
      "Epoch [780/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [781/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [782/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0045\n",
      "Epoch [783/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [784/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0046\n",
      "Epoch [785/2000] Fold 3, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [786/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0045\n",
      "Epoch [787/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0045\n",
      "Epoch [788/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0045\n",
      "Epoch [789/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0046\n",
      "Epoch [790/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0045\n",
      "Epoch [791/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [792/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [793/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [794/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [795/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0045\n",
      "Epoch [796/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0045\n",
      "Epoch [797/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [798/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [799/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0046\n",
      "Epoch [800/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [801/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [802/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [803/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0045\n",
      "Epoch [804/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0045\n",
      "Epoch [805/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [806/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [807/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [808/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0045\n",
      "Epoch [809/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0045\n",
      "Epoch [810/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0045\n",
      "Epoch [811/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0045\n",
      "Epoch [812/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0045\n",
      "Epoch [813/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0048\n",
      "Epoch [814/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0045\n",
      "Epoch [815/2000] Fold 3, Train Loss: 0.0027, Val Loss: 0.0045\n",
      "Epoch [816/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0045\n",
      "Epoch [817/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0045\n",
      "Epoch [818/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [819/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [820/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0044\n",
      "Epoch [821/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [822/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0044\n",
      "Epoch [823/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [824/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [825/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [826/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [827/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [828/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [829/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [830/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [831/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [832/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [833/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [834/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [835/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [836/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [837/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [838/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [839/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0044\n",
      "Epoch [840/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0044\n",
      "Epoch [841/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [842/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [843/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [844/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [845/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [846/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [847/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [848/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [849/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0044\n",
      "Epoch [850/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [851/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [852/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [853/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [854/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0044\n",
      "Epoch [855/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [856/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0044\n",
      "Epoch [857/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [858/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [859/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0044\n",
      "Epoch [860/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0044\n",
      "Epoch [861/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [862/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [863/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [864/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [865/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [866/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [867/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [868/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [869/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [870/2000] Fold 3, Train Loss: 0.0026, Val Loss: 0.0045\n",
      "Epoch [871/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [872/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0044\n",
      "Epoch [873/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0044\n",
      "Epoch [874/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [875/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0044\n",
      "Epoch [876/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0044\n",
      "Epoch [877/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0044\n",
      "Epoch [878/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [879/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [880/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [881/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0044\n",
      "Epoch [882/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0044\n",
      "Epoch [883/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0044\n",
      "Epoch [884/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [885/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [886/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [887/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [888/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [889/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [890/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [891/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [892/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [893/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [894/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [895/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [896/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [897/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [898/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [899/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [900/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [901/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [902/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [903/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0044\n",
      "Epoch [904/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [905/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [906/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [907/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [908/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [909/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0044\n",
      "Epoch [910/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0044\n",
      "Epoch [911/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0048\n",
      "Epoch [912/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0044\n",
      "Epoch [913/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0044\n",
      "Epoch [914/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [915/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [916/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [917/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0044\n",
      "Epoch [918/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0044\n",
      "Epoch [919/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [920/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0043\n",
      "Epoch [921/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [922/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [923/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [924/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [925/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [926/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [927/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [928/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0044\n",
      "Epoch [929/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [930/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0044\n",
      "Epoch [931/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [932/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0044\n",
      "Epoch [933/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [934/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0044\n",
      "Epoch [935/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [936/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [937/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [938/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [939/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0044\n",
      "Epoch [940/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [941/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [942/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0044\n",
      "Epoch [943/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [944/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0044\n",
      "Epoch [945/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0044\n",
      "Epoch [946/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [947/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0044\n",
      "Epoch [948/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [949/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0044\n",
      "Epoch [950/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [951/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [952/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [953/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0044\n",
      "Epoch [954/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [955/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0044\n",
      "Epoch [956/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0044\n",
      "Epoch [957/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [958/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [959/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0043\n",
      "Epoch [960/2000] Fold 3, Train Loss: 0.0025, Val Loss: 0.0044\n",
      "Epoch [961/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0043\n",
      "Epoch [962/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [963/2000] Fold 3, Train Loss: 0.0023, Val Loss: 0.0044\n",
      "Epoch [964/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [965/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0042\n",
      "Epoch [966/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [967/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [968/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [969/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0042\n",
      "Epoch [970/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [971/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0043\n",
      "Epoch [972/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [973/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [974/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [975/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0044\n",
      "Epoch [976/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [977/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [978/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [979/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [980/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [981/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [982/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [983/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [984/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [985/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [986/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [987/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0044\n",
      "Epoch [988/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [989/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [990/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [991/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [992/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0042\n",
      "Epoch [993/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0044\n",
      "Epoch [994/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [995/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0044\n",
      "Epoch [996/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [997/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0042\n",
      "Epoch [998/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [999/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0042\n",
      "Epoch [1000/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1001/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1002/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1003/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1004/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1005/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [1006/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [1007/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0044\n",
      "Epoch [1008/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [1009/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0042\n",
      "Epoch [1010/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1011/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1012/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1013/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1014/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1015/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1016/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1017/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1018/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1019/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1020/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [1021/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1022/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1023/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1024/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1025/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1026/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0044\n",
      "Epoch [1027/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1028/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1029/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [1030/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0042\n",
      "Epoch [1031/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1032/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1033/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1034/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1035/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [1036/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [1037/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [1038/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1039/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1040/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1041/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1042/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0043\n",
      "Epoch [1043/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0043\n",
      "Epoch [1044/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1045/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0041\n",
      "Epoch [1046/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1047/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1048/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1049/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1050/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1051/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1052/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1053/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1054/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1055/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0041\n",
      "Epoch [1056/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0044\n",
      "Epoch [1057/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1058/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1059/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1060/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1061/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1062/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1063/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1064/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1065/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1066/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1067/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1068/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1069/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1070/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0043\n",
      "Epoch [1071/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1072/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1073/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1074/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1075/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1076/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1077/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0043\n",
      "Epoch [1078/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0043\n",
      "Epoch [1079/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0043\n",
      "Epoch [1080/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1081/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1082/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1083/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1084/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1085/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1086/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1087/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0041\n",
      "Epoch [1088/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1089/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1090/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1091/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0043\n",
      "Epoch [1092/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1093/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1094/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1095/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1096/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1097/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1098/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1099/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1100/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1101/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1102/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1103/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1104/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1105/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1106/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0043\n",
      "Epoch [1107/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1108/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1109/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1110/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1111/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1112/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1113/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1114/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1115/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1116/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1117/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1118/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1119/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1120/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1121/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1122/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1123/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0042\n",
      "Epoch [1124/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1125/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1126/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1127/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0042\n",
      "Epoch [1128/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1129/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1130/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0040\n",
      "Epoch [1131/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0042\n",
      "Epoch [1132/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1133/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1134/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1135/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1136/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0042\n",
      "Epoch [1137/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1138/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1139/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1140/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1141/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0040\n",
      "Epoch [1142/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1143/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1144/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1145/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1146/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1147/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0042\n",
      "Epoch [1148/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0042\n",
      "Epoch [1149/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0040\n",
      "Epoch [1150/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1151/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0042\n",
      "Epoch [1152/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0042\n",
      "Epoch [1153/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0042\n",
      "Epoch [1154/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0042\n",
      "Epoch [1155/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1156/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1157/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1158/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0042\n",
      "Epoch [1159/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1160/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0042\n",
      "Epoch [1161/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0043\n",
      "Epoch [1162/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0042\n",
      "Epoch [1163/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0041\n",
      "Epoch [1164/2000] Fold 3, Train Loss: 0.0024, Val Loss: 0.0042\n",
      "Epoch [1165/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1166/2000] Fold 3, Train Loss: 0.0021, Val Loss: 0.0043\n",
      "Epoch [1167/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0043\n",
      "Epoch [1168/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0043\n",
      "Epoch [1169/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0040\n",
      "Epoch [1170/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1171/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0041\n",
      "Epoch [1172/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1173/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1174/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1175/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1176/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1177/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1178/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1179/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1180/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1181/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1182/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1183/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0040\n",
      "Epoch [1184/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0040\n",
      "Epoch [1185/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1186/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1187/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1188/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1189/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1190/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1191/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1192/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1193/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1194/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1195/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1196/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1197/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1198/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1199/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1200/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0042\n",
      "Epoch [1201/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1202/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1203/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1204/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1205/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1206/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1207/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1208/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1209/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1210/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1211/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1212/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1213/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1214/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1215/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1216/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1217/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1218/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1219/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1220/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1221/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1222/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1223/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0039\n",
      "Epoch [1224/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1225/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1226/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1227/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1228/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1229/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1230/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0041\n",
      "Epoch [1231/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1232/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0042\n",
      "Epoch [1233/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1234/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1235/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1236/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1237/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1238/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0039\n",
      "Epoch [1239/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1240/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1241/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1242/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0041\n",
      "Epoch [1243/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1244/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1245/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0039\n",
      "Epoch [1246/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1247/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1248/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1249/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0042\n",
      "Epoch [1250/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0048\n",
      "Epoch [1251/2000] Fold 3, Train Loss: 0.0022, Val Loss: 0.0042\n",
      "Epoch [1252/2000] Fold 3, Train Loss: 0.0018, Val Loss: 0.0042\n",
      "Epoch [1253/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1254/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0039\n",
      "Epoch [1255/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1256/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1257/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1258/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1259/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1260/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1261/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0039\n",
      "Epoch [1262/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1263/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1264/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1265/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1266/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1267/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1268/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1269/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1270/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0041\n",
      "Epoch [1271/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1272/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1273/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1274/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1275/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1276/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1277/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1278/2000] Fold 3, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1279/2000] Fold 3, Train Loss: 0.0019, Val Loss: 0.0041\n",
      "Epoch [1280/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1281/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0039\n",
      "Epoch [1282/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1283/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1284/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1285/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1286/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1287/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1288/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1289/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1290/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1291/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1292/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1293/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1294/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1295/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1296/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1297/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1298/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1299/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1300/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1301/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1302/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1303/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1304/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1305/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1306/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1307/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1308/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1309/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1310/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1311/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1312/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1313/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1314/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1315/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1316/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1317/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1318/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1319/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1320/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1321/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1322/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1323/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1324/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1325/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1326/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1327/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1328/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1329/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1330/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1331/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1332/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1333/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1334/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1335/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1336/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1337/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1338/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1339/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1340/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1341/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1342/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1343/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1344/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0039\n",
      "Epoch [1345/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1346/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1347/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0040\n",
      "Epoch [1348/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1349/2000] Fold 3, Train Loss: 0.0017, Val Loss: 0.0041\n",
      "Epoch [1350/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0040\n",
      "Epoch [1351/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1352/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1353/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1354/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1355/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1356/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1357/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1358/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1359/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1360/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1361/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1362/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1363/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1364/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1365/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1366/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1367/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1368/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1369/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1370/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1371/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1372/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1373/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1374/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1375/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1376/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1377/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1378/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1379/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1380/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1381/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1382/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1383/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1384/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1385/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1386/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1387/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1388/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1389/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1390/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1391/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1392/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1393/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0038\n",
      "Epoch [1394/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1395/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0041\n",
      "Epoch [1396/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1397/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1398/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1399/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1400/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1401/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1402/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0038\n",
      "Epoch [1403/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1404/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1405/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1406/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1407/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1408/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1409/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1410/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1411/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1412/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1413/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1414/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1415/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1416/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0038\n",
      "Epoch [1417/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1418/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1419/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1420/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1421/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1422/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1423/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1424/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1425/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1426/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1427/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1428/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1429/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1430/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1431/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1432/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1433/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1434/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0041\n",
      "Epoch [1435/2000] Fold 3, Train Loss: 0.0016, Val Loss: 0.0039\n",
      "Epoch [1436/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0039\n",
      "Epoch [1437/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1438/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0040\n",
      "Epoch [1439/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0038\n",
      "Epoch [1440/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0038\n",
      "Epoch [1441/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1442/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1443/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1444/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1445/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1446/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1447/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0041\n",
      "Epoch [1448/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1449/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0038\n",
      "Epoch [1450/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0038\n",
      "Epoch [1451/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1452/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1453/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1454/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1455/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1456/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1457/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1458/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1459/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1460/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1461/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1462/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1463/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0038\n",
      "Epoch [1464/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1465/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1466/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1467/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1468/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1469/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1470/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1471/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1472/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1473/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1474/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0040\n",
      "Epoch [1475/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1476/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1477/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1478/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1479/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1480/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1481/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0038\n",
      "Epoch [1482/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0038\n",
      "Epoch [1483/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1484/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1485/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1486/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0041\n",
      "Epoch [1487/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1488/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1489/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1490/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0041\n",
      "Epoch [1491/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1492/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1493/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1494/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1495/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1496/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1497/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1498/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1499/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1500/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1501/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1502/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1503/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1504/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1505/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1506/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1507/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0038\n",
      "Epoch [1508/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0040\n",
      "Epoch [1509/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1510/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0038\n",
      "Epoch [1511/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1512/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1513/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1514/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1515/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1516/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1517/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1518/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1519/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0040\n",
      "Epoch [1520/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1521/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1522/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1523/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1524/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1525/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1526/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1527/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1528/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1529/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1530/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1531/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1532/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1533/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1534/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1535/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0041\n",
      "Epoch [1536/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1537/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0040\n",
      "Epoch [1538/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1539/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1540/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1541/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1542/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1543/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1544/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1545/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1546/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1547/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1548/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1549/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1550/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1551/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1552/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1553/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1554/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1555/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1556/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1557/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1558/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1559/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1560/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1561/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1562/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1563/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1564/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1565/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1566/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1567/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1568/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1569/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1570/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1571/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1572/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1573/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1574/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0040\n",
      "Epoch [1575/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1576/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1577/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1578/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1579/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1580/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1581/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1582/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1583/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1584/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1585/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1586/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1587/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1588/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1589/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0039\n",
      "Epoch [1590/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0039\n",
      "Epoch [1591/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1592/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1593/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1594/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1595/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1596/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1597/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1598/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1599/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1600/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1601/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0040\n",
      "Epoch [1602/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1603/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0042\n",
      "Epoch [1604/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0038\n",
      "Epoch [1605/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0040\n",
      "Epoch [1606/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1607/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0038\n",
      "Epoch [1608/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1609/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0041\n",
      "Epoch [1610/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0038\n",
      "Epoch [1611/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1612/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0039\n",
      "Epoch [1613/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1614/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1615/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1616/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1617/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1618/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1619/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1620/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1621/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1622/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1623/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1624/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1625/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1626/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1627/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1628/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0039\n",
      "Epoch [1629/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1630/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0039\n",
      "Epoch [1631/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1632/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0039\n",
      "Epoch [1633/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1634/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1635/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1636/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1637/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1638/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1639/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0039\n",
      "Epoch [1640/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0039\n",
      "Epoch [1641/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1642/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1643/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1644/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1645/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1646/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1647/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1648/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1649/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1650/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0039\n",
      "Epoch [1651/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1652/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1653/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0039\n",
      "Epoch [1654/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0039\n",
      "Epoch [1655/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1656/2000] Fold 3, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1657/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0039\n",
      "Epoch [1658/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1659/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1660/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0037\n",
      "Epoch [1661/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1662/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1663/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1664/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1665/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1666/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1667/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1668/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1669/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1670/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1671/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0040\n",
      "Epoch [1672/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1673/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1674/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1675/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1676/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1677/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1678/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1679/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1680/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1681/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1682/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1683/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1684/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1685/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1686/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0038\n",
      "Epoch [1687/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1688/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1689/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1690/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1691/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1692/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1693/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1694/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1695/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1696/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1697/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1698/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1699/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1700/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1701/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1702/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1703/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1704/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1705/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1706/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1707/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0039\n",
      "Epoch [1708/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0039\n",
      "Epoch [1709/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1710/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1711/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1712/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1713/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1714/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0039\n",
      "Epoch [1715/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1716/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1717/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1718/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1719/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1720/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1721/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1722/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0040\n",
      "Epoch [1723/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1724/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1725/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1726/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1727/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1728/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1729/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1730/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1731/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0036\n",
      "Epoch [1732/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1733/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0039\n",
      "Epoch [1734/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1735/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1736/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1737/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1738/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1739/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1740/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1741/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0039\n",
      "Epoch [1742/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1743/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1744/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1745/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1746/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1747/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1748/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1749/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1750/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1751/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1752/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1753/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1754/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1755/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1756/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1757/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1758/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1759/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1760/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1761/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1762/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1763/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1764/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1765/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1766/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1767/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1768/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1769/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1770/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1771/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1772/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1773/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1774/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1775/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1776/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1777/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1778/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1779/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1780/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1781/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1782/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0039\n",
      "Epoch [1783/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0037\n",
      "Epoch [1784/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1785/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0039\n",
      "Epoch [1786/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0039\n",
      "Epoch [1787/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1788/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1789/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1790/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1791/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0039\n",
      "Epoch [1792/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1793/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1794/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1795/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1796/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1797/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1798/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1799/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0039\n",
      "Epoch [1800/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0039\n",
      "Epoch [1801/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1802/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1803/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1804/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1805/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1806/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0036\n",
      "Epoch [1807/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1808/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1809/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1810/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1811/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1812/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1813/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1814/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1815/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1816/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1817/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1818/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1819/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1820/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0038\n",
      "Epoch [1821/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1822/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1823/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1824/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0036\n",
      "Epoch [1825/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1826/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1827/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1828/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1829/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1830/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0038\n",
      "Epoch [1831/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1832/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1833/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1834/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0039\n",
      "Epoch [1835/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1836/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1837/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1838/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1839/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0038\n",
      "Epoch [1840/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0041\n",
      "Epoch [1841/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1842/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1843/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1844/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1845/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1846/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1847/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0038\n",
      "Epoch [1848/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1849/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0038\n",
      "Epoch [1850/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1851/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1852/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1853/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1854/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1855/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1856/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0039\n",
      "Epoch [1857/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1858/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0039\n",
      "Epoch [1859/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1860/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1861/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1862/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1863/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1864/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1865/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1866/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1867/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0038\n",
      "Epoch [1868/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1869/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1870/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1871/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0038\n",
      "Epoch [1872/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1873/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0038\n",
      "Epoch [1874/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1875/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1876/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1877/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1878/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0038\n",
      "Epoch [1879/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1880/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1881/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1882/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1883/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1884/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1885/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1886/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1887/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1888/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1889/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1890/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0038\n",
      "Epoch [1891/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1892/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0036\n",
      "Epoch [1893/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1894/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0040\n",
      "Epoch [1895/2000] Fold 3, Train Loss: 0.0013, Val Loss: 0.0039\n",
      "Epoch [1896/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0036\n",
      "Epoch [1897/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0036\n",
      "Epoch [1898/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1899/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0036\n",
      "Epoch [1900/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0038\n",
      "Epoch [1901/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1902/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1903/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1904/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0040\n",
      "Epoch [1905/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0036\n",
      "Epoch [1906/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1907/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1908/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0038\n",
      "Epoch [1909/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0038\n",
      "Epoch [1910/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1911/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1912/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1913/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1914/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1915/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1916/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1917/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1918/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1919/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1920/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1921/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1922/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1923/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1924/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0038\n",
      "Epoch [1925/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1926/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1927/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1928/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1929/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1930/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1931/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1932/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1933/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1934/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1935/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1936/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1937/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0038\n",
      "Epoch [1938/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1939/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1940/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1941/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1942/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1943/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1944/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1945/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1946/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1947/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1948/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1949/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1950/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0037\n",
      "Epoch [1951/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1952/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1953/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0039\n",
      "Epoch [1954/2000] Fold 3, Train Loss: 0.0014, Val Loss: 0.0040\n",
      "Epoch [1955/2000] Fold 3, Train Loss: 0.0012, Val Loss: 0.0038\n",
      "Epoch [1956/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0039\n",
      "Epoch [1957/2000] Fold 3, Train Loss: 0.0011, Val Loss: 0.0038\n",
      "Epoch [1958/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1959/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1960/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1961/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1962/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1963/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1964/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1965/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1966/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1967/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1968/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1969/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0037\n",
      "Epoch [1970/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0036\n",
      "Epoch [1971/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1972/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0036\n",
      "Epoch [1973/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0036\n",
      "Epoch [1974/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0036\n",
      "Epoch [1975/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0036\n",
      "Epoch [1976/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1977/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1978/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1979/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1980/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0037\n",
      "Epoch [1981/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0037\n",
      "Epoch [1982/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1983/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0037\n",
      "Epoch [1984/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0037\n",
      "Epoch [1985/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1986/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0036\n",
      "Epoch [1987/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0036\n",
      "Epoch [1988/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0037\n",
      "Epoch [1989/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0037\n",
      "Epoch [1990/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0037\n",
      "Epoch [1991/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0037\n",
      "Epoch [1992/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0037\n",
      "Epoch [1993/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0037\n",
      "Epoch [1994/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1995/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0037\n",
      "Epoch [1996/2000] Fold 3, Train Loss: 0.0010, Val Loss: 0.0036\n",
      "Epoch [1997/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0036\n",
      "Epoch [1998/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0037\n",
      "Epoch [1999/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0037\n",
      "Epoch [2000/2000] Fold 3, Train Loss: 0.0009, Val Loss: 0.0038\n",
      "Fold 4/5\n",
      "Epoch [1/2000] Fold 4, Train Loss: 0.0262, Val Loss: 0.0253\n",
      "Epoch [2/2000] Fold 4, Train Loss: 0.0225, Val Loss: 0.0216\n",
      "Epoch [3/2000] Fold 4, Train Loss: 0.0191, Val Loss: 0.0181\n",
      "Epoch [4/2000] Fold 4, Train Loss: 0.0161, Val Loss: 0.0157\n",
      "Epoch [5/2000] Fold 4, Train Loss: 0.0144, Val Loss: 0.0146\n",
      "Epoch [6/2000] Fold 4, Train Loss: 0.0137, Val Loss: 0.0143\n",
      "Epoch [7/2000] Fold 4, Train Loss: 0.0134, Val Loss: 0.0142\n",
      "Epoch [8/2000] Fold 4, Train Loss: 0.0135, Val Loss: 0.0142\n",
      "Epoch [9/2000] Fold 4, Train Loss: 0.0134, Val Loss: 0.0142\n",
      "Epoch [10/2000] Fold 4, Train Loss: 0.0134, Val Loss: 0.0142\n",
      "Epoch [11/2000] Fold 4, Train Loss: 0.0134, Val Loss: 0.0142\n",
      "Epoch [12/2000] Fold 4, Train Loss: 0.0134, Val Loss: 0.0142\n",
      "Epoch [13/2000] Fold 4, Train Loss: 0.0134, Val Loss: 0.0141\n",
      "Epoch [14/2000] Fold 4, Train Loss: 0.0135, Val Loss: 0.0142\n",
      "Epoch [15/2000] Fold 4, Train Loss: 0.0135, Val Loss: 0.0142\n",
      "Epoch [16/2000] Fold 4, Train Loss: 0.0134, Val Loss: 0.0141\n",
      "Epoch [17/2000] Fold 4, Train Loss: 0.0135, Val Loss: 0.0142\n",
      "Epoch [18/2000] Fold 4, Train Loss: 0.0134, Val Loss: 0.0142\n",
      "Epoch [19/2000] Fold 4, Train Loss: 0.0135, Val Loss: 0.0142\n",
      "Epoch [20/2000] Fold 4, Train Loss: 0.0135, Val Loss: 0.0142\n",
      "Epoch [21/2000] Fold 4, Train Loss: 0.0134, Val Loss: 0.0141\n",
      "Epoch [22/2000] Fold 4, Train Loss: 0.0135, Val Loss: 0.0142\n",
      "Epoch [23/2000] Fold 4, Train Loss: 0.0135, Val Loss: 0.0142\n",
      "Epoch [24/2000] Fold 4, Train Loss: 0.0134, Val Loss: 0.0141\n",
      "Epoch [25/2000] Fold 4, Train Loss: 0.0134, Val Loss: 0.0142\n",
      "Epoch [26/2000] Fold 4, Train Loss: 0.0135, Val Loss: 0.0142\n",
      "Epoch [27/2000] Fold 4, Train Loss: 0.0134, Val Loss: 0.0141\n",
      "Epoch [28/2000] Fold 4, Train Loss: 0.0135, Val Loss: 0.0142\n",
      "Epoch [29/2000] Fold 4, Train Loss: 0.0134, Val Loss: 0.0141\n",
      "Epoch [30/2000] Fold 4, Train Loss: 0.0134, Val Loss: 0.0141\n",
      "Epoch [31/2000] Fold 4, Train Loss: 0.0134, Val Loss: 0.0141\n",
      "Epoch [32/2000] Fold 4, Train Loss: 0.0133, Val Loss: 0.0139\n",
      "Epoch [33/2000] Fold 4, Train Loss: 0.0130, Val Loss: 0.0131\n",
      "Epoch [34/2000] Fold 4, Train Loss: 0.0119, Val Loss: 0.0115\n",
      "Epoch [35/2000] Fold 4, Train Loss: 0.0107, Val Loss: 0.0106\n",
      "Epoch [36/2000] Fold 4, Train Loss: 0.0100, Val Loss: 0.0103\n",
      "Epoch [37/2000] Fold 4, Train Loss: 0.0098, Val Loss: 0.0100\n",
      "Epoch [38/2000] Fold 4, Train Loss: 0.0096, Val Loss: 0.0099\n",
      "Epoch [39/2000] Fold 4, Train Loss: 0.0094, Val Loss: 0.0097\n",
      "Epoch [40/2000] Fold 4, Train Loss: 0.0092, Val Loss: 0.0096\n",
      "Epoch [41/2000] Fold 4, Train Loss: 0.0090, Val Loss: 0.0094\n",
      "Epoch [42/2000] Fold 4, Train Loss: 0.0089, Val Loss: 0.0093\n",
      "Epoch [43/2000] Fold 4, Train Loss: 0.0088, Val Loss: 0.0093\n",
      "Epoch [44/2000] Fold 4, Train Loss: 0.0088, Val Loss: 0.0092\n",
      "Epoch [45/2000] Fold 4, Train Loss: 0.0087, Val Loss: 0.0092\n",
      "Epoch [46/2000] Fold 4, Train Loss: 0.0087, Val Loss: 0.0091\n",
      "Epoch [47/2000] Fold 4, Train Loss: 0.0086, Val Loss: 0.0091\n",
      "Epoch [48/2000] Fold 4, Train Loss: 0.0086, Val Loss: 0.0091\n",
      "Epoch [49/2000] Fold 4, Train Loss: 0.0086, Val Loss: 0.0090\n",
      "Epoch [50/2000] Fold 4, Train Loss: 0.0085, Val Loss: 0.0090\n",
      "Epoch [51/2000] Fold 4, Train Loss: 0.0085, Val Loss: 0.0090\n",
      "Epoch [52/2000] Fold 4, Train Loss: 0.0085, Val Loss: 0.0089\n",
      "Epoch [53/2000] Fold 4, Train Loss: 0.0084, Val Loss: 0.0089\n",
      "Epoch [54/2000] Fold 4, Train Loss: 0.0084, Val Loss: 0.0089\n",
      "Epoch [55/2000] Fold 4, Train Loss: 0.0084, Val Loss: 0.0089\n",
      "Epoch [56/2000] Fold 4, Train Loss: 0.0084, Val Loss: 0.0089\n",
      "Epoch [57/2000] Fold 4, Train Loss: 0.0084, Val Loss: 0.0088\n",
      "Epoch [58/2000] Fold 4, Train Loss: 0.0083, Val Loss: 0.0088\n",
      "Epoch [59/2000] Fold 4, Train Loss: 0.0083, Val Loss: 0.0088\n",
      "Epoch [60/2000] Fold 4, Train Loss: 0.0082, Val Loss: 0.0088\n",
      "Epoch [61/2000] Fold 4, Train Loss: 0.0082, Val Loss: 0.0087\n",
      "Epoch [62/2000] Fold 4, Train Loss: 0.0081, Val Loss: 0.0086\n",
      "Epoch [63/2000] Fold 4, Train Loss: 0.0080, Val Loss: 0.0086\n",
      "Epoch [64/2000] Fold 4, Train Loss: 0.0080, Val Loss: 0.0085\n",
      "Epoch [65/2000] Fold 4, Train Loss: 0.0079, Val Loss: 0.0085\n",
      "Epoch [66/2000] Fold 4, Train Loss: 0.0079, Val Loss: 0.0084\n",
      "Epoch [67/2000] Fold 4, Train Loss: 0.0078, Val Loss: 0.0084\n",
      "Epoch [68/2000] Fold 4, Train Loss: 0.0078, Val Loss: 0.0084\n",
      "Epoch [69/2000] Fold 4, Train Loss: 0.0078, Val Loss: 0.0084\n",
      "Epoch [70/2000] Fold 4, Train Loss: 0.0078, Val Loss: 0.0083\n",
      "Epoch [71/2000] Fold 4, Train Loss: 0.0077, Val Loss: 0.0082\n",
      "Epoch [72/2000] Fold 4, Train Loss: 0.0077, Val Loss: 0.0082\n",
      "Epoch [73/2000] Fold 4, Train Loss: 0.0076, Val Loss: 0.0083\n",
      "Epoch [74/2000] Fold 4, Train Loss: 0.0076, Val Loss: 0.0082\n",
      "Epoch [75/2000] Fold 4, Train Loss: 0.0076, Val Loss: 0.0082\n",
      "Epoch [76/2000] Fold 4, Train Loss: 0.0076, Val Loss: 0.0082\n",
      "Epoch [77/2000] Fold 4, Train Loss: 0.0075, Val Loss: 0.0081\n",
      "Epoch [78/2000] Fold 4, Train Loss: 0.0075, Val Loss: 0.0081\n",
      "Epoch [79/2000] Fold 4, Train Loss: 0.0075, Val Loss: 0.0080\n",
      "Epoch [80/2000] Fold 4, Train Loss: 0.0075, Val Loss: 0.0081\n",
      "Epoch [81/2000] Fold 4, Train Loss: 0.0074, Val Loss: 0.0080\n",
      "Epoch [82/2000] Fold 4, Train Loss: 0.0074, Val Loss: 0.0080\n",
      "Epoch [83/2000] Fold 4, Train Loss: 0.0074, Val Loss: 0.0080\n",
      "Epoch [84/2000] Fold 4, Train Loss: 0.0073, Val Loss: 0.0079\n",
      "Epoch [85/2000] Fold 4, Train Loss: 0.0074, Val Loss: 0.0079\n",
      "Epoch [86/2000] Fold 4, Train Loss: 0.0073, Val Loss: 0.0078\n",
      "Epoch [87/2000] Fold 4, Train Loss: 0.0073, Val Loss: 0.0079\n",
      "Epoch [88/2000] Fold 4, Train Loss: 0.0073, Val Loss: 0.0078\n",
      "Epoch [89/2000] Fold 4, Train Loss: 0.0072, Val Loss: 0.0078\n",
      "Epoch [90/2000] Fold 4, Train Loss: 0.0073, Val Loss: 0.0078\n",
      "Epoch [91/2000] Fold 4, Train Loss: 0.0072, Val Loss: 0.0078\n",
      "Epoch [92/2000] Fold 4, Train Loss: 0.0072, Val Loss: 0.0077\n",
      "Epoch [93/2000] Fold 4, Train Loss: 0.0072, Val Loss: 0.0077\n",
      "Epoch [94/2000] Fold 4, Train Loss: 0.0072, Val Loss: 0.0077\n",
      "Epoch [95/2000] Fold 4, Train Loss: 0.0071, Val Loss: 0.0077\n",
      "Epoch [96/2000] Fold 4, Train Loss: 0.0071, Val Loss: 0.0077\n",
      "Epoch [97/2000] Fold 4, Train Loss: 0.0071, Val Loss: 0.0077\n",
      "Epoch [98/2000] Fold 4, Train Loss: 0.0071, Val Loss: 0.0077\n",
      "Epoch [99/2000] Fold 4, Train Loss: 0.0071, Val Loss: 0.0077\n",
      "Epoch [100/2000] Fold 4, Train Loss: 0.0070, Val Loss: 0.0076\n",
      "Epoch [101/2000] Fold 4, Train Loss: 0.0070, Val Loss: 0.0076\n",
      "Epoch [102/2000] Fold 4, Train Loss: 0.0070, Val Loss: 0.0076\n",
      "Epoch [103/2000] Fold 4, Train Loss: 0.0070, Val Loss: 0.0076\n",
      "Epoch [104/2000] Fold 4, Train Loss: 0.0070, Val Loss: 0.0076\n",
      "Epoch [105/2000] Fold 4, Train Loss: 0.0069, Val Loss: 0.0076\n",
      "Epoch [106/2000] Fold 4, Train Loss: 0.0070, Val Loss: 0.0075\n",
      "Epoch [107/2000] Fold 4, Train Loss: 0.0069, Val Loss: 0.0075\n",
      "Epoch [108/2000] Fold 4, Train Loss: 0.0069, Val Loss: 0.0075\n",
      "Epoch [109/2000] Fold 4, Train Loss: 0.0069, Val Loss: 0.0075\n",
      "Epoch [110/2000] Fold 4, Train Loss: 0.0069, Val Loss: 0.0075\n",
      "Epoch [111/2000] Fold 4, Train Loss: 0.0068, Val Loss: 0.0074\n",
      "Epoch [112/2000] Fold 4, Train Loss: 0.0068, Val Loss: 0.0075\n",
      "Epoch [113/2000] Fold 4, Train Loss: 0.0068, Val Loss: 0.0074\n",
      "Epoch [114/2000] Fold 4, Train Loss: 0.0068, Val Loss: 0.0074\n",
      "Epoch [115/2000] Fold 4, Train Loss: 0.0068, Val Loss: 0.0075\n",
      "Epoch [116/2000] Fold 4, Train Loss: 0.0068, Val Loss: 0.0075\n",
      "Epoch [117/2000] Fold 4, Train Loss: 0.0068, Val Loss: 0.0074\n",
      "Epoch [118/2000] Fold 4, Train Loss: 0.0067, Val Loss: 0.0074\n",
      "Epoch [119/2000] Fold 4, Train Loss: 0.0067, Val Loss: 0.0074\n",
      "Epoch [120/2000] Fold 4, Train Loss: 0.0067, Val Loss: 0.0074\n",
      "Epoch [121/2000] Fold 4, Train Loss: 0.0067, Val Loss: 0.0074\n",
      "Epoch [122/2000] Fold 4, Train Loss: 0.0066, Val Loss: 0.0073\n",
      "Epoch [123/2000] Fold 4, Train Loss: 0.0066, Val Loss: 0.0074\n",
      "Epoch [124/2000] Fold 4, Train Loss: 0.0066, Val Loss: 0.0073\n",
      "Epoch [125/2000] Fold 4, Train Loss: 0.0065, Val Loss: 0.0073\n",
      "Epoch [126/2000] Fold 4, Train Loss: 0.0065, Val Loss: 0.0073\n",
      "Epoch [127/2000] Fold 4, Train Loss: 0.0065, Val Loss: 0.0073\n",
      "Epoch [128/2000] Fold 4, Train Loss: 0.0066, Val Loss: 0.0073\n",
      "Epoch [129/2000] Fold 4, Train Loss: 0.0065, Val Loss: 0.0073\n",
      "Epoch [130/2000] Fold 4, Train Loss: 0.0065, Val Loss: 0.0072\n",
      "Epoch [131/2000] Fold 4, Train Loss: 0.0064, Val Loss: 0.0073\n",
      "Epoch [132/2000] Fold 4, Train Loss: 0.0065, Val Loss: 0.0073\n",
      "Epoch [133/2000] Fold 4, Train Loss: 0.0065, Val Loss: 0.0072\n",
      "Epoch [134/2000] Fold 4, Train Loss: 0.0064, Val Loss: 0.0072\n",
      "Epoch [135/2000] Fold 4, Train Loss: 0.0064, Val Loss: 0.0072\n",
      "Epoch [136/2000] Fold 4, Train Loss: 0.0065, Val Loss: 0.0074\n",
      "Epoch [137/2000] Fold 4, Train Loss: 0.0064, Val Loss: 0.0072\n",
      "Epoch [138/2000] Fold 4, Train Loss: 0.0063, Val Loss: 0.0072\n",
      "Epoch [139/2000] Fold 4, Train Loss: 0.0063, Val Loss: 0.0071\n",
      "Epoch [140/2000] Fold 4, Train Loss: 0.0063, Val Loss: 0.0071\n",
      "Epoch [141/2000] Fold 4, Train Loss: 0.0063, Val Loss: 0.0071\n",
      "Epoch [142/2000] Fold 4, Train Loss: 0.0063, Val Loss: 0.0071\n",
      "Epoch [143/2000] Fold 4, Train Loss: 0.0063, Val Loss: 0.0071\n",
      "Epoch [144/2000] Fold 4, Train Loss: 0.0062, Val Loss: 0.0071\n",
      "Epoch [145/2000] Fold 4, Train Loss: 0.0062, Val Loss: 0.0070\n",
      "Epoch [146/2000] Fold 4, Train Loss: 0.0062, Val Loss: 0.0070\n",
      "Epoch [147/2000] Fold 4, Train Loss: 0.0062, Val Loss: 0.0070\n",
      "Epoch [148/2000] Fold 4, Train Loss: 0.0062, Val Loss: 0.0071\n",
      "Epoch [149/2000] Fold 4, Train Loss: 0.0062, Val Loss: 0.0070\n",
      "Epoch [150/2000] Fold 4, Train Loss: 0.0061, Val Loss: 0.0070\n",
      "Epoch [151/2000] Fold 4, Train Loss: 0.0061, Val Loss: 0.0070\n",
      "Epoch [152/2000] Fold 4, Train Loss: 0.0061, Val Loss: 0.0071\n",
      "Epoch [153/2000] Fold 4, Train Loss: 0.0061, Val Loss: 0.0070\n",
      "Epoch [154/2000] Fold 4, Train Loss: 0.0061, Val Loss: 0.0070\n",
      "Epoch [155/2000] Fold 4, Train Loss: 0.0061, Val Loss: 0.0070\n",
      "Epoch [156/2000] Fold 4, Train Loss: 0.0060, Val Loss: 0.0070\n",
      "Epoch [157/2000] Fold 4, Train Loss: 0.0061, Val Loss: 0.0070\n",
      "Epoch [158/2000] Fold 4, Train Loss: 0.0061, Val Loss: 0.0070\n",
      "Epoch [159/2000] Fold 4, Train Loss: 0.0060, Val Loss: 0.0070\n",
      "Epoch [160/2000] Fold 4, Train Loss: 0.0060, Val Loss: 0.0069\n",
      "Epoch [161/2000] Fold 4, Train Loss: 0.0060, Val Loss: 0.0070\n",
      "Epoch [162/2000] Fold 4, Train Loss: 0.0060, Val Loss: 0.0069\n",
      "Epoch [163/2000] Fold 4, Train Loss: 0.0060, Val Loss: 0.0069\n",
      "Epoch [164/2000] Fold 4, Train Loss: 0.0060, Val Loss: 0.0069\n",
      "Epoch [165/2000] Fold 4, Train Loss: 0.0060, Val Loss: 0.0069\n",
      "Epoch [166/2000] Fold 4, Train Loss: 0.0060, Val Loss: 0.0069\n",
      "Epoch [167/2000] Fold 4, Train Loss: 0.0060, Val Loss: 0.0069\n",
      "Epoch [168/2000] Fold 4, Train Loss: 0.0059, Val Loss: 0.0069\n",
      "Epoch [169/2000] Fold 4, Train Loss: 0.0059, Val Loss: 0.0069\n",
      "Epoch [170/2000] Fold 4, Train Loss: 0.0059, Val Loss: 0.0070\n",
      "Epoch [171/2000] Fold 4, Train Loss: 0.0059, Val Loss: 0.0069\n",
      "Epoch [172/2000] Fold 4, Train Loss: 0.0059, Val Loss: 0.0069\n",
      "Epoch [173/2000] Fold 4, Train Loss: 0.0059, Val Loss: 0.0068\n",
      "Epoch [174/2000] Fold 4, Train Loss: 0.0059, Val Loss: 0.0068\n",
      "Epoch [175/2000] Fold 4, Train Loss: 0.0059, Val Loss: 0.0069\n",
      "Epoch [176/2000] Fold 4, Train Loss: 0.0058, Val Loss: 0.0069\n",
      "Epoch [177/2000] Fold 4, Train Loss: 0.0059, Val Loss: 0.0068\n",
      "Epoch [178/2000] Fold 4, Train Loss: 0.0059, Val Loss: 0.0069\n",
      "Epoch [179/2000] Fold 4, Train Loss: 0.0059, Val Loss: 0.0069\n",
      "Epoch [180/2000] Fold 4, Train Loss: 0.0059, Val Loss: 0.0068\n",
      "Epoch [181/2000] Fold 4, Train Loss: 0.0059, Val Loss: 0.0068\n",
      "Epoch [182/2000] Fold 4, Train Loss: 0.0058, Val Loss: 0.0068\n",
      "Epoch [183/2000] Fold 4, Train Loss: 0.0059, Val Loss: 0.0069\n",
      "Epoch [184/2000] Fold 4, Train Loss: 0.0059, Val Loss: 0.0069\n",
      "Epoch [185/2000] Fold 4, Train Loss: 0.0058, Val Loss: 0.0068\n",
      "Epoch [186/2000] Fold 4, Train Loss: 0.0058, Val Loss: 0.0068\n",
      "Epoch [187/2000] Fold 4, Train Loss: 0.0058, Val Loss: 0.0068\n",
      "Epoch [188/2000] Fold 4, Train Loss: 0.0058, Val Loss: 0.0069\n",
      "Epoch [189/2000] Fold 4, Train Loss: 0.0058, Val Loss: 0.0068\n",
      "Epoch [190/2000] Fold 4, Train Loss: 0.0058, Val Loss: 0.0068\n",
      "Epoch [191/2000] Fold 4, Train Loss: 0.0058, Val Loss: 0.0068\n",
      "Epoch [192/2000] Fold 4, Train Loss: 0.0058, Val Loss: 0.0069\n",
      "Epoch [193/2000] Fold 4, Train Loss: 0.0058, Val Loss: 0.0068\n",
      "Epoch [194/2000] Fold 4, Train Loss: 0.0058, Val Loss: 0.0068\n",
      "Epoch [195/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0069\n",
      "Epoch [196/2000] Fold 4, Train Loss: 0.0058, Val Loss: 0.0068\n",
      "Epoch [197/2000] Fold 4, Train Loss: 0.0058, Val Loss: 0.0068\n",
      "Epoch [198/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0068\n",
      "Epoch [199/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0068\n",
      "Epoch [200/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0068\n",
      "Epoch [201/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0067\n",
      "Epoch [202/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0067\n",
      "Epoch [203/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0068\n",
      "Epoch [204/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0068\n",
      "Epoch [205/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0068\n",
      "Epoch [206/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0068\n",
      "Epoch [207/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0067\n",
      "Epoch [208/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0067\n",
      "Epoch [209/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0067\n",
      "Epoch [210/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0067\n",
      "Epoch [211/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0067\n",
      "Epoch [212/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0068\n",
      "Epoch [213/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0067\n",
      "Epoch [214/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0067\n",
      "Epoch [215/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0066\n",
      "Epoch [216/2000] Fold 4, Train Loss: 0.0057, Val Loss: 0.0067\n",
      "Epoch [217/2000] Fold 4, Train Loss: 0.0056, Val Loss: 0.0067\n",
      "Epoch [218/2000] Fold 4, Train Loss: 0.0056, Val Loss: 0.0067\n",
      "Epoch [219/2000] Fold 4, Train Loss: 0.0056, Val Loss: 0.0067\n",
      "Epoch [220/2000] Fold 4, Train Loss: 0.0056, Val Loss: 0.0067\n",
      "Epoch [221/2000] Fold 4, Train Loss: 0.0056, Val Loss: 0.0067\n",
      "Epoch [222/2000] Fold 4, Train Loss: 0.0056, Val Loss: 0.0067\n",
      "Epoch [223/2000] Fold 4, Train Loss: 0.0056, Val Loss: 0.0067\n",
      "Epoch [224/2000] Fold 4, Train Loss: 0.0056, Val Loss: 0.0066\n",
      "Epoch [225/2000] Fold 4, Train Loss: 0.0055, Val Loss: 0.0067\n",
      "Epoch [226/2000] Fold 4, Train Loss: 0.0056, Val Loss: 0.0067\n",
      "Epoch [227/2000] Fold 4, Train Loss: 0.0056, Val Loss: 0.0067\n",
      "Epoch [228/2000] Fold 4, Train Loss: 0.0056, Val Loss: 0.0067\n",
      "Epoch [229/2000] Fold 4, Train Loss: 0.0055, Val Loss: 0.0066\n",
      "Epoch [230/2000] Fold 4, Train Loss: 0.0055, Val Loss: 0.0067\n",
      "Epoch [231/2000] Fold 4, Train Loss: 0.0055, Val Loss: 0.0066\n",
      "Epoch [232/2000] Fold 4, Train Loss: 0.0055, Val Loss: 0.0066\n",
      "Epoch [233/2000] Fold 4, Train Loss: 0.0055, Val Loss: 0.0067\n",
      "Epoch [234/2000] Fold 4, Train Loss: 0.0055, Val Loss: 0.0066\n",
      "Epoch [235/2000] Fold 4, Train Loss: 0.0055, Val Loss: 0.0066\n",
      "Epoch [236/2000] Fold 4, Train Loss: 0.0055, Val Loss: 0.0066\n",
      "Epoch [237/2000] Fold 4, Train Loss: 0.0055, Val Loss: 0.0066\n",
      "Epoch [238/2000] Fold 4, Train Loss: 0.0055, Val Loss: 0.0066\n",
      "Epoch [239/2000] Fold 4, Train Loss: 0.0054, Val Loss: 0.0066\n",
      "Epoch [240/2000] Fold 4, Train Loss: 0.0054, Val Loss: 0.0066\n",
      "Epoch [241/2000] Fold 4, Train Loss: 0.0054, Val Loss: 0.0066\n",
      "Epoch [242/2000] Fold 4, Train Loss: 0.0054, Val Loss: 0.0066\n",
      "Epoch [243/2000] Fold 4, Train Loss: 0.0054, Val Loss: 0.0066\n",
      "Epoch [244/2000] Fold 4, Train Loss: 0.0054, Val Loss: 0.0065\n",
      "Epoch [245/2000] Fold 4, Train Loss: 0.0054, Val Loss: 0.0066\n",
      "Epoch [246/2000] Fold 4, Train Loss: 0.0054, Val Loss: 0.0065\n",
      "Epoch [247/2000] Fold 4, Train Loss: 0.0054, Val Loss: 0.0066\n",
      "Epoch [248/2000] Fold 4, Train Loss: 0.0054, Val Loss: 0.0066\n",
      "Epoch [249/2000] Fold 4, Train Loss: 0.0054, Val Loss: 0.0066\n",
      "Epoch [250/2000] Fold 4, Train Loss: 0.0054, Val Loss: 0.0065\n",
      "Epoch [251/2000] Fold 4, Train Loss: 0.0054, Val Loss: 0.0065\n",
      "Epoch [252/2000] Fold 4, Train Loss: 0.0054, Val Loss: 0.0065\n",
      "Epoch [253/2000] Fold 4, Train Loss: 0.0053, Val Loss: 0.0065\n",
      "Epoch [254/2000] Fold 4, Train Loss: 0.0053, Val Loss: 0.0065\n",
      "Epoch [255/2000] Fold 4, Train Loss: 0.0053, Val Loss: 0.0065\n",
      "Epoch [256/2000] Fold 4, Train Loss: 0.0053, Val Loss: 0.0065\n",
      "Epoch [257/2000] Fold 4, Train Loss: 0.0053, Val Loss: 0.0064\n",
      "Epoch [258/2000] Fold 4, Train Loss: 0.0053, Val Loss: 0.0065\n",
      "Epoch [259/2000] Fold 4, Train Loss: 0.0053, Val Loss: 0.0065\n",
      "Epoch [260/2000] Fold 4, Train Loss: 0.0053, Val Loss: 0.0065\n",
      "Epoch [261/2000] Fold 4, Train Loss: 0.0053, Val Loss: 0.0065\n",
      "Epoch [262/2000] Fold 4, Train Loss: 0.0053, Val Loss: 0.0064\n",
      "Epoch [263/2000] Fold 4, Train Loss: 0.0052, Val Loss: 0.0065\n",
      "Epoch [264/2000] Fold 4, Train Loss: 0.0053, Val Loss: 0.0065\n",
      "Epoch [265/2000] Fold 4, Train Loss: 0.0052, Val Loss: 0.0064\n",
      "Epoch [266/2000] Fold 4, Train Loss: 0.0052, Val Loss: 0.0064\n",
      "Epoch [267/2000] Fold 4, Train Loss: 0.0052, Val Loss: 0.0065\n",
      "Epoch [268/2000] Fold 4, Train Loss: 0.0052, Val Loss: 0.0064\n",
      "Epoch [269/2000] Fold 4, Train Loss: 0.0052, Val Loss: 0.0065\n",
      "Epoch [270/2000] Fold 4, Train Loss: 0.0052, Val Loss: 0.0067\n",
      "Epoch [271/2000] Fold 4, Train Loss: 0.0052, Val Loss: 0.0063\n",
      "Epoch [272/2000] Fold 4, Train Loss: 0.0051, Val Loss: 0.0064\n",
      "Epoch [273/2000] Fold 4, Train Loss: 0.0051, Val Loss: 0.0063\n",
      "Epoch [274/2000] Fold 4, Train Loss: 0.0052, Val Loss: 0.0063\n",
      "Epoch [275/2000] Fold 4, Train Loss: 0.0052, Val Loss: 0.0064\n",
      "Epoch [276/2000] Fold 4, Train Loss: 0.0051, Val Loss: 0.0063\n",
      "Epoch [277/2000] Fold 4, Train Loss: 0.0051, Val Loss: 0.0063\n",
      "Epoch [278/2000] Fold 4, Train Loss: 0.0051, Val Loss: 0.0062\n",
      "Epoch [279/2000] Fold 4, Train Loss: 0.0051, Val Loss: 0.0064\n",
      "Epoch [280/2000] Fold 4, Train Loss: 0.0051, Val Loss: 0.0062\n",
      "Epoch [281/2000] Fold 4, Train Loss: 0.0051, Val Loss: 0.0063\n",
      "Epoch [282/2000] Fold 4, Train Loss: 0.0051, Val Loss: 0.0064\n",
      "Epoch [283/2000] Fold 4, Train Loss: 0.0051, Val Loss: 0.0063\n",
      "Epoch [284/2000] Fold 4, Train Loss: 0.0050, Val Loss: 0.0062\n",
      "Epoch [285/2000] Fold 4, Train Loss: 0.0050, Val Loss: 0.0062\n",
      "Epoch [286/2000] Fold 4, Train Loss: 0.0050, Val Loss: 0.0063\n",
      "Epoch [287/2000] Fold 4, Train Loss: 0.0050, Val Loss: 0.0062\n",
      "Epoch [288/2000] Fold 4, Train Loss: 0.0050, Val Loss: 0.0062\n",
      "Epoch [289/2000] Fold 4, Train Loss: 0.0050, Val Loss: 0.0063\n",
      "Epoch [290/2000] Fold 4, Train Loss: 0.0049, Val Loss: 0.0062\n",
      "Epoch [291/2000] Fold 4, Train Loss: 0.0049, Val Loss: 0.0062\n",
      "Epoch [292/2000] Fold 4, Train Loss: 0.0050, Val Loss: 0.0063\n",
      "Epoch [293/2000] Fold 4, Train Loss: 0.0050, Val Loss: 0.0062\n",
      "Epoch [294/2000] Fold 4, Train Loss: 0.0050, Val Loss: 0.0062\n",
      "Epoch [295/2000] Fold 4, Train Loss: 0.0049, Val Loss: 0.0062\n",
      "Epoch [296/2000] Fold 4, Train Loss: 0.0049, Val Loss: 0.0062\n",
      "Epoch [297/2000] Fold 4, Train Loss: 0.0050, Val Loss: 0.0063\n",
      "Epoch [298/2000] Fold 4, Train Loss: 0.0049, Val Loss: 0.0062\n",
      "Epoch [299/2000] Fold 4, Train Loss: 0.0049, Val Loss: 0.0062\n",
      "Epoch [300/2000] Fold 4, Train Loss: 0.0050, Val Loss: 0.0062\n",
      "Epoch [301/2000] Fold 4, Train Loss: 0.0050, Val Loss: 0.0062\n",
      "Epoch [302/2000] Fold 4, Train Loss: 0.0049, Val Loss: 0.0061\n",
      "Epoch [303/2000] Fold 4, Train Loss: 0.0049, Val Loss: 0.0061\n",
      "Epoch [304/2000] Fold 4, Train Loss: 0.0048, Val Loss: 0.0061\n",
      "Epoch [305/2000] Fold 4, Train Loss: 0.0048, Val Loss: 0.0062\n",
      "Epoch [306/2000] Fold 4, Train Loss: 0.0048, Val Loss: 0.0062\n",
      "Epoch [307/2000] Fold 4, Train Loss: 0.0048, Val Loss: 0.0062\n",
      "Epoch [308/2000] Fold 4, Train Loss: 0.0048, Val Loss: 0.0062\n",
      "Epoch [309/2000] Fold 4, Train Loss: 0.0048, Val Loss: 0.0062\n",
      "Epoch [310/2000] Fold 4, Train Loss: 0.0048, Val Loss: 0.0062\n",
      "Epoch [311/2000] Fold 4, Train Loss: 0.0048, Val Loss: 0.0061\n",
      "Epoch [312/2000] Fold 4, Train Loss: 0.0048, Val Loss: 0.0061\n",
      "Epoch [313/2000] Fold 4, Train Loss: 0.0048, Val Loss: 0.0062\n",
      "Epoch [314/2000] Fold 4, Train Loss: 0.0048, Val Loss: 0.0062\n",
      "Epoch [315/2000] Fold 4, Train Loss: 0.0047, Val Loss: 0.0061\n",
      "Epoch [316/2000] Fold 4, Train Loss: 0.0047, Val Loss: 0.0062\n",
      "Epoch [317/2000] Fold 4, Train Loss: 0.0048, Val Loss: 0.0061\n",
      "Epoch [318/2000] Fold 4, Train Loss: 0.0047, Val Loss: 0.0061\n",
      "Epoch [319/2000] Fold 4, Train Loss: 0.0047, Val Loss: 0.0061\n",
      "Epoch [320/2000] Fold 4, Train Loss: 0.0047, Val Loss: 0.0061\n",
      "Epoch [321/2000] Fold 4, Train Loss: 0.0047, Val Loss: 0.0061\n",
      "Epoch [322/2000] Fold 4, Train Loss: 0.0047, Val Loss: 0.0061\n",
      "Epoch [323/2000] Fold 4, Train Loss: 0.0047, Val Loss: 0.0061\n",
      "Epoch [324/2000] Fold 4, Train Loss: 0.0047, Val Loss: 0.0061\n",
      "Epoch [325/2000] Fold 4, Train Loss: 0.0047, Val Loss: 0.0062\n",
      "Epoch [326/2000] Fold 4, Train Loss: 0.0047, Val Loss: 0.0062\n",
      "Epoch [327/2000] Fold 4, Train Loss: 0.0047, Val Loss: 0.0061\n",
      "Epoch [328/2000] Fold 4, Train Loss: 0.0048, Val Loss: 0.0062\n",
      "Epoch [329/2000] Fold 4, Train Loss: 0.0047, Val Loss: 0.0061\n",
      "Epoch [330/2000] Fold 4, Train Loss: 0.0047, Val Loss: 0.0061\n",
      "Epoch [331/2000] Fold 4, Train Loss: 0.0047, Val Loss: 0.0062\n",
      "Epoch [332/2000] Fold 4, Train Loss: 0.0046, Val Loss: 0.0060\n",
      "Epoch [333/2000] Fold 4, Train Loss: 0.0046, Val Loss: 0.0061\n",
      "Epoch [334/2000] Fold 4, Train Loss: 0.0046, Val Loss: 0.0061\n",
      "Epoch [335/2000] Fold 4, Train Loss: 0.0046, Val Loss: 0.0061\n",
      "Epoch [336/2000] Fold 4, Train Loss: 0.0046, Val Loss: 0.0062\n",
      "Epoch [337/2000] Fold 4, Train Loss: 0.0046, Val Loss: 0.0061\n",
      "Epoch [338/2000] Fold 4, Train Loss: 0.0046, Val Loss: 0.0062\n",
      "Epoch [339/2000] Fold 4, Train Loss: 0.0046, Val Loss: 0.0061\n",
      "Epoch [340/2000] Fold 4, Train Loss: 0.0046, Val Loss: 0.0061\n",
      "Epoch [341/2000] Fold 4, Train Loss: 0.0046, Val Loss: 0.0061\n",
      "Epoch [342/2000] Fold 4, Train Loss: 0.0046, Val Loss: 0.0061\n",
      "Epoch [343/2000] Fold 4, Train Loss: 0.0047, Val Loss: 0.0062\n",
      "Epoch [344/2000] Fold 4, Train Loss: 0.0046, Val Loss: 0.0062\n",
      "Epoch [345/2000] Fold 4, Train Loss: 0.0046, Val Loss: 0.0060\n",
      "Epoch [346/2000] Fold 4, Train Loss: 0.0046, Val Loss: 0.0061\n",
      "Epoch [347/2000] Fold 4, Train Loss: 0.0045, Val Loss: 0.0061\n",
      "Epoch [348/2000] Fold 4, Train Loss: 0.0045, Val Loss: 0.0061\n",
      "Epoch [349/2000] Fold 4, Train Loss: 0.0045, Val Loss: 0.0061\n",
      "Epoch [350/2000] Fold 4, Train Loss: 0.0045, Val Loss: 0.0061\n",
      "Epoch [351/2000] Fold 4, Train Loss: 0.0045, Val Loss: 0.0060\n",
      "Epoch [352/2000] Fold 4, Train Loss: 0.0044, Val Loss: 0.0060\n",
      "Epoch [353/2000] Fold 4, Train Loss: 0.0045, Val Loss: 0.0061\n",
      "Epoch [354/2000] Fold 4, Train Loss: 0.0045, Val Loss: 0.0061\n",
      "Epoch [355/2000] Fold 4, Train Loss: 0.0045, Val Loss: 0.0061\n",
      "Epoch [356/2000] Fold 4, Train Loss: 0.0045, Val Loss: 0.0061\n",
      "Epoch [357/2000] Fold 4, Train Loss: 0.0045, Val Loss: 0.0061\n",
      "Epoch [358/2000] Fold 4, Train Loss: 0.0045, Val Loss: 0.0062\n",
      "Epoch [359/2000] Fold 4, Train Loss: 0.0045, Val Loss: 0.0060\n",
      "Epoch [360/2000] Fold 4, Train Loss: 0.0045, Val Loss: 0.0061\n",
      "Epoch [361/2000] Fold 4, Train Loss: 0.0044, Val Loss: 0.0061\n",
      "Epoch [362/2000] Fold 4, Train Loss: 0.0044, Val Loss: 0.0060\n",
      "Epoch [363/2000] Fold 4, Train Loss: 0.0044, Val Loss: 0.0060\n",
      "Epoch [364/2000] Fold 4, Train Loss: 0.0044, Val Loss: 0.0060\n",
      "Epoch [365/2000] Fold 4, Train Loss: 0.0044, Val Loss: 0.0061\n",
      "Epoch [366/2000] Fold 4, Train Loss: 0.0044, Val Loss: 0.0060\n",
      "Epoch [367/2000] Fold 4, Train Loss: 0.0044, Val Loss: 0.0060\n",
      "Epoch [368/2000] Fold 4, Train Loss: 0.0044, Val Loss: 0.0060\n",
      "Epoch [369/2000] Fold 4, Train Loss: 0.0044, Val Loss: 0.0060\n",
      "Epoch [370/2000] Fold 4, Train Loss: 0.0044, Val Loss: 0.0060\n",
      "Epoch [371/2000] Fold 4, Train Loss: 0.0044, Val Loss: 0.0060\n",
      "Epoch [372/2000] Fold 4, Train Loss: 0.0044, Val Loss: 0.0060\n",
      "Epoch [373/2000] Fold 4, Train Loss: 0.0044, Val Loss: 0.0060\n",
      "Epoch [374/2000] Fold 4, Train Loss: 0.0044, Val Loss: 0.0060\n",
      "Epoch [375/2000] Fold 4, Train Loss: 0.0044, Val Loss: 0.0060\n",
      "Epoch [376/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0060\n",
      "Epoch [377/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0060\n",
      "Epoch [378/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0060\n",
      "Epoch [379/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0060\n",
      "Epoch [380/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0061\n",
      "Epoch [381/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0060\n",
      "Epoch [382/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0060\n",
      "Epoch [383/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0060\n",
      "Epoch [384/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0060\n",
      "Epoch [385/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0060\n",
      "Epoch [386/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0060\n",
      "Epoch [387/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0060\n",
      "Epoch [388/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0060\n",
      "Epoch [389/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0060\n",
      "Epoch [390/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0059\n",
      "Epoch [391/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0060\n",
      "Epoch [392/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0060\n",
      "Epoch [393/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0061\n",
      "Epoch [394/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0060\n",
      "Epoch [395/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [396/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [397/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0060\n",
      "Epoch [398/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0060\n",
      "Epoch [399/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0060\n",
      "Epoch [400/2000] Fold 4, Train Loss: 0.0043, Val Loss: 0.0060\n",
      "Epoch [401/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [402/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [403/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [404/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [405/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [406/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0060\n",
      "Epoch [407/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [408/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [409/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [410/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0060\n",
      "Epoch [411/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [412/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [413/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [414/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0060\n",
      "Epoch [415/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0060\n",
      "Epoch [416/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [417/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [418/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [419/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [420/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0060\n",
      "Epoch [421/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [422/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [423/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [424/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [425/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [426/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [427/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [428/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [429/2000] Fold 4, Train Loss: 0.0042, Val Loss: 0.0059\n",
      "Epoch [430/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [431/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [432/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0058\n",
      "Epoch [433/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [434/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [435/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [436/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0058\n",
      "Epoch [437/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [438/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [439/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [440/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0058\n",
      "Epoch [441/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0058\n",
      "Epoch [442/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0058\n",
      "Epoch [443/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [444/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [445/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [446/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [447/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [448/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [449/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [450/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0059\n",
      "Epoch [451/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0057\n",
      "Epoch [452/2000] Fold 4, Train Loss: 0.0041, Val Loss: 0.0058\n",
      "Epoch [453/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [454/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [455/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0059\n",
      "Epoch [456/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [457/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0059\n",
      "Epoch [458/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0059\n",
      "Epoch [459/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0059\n",
      "Epoch [460/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [461/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [462/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [463/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [464/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [465/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0059\n",
      "Epoch [466/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0059\n",
      "Epoch [467/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [468/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [469/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [470/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [471/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [472/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [473/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [474/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [475/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [476/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0057\n",
      "Epoch [477/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [478/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0059\n",
      "Epoch [479/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0058\n",
      "Epoch [480/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0059\n",
      "Epoch [481/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0059\n",
      "Epoch [482/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [483/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [484/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [485/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [486/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [487/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0057\n",
      "Epoch [488/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [489/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0057\n",
      "Epoch [490/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0057\n",
      "Epoch [491/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [492/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [493/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [494/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [495/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0058\n",
      "Epoch [496/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [497/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0060\n",
      "Epoch [498/2000] Fold 4, Train Loss: 0.0040, Val Loss: 0.0062\n",
      "Epoch [499/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0056\n",
      "Epoch [500/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [501/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0060\n",
      "Epoch [502/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [503/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [504/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0058\n",
      "Epoch [505/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [506/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [507/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [508/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0058\n",
      "Epoch [509/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [510/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [511/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [512/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [513/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [514/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0058\n",
      "Epoch [515/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [516/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0058\n",
      "Epoch [517/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0058\n",
      "Epoch [518/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [519/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [520/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [521/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [522/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0058\n",
      "Epoch [523/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [524/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [525/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [526/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [527/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [528/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0058\n",
      "Epoch [529/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [530/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0058\n",
      "Epoch [531/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [532/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0056\n",
      "Epoch [533/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0057\n",
      "Epoch [534/2000] Fold 4, Train Loss: 0.0039, Val Loss: 0.0058\n",
      "Epoch [535/2000] Fold 4, Train Loss: 0.0038, Val Loss: 0.0058\n",
      "Epoch [536/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0056\n",
      "Epoch [537/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [538/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [539/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [540/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [541/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [542/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0058\n",
      "Epoch [543/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0058\n",
      "Epoch [544/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0056\n",
      "Epoch [545/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [546/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [547/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [548/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [549/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [550/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0056\n",
      "Epoch [551/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [552/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [553/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0056\n",
      "Epoch [554/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [555/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0058\n",
      "Epoch [556/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0059\n",
      "Epoch [557/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [558/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [559/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0056\n",
      "Epoch [560/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0058\n",
      "Epoch [561/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [562/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [563/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0056\n",
      "Epoch [564/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [565/2000] Fold 4, Train Loss: 0.0037, Val Loss: 0.0057\n",
      "Epoch [566/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0056\n",
      "Epoch [567/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0056\n",
      "Epoch [568/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0056\n",
      "Epoch [569/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [570/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0056\n",
      "Epoch [571/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [572/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [573/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [574/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0056\n",
      "Epoch [575/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [576/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [577/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [578/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [579/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0056\n",
      "Epoch [580/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0056\n",
      "Epoch [581/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [582/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [583/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [584/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0056\n",
      "Epoch [585/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [586/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0056\n",
      "Epoch [587/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0056\n",
      "Epoch [588/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [589/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [590/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0056\n",
      "Epoch [591/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0057\n",
      "Epoch [592/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [593/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [594/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [595/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [596/2000] Fold 4, Train Loss: 0.0036, Val Loss: 0.0057\n",
      "Epoch [597/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [598/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [599/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [600/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [601/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [602/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [603/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0055\n",
      "Epoch [604/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [605/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0056\n",
      "Epoch [606/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0058\n",
      "Epoch [607/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [608/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [609/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [610/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0055\n",
      "Epoch [611/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [612/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [613/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0056\n",
      "Epoch [614/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0056\n",
      "Epoch [615/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0057\n",
      "Epoch [616/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [617/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [618/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [619/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0056\n",
      "Epoch [620/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0056\n",
      "Epoch [621/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0056\n",
      "Epoch [622/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0056\n",
      "Epoch [623/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [624/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0057\n",
      "Epoch [625/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [626/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0057\n",
      "Epoch [627/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0056\n",
      "Epoch [628/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [629/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0057\n",
      "Epoch [630/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [631/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0056\n",
      "Epoch [632/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0056\n",
      "Epoch [633/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0056\n",
      "Epoch [634/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0056\n",
      "Epoch [635/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [636/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [637/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0056\n",
      "Epoch [638/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [639/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [640/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [641/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [642/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [643/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [644/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [645/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0056\n",
      "Epoch [646/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0056\n",
      "Epoch [647/2000] Fold 4, Train Loss: 0.0035, Val Loss: 0.0056\n",
      "Epoch [648/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [649/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0056\n",
      "Epoch [650/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [651/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [652/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [653/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [654/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [655/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [656/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [657/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [658/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [659/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [660/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [661/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [662/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0056\n",
      "Epoch [663/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [664/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0056\n",
      "Epoch [665/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [666/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [667/2000] Fold 4, Train Loss: 0.0034, Val Loss: 0.0055\n",
      "Epoch [668/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0056\n",
      "Epoch [669/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [670/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [671/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [672/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [673/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0056\n",
      "Epoch [674/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [675/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0054\n",
      "Epoch [676/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [677/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [678/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0056\n",
      "Epoch [679/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0054\n",
      "Epoch [680/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [681/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0054\n",
      "Epoch [682/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [683/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [684/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0054\n",
      "Epoch [685/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [686/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [687/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0056\n",
      "Epoch [688/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [689/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [690/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0056\n",
      "Epoch [691/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0057\n",
      "Epoch [692/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [693/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [694/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0056\n",
      "Epoch [695/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [696/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [697/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [698/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0056\n",
      "Epoch [699/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [700/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0056\n",
      "Epoch [701/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [702/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [703/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0054\n",
      "Epoch [704/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [705/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [706/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0054\n",
      "Epoch [707/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [708/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0054\n",
      "Epoch [709/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0054\n",
      "Epoch [710/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [711/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0056\n",
      "Epoch [712/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [713/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0054\n",
      "Epoch [714/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [715/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [716/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0054\n",
      "Epoch [717/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0054\n",
      "Epoch [718/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [719/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [720/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [721/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0054\n",
      "Epoch [722/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [723/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0054\n",
      "Epoch [724/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0054\n",
      "Epoch [725/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0056\n",
      "Epoch [726/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [727/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [728/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0054\n",
      "Epoch [729/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [730/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [731/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [732/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0054\n",
      "Epoch [733/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [734/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0055\n",
      "Epoch [735/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [736/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0055\n",
      "Epoch [737/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [738/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [739/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0055\n",
      "Epoch [740/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [741/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [742/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [743/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [744/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0055\n",
      "Epoch [745/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0055\n",
      "Epoch [746/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0055\n",
      "Epoch [747/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [748/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [749/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0054\n",
      "Epoch [750/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [751/2000] Fold 4, Train Loss: 0.0033, Val Loss: 0.0055\n",
      "Epoch [752/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0057\n",
      "Epoch [753/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0056\n",
      "Epoch [754/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0055\n",
      "Epoch [755/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [756/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0055\n",
      "Epoch [757/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0055\n",
      "Epoch [758/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [759/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [760/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [761/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [762/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [763/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [764/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [765/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0053\n",
      "Epoch [766/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [767/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [768/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [769/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [770/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0053\n",
      "Epoch [771/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0055\n",
      "Epoch [772/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [773/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [774/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [775/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0053\n",
      "Epoch [776/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [777/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [778/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [779/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [780/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [781/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [782/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [783/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [784/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0055\n",
      "Epoch [785/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [786/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [787/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [788/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0055\n",
      "Epoch [789/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0056\n",
      "Epoch [790/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0055\n",
      "Epoch [791/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0054\n",
      "Epoch [792/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [793/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0055\n",
      "Epoch [794/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [795/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [796/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [797/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0053\n",
      "Epoch [798/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [799/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0055\n",
      "Epoch [800/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0055\n",
      "Epoch [801/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [802/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [803/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [804/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0053\n",
      "Epoch [805/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [806/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0053\n",
      "Epoch [807/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [808/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0053\n",
      "Epoch [809/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [810/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [811/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0053\n",
      "Epoch [812/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [813/2000] Fold 4, Train Loss: 0.0031, Val Loss: 0.0054\n",
      "Epoch [814/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [815/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0053\n",
      "Epoch [816/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [817/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [818/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [819/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [820/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0053\n",
      "Epoch [821/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [822/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [823/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0054\n",
      "Epoch [824/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [825/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0054\n",
      "Epoch [826/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0053\n",
      "Epoch [827/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [828/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [829/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [830/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [831/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0057\n",
      "Epoch [832/2000] Fold 4, Train Loss: 0.0032, Val Loss: 0.0056\n",
      "Epoch [833/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [834/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0053\n",
      "Epoch [835/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [836/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [837/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0054\n",
      "Epoch [838/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [839/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0054\n",
      "Epoch [840/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [841/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [842/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0053\n",
      "Epoch [843/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0055\n",
      "Epoch [844/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0055\n",
      "Epoch [845/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [846/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0054\n",
      "Epoch [847/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [848/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0055\n",
      "Epoch [849/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [850/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [851/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [852/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [853/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [854/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [855/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [856/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [857/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [858/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [859/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [860/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0054\n",
      "Epoch [861/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [862/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0054\n",
      "Epoch [863/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [864/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [865/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0054\n",
      "Epoch [866/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0054\n",
      "Epoch [867/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [868/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [869/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [870/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [871/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [872/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [873/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [874/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [875/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [876/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [877/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [878/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0054\n",
      "Epoch [879/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [880/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0054\n",
      "Epoch [881/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0055\n",
      "Epoch [882/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0054\n",
      "Epoch [883/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [884/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [885/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0054\n",
      "Epoch [886/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0054\n",
      "Epoch [887/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [888/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [889/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [890/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [891/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [892/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [893/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [894/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [895/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [896/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [897/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [898/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0054\n",
      "Epoch [899/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0055\n",
      "Epoch [900/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0056\n",
      "Epoch [901/2000] Fold 4, Train Loss: 0.0030, Val Loss: 0.0053\n",
      "Epoch [902/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0054\n",
      "Epoch [903/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [904/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [905/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0052\n",
      "Epoch [906/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0052\n",
      "Epoch [907/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0052\n",
      "Epoch [908/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0054\n",
      "Epoch [909/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [910/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [911/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0052\n",
      "Epoch [912/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [913/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [914/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [915/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [916/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [917/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [918/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [919/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [920/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [921/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0054\n",
      "Epoch [922/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0055\n",
      "Epoch [923/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0054\n",
      "Epoch [924/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [925/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0053\n",
      "Epoch [926/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [927/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0055\n",
      "Epoch [928/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [929/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [930/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [931/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [932/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [933/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [934/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [935/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [936/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [937/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [938/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [939/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [940/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [941/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [942/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [943/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [944/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0054\n",
      "Epoch [945/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [946/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0054\n",
      "Epoch [947/2000] Fold 4, Train Loss: 0.0029, Val Loss: 0.0054\n",
      "Epoch [948/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [949/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [950/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [951/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [952/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [953/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [954/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [955/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [956/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [957/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [958/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0054\n",
      "Epoch [959/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [960/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [961/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [962/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [963/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [964/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [965/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [966/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0054\n",
      "Epoch [967/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [968/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [969/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [970/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [971/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [972/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [973/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [974/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [975/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [976/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [977/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0052\n",
      "Epoch [978/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [979/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0054\n",
      "Epoch [980/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [981/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [982/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [983/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0055\n",
      "Epoch [984/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [985/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0054\n",
      "Epoch [986/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0054\n",
      "Epoch [987/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0054\n",
      "Epoch [988/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [989/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [990/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [991/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [992/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [993/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0052\n",
      "Epoch [994/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0054\n",
      "Epoch [995/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [996/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [997/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [998/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [999/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [1000/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1001/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1002/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1003/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1004/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1005/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1006/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0052\n",
      "Epoch [1007/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1008/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1009/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0054\n",
      "Epoch [1010/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1011/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0054\n",
      "Epoch [1012/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1013/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0052\n",
      "Epoch [1014/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1015/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0052\n",
      "Epoch [1016/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1017/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1018/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1019/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1020/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [1021/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1022/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0054\n",
      "Epoch [1023/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1024/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1025/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1026/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1027/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0054\n",
      "Epoch [1028/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1029/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1030/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1031/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1032/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0052\n",
      "Epoch [1033/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0052\n",
      "Epoch [1034/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1035/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1036/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0055\n",
      "Epoch [1037/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [1038/2000] Fold 4, Train Loss: 0.0028, Val Loss: 0.0053\n",
      "Epoch [1039/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0054\n",
      "Epoch [1040/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0052\n",
      "Epoch [1041/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0054\n",
      "Epoch [1042/2000] Fold 4, Train Loss: 0.0027, Val Loss: 0.0053\n",
      "Epoch [1043/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1044/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1045/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0052\n",
      "Epoch [1046/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1047/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1048/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1049/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1050/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1051/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1052/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1053/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1054/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1055/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1056/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1057/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0052\n",
      "Epoch [1058/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1059/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0052\n",
      "Epoch [1060/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0054\n",
      "Epoch [1061/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1062/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0054\n",
      "Epoch [1063/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1064/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1065/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1066/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0052\n",
      "Epoch [1067/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1068/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1069/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1070/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1071/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1072/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1073/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1074/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1075/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0052\n",
      "Epoch [1076/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1077/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1078/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1079/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1080/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1081/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1082/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1083/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0055\n",
      "Epoch [1084/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0054\n",
      "Epoch [1085/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0054\n",
      "Epoch [1086/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0052\n",
      "Epoch [1087/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1088/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0054\n",
      "Epoch [1089/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1090/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0054\n",
      "Epoch [1091/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1092/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0054\n",
      "Epoch [1093/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0054\n",
      "Epoch [1094/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1095/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1096/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1097/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1098/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0054\n",
      "Epoch [1099/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1100/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1101/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1102/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1103/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0052\n",
      "Epoch [1104/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1105/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1106/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1107/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1108/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1109/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1110/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1111/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0052\n",
      "Epoch [1112/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0054\n",
      "Epoch [1113/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1114/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0054\n",
      "Epoch [1115/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1116/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1117/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0054\n",
      "Epoch [1118/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1119/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1120/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1121/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1122/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1123/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1124/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1125/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0052\n",
      "Epoch [1126/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1127/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1128/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1129/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0052\n",
      "Epoch [1130/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0052\n",
      "Epoch [1131/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1132/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0054\n",
      "Epoch [1133/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0055\n",
      "Epoch [1134/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0054\n",
      "Epoch [1135/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1136/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1137/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1138/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1139/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1140/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1141/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1142/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1143/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1144/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1145/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1146/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1147/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1148/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1149/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1150/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1151/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1152/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1153/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1154/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1155/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1156/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0052\n",
      "Epoch [1157/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1158/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1159/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1160/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1161/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0054\n",
      "Epoch [1162/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0052\n",
      "Epoch [1163/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1164/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1165/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1166/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1167/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1168/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0054\n",
      "Epoch [1169/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1170/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0054\n",
      "Epoch [1171/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0054\n",
      "Epoch [1172/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1173/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1174/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1175/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1176/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1177/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1178/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1179/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0054\n",
      "Epoch [1180/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1181/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0054\n",
      "Epoch [1182/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0054\n",
      "Epoch [1183/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1184/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1185/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0055\n",
      "Epoch [1186/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1187/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0054\n",
      "Epoch [1188/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1189/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0054\n",
      "Epoch [1190/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0053\n",
      "Epoch [1191/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1192/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0052\n",
      "Epoch [1193/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1194/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1195/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1196/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1197/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1198/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1199/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1200/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1201/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1202/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1203/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1204/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1205/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0054\n",
      "Epoch [1206/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0054\n",
      "Epoch [1207/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1208/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1209/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0054\n",
      "Epoch [1210/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1211/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0054\n",
      "Epoch [1212/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0054\n",
      "Epoch [1213/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0053\n",
      "Epoch [1214/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1215/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0052\n",
      "Epoch [1216/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0054\n",
      "Epoch [1217/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1218/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1219/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1220/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1221/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0054\n",
      "Epoch [1222/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1223/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1224/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1225/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1226/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1227/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1228/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1229/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1230/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1231/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1232/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1233/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1234/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1235/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1236/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1237/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1238/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1239/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1240/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1241/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1242/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1243/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1244/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1245/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0054\n",
      "Epoch [1246/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1247/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1248/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1249/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1250/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1251/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1252/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1253/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0058\n",
      "Epoch [1254/2000] Fold 4, Train Loss: 0.0026, Val Loss: 0.0054\n",
      "Epoch [1255/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0056\n",
      "Epoch [1256/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1257/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1258/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0054\n",
      "Epoch [1259/2000] Fold 4, Train Loss: 0.0025, Val Loss: 0.0054\n",
      "Epoch [1260/2000] Fold 4, Train Loss: 0.0024, Val Loss: 0.0053\n",
      "Epoch [1261/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1262/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1263/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1264/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1265/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1266/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1267/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1268/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1269/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1270/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1271/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1272/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1273/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1274/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1275/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1276/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1277/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1278/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1279/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1280/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1281/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1282/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1283/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1284/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1285/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1286/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1287/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1288/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1289/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1290/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1291/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1292/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1293/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1294/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1295/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1296/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1297/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1298/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1299/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1300/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1301/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1302/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0051\n",
      "Epoch [1303/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1304/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1305/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1306/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1307/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1308/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0051\n",
      "Epoch [1309/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1310/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1311/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1312/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0053\n",
      "Epoch [1313/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1314/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1315/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1316/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1317/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1318/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1319/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1320/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1321/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0054\n",
      "Epoch [1322/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1323/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1324/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1325/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0053\n",
      "Epoch [1326/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1327/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1328/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1329/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1330/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1331/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1332/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1333/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1334/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1335/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0051\n",
      "Epoch [1336/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1337/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1338/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0053\n",
      "Epoch [1339/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1340/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1341/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1342/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1343/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1344/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1345/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1346/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1347/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1348/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0053\n",
      "Epoch [1349/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1350/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1351/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1352/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1353/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0053\n",
      "Epoch [1354/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1355/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1356/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1357/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0053\n",
      "Epoch [1358/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1359/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0051\n",
      "Epoch [1360/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1361/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1362/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0051\n",
      "Epoch [1363/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1364/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1365/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1366/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1367/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0053\n",
      "Epoch [1368/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1369/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0053\n",
      "Epoch [1370/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1371/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1372/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0053\n",
      "Epoch [1373/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0053\n",
      "Epoch [1374/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0051\n",
      "Epoch [1375/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0051\n",
      "Epoch [1376/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0053\n",
      "Epoch [1377/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1378/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1379/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1380/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1381/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0051\n",
      "Epoch [1382/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1383/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1384/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1385/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1386/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1387/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1388/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1389/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1390/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1391/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0055\n",
      "Epoch [1392/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0056\n",
      "Epoch [1393/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0055\n",
      "Epoch [1394/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1395/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0054\n",
      "Epoch [1396/2000] Fold 4, Train Loss: 0.0023, Val Loss: 0.0052\n",
      "Epoch [1397/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0053\n",
      "Epoch [1398/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0051\n",
      "Epoch [1399/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1400/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1401/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0051\n",
      "Epoch [1402/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1403/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1404/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1405/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1406/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1407/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1408/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1409/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1410/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1411/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0053\n",
      "Epoch [1412/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1413/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1414/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1415/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0054\n",
      "Epoch [1416/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1417/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0051\n",
      "Epoch [1418/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1419/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1420/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1421/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1422/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1423/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1424/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1425/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1426/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1427/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1428/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1429/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1430/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0053\n",
      "Epoch [1431/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1432/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1433/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1434/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1435/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1436/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1437/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1438/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1439/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1440/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1441/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1442/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1443/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1444/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1445/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1446/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1447/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1448/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1449/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1450/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0053\n",
      "Epoch [1451/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1452/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1453/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1454/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1455/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1456/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1457/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0053\n",
      "Epoch [1458/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1459/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1460/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1461/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0054\n",
      "Epoch [1462/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0055\n",
      "Epoch [1463/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0055\n",
      "Epoch [1464/2000] Fold 4, Train Loss: 0.0022, Val Loss: 0.0052\n",
      "Epoch [1465/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0053\n",
      "Epoch [1466/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1467/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0053\n",
      "Epoch [1468/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1469/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1470/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1471/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1472/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1473/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1474/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1475/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1476/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1477/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1478/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1479/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1480/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1481/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1482/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1483/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1484/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1485/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1486/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1487/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1488/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1489/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1490/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1491/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1492/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1493/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1494/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1495/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1496/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0053\n",
      "Epoch [1497/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1498/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0053\n",
      "Epoch [1499/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1500/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1501/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0053\n",
      "Epoch [1502/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0054\n",
      "Epoch [1503/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1504/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1505/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0053\n",
      "Epoch [1506/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0053\n",
      "Epoch [1507/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1508/2000] Fold 4, Train Loss: 0.0021, Val Loss: 0.0052\n",
      "Epoch [1509/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0051\n",
      "Epoch [1510/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1511/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1512/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1513/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1514/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1515/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1516/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1517/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1518/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1519/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1520/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1521/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1522/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1523/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1524/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1525/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1526/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1527/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1528/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1529/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1530/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1531/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1532/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1533/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1534/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1535/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1536/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1537/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1538/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1539/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1540/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1541/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0050\n",
      "Epoch [1542/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1543/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1544/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1545/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1546/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1547/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1548/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1549/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1550/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1551/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1552/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1553/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1554/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1555/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1556/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1557/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1558/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1559/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1560/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1561/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1562/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1563/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1564/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1565/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1566/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1567/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1568/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1569/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1570/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1571/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1572/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1573/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1574/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1575/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1576/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1577/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1578/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1579/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1580/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1581/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1582/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1583/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1584/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1585/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1586/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1587/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1588/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1589/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1590/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1591/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1592/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1593/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1594/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1595/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1596/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1597/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1598/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1599/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1600/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0052\n",
      "Epoch [1601/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1602/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1603/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1604/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0052\n",
      "Epoch [1605/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1606/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1607/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0052\n",
      "Epoch [1608/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1609/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1610/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1611/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0052\n",
      "Epoch [1612/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1613/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1614/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1615/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1616/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1617/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0052\n",
      "Epoch [1618/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1619/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1620/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0052\n",
      "Epoch [1621/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1622/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1623/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1624/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0050\n",
      "Epoch [1625/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0052\n",
      "Epoch [1626/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1627/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1628/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1629/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1630/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1631/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1632/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0053\n",
      "Epoch [1633/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1634/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1635/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0052\n",
      "Epoch [1636/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0052\n",
      "Epoch [1637/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1638/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1639/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0052\n",
      "Epoch [1640/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1641/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1642/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1643/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0053\n",
      "Epoch [1644/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0053\n",
      "Epoch [1645/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1646/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1647/2000] Fold 4, Train Loss: 0.0020, Val Loss: 0.0052\n",
      "Epoch [1648/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1649/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1650/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1651/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0052\n",
      "Epoch [1652/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1653/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0053\n",
      "Epoch [1654/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1655/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1656/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1657/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1658/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1659/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1660/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1661/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1662/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1663/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1664/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1665/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1666/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1667/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1668/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0052\n",
      "Epoch [1669/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0053\n",
      "Epoch [1670/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1671/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0053\n",
      "Epoch [1672/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1673/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1674/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1675/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1676/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1677/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1678/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1679/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1680/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1681/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1682/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1683/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1684/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0052\n",
      "Epoch [1685/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1686/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0052\n",
      "Epoch [1687/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1688/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1689/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1690/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1691/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1692/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1693/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1694/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1695/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1696/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1697/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1698/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1699/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1700/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1701/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1702/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1703/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1704/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1705/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1706/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1707/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1708/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1709/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0052\n",
      "Epoch [1710/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0052\n",
      "Epoch [1711/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1712/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1713/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1714/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1715/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0052\n",
      "Epoch [1716/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0052\n",
      "Epoch [1717/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0051\n",
      "Epoch [1718/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1719/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1720/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1721/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1722/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0052\n",
      "Epoch [1723/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1724/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1725/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1726/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1727/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1728/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1729/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1730/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1731/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1732/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0052\n",
      "Epoch [1733/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1734/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1735/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1736/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1737/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1738/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1739/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1740/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1741/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1742/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1743/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1744/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1745/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1746/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1747/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1748/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1749/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1750/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1751/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1752/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1753/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1754/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1755/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0052\n",
      "Epoch [1756/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1757/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1758/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1759/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1760/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1761/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1762/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1763/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0052\n",
      "Epoch [1764/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1765/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0051\n",
      "Epoch [1766/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1767/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1768/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1769/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1770/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1771/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1772/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1773/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1774/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1775/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1776/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0049\n",
      "Epoch [1777/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1778/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1779/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1780/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0052\n",
      "Epoch [1781/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1782/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1783/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1784/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1785/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1786/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1787/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1788/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1789/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1790/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1791/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0051\n",
      "Epoch [1792/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1793/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0051\n",
      "Epoch [1794/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1795/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1796/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1797/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1798/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1799/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1800/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1801/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1802/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1803/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1804/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1805/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1806/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1807/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1808/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1809/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1810/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1811/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1812/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1813/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1814/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1815/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1816/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1817/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1818/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0052\n",
      "Epoch [1819/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1820/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1821/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1822/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1823/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1824/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1825/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1826/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1827/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1828/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1829/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1830/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1831/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1832/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1833/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0051\n",
      "Epoch [1834/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1835/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1836/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0051\n",
      "Epoch [1837/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0049\n",
      "Epoch [1838/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0055\n",
      "Epoch [1839/2000] Fold 4, Train Loss: 0.0019, Val Loss: 0.0050\n",
      "Epoch [1840/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1841/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1842/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1843/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1844/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1845/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1846/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1847/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1848/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1849/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1850/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1851/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1852/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1853/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1854/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1855/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1856/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1857/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0051\n",
      "Epoch [1858/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1859/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1860/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0051\n",
      "Epoch [1861/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0049\n",
      "Epoch [1862/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1863/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1864/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1865/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1866/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1867/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1868/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1869/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1870/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1871/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1872/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1873/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1874/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1875/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1876/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0050\n",
      "Epoch [1877/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1878/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0050\n",
      "Epoch [1879/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1880/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1881/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1882/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1883/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1884/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1885/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1886/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1887/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1888/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1889/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1890/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1891/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1892/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1893/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1894/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1895/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1896/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1897/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1898/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1899/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1900/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1901/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1902/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0050\n",
      "Epoch [1903/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1904/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1905/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0051\n",
      "Epoch [1906/2000] Fold 4, Train Loss: 0.0018, Val Loss: 0.0050\n",
      "Epoch [1907/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1908/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1909/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1910/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1911/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1912/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1913/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1914/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1915/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0050\n",
      "Epoch [1916/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0050\n",
      "Epoch [1917/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1918/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0048\n",
      "Epoch [1919/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1920/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1921/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0050\n",
      "Epoch [1922/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1923/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1924/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1925/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1926/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1927/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0050\n",
      "Epoch [1928/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1929/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1930/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1931/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1932/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1933/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1934/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0050\n",
      "Epoch [1935/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1936/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1937/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1938/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1939/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1940/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1941/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1942/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1943/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1944/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1945/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0050\n",
      "Epoch [1946/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1947/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1948/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1949/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1950/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1951/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0050\n",
      "Epoch [1952/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1953/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1954/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0048\n",
      "Epoch [1955/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0050\n",
      "Epoch [1956/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1957/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1958/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1959/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0051\n",
      "Epoch [1960/2000] Fold 4, Train Loss: 0.0017, Val Loss: 0.0050\n",
      "Epoch [1961/2000] Fold 4, Train Loss: 0.0016, Val Loss: 0.0049\n",
      "Epoch [1962/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0048\n",
      "Epoch [1963/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0050\n",
      "Epoch [1964/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0050\n",
      "Epoch [1965/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1966/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0050\n",
      "Epoch [1967/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1968/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0048\n",
      "Epoch [1969/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1970/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0048\n",
      "Epoch [1971/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1972/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1973/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1974/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1975/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1976/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1977/2000] Fold 4, Train Loss: 0.0014, Val Loss: 0.0048\n",
      "Epoch [1978/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1979/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0048\n",
      "Epoch [1980/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0048\n",
      "Epoch [1981/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0048\n",
      "Epoch [1982/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0048\n",
      "Epoch [1983/2000] Fold 4, Train Loss: 0.0014, Val Loss: 0.0048\n",
      "Epoch [1984/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0048\n",
      "Epoch [1985/2000] Fold 4, Train Loss: 0.0014, Val Loss: 0.0048\n",
      "Epoch [1986/2000] Fold 4, Train Loss: 0.0014, Val Loss: 0.0050\n",
      "Epoch [1987/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1988/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1989/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1990/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1991/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0048\n",
      "Epoch [1992/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1993/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1994/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1995/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1996/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0049\n",
      "Epoch [1997/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0048\n",
      "Epoch [1998/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0048\n",
      "Epoch [1999/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0048\n",
      "Epoch [2000/2000] Fold 4, Train Loss: 0.0015, Val Loss: 0.0048\n",
      "Fold 5/5\n",
      "Epoch [1/2000] Fold 5, Train Loss: 0.0273, Val Loss: 0.0258\n",
      "Epoch [2/2000] Fold 5, Train Loss: 0.0242, Val Loss: 0.0226\n",
      "Epoch [3/2000] Fold 5, Train Loss: 0.0208, Val Loss: 0.0192\n",
      "Epoch [4/2000] Fold 5, Train Loss: 0.0176, Val Loss: 0.0162\n",
      "Epoch [5/2000] Fold 5, Train Loss: 0.0152, Val Loss: 0.0145\n",
      "Epoch [6/2000] Fold 5, Train Loss: 0.0142, Val Loss: 0.0138\n",
      "Epoch [7/2000] Fold 5, Train Loss: 0.0137, Val Loss: 0.0136\n",
      "Epoch [8/2000] Fold 5, Train Loss: 0.0136, Val Loss: 0.0136\n",
      "Epoch [9/2000] Fold 5, Train Loss: 0.0136, Val Loss: 0.0136\n",
      "Epoch [10/2000] Fold 5, Train Loss: 0.0136, Val Loss: 0.0136\n",
      "Epoch [11/2000] Fold 5, Train Loss: 0.0135, Val Loss: 0.0136\n",
      "Epoch [12/2000] Fold 5, Train Loss: 0.0135, Val Loss: 0.0135\n",
      "Epoch [13/2000] Fold 5, Train Loss: 0.0135, Val Loss: 0.0135\n",
      "Epoch [14/2000] Fold 5, Train Loss: 0.0135, Val Loss: 0.0135\n",
      "Epoch [15/2000] Fold 5, Train Loss: 0.0134, Val Loss: 0.0133\n",
      "Epoch [16/2000] Fold 5, Train Loss: 0.0132, Val Loss: 0.0130\n",
      "Epoch [17/2000] Fold 5, Train Loss: 0.0127, Val Loss: 0.0124\n",
      "Epoch [18/2000] Fold 5, Train Loss: 0.0119, Val Loss: 0.0116\n",
      "Epoch [19/2000] Fold 5, Train Loss: 0.0110, Val Loss: 0.0110\n",
      "Epoch [20/2000] Fold 5, Train Loss: 0.0105, Val Loss: 0.0105\n",
      "Epoch [21/2000] Fold 5, Train Loss: 0.0102, Val Loss: 0.0103\n",
      "Epoch [22/2000] Fold 5, Train Loss: 0.0100, Val Loss: 0.0102\n",
      "Epoch [23/2000] Fold 5, Train Loss: 0.0099, Val Loss: 0.0101\n",
      "Epoch [24/2000] Fold 5, Train Loss: 0.0098, Val Loss: 0.0099\n",
      "Epoch [25/2000] Fold 5, Train Loss: 0.0096, Val Loss: 0.0098\n",
      "Epoch [26/2000] Fold 5, Train Loss: 0.0095, Val Loss: 0.0098\n",
      "Epoch [27/2000] Fold 5, Train Loss: 0.0095, Val Loss: 0.0096\n",
      "Epoch [28/2000] Fold 5, Train Loss: 0.0092, Val Loss: 0.0095\n",
      "Epoch [29/2000] Fold 5, Train Loss: 0.0091, Val Loss: 0.0095\n",
      "Epoch [30/2000] Fold 5, Train Loss: 0.0091, Val Loss: 0.0093\n",
      "Epoch [31/2000] Fold 5, Train Loss: 0.0090, Val Loss: 0.0093\n",
      "Epoch [32/2000] Fold 5, Train Loss: 0.0089, Val Loss: 0.0092\n",
      "Epoch [33/2000] Fold 5, Train Loss: 0.0088, Val Loss: 0.0090\n",
      "Epoch [34/2000] Fold 5, Train Loss: 0.0087, Val Loss: 0.0090\n",
      "Epoch [35/2000] Fold 5, Train Loss: 0.0087, Val Loss: 0.0089\n",
      "Epoch [36/2000] Fold 5, Train Loss: 0.0086, Val Loss: 0.0089\n",
      "Epoch [37/2000] Fold 5, Train Loss: 0.0085, Val Loss: 0.0088\n",
      "Epoch [38/2000] Fold 5, Train Loss: 0.0084, Val Loss: 0.0088\n",
      "Epoch [39/2000] Fold 5, Train Loss: 0.0084, Val Loss: 0.0088\n",
      "Epoch [40/2000] Fold 5, Train Loss: 0.0084, Val Loss: 0.0088\n",
      "Epoch [41/2000] Fold 5, Train Loss: 0.0083, Val Loss: 0.0087\n",
      "Epoch [42/2000] Fold 5, Train Loss: 0.0083, Val Loss: 0.0087\n",
      "Epoch [43/2000] Fold 5, Train Loss: 0.0083, Val Loss: 0.0086\n",
      "Epoch [44/2000] Fold 5, Train Loss: 0.0083, Val Loss: 0.0087\n",
      "Epoch [45/2000] Fold 5, Train Loss: 0.0083, Val Loss: 0.0086\n",
      "Epoch [46/2000] Fold 5, Train Loss: 0.0082, Val Loss: 0.0086\n",
      "Epoch [47/2000] Fold 5, Train Loss: 0.0082, Val Loss: 0.0085\n",
      "Epoch [48/2000] Fold 5, Train Loss: 0.0082, Val Loss: 0.0085\n",
      "Epoch [49/2000] Fold 5, Train Loss: 0.0081, Val Loss: 0.0085\n",
      "Epoch [50/2000] Fold 5, Train Loss: 0.0082, Val Loss: 0.0085\n",
      "Epoch [51/2000] Fold 5, Train Loss: 0.0081, Val Loss: 0.0085\n",
      "Epoch [52/2000] Fold 5, Train Loss: 0.0081, Val Loss: 0.0084\n",
      "Epoch [53/2000] Fold 5, Train Loss: 0.0081, Val Loss: 0.0084\n",
      "Epoch [54/2000] Fold 5, Train Loss: 0.0081, Val Loss: 0.0085\n",
      "Epoch [55/2000] Fold 5, Train Loss: 0.0080, Val Loss: 0.0084\n",
      "Epoch [56/2000] Fold 5, Train Loss: 0.0081, Val Loss: 0.0084\n",
      "Epoch [57/2000] Fold 5, Train Loss: 0.0080, Val Loss: 0.0083\n",
      "Epoch [58/2000] Fold 5, Train Loss: 0.0080, Val Loss: 0.0084\n",
      "Epoch [59/2000] Fold 5, Train Loss: 0.0080, Val Loss: 0.0083\n",
      "Epoch [60/2000] Fold 5, Train Loss: 0.0079, Val Loss: 0.0083\n",
      "Epoch [61/2000] Fold 5, Train Loss: 0.0079, Val Loss: 0.0083\n",
      "Epoch [62/2000] Fold 5, Train Loss: 0.0079, Val Loss: 0.0083\n",
      "Epoch [63/2000] Fold 5, Train Loss: 0.0079, Val Loss: 0.0082\n",
      "Epoch [64/2000] Fold 5, Train Loss: 0.0079, Val Loss: 0.0082\n",
      "Epoch [65/2000] Fold 5, Train Loss: 0.0078, Val Loss: 0.0082\n",
      "Epoch [66/2000] Fold 5, Train Loss: 0.0079, Val Loss: 0.0082\n",
      "Epoch [67/2000] Fold 5, Train Loss: 0.0078, Val Loss: 0.0082\n",
      "Epoch [68/2000] Fold 5, Train Loss: 0.0078, Val Loss: 0.0082\n",
      "Epoch [69/2000] Fold 5, Train Loss: 0.0078, Val Loss: 0.0082\n",
      "Epoch [70/2000] Fold 5, Train Loss: 0.0077, Val Loss: 0.0081\n",
      "Epoch [71/2000] Fold 5, Train Loss: 0.0077, Val Loss: 0.0081\n",
      "Epoch [72/2000] Fold 5, Train Loss: 0.0077, Val Loss: 0.0082\n",
      "Epoch [73/2000] Fold 5, Train Loss: 0.0077, Val Loss: 0.0081\n",
      "Epoch [74/2000] Fold 5, Train Loss: 0.0077, Val Loss: 0.0081\n",
      "Epoch [75/2000] Fold 5, Train Loss: 0.0077, Val Loss: 0.0081\n",
      "Epoch [76/2000] Fold 5, Train Loss: 0.0076, Val Loss: 0.0081\n",
      "Epoch [77/2000] Fold 5, Train Loss: 0.0076, Val Loss: 0.0080\n",
      "Epoch [78/2000] Fold 5, Train Loss: 0.0076, Val Loss: 0.0080\n",
      "Epoch [79/2000] Fold 5, Train Loss: 0.0076, Val Loss: 0.0080\n",
      "Epoch [80/2000] Fold 5, Train Loss: 0.0076, Val Loss: 0.0079\n",
      "Epoch [81/2000] Fold 5, Train Loss: 0.0075, Val Loss: 0.0079\n",
      "Epoch [82/2000] Fold 5, Train Loss: 0.0075, Val Loss: 0.0079\n",
      "Epoch [83/2000] Fold 5, Train Loss: 0.0075, Val Loss: 0.0079\n",
      "Epoch [84/2000] Fold 5, Train Loss: 0.0075, Val Loss: 0.0079\n",
      "Epoch [85/2000] Fold 5, Train Loss: 0.0074, Val Loss: 0.0079\n",
      "Epoch [86/2000] Fold 5, Train Loss: 0.0074, Val Loss: 0.0079\n",
      "Epoch [87/2000] Fold 5, Train Loss: 0.0074, Val Loss: 0.0078\n",
      "Epoch [88/2000] Fold 5, Train Loss: 0.0074, Val Loss: 0.0078\n",
      "Epoch [89/2000] Fold 5, Train Loss: 0.0074, Val Loss: 0.0078\n",
      "Epoch [90/2000] Fold 5, Train Loss: 0.0073, Val Loss: 0.0078\n",
      "Epoch [91/2000] Fold 5, Train Loss: 0.0073, Val Loss: 0.0078\n",
      "Epoch [92/2000] Fold 5, Train Loss: 0.0073, Val Loss: 0.0077\n",
      "Epoch [93/2000] Fold 5, Train Loss: 0.0073, Val Loss: 0.0077\n",
      "Epoch [94/2000] Fold 5, Train Loss: 0.0073, Val Loss: 0.0077\n",
      "Epoch [95/2000] Fold 5, Train Loss: 0.0073, Val Loss: 0.0077\n",
      "Epoch [96/2000] Fold 5, Train Loss: 0.0072, Val Loss: 0.0076\n",
      "Epoch [97/2000] Fold 5, Train Loss: 0.0072, Val Loss: 0.0076\n",
      "Epoch [98/2000] Fold 5, Train Loss: 0.0072, Val Loss: 0.0076\n",
      "Epoch [99/2000] Fold 5, Train Loss: 0.0072, Val Loss: 0.0076\n",
      "Epoch [100/2000] Fold 5, Train Loss: 0.0071, Val Loss: 0.0076\n",
      "Epoch [101/2000] Fold 5, Train Loss: 0.0071, Val Loss: 0.0075\n",
      "Epoch [102/2000] Fold 5, Train Loss: 0.0071, Val Loss: 0.0075\n",
      "Epoch [103/2000] Fold 5, Train Loss: 0.0071, Val Loss: 0.0075\n",
      "Epoch [104/2000] Fold 5, Train Loss: 0.0071, Val Loss: 0.0075\n",
      "Epoch [105/2000] Fold 5, Train Loss: 0.0071, Val Loss: 0.0076\n",
      "Epoch [106/2000] Fold 5, Train Loss: 0.0071, Val Loss: 0.0075\n",
      "Epoch [107/2000] Fold 5, Train Loss: 0.0071, Val Loss: 0.0075\n",
      "Epoch [108/2000] Fold 5, Train Loss: 0.0070, Val Loss: 0.0075\n",
      "Epoch [109/2000] Fold 5, Train Loss: 0.0071, Val Loss: 0.0075\n",
      "Epoch [110/2000] Fold 5, Train Loss: 0.0070, Val Loss: 0.0074\n",
      "Epoch [111/2000] Fold 5, Train Loss: 0.0070, Val Loss: 0.0074\n",
      "Epoch [112/2000] Fold 5, Train Loss: 0.0070, Val Loss: 0.0074\n",
      "Epoch [113/2000] Fold 5, Train Loss: 0.0070, Val Loss: 0.0074\n",
      "Epoch [114/2000] Fold 5, Train Loss: 0.0069, Val Loss: 0.0074\n",
      "Epoch [115/2000] Fold 5, Train Loss: 0.0069, Val Loss: 0.0073\n",
      "Epoch [116/2000] Fold 5, Train Loss: 0.0069, Val Loss: 0.0073\n",
      "Epoch [117/2000] Fold 5, Train Loss: 0.0068, Val Loss: 0.0073\n",
      "Epoch [118/2000] Fold 5, Train Loss: 0.0069, Val Loss: 0.0073\n",
      "Epoch [119/2000] Fold 5, Train Loss: 0.0069, Val Loss: 0.0073\n",
      "Epoch [120/2000] Fold 5, Train Loss: 0.0069, Val Loss: 0.0073\n",
      "Epoch [121/2000] Fold 5, Train Loss: 0.0069, Val Loss: 0.0073\n",
      "Epoch [122/2000] Fold 5, Train Loss: 0.0068, Val Loss: 0.0072\n",
      "Epoch [123/2000] Fold 5, Train Loss: 0.0068, Val Loss: 0.0072\n",
      "Epoch [124/2000] Fold 5, Train Loss: 0.0068, Val Loss: 0.0072\n",
      "Epoch [125/2000] Fold 5, Train Loss: 0.0068, Val Loss: 0.0072\n",
      "Epoch [126/2000] Fold 5, Train Loss: 0.0067, Val Loss: 0.0073\n",
      "Epoch [127/2000] Fold 5, Train Loss: 0.0068, Val Loss: 0.0072\n",
      "Epoch [128/2000] Fold 5, Train Loss: 0.0067, Val Loss: 0.0072\n",
      "Epoch [129/2000] Fold 5, Train Loss: 0.0067, Val Loss: 0.0072\n",
      "Epoch [130/2000] Fold 5, Train Loss: 0.0067, Val Loss: 0.0072\n",
      "Epoch [131/2000] Fold 5, Train Loss: 0.0067, Val Loss: 0.0072\n",
      "Epoch [132/2000] Fold 5, Train Loss: 0.0067, Val Loss: 0.0072\n",
      "Epoch [133/2000] Fold 5, Train Loss: 0.0067, Val Loss: 0.0071\n",
      "Epoch [134/2000] Fold 5, Train Loss: 0.0066, Val Loss: 0.0071\n",
      "Epoch [135/2000] Fold 5, Train Loss: 0.0066, Val Loss: 0.0072\n",
      "Epoch [136/2000] Fold 5, Train Loss: 0.0066, Val Loss: 0.0071\n",
      "Epoch [137/2000] Fold 5, Train Loss: 0.0066, Val Loss: 0.0071\n",
      "Epoch [138/2000] Fold 5, Train Loss: 0.0066, Val Loss: 0.0072\n",
      "Epoch [139/2000] Fold 5, Train Loss: 0.0067, Val Loss: 0.0072\n",
      "Epoch [140/2000] Fold 5, Train Loss: 0.0067, Val Loss: 0.0071\n",
      "Epoch [141/2000] Fold 5, Train Loss: 0.0066, Val Loss: 0.0071\n",
      "Epoch [142/2000] Fold 5, Train Loss: 0.0065, Val Loss: 0.0071\n",
      "Epoch [143/2000] Fold 5, Train Loss: 0.0066, Val Loss: 0.0071\n",
      "Epoch [144/2000] Fold 5, Train Loss: 0.0065, Val Loss: 0.0071\n",
      "Epoch [145/2000] Fold 5, Train Loss: 0.0065, Val Loss: 0.0071\n",
      "Epoch [146/2000] Fold 5, Train Loss: 0.0065, Val Loss: 0.0071\n",
      "Epoch [147/2000] Fold 5, Train Loss: 0.0065, Val Loss: 0.0071\n",
      "Epoch [148/2000] Fold 5, Train Loss: 0.0065, Val Loss: 0.0071\n",
      "Epoch [149/2000] Fold 5, Train Loss: 0.0065, Val Loss: 0.0070\n",
      "Epoch [150/2000] Fold 5, Train Loss: 0.0065, Val Loss: 0.0070\n",
      "Epoch [151/2000] Fold 5, Train Loss: 0.0064, Val Loss: 0.0070\n",
      "Epoch [152/2000] Fold 5, Train Loss: 0.0064, Val Loss: 0.0070\n",
      "Epoch [153/2000] Fold 5, Train Loss: 0.0064, Val Loss: 0.0071\n",
      "Epoch [154/2000] Fold 5, Train Loss: 0.0064, Val Loss: 0.0070\n",
      "Epoch [155/2000] Fold 5, Train Loss: 0.0064, Val Loss: 0.0070\n",
      "Epoch [156/2000] Fold 5, Train Loss: 0.0064, Val Loss: 0.0070\n",
      "Epoch [157/2000] Fold 5, Train Loss: 0.0064, Val Loss: 0.0070\n",
      "Epoch [158/2000] Fold 5, Train Loss: 0.0064, Val Loss: 0.0070\n",
      "Epoch [159/2000] Fold 5, Train Loss: 0.0064, Val Loss: 0.0070\n",
      "Epoch [160/2000] Fold 5, Train Loss: 0.0063, Val Loss: 0.0070\n",
      "Epoch [161/2000] Fold 5, Train Loss: 0.0063, Val Loss: 0.0070\n",
      "Epoch [162/2000] Fold 5, Train Loss: 0.0064, Val Loss: 0.0070\n",
      "Epoch [163/2000] Fold 5, Train Loss: 0.0063, Val Loss: 0.0069\n",
      "Epoch [164/2000] Fold 5, Train Loss: 0.0063, Val Loss: 0.0070\n",
      "Epoch [165/2000] Fold 5, Train Loss: 0.0063, Val Loss: 0.0069\n",
      "Epoch [166/2000] Fold 5, Train Loss: 0.0063, Val Loss: 0.0070\n",
      "Epoch [167/2000] Fold 5, Train Loss: 0.0063, Val Loss: 0.0070\n",
      "Epoch [168/2000] Fold 5, Train Loss: 0.0063, Val Loss: 0.0070\n",
      "Epoch [169/2000] Fold 5, Train Loss: 0.0063, Val Loss: 0.0069\n",
      "Epoch [170/2000] Fold 5, Train Loss: 0.0063, Val Loss: 0.0069\n",
      "Epoch [171/2000] Fold 5, Train Loss: 0.0063, Val Loss: 0.0070\n",
      "Epoch [172/2000] Fold 5, Train Loss: 0.0063, Val Loss: 0.0069\n",
      "Epoch [173/2000] Fold 5, Train Loss: 0.0063, Val Loss: 0.0069\n",
      "Epoch [174/2000] Fold 5, Train Loss: 0.0063, Val Loss: 0.0069\n",
      "Epoch [175/2000] Fold 5, Train Loss: 0.0063, Val Loss: 0.0069\n",
      "Epoch [176/2000] Fold 5, Train Loss: 0.0062, Val Loss: 0.0069\n",
      "Epoch [177/2000] Fold 5, Train Loss: 0.0062, Val Loss: 0.0069\n",
      "Epoch [178/2000] Fold 5, Train Loss: 0.0062, Val Loss: 0.0069\n",
      "Epoch [179/2000] Fold 5, Train Loss: 0.0062, Val Loss: 0.0069\n",
      "Epoch [180/2000] Fold 5, Train Loss: 0.0062, Val Loss: 0.0069\n",
      "Epoch [181/2000] Fold 5, Train Loss: 0.0061, Val Loss: 0.0069\n",
      "Epoch [182/2000] Fold 5, Train Loss: 0.0062, Val Loss: 0.0069\n",
      "Epoch [183/2000] Fold 5, Train Loss: 0.0061, Val Loss: 0.0068\n",
      "Epoch [184/2000] Fold 5, Train Loss: 0.0061, Val Loss: 0.0069\n",
      "Epoch [185/2000] Fold 5, Train Loss: 0.0061, Val Loss: 0.0068\n",
      "Epoch [186/2000] Fold 5, Train Loss: 0.0061, Val Loss: 0.0068\n",
      "Epoch [187/2000] Fold 5, Train Loss: 0.0061, Val Loss: 0.0069\n",
      "Epoch [188/2000] Fold 5, Train Loss: 0.0061, Val Loss: 0.0068\n",
      "Epoch [189/2000] Fold 5, Train Loss: 0.0061, Val Loss: 0.0069\n",
      "Epoch [190/2000] Fold 5, Train Loss: 0.0061, Val Loss: 0.0068\n",
      "Epoch [191/2000] Fold 5, Train Loss: 0.0061, Val Loss: 0.0069\n",
      "Epoch [192/2000] Fold 5, Train Loss: 0.0061, Val Loss: 0.0068\n",
      "Epoch [193/2000] Fold 5, Train Loss: 0.0061, Val Loss: 0.0068\n",
      "Epoch [194/2000] Fold 5, Train Loss: 0.0060, Val Loss: 0.0068\n",
      "Epoch [195/2000] Fold 5, Train Loss: 0.0060, Val Loss: 0.0068\n",
      "Epoch [196/2000] Fold 5, Train Loss: 0.0060, Val Loss: 0.0068\n",
      "Epoch [197/2000] Fold 5, Train Loss: 0.0060, Val Loss: 0.0068\n",
      "Epoch [198/2000] Fold 5, Train Loss: 0.0061, Val Loss: 0.0068\n",
      "Epoch [199/2000] Fold 5, Train Loss: 0.0060, Val Loss: 0.0068\n",
      "Epoch [200/2000] Fold 5, Train Loss: 0.0060, Val Loss: 0.0068\n",
      "Epoch [201/2000] Fold 5, Train Loss: 0.0060, Val Loss: 0.0068\n",
      "Epoch [202/2000] Fold 5, Train Loss: 0.0060, Val Loss: 0.0068\n",
      "Epoch [203/2000] Fold 5, Train Loss: 0.0060, Val Loss: 0.0068\n",
      "Epoch [204/2000] Fold 5, Train Loss: 0.0060, Val Loss: 0.0068\n",
      "Epoch [205/2000] Fold 5, Train Loss: 0.0060, Val Loss: 0.0069\n",
      "Epoch [206/2000] Fold 5, Train Loss: 0.0061, Val Loss: 0.0068\n",
      "Epoch [207/2000] Fold 5, Train Loss: 0.0060, Val Loss: 0.0068\n",
      "Epoch [208/2000] Fold 5, Train Loss: 0.0060, Val Loss: 0.0068\n",
      "Epoch [209/2000] Fold 5, Train Loss: 0.0060, Val Loss: 0.0068\n",
      "Epoch [210/2000] Fold 5, Train Loss: 0.0060, Val Loss: 0.0067\n",
      "Epoch [211/2000] Fold 5, Train Loss: 0.0059, Val Loss: 0.0067\n",
      "Epoch [212/2000] Fold 5, Train Loss: 0.0059, Val Loss: 0.0068\n",
      "Epoch [213/2000] Fold 5, Train Loss: 0.0059, Val Loss: 0.0068\n",
      "Epoch [214/2000] Fold 5, Train Loss: 0.0060, Val Loss: 0.0067\n",
      "Epoch [215/2000] Fold 5, Train Loss: 0.0059, Val Loss: 0.0067\n",
      "Epoch [216/2000] Fold 5, Train Loss: 0.0059, Val Loss: 0.0067\n",
      "Epoch [217/2000] Fold 5, Train Loss: 0.0059, Val Loss: 0.0067\n",
      "Epoch [218/2000] Fold 5, Train Loss: 0.0059, Val Loss: 0.0067\n",
      "Epoch [219/2000] Fold 5, Train Loss: 0.0059, Val Loss: 0.0067\n",
      "Epoch [220/2000] Fold 5, Train Loss: 0.0059, Val Loss: 0.0067\n",
      "Epoch [221/2000] Fold 5, Train Loss: 0.0059, Val Loss: 0.0067\n",
      "Epoch [222/2000] Fold 5, Train Loss: 0.0059, Val Loss: 0.0067\n",
      "Epoch [223/2000] Fold 5, Train Loss: 0.0059, Val Loss: 0.0067\n",
      "Epoch [224/2000] Fold 5, Train Loss: 0.0059, Val Loss: 0.0067\n",
      "Epoch [225/2000] Fold 5, Train Loss: 0.0058, Val Loss: 0.0067\n",
      "Epoch [226/2000] Fold 5, Train Loss: 0.0059, Val Loss: 0.0067\n",
      "Epoch [227/2000] Fold 5, Train Loss: 0.0058, Val Loss: 0.0067\n",
      "Epoch [228/2000] Fold 5, Train Loss: 0.0059, Val Loss: 0.0067\n",
      "Epoch [229/2000] Fold 5, Train Loss: 0.0058, Val Loss: 0.0067\n",
      "Epoch [230/2000] Fold 5, Train Loss: 0.0059, Val Loss: 0.0067\n",
      "Epoch [231/2000] Fold 5, Train Loss: 0.0058, Val Loss: 0.0067\n",
      "Epoch [232/2000] Fold 5, Train Loss: 0.0059, Val Loss: 0.0066\n",
      "Epoch [233/2000] Fold 5, Train Loss: 0.0058, Val Loss: 0.0067\n",
      "Epoch [234/2000] Fold 5, Train Loss: 0.0058, Val Loss: 0.0067\n",
      "Epoch [235/2000] Fold 5, Train Loss: 0.0058, Val Loss: 0.0066\n",
      "Epoch [236/2000] Fold 5, Train Loss: 0.0058, Val Loss: 0.0067\n",
      "Epoch [237/2000] Fold 5, Train Loss: 0.0058, Val Loss: 0.0066\n",
      "Epoch [238/2000] Fold 5, Train Loss: 0.0058, Val Loss: 0.0066\n",
      "Epoch [239/2000] Fold 5, Train Loss: 0.0058, Val Loss: 0.0067\n",
      "Epoch [240/2000] Fold 5, Train Loss: 0.0058, Val Loss: 0.0067\n",
      "Epoch [241/2000] Fold 5, Train Loss: 0.0058, Val Loss: 0.0066\n",
      "Epoch [242/2000] Fold 5, Train Loss: 0.0058, Val Loss: 0.0067\n",
      "Epoch [243/2000] Fold 5, Train Loss: 0.0057, Val Loss: 0.0067\n",
      "Epoch [244/2000] Fold 5, Train Loss: 0.0057, Val Loss: 0.0066\n",
      "Epoch [245/2000] Fold 5, Train Loss: 0.0057, Val Loss: 0.0066\n",
      "Epoch [246/2000] Fold 5, Train Loss: 0.0057, Val Loss: 0.0066\n",
      "Epoch [247/2000] Fold 5, Train Loss: 0.0058, Val Loss: 0.0066\n",
      "Epoch [248/2000] Fold 5, Train Loss: 0.0057, Val Loss: 0.0066\n",
      "Epoch [249/2000] Fold 5, Train Loss: 0.0058, Val Loss: 0.0066\n",
      "Epoch [250/2000] Fold 5, Train Loss: 0.0057, Val Loss: 0.0066\n",
      "Epoch [251/2000] Fold 5, Train Loss: 0.0057, Val Loss: 0.0066\n",
      "Epoch [252/2000] Fold 5, Train Loss: 0.0057, Val Loss: 0.0066\n",
      "Epoch [253/2000] Fold 5, Train Loss: 0.0057, Val Loss: 0.0066\n",
      "Epoch [254/2000] Fold 5, Train Loss: 0.0057, Val Loss: 0.0066\n",
      "Epoch [255/2000] Fold 5, Train Loss: 0.0057, Val Loss: 0.0066\n",
      "Epoch [256/2000] Fold 5, Train Loss: 0.0057, Val Loss: 0.0066\n",
      "Epoch [257/2000] Fold 5, Train Loss: 0.0057, Val Loss: 0.0065\n",
      "Epoch [258/2000] Fold 5, Train Loss: 0.0056, Val Loss: 0.0066\n",
      "Epoch [259/2000] Fold 5, Train Loss: 0.0056, Val Loss: 0.0066\n",
      "Epoch [260/2000] Fold 5, Train Loss: 0.0056, Val Loss: 0.0065\n",
      "Epoch [261/2000] Fold 5, Train Loss: 0.0057, Val Loss: 0.0065\n",
      "Epoch [262/2000] Fold 5, Train Loss: 0.0056, Val Loss: 0.0065\n",
      "Epoch [263/2000] Fold 5, Train Loss: 0.0056, Val Loss: 0.0065\n",
      "Epoch [264/2000] Fold 5, Train Loss: 0.0056, Val Loss: 0.0065\n",
      "Epoch [265/2000] Fold 5, Train Loss: 0.0056, Val Loss: 0.0067\n",
      "Epoch [266/2000] Fold 5, Train Loss: 0.0057, Val Loss: 0.0065\n",
      "Epoch [267/2000] Fold 5, Train Loss: 0.0056, Val Loss: 0.0066\n",
      "Epoch [268/2000] Fold 5, Train Loss: 0.0056, Val Loss: 0.0065\n",
      "Epoch [269/2000] Fold 5, Train Loss: 0.0056, Val Loss: 0.0065\n",
      "Epoch [270/2000] Fold 5, Train Loss: 0.0056, Val Loss: 0.0065\n",
      "Epoch [271/2000] Fold 5, Train Loss: 0.0056, Val Loss: 0.0065\n",
      "Epoch [272/2000] Fold 5, Train Loss: 0.0056, Val Loss: 0.0065\n",
      "Epoch [273/2000] Fold 5, Train Loss: 0.0056, Val Loss: 0.0065\n",
      "Epoch [274/2000] Fold 5, Train Loss: 0.0056, Val Loss: 0.0065\n",
      "Epoch [275/2000] Fold 5, Train Loss: 0.0056, Val Loss: 0.0064\n",
      "Epoch [276/2000] Fold 5, Train Loss: 0.0055, Val Loss: 0.0064\n",
      "Epoch [277/2000] Fold 5, Train Loss: 0.0055, Val Loss: 0.0064\n",
      "Epoch [278/2000] Fold 5, Train Loss: 0.0055, Val Loss: 0.0064\n",
      "Epoch [279/2000] Fold 5, Train Loss: 0.0055, Val Loss: 0.0064\n",
      "Epoch [280/2000] Fold 5, Train Loss: 0.0055, Val Loss: 0.0064\n",
      "Epoch [281/2000] Fold 5, Train Loss: 0.0055, Val Loss: 0.0064\n",
      "Epoch [282/2000] Fold 5, Train Loss: 0.0054, Val Loss: 0.0064\n",
      "Epoch [283/2000] Fold 5, Train Loss: 0.0055, Val Loss: 0.0064\n",
      "Epoch [284/2000] Fold 5, Train Loss: 0.0054, Val Loss: 0.0064\n",
      "Epoch [285/2000] Fold 5, Train Loss: 0.0055, Val Loss: 0.0064\n",
      "Epoch [286/2000] Fold 5, Train Loss: 0.0054, Val Loss: 0.0064\n",
      "Epoch [287/2000] Fold 5, Train Loss: 0.0054, Val Loss: 0.0064\n",
      "Epoch [288/2000] Fold 5, Train Loss: 0.0055, Val Loss: 0.0064\n",
      "Epoch [289/2000] Fold 5, Train Loss: 0.0054, Val Loss: 0.0064\n",
      "Epoch [290/2000] Fold 5, Train Loss: 0.0054, Val Loss: 0.0064\n",
      "Epoch [291/2000] Fold 5, Train Loss: 0.0054, Val Loss: 0.0064\n",
      "Epoch [292/2000] Fold 5, Train Loss: 0.0054, Val Loss: 0.0064\n",
      "Epoch [293/2000] Fold 5, Train Loss: 0.0054, Val Loss: 0.0063\n",
      "Epoch [294/2000] Fold 5, Train Loss: 0.0054, Val Loss: 0.0063\n",
      "Epoch [295/2000] Fold 5, Train Loss: 0.0053, Val Loss: 0.0063\n",
      "Epoch [296/2000] Fold 5, Train Loss: 0.0054, Val Loss: 0.0063\n",
      "Epoch [297/2000] Fold 5, Train Loss: 0.0053, Val Loss: 0.0063\n",
      "Epoch [298/2000] Fold 5, Train Loss: 0.0054, Val Loss: 0.0063\n",
      "Epoch [299/2000] Fold 5, Train Loss: 0.0053, Val Loss: 0.0063\n",
      "Epoch [300/2000] Fold 5, Train Loss: 0.0053, Val Loss: 0.0063\n",
      "Epoch [301/2000] Fold 5, Train Loss: 0.0053, Val Loss: 0.0063\n",
      "Epoch [302/2000] Fold 5, Train Loss: 0.0053, Val Loss: 0.0063\n",
      "Epoch [303/2000] Fold 5, Train Loss: 0.0053, Val Loss: 0.0063\n",
      "Epoch [304/2000] Fold 5, Train Loss: 0.0053, Val Loss: 0.0063\n",
      "Epoch [305/2000] Fold 5, Train Loss: 0.0053, Val Loss: 0.0063\n",
      "Epoch [306/2000] Fold 5, Train Loss: 0.0053, Val Loss: 0.0062\n",
      "Epoch [307/2000] Fold 5, Train Loss: 0.0052, Val Loss: 0.0063\n",
      "Epoch [308/2000] Fold 5, Train Loss: 0.0053, Val Loss: 0.0063\n",
      "Epoch [309/2000] Fold 5, Train Loss: 0.0053, Val Loss: 0.0063\n",
      "Epoch [310/2000] Fold 5, Train Loss: 0.0053, Val Loss: 0.0062\n",
      "Epoch [311/2000] Fold 5, Train Loss: 0.0053, Val Loss: 0.0062\n",
      "Epoch [312/2000] Fold 5, Train Loss: 0.0052, Val Loss: 0.0063\n",
      "Epoch [313/2000] Fold 5, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [314/2000] Fold 5, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [315/2000] Fold 5, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [316/2000] Fold 5, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [317/2000] Fold 5, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [318/2000] Fold 5, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [319/2000] Fold 5, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [320/2000] Fold 5, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [321/2000] Fold 5, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [322/2000] Fold 5, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [323/2000] Fold 5, Train Loss: 0.0051, Val Loss: 0.0062\n",
      "Epoch [324/2000] Fold 5, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [325/2000] Fold 5, Train Loss: 0.0052, Val Loss: 0.0062\n",
      "Epoch [326/2000] Fold 5, Train Loss: 0.0052, Val Loss: 0.0061\n",
      "Epoch [327/2000] Fold 5, Train Loss: 0.0051, Val Loss: 0.0062\n",
      "Epoch [328/2000] Fold 5, Train Loss: 0.0052, Val Loss: 0.0061\n",
      "Epoch [329/2000] Fold 5, Train Loss: 0.0051, Val Loss: 0.0061\n",
      "Epoch [330/2000] Fold 5, Train Loss: 0.0051, Val Loss: 0.0062\n",
      "Epoch [331/2000] Fold 5, Train Loss: 0.0051, Val Loss: 0.0062\n",
      "Epoch [332/2000] Fold 5, Train Loss: 0.0051, Val Loss: 0.0062\n",
      "Epoch [333/2000] Fold 5, Train Loss: 0.0051, Val Loss: 0.0062\n",
      "Epoch [334/2000] Fold 5, Train Loss: 0.0051, Val Loss: 0.0061\n",
      "Epoch [335/2000] Fold 5, Train Loss: 0.0051, Val Loss: 0.0061\n",
      "Epoch [336/2000] Fold 5, Train Loss: 0.0050, Val Loss: 0.0062\n",
      "Epoch [337/2000] Fold 5, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [338/2000] Fold 5, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [339/2000] Fold 5, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [340/2000] Fold 5, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [341/2000] Fold 5, Train Loss: 0.0050, Val Loss: 0.0060\n",
      "Epoch [342/2000] Fold 5, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [343/2000] Fold 5, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [344/2000] Fold 5, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [345/2000] Fold 5, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [346/2000] Fold 5, Train Loss: 0.0050, Val Loss: 0.0060\n",
      "Epoch [347/2000] Fold 5, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [348/2000] Fold 5, Train Loss: 0.0050, Val Loss: 0.0060\n",
      "Epoch [349/2000] Fold 5, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [350/2000] Fold 5, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [351/2000] Fold 5, Train Loss: 0.0050, Val Loss: 0.0061\n",
      "Epoch [352/2000] Fold 5, Train Loss: 0.0049, Val Loss: 0.0061\n",
      "Epoch [353/2000] Fold 5, Train Loss: 0.0050, Val Loss: 0.0060\n",
      "Epoch [354/2000] Fold 5, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [355/2000] Fold 5, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [356/2000] Fold 5, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [357/2000] Fold 5, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [358/2000] Fold 5, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [359/2000] Fold 5, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [360/2000] Fold 5, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [361/2000] Fold 5, Train Loss: 0.0049, Val Loss: 0.0059\n",
      "Epoch [362/2000] Fold 5, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [363/2000] Fold 5, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [364/2000] Fold 5, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [365/2000] Fold 5, Train Loss: 0.0049, Val Loss: 0.0060\n",
      "Epoch [366/2000] Fold 5, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [367/2000] Fold 5, Train Loss: 0.0048, Val Loss: 0.0059\n",
      "Epoch [368/2000] Fold 5, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [369/2000] Fold 5, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [370/2000] Fold 5, Train Loss: 0.0048, Val Loss: 0.0059\n",
      "Epoch [371/2000] Fold 5, Train Loss: 0.0048, Val Loss: 0.0060\n",
      "Epoch [372/2000] Fold 5, Train Loss: 0.0048, Val Loss: 0.0059\n",
      "Epoch [373/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [374/2000] Fold 5, Train Loss: 0.0048, Val Loss: 0.0059\n",
      "Epoch [375/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [376/2000] Fold 5, Train Loss: 0.0048, Val Loss: 0.0059\n",
      "Epoch [377/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [378/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [379/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [380/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [381/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [382/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [383/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [384/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [385/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0058\n",
      "Epoch [386/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [387/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0058\n",
      "Epoch [388/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [389/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [390/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [391/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [392/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [393/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0058\n",
      "Epoch [394/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0058\n",
      "Epoch [395/2000] Fold 5, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch [396/2000] Fold 5, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch [397/2000] Fold 5, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch [398/2000] Fold 5, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch [399/2000] Fold 5, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch [400/2000] Fold 5, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch [401/2000] Fold 5, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch [402/2000] Fold 5, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch [403/2000] Fold 5, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch [404/2000] Fold 5, Train Loss: 0.0047, Val Loss: 0.0059\n",
      "Epoch [405/2000] Fold 5, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch [406/2000] Fold 5, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch [407/2000] Fold 5, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch [408/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0059\n",
      "Epoch [409/2000] Fold 5, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch [410/2000] Fold 5, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch [411/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0057\n",
      "Epoch [412/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0057\n",
      "Epoch [413/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0057\n",
      "Epoch [414/2000] Fold 5, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch [415/2000] Fold 5, Train Loss: 0.0046, Val Loss: 0.0058\n",
      "Epoch [416/2000] Fold 5, Train Loss: 0.0046, Val Loss: 0.0057\n",
      "Epoch [417/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0058\n",
      "Epoch [418/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0057\n",
      "Epoch [419/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0057\n",
      "Epoch [420/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0057\n",
      "Epoch [421/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0057\n",
      "Epoch [422/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0058\n",
      "Epoch [423/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0058\n",
      "Epoch [424/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0057\n",
      "Epoch [425/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0057\n",
      "Epoch [426/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0057\n",
      "Epoch [427/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0057\n",
      "Epoch [428/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0057\n",
      "Epoch [429/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0057\n",
      "Epoch [430/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0057\n",
      "Epoch [431/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0057\n",
      "Epoch [432/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0058\n",
      "Epoch [433/2000] Fold 5, Train Loss: 0.0045, Val Loss: 0.0057\n",
      "Epoch [434/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0057\n",
      "Epoch [435/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0057\n",
      "Epoch [436/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0057\n",
      "Epoch [437/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0057\n",
      "Epoch [438/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0057\n",
      "Epoch [439/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0057\n",
      "Epoch [440/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0057\n",
      "Epoch [441/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0057\n",
      "Epoch [442/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0056\n",
      "Epoch [443/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0056\n",
      "Epoch [444/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0057\n",
      "Epoch [445/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0057\n",
      "Epoch [446/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0057\n",
      "Epoch [447/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0056\n",
      "Epoch [448/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0056\n",
      "Epoch [449/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0057\n",
      "Epoch [450/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0057\n",
      "Epoch [451/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0056\n",
      "Epoch [452/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0056\n",
      "Epoch [453/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0057\n",
      "Epoch [454/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0056\n",
      "Epoch [455/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0057\n",
      "Epoch [456/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0056\n",
      "Epoch [457/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0056\n",
      "Epoch [458/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0056\n",
      "Epoch [459/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0056\n",
      "Epoch [460/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0056\n",
      "Epoch [461/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0056\n",
      "Epoch [462/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0057\n",
      "Epoch [463/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0057\n",
      "Epoch [464/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0056\n",
      "Epoch [465/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0056\n",
      "Epoch [466/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0056\n",
      "Epoch [467/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0056\n",
      "Epoch [468/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0057\n",
      "Epoch [469/2000] Fold 5, Train Loss: 0.0044, Val Loss: 0.0056\n",
      "Epoch [470/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0056\n",
      "Epoch [471/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0056\n",
      "Epoch [472/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [473/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0056\n",
      "Epoch [474/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0056\n",
      "Epoch [475/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0056\n",
      "Epoch [476/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0055\n",
      "Epoch [477/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0055\n",
      "Epoch [478/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [479/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [480/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0056\n",
      "Epoch [481/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0055\n",
      "Epoch [482/2000] Fold 5, Train Loss: 0.0043, Val Loss: 0.0055\n",
      "Epoch [483/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [484/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [485/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [486/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0056\n",
      "Epoch [487/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [488/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0056\n",
      "Epoch [489/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [490/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [491/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [492/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [493/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [494/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [495/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0056\n",
      "Epoch [496/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [497/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [498/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [499/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [500/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [501/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0055\n",
      "Epoch [502/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0055\n",
      "Epoch [503/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [504/2000] Fold 5, Train Loss: 0.0042, Val Loss: 0.0055\n",
      "Epoch [505/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [506/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0055\n",
      "Epoch [507/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0055\n",
      "Epoch [508/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0055\n",
      "Epoch [509/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [510/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0055\n",
      "Epoch [511/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [512/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [513/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [514/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0055\n",
      "Epoch [515/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [516/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [517/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [518/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [519/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [520/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0055\n",
      "Epoch [521/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0055\n",
      "Epoch [522/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [523/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0054\n",
      "Epoch [524/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [525/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0054\n",
      "Epoch [526/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [527/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [528/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [529/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0054\n",
      "Epoch [530/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0054\n",
      "Epoch [531/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0055\n",
      "Epoch [532/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [533/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [534/2000] Fold 5, Train Loss: 0.0041, Val Loss: 0.0054\n",
      "Epoch [535/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0054\n",
      "Epoch [536/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0054\n",
      "Epoch [537/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0053\n",
      "Epoch [538/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0053\n",
      "Epoch [539/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0053\n",
      "Epoch [540/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0054\n",
      "Epoch [541/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0054\n",
      "Epoch [542/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0054\n",
      "Epoch [543/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0054\n",
      "Epoch [544/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0053\n",
      "Epoch [545/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0053\n",
      "Epoch [546/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0053\n",
      "Epoch [547/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [548/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0053\n",
      "Epoch [549/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0054\n",
      "Epoch [550/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0053\n",
      "Epoch [551/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [552/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [553/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [554/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [555/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [556/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0053\n",
      "Epoch [557/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [558/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0054\n",
      "Epoch [559/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0054\n",
      "Epoch [560/2000] Fold 5, Train Loss: 0.0040, Val Loss: 0.0055\n",
      "Epoch [561/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [562/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [563/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [564/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0054\n",
      "Epoch [565/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [566/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [567/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [568/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [569/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [570/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [571/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [572/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [573/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [574/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [575/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [576/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [577/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0054\n",
      "Epoch [578/2000] Fold 5, Train Loss: 0.0039, Val Loss: 0.0053\n",
      "Epoch [579/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [580/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [581/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [582/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [583/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [584/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [585/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [586/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [587/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [588/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [589/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [590/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [591/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [592/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [593/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0053\n",
      "Epoch [594/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [595/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [596/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [597/2000] Fold 5, Train Loss: 0.0038, Val Loss: 0.0052\n",
      "Epoch [598/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [599/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [600/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [601/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [602/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [603/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [604/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [605/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [606/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [607/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [608/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0051\n",
      "Epoch [609/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [610/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [611/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [612/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0051\n",
      "Epoch [613/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0051\n",
      "Epoch [614/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [615/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0051\n",
      "Epoch [616/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0051\n",
      "Epoch [617/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [618/2000] Fold 5, Train Loss: 0.0037, Val Loss: 0.0052\n",
      "Epoch [619/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [620/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [621/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [622/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [623/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [624/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [625/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [626/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0052\n",
      "Epoch [627/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [628/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [629/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [630/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [631/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [632/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [633/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [634/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [635/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [636/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [637/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [638/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [639/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [640/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0050\n",
      "Epoch [641/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [642/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [643/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [644/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [645/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0050\n",
      "Epoch [646/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [647/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [648/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0050\n",
      "Epoch [649/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0050\n",
      "Epoch [650/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0050\n",
      "Epoch [651/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [652/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0050\n",
      "Epoch [653/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0050\n",
      "Epoch [654/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0053\n",
      "Epoch [655/2000] Fold 5, Train Loss: 0.0036, Val Loss: 0.0051\n",
      "Epoch [656/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0050\n",
      "Epoch [657/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0050\n",
      "Epoch [658/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0050\n",
      "Epoch [659/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0050\n",
      "Epoch [660/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0051\n",
      "Epoch [661/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [662/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0051\n",
      "Epoch [663/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0050\n",
      "Epoch [664/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0050\n",
      "Epoch [665/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0050\n",
      "Epoch [666/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [667/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [668/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [669/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0050\n",
      "Epoch [670/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [671/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [672/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [673/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [674/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0050\n",
      "Epoch [675/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [676/2000] Fold 5, Train Loss: 0.0035, Val Loss: 0.0050\n",
      "Epoch [677/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [678/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [679/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [680/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [681/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [682/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [683/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [684/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [685/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [686/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [687/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [688/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [689/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0049\n",
      "Epoch [690/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [691/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [692/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [693/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0049\n",
      "Epoch [694/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0050\n",
      "Epoch [695/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0049\n",
      "Epoch [696/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [697/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [698/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [699/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0049\n",
      "Epoch [700/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [701/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [702/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0049\n",
      "Epoch [703/2000] Fold 5, Train Loss: 0.0034, Val Loss: 0.0049\n",
      "Epoch [704/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [705/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0050\n",
      "Epoch [706/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0050\n",
      "Epoch [707/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0050\n",
      "Epoch [708/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0050\n",
      "Epoch [709/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [710/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [711/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [712/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [713/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [714/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0050\n",
      "Epoch [715/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0050\n",
      "Epoch [716/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [717/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [718/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [719/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [720/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [721/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [722/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [723/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [724/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [725/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [726/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [727/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [728/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [729/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0048\n",
      "Epoch [730/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [731/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [732/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [733/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [734/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [735/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [736/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [737/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [738/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [739/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [740/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [741/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0050\n",
      "Epoch [742/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [743/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [744/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [745/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0050\n",
      "Epoch [746/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [747/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [748/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [749/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0048\n",
      "Epoch [750/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [751/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [752/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [753/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0050\n",
      "Epoch [754/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [755/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0051\n",
      "Epoch [756/2000] Fold 5, Train Loss: 0.0033, Val Loss: 0.0049\n",
      "Epoch [757/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [758/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [759/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [760/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0048\n",
      "Epoch [761/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [762/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [763/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [764/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [765/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [766/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0048\n",
      "Epoch [767/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [768/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [769/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [770/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [771/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [772/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [773/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [774/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0050\n",
      "Epoch [775/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [776/2000] Fold 5, Train Loss: 0.0032, Val Loss: 0.0049\n",
      "Epoch [777/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [778/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [779/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [780/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [781/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [782/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [783/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [784/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [785/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [786/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [787/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [788/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [789/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [790/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [791/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [792/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [793/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [794/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [795/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [796/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [797/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [798/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [799/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [800/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [801/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [802/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [803/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [804/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [805/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [806/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [807/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0048\n",
      "Epoch [808/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [809/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [810/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [811/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [812/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [813/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [814/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [815/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [816/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [817/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [818/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [819/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [820/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [821/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [822/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [823/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [824/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [825/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [826/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [827/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [828/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [829/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [830/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [831/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [832/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [833/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [834/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [835/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [836/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [837/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [838/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [839/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [840/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [841/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [842/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [843/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [844/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [845/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [846/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [847/2000] Fold 5, Train Loss: 0.0031, Val Loss: 0.0049\n",
      "Epoch [848/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [849/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0048\n",
      "Epoch [850/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [851/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0049\n",
      "Epoch [852/2000] Fold 5, Train Loss: 0.0030, Val Loss: 0.0047\n",
      "Epoch [853/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [854/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [855/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [856/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [857/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [858/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [859/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [860/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [861/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [862/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [863/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [864/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [865/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [866/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [867/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [868/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [869/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [870/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [871/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [872/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [873/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [874/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [875/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0049\n",
      "Epoch [876/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [877/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0047\n",
      "Epoch [878/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [879/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [880/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [881/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [882/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [883/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [884/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [885/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [886/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [887/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [888/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [889/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [890/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [891/2000] Fold 5, Train Loss: 0.0029, Val Loss: 0.0048\n",
      "Epoch [892/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [893/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [894/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [895/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [896/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [897/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [898/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [899/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [900/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [901/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [902/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [903/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [904/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [905/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [906/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [907/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [908/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [909/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [910/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [911/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [912/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [913/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [914/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [915/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [916/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [917/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [918/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [919/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [920/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0048\n",
      "Epoch [921/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [922/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [923/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [924/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [925/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [926/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [927/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [928/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [929/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [930/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [931/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [932/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0048\n",
      "Epoch [933/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [934/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [935/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [936/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [937/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [938/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0048\n",
      "Epoch [939/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [940/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [941/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0048\n",
      "Epoch [942/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [943/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [944/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [945/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0048\n",
      "Epoch [946/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [947/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [948/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [949/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0046\n",
      "Epoch [950/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [951/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [952/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [953/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [954/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [955/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [956/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0048\n",
      "Epoch [957/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [958/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [959/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [960/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [961/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0048\n",
      "Epoch [962/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [963/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [964/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0046\n",
      "Epoch [965/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [966/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [967/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [968/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [969/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [970/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0046\n",
      "Epoch [971/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [972/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [973/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [974/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [975/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [976/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [977/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [978/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [979/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [980/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0046\n",
      "Epoch [981/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [982/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [983/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [984/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [985/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [986/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [987/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [988/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0048\n",
      "Epoch [989/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [990/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [991/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [992/2000] Fold 5, Train Loss: 0.0027, Val Loss: 0.0047\n",
      "Epoch [993/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [994/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [995/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [996/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [997/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [998/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [999/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [1000/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [1001/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [1002/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [1003/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [1004/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [1005/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [1006/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0048\n",
      "Epoch [1007/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [1008/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [1009/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [1010/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [1011/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [1012/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1013/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1014/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1015/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1016/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [1017/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [1018/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [1019/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1020/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [1021/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [1022/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1023/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1024/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1025/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1026/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [1027/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [1028/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [1029/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [1030/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [1031/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1032/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1033/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [1034/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1035/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1036/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1037/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1038/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1039/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1040/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1041/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1042/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1043/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1044/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1045/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1046/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1047/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1048/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1049/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1050/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1051/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1052/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1053/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1054/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1055/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1056/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1057/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0048\n",
      "Epoch [1058/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0046\n",
      "Epoch [1059/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1060/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1061/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1062/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1063/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [1064/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1065/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1066/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1067/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1068/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1069/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0047\n",
      "Epoch [1070/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0048\n",
      "Epoch [1071/2000] Fold 5, Train Loss: 0.0028, Val Loss: 0.0047\n",
      "Epoch [1072/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1073/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [1074/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1075/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0047\n",
      "Epoch [1076/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1077/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1078/2000] Fold 5, Train Loss: 0.0026, Val Loss: 0.0047\n",
      "Epoch [1079/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1080/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0045\n",
      "Epoch [1081/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [1082/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1083/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1084/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [1085/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1086/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1087/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1088/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1089/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1090/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1091/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1092/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1093/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1094/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [1095/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1096/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0047\n",
      "Epoch [1097/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1098/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0047\n",
      "Epoch [1099/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1100/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1101/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1102/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1103/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1104/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1105/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1106/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1107/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1108/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1109/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1110/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1111/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1112/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0047\n",
      "Epoch [1113/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1114/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1115/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1116/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1117/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1118/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0047\n",
      "Epoch [1119/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1120/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1121/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0047\n",
      "Epoch [1122/2000] Fold 5, Train Loss: 0.0025, Val Loss: 0.0046\n",
      "Epoch [1123/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1124/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1125/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0045\n",
      "Epoch [1126/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1127/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1128/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0047\n",
      "Epoch [1129/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1130/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1131/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1132/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1133/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1134/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1135/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1136/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1137/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1138/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1139/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1140/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1141/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1142/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1143/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1144/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1145/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1146/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1147/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1148/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1149/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1150/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1151/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1152/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0047\n",
      "Epoch [1153/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1154/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1155/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1156/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1157/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0048\n",
      "Epoch [1158/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1159/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1160/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1161/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1162/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1163/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1164/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1165/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1166/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1167/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1168/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1169/2000] Fold 5, Train Loss: 0.0024, Val Loss: 0.0046\n",
      "Epoch [1170/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0047\n",
      "Epoch [1171/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1172/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1173/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1174/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1175/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1176/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1177/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1178/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1179/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1180/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1181/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1182/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1183/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1184/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1185/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1186/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1187/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1188/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1189/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1190/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1191/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1192/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1193/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0047\n",
      "Epoch [1194/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1195/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1196/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1197/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1198/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1199/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1200/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1201/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1202/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1203/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1204/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1205/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1206/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1207/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1208/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1209/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1210/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1211/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1212/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1213/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1214/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1215/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1216/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0045\n",
      "Epoch [1217/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1218/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1219/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1220/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1221/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1222/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1223/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1224/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1225/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1226/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1227/2000] Fold 5, Train Loss: 0.0023, Val Loss: 0.0046\n",
      "Epoch [1228/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1229/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1230/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1231/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1232/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1233/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1234/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1235/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1236/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1237/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1238/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1239/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1240/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1241/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0047\n",
      "Epoch [1242/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1243/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1244/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1245/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1246/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1247/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1248/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1249/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1250/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1251/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1252/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1253/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1254/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1255/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0047\n",
      "Epoch [1256/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1257/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1258/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1259/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1260/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1261/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1262/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1263/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1264/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1265/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1266/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0044\n",
      "Epoch [1267/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1268/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1269/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1270/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1271/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1272/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1273/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1274/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1275/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1276/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1277/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1278/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1279/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1280/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1281/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1282/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1283/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1284/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0044\n",
      "Epoch [1285/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1286/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1287/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1288/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1289/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1290/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1291/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1292/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1293/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1294/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1295/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1296/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1297/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0045\n",
      "Epoch [1298/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1299/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1300/2000] Fold 5, Train Loss: 0.0022, Val Loss: 0.0046\n",
      "Epoch [1301/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1302/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1303/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1304/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0046\n",
      "Epoch [1305/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1306/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1307/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1308/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1309/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1310/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1311/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1312/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1313/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1314/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1315/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1316/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1317/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1318/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0046\n",
      "Epoch [1319/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1320/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1321/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1322/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1323/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0046\n",
      "Epoch [1324/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1325/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0046\n",
      "Epoch [1326/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1327/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1328/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1329/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1330/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1331/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0046\n",
      "Epoch [1332/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1333/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0044\n",
      "Epoch [1334/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0046\n",
      "Epoch [1335/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1336/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0046\n",
      "Epoch [1337/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1338/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1339/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1340/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1341/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1342/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1343/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0044\n",
      "Epoch [1344/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1345/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0046\n",
      "Epoch [1346/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1347/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1348/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1349/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1350/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1351/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1352/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1353/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1354/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1355/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1356/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0046\n",
      "Epoch [1357/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1358/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1359/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1360/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1361/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1362/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1363/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1364/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1365/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1366/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0046\n",
      "Epoch [1367/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1368/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1369/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1370/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1371/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0044\n",
      "Epoch [1372/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1373/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1374/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1375/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0046\n",
      "Epoch [1376/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1377/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0044\n",
      "Epoch [1378/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0044\n",
      "Epoch [1379/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0044\n",
      "Epoch [1380/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1381/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1382/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1383/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1384/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1385/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0044\n",
      "Epoch [1386/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1387/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1388/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1389/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0046\n",
      "Epoch [1390/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1391/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0044\n",
      "Epoch [1392/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1393/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1394/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1395/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1396/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1397/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1398/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1399/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1400/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1401/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0044\n",
      "Epoch [1402/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0046\n",
      "Epoch [1403/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0046\n",
      "Epoch [1404/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1405/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1406/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0046\n",
      "Epoch [1407/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1408/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1409/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1410/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1411/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1412/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1413/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0046\n",
      "Epoch [1414/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1415/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0046\n",
      "Epoch [1416/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1417/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1418/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1419/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0046\n",
      "Epoch [1420/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1421/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1422/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1423/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1424/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0046\n",
      "Epoch [1425/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0046\n",
      "Epoch [1426/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0047\n",
      "Epoch [1427/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0047\n",
      "Epoch [1428/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0045\n",
      "Epoch [1429/2000] Fold 5, Train Loss: 0.0020, Val Loss: 0.0045\n",
      "Epoch [1430/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1431/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1432/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1433/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1434/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1435/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1436/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1437/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1438/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1439/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1440/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1441/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1442/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1443/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1444/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0046\n",
      "Epoch [1445/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1446/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1447/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1448/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1449/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1450/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1451/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0043\n",
      "Epoch [1452/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1453/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1454/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1455/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1456/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1457/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1458/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1459/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1460/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1461/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1462/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1463/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1464/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1465/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1466/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1467/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1468/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1469/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0044\n",
      "Epoch [1470/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1471/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1472/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1473/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1474/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1475/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1476/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1477/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1478/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1479/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1480/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1481/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1482/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1483/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1484/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1485/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1486/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1487/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0046\n",
      "Epoch [1488/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0046\n",
      "Epoch [1489/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1490/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1491/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1492/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1493/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1494/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1495/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1496/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1497/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1498/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1499/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1500/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1501/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1502/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1503/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1504/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1505/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1506/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1507/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1508/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1509/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1510/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1511/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1512/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1513/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1514/2000] Fold 5, Train Loss: 0.0019, Val Loss: 0.0045\n",
      "Epoch [1515/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1516/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1517/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1518/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1519/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1520/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1521/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1522/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1523/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1524/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1525/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1526/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1527/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1528/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1529/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1530/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1531/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1532/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1533/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1534/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1535/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1536/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1537/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1538/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1539/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1540/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1541/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1542/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1543/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1544/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1545/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0043\n",
      "Epoch [1546/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1547/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1548/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1549/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1550/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1551/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1552/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1553/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1554/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1555/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1556/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1557/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0043\n",
      "Epoch [1558/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1559/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1560/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1561/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1562/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1563/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1564/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1565/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1566/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1567/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1568/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1569/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1570/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1571/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1572/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1573/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1574/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1575/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1576/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1577/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1578/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1579/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1580/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1581/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1582/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1583/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1584/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1585/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1586/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0046\n",
      "Epoch [1587/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1588/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0043\n",
      "Epoch [1589/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1590/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0043\n",
      "Epoch [1591/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1592/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0043\n",
      "Epoch [1593/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0043\n",
      "Epoch [1594/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1595/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0043\n",
      "Epoch [1596/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1597/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1598/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1599/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1600/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1601/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1602/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1603/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0043\n",
      "Epoch [1604/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1605/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1606/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1607/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1608/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1609/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1610/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1611/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1612/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1613/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0043\n",
      "Epoch [1614/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1615/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1616/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1617/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1618/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1619/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1620/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1621/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1622/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1623/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1624/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0043\n",
      "Epoch [1625/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1626/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1627/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1628/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1629/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1630/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1631/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1632/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1633/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1634/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1635/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1636/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1637/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1638/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1639/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1640/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1641/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1642/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1643/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1644/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1645/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0045\n",
      "Epoch [1646/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1647/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1648/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1649/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1650/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1651/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1652/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1653/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1654/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1655/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1656/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0043\n",
      "Epoch [1657/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1658/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1659/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1660/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1661/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1662/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1663/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1664/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1665/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1666/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1667/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1668/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1669/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1670/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1671/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1672/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1673/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1674/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1675/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0045\n",
      "Epoch [1676/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1677/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1678/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1679/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1680/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1681/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1682/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1683/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1684/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1685/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1686/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1687/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1688/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1689/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1690/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1691/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1692/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0045\n",
      "Epoch [1693/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0045\n",
      "Epoch [1694/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1695/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1696/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1697/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1698/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0045\n",
      "Epoch [1699/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0043\n",
      "Epoch [1700/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1701/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1702/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1703/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0045\n",
      "Epoch [1704/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1705/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0045\n",
      "Epoch [1706/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1707/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1708/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1709/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1710/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1711/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1712/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1713/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1714/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1715/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1716/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1717/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1718/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1719/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1720/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1721/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0045\n",
      "Epoch [1722/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0045\n",
      "Epoch [1723/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1724/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1725/2000] Fold 5, Train Loss: 0.0017, Val Loss: 0.0044\n",
      "Epoch [1726/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1727/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1728/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1729/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1730/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1731/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1732/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1733/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1734/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1735/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1736/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1737/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1738/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1739/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0045\n",
      "Epoch [1740/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1741/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1742/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1743/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0045\n",
      "Epoch [1744/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1745/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1746/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1747/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1748/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1749/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1750/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1751/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1752/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1753/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1754/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0045\n",
      "Epoch [1755/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1756/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1757/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1758/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1759/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1760/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0045\n",
      "Epoch [1761/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0046\n",
      "Epoch [1762/2000] Fold 5, Train Loss: 0.0021, Val Loss: 0.0046\n",
      "Epoch [1763/2000] Fold 5, Train Loss: 0.0018, Val Loss: 0.0044\n",
      "Epoch [1764/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1765/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1766/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1767/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1768/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1769/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1770/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1771/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1772/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1773/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1774/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1775/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1776/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1777/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1778/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1779/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1780/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1781/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1782/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1783/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1784/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1785/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1786/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1787/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1788/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1789/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1790/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1791/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1792/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1793/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1794/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1795/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1796/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1797/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1798/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1799/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1800/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1801/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1802/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1803/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1804/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1805/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1806/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1807/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1808/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1809/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1810/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1811/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1812/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1813/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1814/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1815/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1816/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1817/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1818/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1819/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1820/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1821/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1822/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1823/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1824/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1825/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1826/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1827/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1828/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1829/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1830/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1831/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1832/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1833/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1834/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0045\n",
      "Epoch [1835/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0045\n",
      "Epoch [1836/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1837/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1838/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1839/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1840/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1841/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1842/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1843/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1844/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1845/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1846/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1847/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1848/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1849/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1850/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1851/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1852/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1853/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1854/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1855/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1856/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1857/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1858/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1859/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1860/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1861/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1862/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1863/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1864/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1865/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1866/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1867/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1868/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0043\n",
      "Epoch [1869/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1870/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1871/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1872/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1873/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1874/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1875/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1876/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1877/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1878/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1879/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1880/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1881/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0045\n",
      "Epoch [1882/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1883/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1884/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1885/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1886/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1887/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1888/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1889/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1890/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1891/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1892/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1893/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1894/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1895/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1896/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1897/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1898/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1899/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1900/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1901/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1902/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1903/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1904/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1905/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1906/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1907/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1908/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1909/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1910/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1911/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1912/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1913/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1914/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1915/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1916/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1917/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1918/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1919/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1920/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1921/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1922/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1923/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1924/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1925/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1926/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1927/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1928/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1929/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1930/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1931/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1932/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1933/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1934/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1935/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1936/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1937/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1938/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1939/2000] Fold 5, Train Loss: 0.0016, Val Loss: 0.0044\n",
      "Epoch [1940/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1941/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1942/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1943/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1944/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1945/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1946/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1947/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1948/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1949/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0045\n",
      "Epoch [1950/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1951/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1952/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1953/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1954/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1955/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1956/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1957/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1958/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1959/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1960/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1961/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1962/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1963/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1964/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1965/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0045\n",
      "Epoch [1966/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1967/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1968/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1969/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1970/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1971/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0042\n",
      "Epoch [1972/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1973/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1974/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0045\n",
      "Epoch [1975/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0044\n",
      "Epoch [1976/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1977/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1978/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1979/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1980/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1981/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1982/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1983/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1984/2000] Fold 5, Train Loss: 0.0015, Val Loss: 0.0043\n",
      "Epoch [1985/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1986/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1987/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1988/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0042\n",
      "Epoch [1989/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0042\n",
      "Epoch [1990/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1991/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1992/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1993/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1994/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1995/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1996/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1997/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n",
      "Epoch [1998/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0044\n",
      "Epoch [1999/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0042\n",
      "Epoch [2000/2000] Fold 5, Train Loss: 0.0014, Val Loss: 0.0043\n"
     ]
    }
   ],
   "source": [
    "# MIN MAX\n",
    "dataset = TensorDataset(train_day7_feats_minmaxed, train_day10_feats_minmaxed)\n",
    "\n",
    "cv_histories, best_models = cross_validate_with_early_stopping(\n",
    "    model_class=FeaturePredictor,\n",
    "    dataset=dataset,\n",
    "    criterion=nn.MSELoss(),\n",
    "    optimizer_class=torch.optim.Adam,\n",
    "    num_epochs=2000,\n",
    "    patience=500\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Validation Loss: 0.0043\n"
     ]
    }
   ],
   "source": [
    "# Example: Average validation loss across folds\n",
    "avg_val_loss = np.mean([history['val_loss'][-1] for history in cv_histories])\n",
    "print(f\"Average Validation Loss: {avg_val_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1:\n",
      "  Best Validation Loss = 0.0035\n",
      "  Corresponding Training Loss = 0.0016\n",
      "  Best Epoch = 1786\n",
      "Fold 2:\n",
      "  Best Validation Loss = 0.0048\n",
      "  Corresponding Training Loss = 0.0021\n",
      "  Best Epoch = 1986\n",
      "Fold 3:\n",
      "  Best Validation Loss = 0.0036\n",
      "  Corresponding Training Loss = 0.0010\n",
      "  Best Epoch = 1946\n",
      "Fold 4:\n",
      "  Best Validation Loss = 0.0048\n",
      "  Corresponding Training Loss = 0.0015\n",
      "  Best Epoch = 1982\n",
      "Fold 5:\n",
      "  Best Validation Loss = 0.0042\n",
      "  Corresponding Training Loss = 0.0014\n",
      "  Best Epoch = 1989\n"
     ]
    }
   ],
   "source": [
    "# Analyze the best results for each fold outside the training function\n",
    "for fold_idx, history in enumerate(cv_histories):\n",
    "    # Find the epoch with the lowest validation loss\n",
    "    best_epoch = int(np.argmin(history['val_loss'])) + 1  # Adding 1 because epochs are 1-indexed\n",
    "    best_val_loss = history['val_loss'][best_epoch - 1]  # Accessing the loss using 0-based index\n",
    "    best_train_loss = history['train_loss'][best_epoch - 1]\n",
    "\n",
    "    print(f\"Fold {fold_idx + 1}:\")\n",
    "    print(f\"  Best Validation Loss = {best_val_loss:.4f}\")\n",
    "    print(f\"  Corresponding Training Loss = {best_train_loss:.4f}\")\n",
    "    print(f\"  Best Epoch = {best_epoch}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Models saved to C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Source_Code\\Ranking(prediction)_model\\day7to10_simclr_pred\\sweetcrop\\dataaug\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "# Define the directory where models will be saved\n",
    "save_dir = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Source_Code\\Ranking(prediction)_model\\day7to10_simclr_pred\\sweetcrop\\dataaug'\n",
    "os.makedirs(save_dir, exist_ok=True)  # Create the directory if it doesn't exist\n",
    "\n",
    "# Save each fold's best model to the directory\n",
    "for i, model_state in enumerate(best_models):\n",
    "    save_path = os.path.join(save_dir, f'best_model_fold_{i+1}.pth')\n",
    "    torch.save(model_state, save_path)\n",
    "\n",
    "print(f\"Models saved to {save_dir}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_loss_curves_separately(cv_histories):\n",
    "    \"\"\"\n",
    "    Plot training and validation loss curves for each fold in separate figures.\n",
    "    \n",
    "    Args:\n",
    "        cv_histories (list): List of loss histories for each fold.\n",
    "    \"\"\"\n",
    "    # Plot Training Loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for fold, history in enumerate(cv_histories):\n",
    "        epochs = range(1, len(history['train_loss']) + 1)  # Dynamically set range\n",
    "        plt.plot(epochs, history['train_loss'], label=f'Fold {fold + 1} Train Loss')\n",
    "    plt.title('Training Loss per Fold')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Validation Loss\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    for fold, history in enumerate(cv_histories):\n",
    "        epochs = range(1, len(history['val_loss']) + 1)  # Dynamically set range\n",
    "        plt.plot(epochs, history['val_loss'], label=f'Fold {fold + 1} Val Loss', linestyle='--')\n",
    "    plt.title('Validation Loss per Fold')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plot_loss_curves_separately(cv_histories)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
