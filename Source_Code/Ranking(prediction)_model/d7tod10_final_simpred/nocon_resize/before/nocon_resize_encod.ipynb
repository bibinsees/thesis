{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import random\n",
    "\n",
    "\n",
    "\n",
    "from collections import Counter\n",
    "from scipy.stats import mode\n",
    "\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# Add the directory containing 'aug.py' to the Python path\n",
    "sys.path.append(os.path.abspath(r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Source_Code\\Ranking(prediction)_model\\day7to10_simclr_pred\"))\n",
    "from aug import one_Original,two_Ori_Hori_blur,three_Orig_Veri_sharp,four_Orig_verihori_sharp_blur,five_only_D10_Hori,six_only_D10_veri,seven_D10_verihori,ate_only_D7_Hori,nine_only_D7_veri,ten_D7_verihori,eleven_Orig_R90_sharp_blur,twelve_Orig_R270_sharp_blur,thirteen_Orig_HoriR90_sharp_blur,fourteen_Orig_HoriR270_sharp_blur,fifteen_D7_R90,sixteen_D7_R270,seventeen_D7_HoriR90,ateen_D7_HoriR270,ninteen_D10_R90,twenty_D10_R270,twentyone_D10_HoriR90,twentytwo_D10_HoriR270"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define file paths\n",
    "model_path = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\Source_Code\\SimCLR_base_models\\ohnecontrast_balancedResize_simclr_modelepoch245.pth'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay,max_epochs):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        # Load the pretrained ResNet-18 model\n",
    "        self.convnet = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "        \n",
    "        # Modify the fully connected layer\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4 * hidden_dim),  # Linear layer with 4*hidden_dim output\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * hidden_dim, 20)  # Output layer with hidden_dim output\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.AdamW(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        self.lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=max_epochs, eta_min=lr / 50)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convnet(x)\n",
    "\n",
    "    def info_nce_loss(self, imgs1, imgs2, device):\n",
    "\n",
    "        imgs = torch.cat((imgs1, imgs2), dim=0)  # Concatenate along the batch dimension\n",
    "        imgs = imgs.to(device)  # Move images to the device\n",
    "\n",
    "        # Encode all images\n",
    "        feats = self.forward(imgs)\n",
    "    \n",
    "        # Calculate cosine similarity\n",
    "        cos_sim = nn.functional.cosine_similarity(feats[:, None, :], feats[None, :, :], dim=-1)\n",
    "    \n",
    "        # Mask out cosine similarity to itself\n",
    "        self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "        cos_sim.masked_fill_(self_mask, -9e15)\n",
    "    \n",
    "        # Find positive example -> batch_size//2 away from the original example\n",
    "        pos_mask = self_mask.roll(shifts=cos_sim.shape[0] // 2, dims=0)\n",
    "    \n",
    "        # Normalize similarity scores by temperature\n",
    "        cos_sim = cos_sim / self.temperature\n",
    "\n",
    "        # InfoNCE loss\n",
    "        nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "        nll = nll.mean()\n",
    "\n",
    "        # Accuracy calculations\n",
    "        # Create a combination of positive and negative similarities for ranking\n",
    "        comb_sim = torch.cat([cos_sim[pos_mask][:, None],  # Positive example in first position\n",
    "                          cos_sim.masked_fill(pos_mask, -9e15)], dim=-1)\n",
    "    \n",
    "        # Sort and get the ranking position of the positive example\n",
    "        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
    "    \n",
    "        # Compute accuracy metrics\n",
    "        top1_acc = (sim_argsort == 0).float().mean()  # Top-1 accuracy\n",
    "        top5_acc = (sim_argsort < 5).float().mean()   # Top-5 accuracy\n",
    "        mean_pos = 1 + sim_argsort.float().mean()     # Mean position of the positive example\n",
    "\n",
    "        return nll, top1_acc, top5_acc, mean_pos\n",
    "\n",
    "    def train_epoch(self, train_loader, device):\n",
    "        self.train()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            imgs1, imgs2, _ = batch\n",
    "            imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "        \n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Calculate loss and accuracy metrics\n",
    "            loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            #self.lr_scheduler.step()\n",
    "\n",
    "            # Accumulate metrics\n",
    "            total_loss += loss.item()\n",
    "            total_top1_acc += top1_acc.item()\n",
    "            total_top5_acc += top5_acc.item()\n",
    "            total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(train_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(train_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(train_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos\n",
    "\n",
    "    def validate_epoch(self, val_loader, device):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "                imgs1, imgs2, _ = batch\n",
    "                imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "\n",
    "                # Calculate loss and accuracy metrics\n",
    "                loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "                # Accumulate metrics\n",
    "                total_loss += loss.item()\n",
    "                total_top1_acc += top1_acc.item()\n",
    "                total_top5_acc += top5_acc.item()\n",
    "                total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(val_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(val_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(val_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(val_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos\n",
    "    \n",
    "\n",
    "    def inference_epoch(self, inference_loader, device):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(inference_loader, desc=\"Inferencing\", leave=False):\n",
    "                imgs1, imgs2, _ = batch\n",
    "                imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "\n",
    "                # Calculate loss and accuracy metrics\n",
    "                loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "                # Accumulate metrics\n",
    "                total_loss += loss.item()\n",
    "                total_top1_acc += top1_acc.item()\n",
    "                total_top5_acc += top5_acc.item()\n",
    "                total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(inference_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(inference_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(inference_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(inference_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_19600\\3778111997.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  simclr_model.load_state_dict(torch.load(model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (convnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=512, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simclr_model = SimCLR(hidden_dim=128, lr=5e-4, temperature=0.07, weight_decay=1e-4,max_epochs=245)\n",
    "simclr_model.load_state_dict(torch.load(model_path))\n",
    "simclr_model.to(device)\n",
    "simclr_model.eval()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Resize, RandomHorizontalFlip,RandomVerticalFlip\n",
    "import random\n",
    "import torchvision.transforms.functional as TF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Specify paths for both day7 and day10 folders\n",
    "train_day7_dir = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\day7_day10\\control130_all\\combined\\day7'\n",
    "train_day10_dir = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\day7_day10\\control130_all\\combined\\day10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_day7_dir = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\day7_day10\\sd_ds\\single_dose\\RBT 01.04_gant61\\Before (untreated) Day7\\GANT61'\n",
    "train_day10_dir = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\day7_day10\\sd_ds\\single_dose\\RBT 01.04_gant61\\After Day10\\GANT61'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_day7_dir = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\day7_day10\\exploded38\\day7'\n",
    "train_day10_dir = r'C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\day7_day10\\exploded38\\day10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_data_features(model, dataloader):\n",
    "    # Prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    # Encode all paired images\n",
    "    day7_feats = []\n",
    "    day10_feats = []\n",
    "    \n",
    "    for batch_day7_imgs, batch_day10_imgs in tqdm(dataloader):\n",
    "        # Move images to the device\n",
    "        batch_day7_imgs = batch_day7_imgs.to(device)\n",
    "        batch_day10_imgs = batch_day10_imgs.to(device)\n",
    "\n",
    "        # Extract features for day7 and day10 images\n",
    "        batch_day7_feats = network(batch_day7_imgs)\n",
    "        batch_day10_feats = network(batch_day10_imgs)\n",
    "\n",
    "        print(f\"Day 7 Batch features shape: {batch_day7_feats.shape}\")\n",
    "        print(f\"Day 10 Batch features shape: {batch_day10_feats.shape}\")\n",
    "\n",
    "        # Collect features\n",
    "        day7_feats.append(batch_day7_feats.detach().cpu())\n",
    "        day10_feats.append(batch_day10_feats.detach().cpu())\n",
    "\n",
    "    # Concatenate features\n",
    "    day7_feats = torch.cat(day7_feats, dim=0)\n",
    "    day10_feats = torch.cat(day10_feats, dim=0)\n",
    "\n",
    "    print(f\"Day 7 Features shape after concatenation: {day7_feats.shape}\")\n",
    "    print(f\"Day 10 Features shape after concatenation: {day10_feats.shape}\")\n",
    "\n",
    "    return day7_feats, day10_feats\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cond\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define dataset mappings\n",
    "dataset_mapping = {\n",
    "    #\"one\": lambda: one_Original(train_day7_dir, train_day10_dir),\n",
    "    #\"two\": lambda: two_Ori_Hori_blur(train_day7_dir, train_day10_dir),\n",
    "    \"three\": lambda: three_Orig_Veri_sharp(train_day7_dir, train_day10_dir),\n",
    "    \"four\": lambda: four_Orig_verihori_sharp_blur(train_day7_dir, train_day10_dir),\n",
    "    #\"five\": lambda: five_only_D10_Hori(train_day7_dir, train_day10_dir),\n",
    "    #\"six\": lambda: six_only_D10_veri(train_day7_dir, train_day10_dir),\n",
    "    \"seven\": lambda: seven_D10_verihori(train_day7_dir, train_day10_dir),\n",
    "    #\"eight\": lambda: ate_only_D7_Hori(train_day7_dir, train_day10_dir),\n",
    "    #\"nine\": lambda: nine_only_D7_veri(train_day7_dir, train_day10_dir),\n",
    "    \"ten\": lambda: ten_D7_verihori(train_day7_dir, train_day10_dir),\n",
    "    #\"eleven\": lambda: eleven_Orig_R90_sharp_blur(train_day7_dir, train_day10_dir),\n",
    "    #\"twelve\": lambda: twelve_Orig_R270_sharp_blur(train_day7_dir, train_day10_dir),\n",
    "    #\"thirteen\": lambda: thirteen_Orig_HoriR90_sharp_blur(train_day7_dir, train_day10_dir),\n",
    "    \"fourteen\": lambda: fourteen_Orig_HoriR270_sharp_blur(train_day7_dir, train_day10_dir),\n",
    "    #\"fifteen\": lambda: fifteen_D7_R90(train_day7_dir, train_day10_dir),\n",
    "    #\"sixteen\": lambda: sixteen_D7_R270(train_day7_dir, train_day10_dir),\n",
    "    #\"seventeen\": lambda: seventeen_D7_HoriR90(train_day7_dir, train_day10_dir),\n",
    "    #\"eighteen\": lambda: ateen_D7_HoriR270(train_day7_dir, train_day10_dir),\n",
    "    #\"nineteen\": lambda: ninteen_D10_R90(train_day7_dir, train_day10_dir),\n",
    "    #\"twenty\": lambda: twenty_D10_R270(train_day7_dir, train_day10_dir),\n",
    "    #\"twentyone\": lambda: twentyone_D10_HoriR90(train_day7_dir, train_day10_dir),\n",
    "    #\"twentytwo\": lambda: twentytwo_D10_HoriR270(train_day7_dir, train_day10_dir),\n",
    "}\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 16\n",
    "\n",
    "# Function to extract and concatenate features\n",
    "import os\n",
    "\n",
    "def extract_and_combine_features(simclr_model, dataset_mapping):\n",
    "    day7_features = []\n",
    "    day10_features = []\n",
    "\n",
    "    for key, dataset_func in dataset_mapping.items():\n",
    "        # Load dataset\n",
    "        train_dataset = dataset_func()\n",
    "\n",
    "        # Define DataLoader\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "        # Extract features\n",
    "        cond7_feats, cond10_feats = prepare_data_features(simclr_model, train_loader)\n",
    "\n",
    "        # Append to the list for concatenation\n",
    "        day7_features.append(cond7_feats)\n",
    "        day10_features.append(cond10_feats)\n",
    "\n",
    "    # Concatenate all day 7 and day 10 features\n",
    "    combined_cond7 = torch.cat(day7_features, dim=0)\n",
    "    combined_cond10 = torch.cat(day10_features, dim=0)\n",
    "\n",
    "    # Save combined features in the current directory\n",
    "    combined_cond7_path = \"combined_cond7.pt\"\n",
    "    combined_cond10_path = \"combined_cond10.pt\"\n",
    "\n",
    "    print(f\"Saving combined Day 7 features to: {combined_cond7_path}\")\n",
    "    print(f\"Saving combined Day 10 features to: {combined_cond10_path}\")\n",
    "    torch.save(combined_cond7, combined_cond7_path)\n",
    "    torch.save(combined_cond10, combined_cond10_path)\n",
    "\n",
    "    return combined_cond7, combined_cond10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/9 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:01<00:12,  1.61s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:02<00:10,  1.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:04<00:08,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:05<00:06,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:06<00:05,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [00:08<00:04,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [00:09<00:02,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [00:10<00:01,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:11<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([2, 512])\n",
      "Day 10 Batch features shape: torch.Size([2, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([130, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([130, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:01<00:10,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:02<00:09,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:04<00:08,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:05<00:06,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:06<00:05,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [00:08<00:04,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [00:09<00:02,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [00:10<00:01,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:10<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([2, 512])\n",
      "Day 10 Batch features shape: torch.Size([2, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([130, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([130, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:01<00:10,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:02<00:09,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:03<00:07,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:05<00:06,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:06<00:05,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [00:07<00:03,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [00:09<00:02,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [00:10<00:01,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n",
      "Day 7 Batch features shape: torch.Size([2, 512])\n",
      "Day 10 Batch features shape: torch.Size([2, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:10<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Features shape after concatenation: torch.Size([130, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([130, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:01<00:10,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:02<00:09,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:03<00:07,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:05<00:06,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:06<00:05,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [00:07<00:03,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [00:09<00:02,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [00:10<00:01,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:10<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([2, 512])\n",
      "Day 10 Batch features shape: torch.Size([2, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([130, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([130, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 11%|█         | 1/9 [00:01<00:10,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 22%|██▏       | 2/9 [00:02<00:09,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 3/9 [00:04<00:08,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▍     | 4/9 [00:05<00:06,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▌    | 5/9 [00:06<00:05,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 6/9 [00:08<00:04,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 78%|███████▊  | 7/9 [00:09<00:02,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 89%|████████▉ | 8/9 [00:10<00:01,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 9/9 [00:10<00:00,  1.22s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([2, 512])\n",
      "Day 10 Batch features shape: torch.Size([2, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([130, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([130, 512])\n",
      "Saving combined Day 7 features to: combined_cond7.pt\n",
      "Saving combined Day 10 features to: combined_cond10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "combined_sd7, combined_sd10 = extract_and_combine_features(simclr_model, dataset_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([650, 512])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_sd7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sd\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define dataset mappings\n",
    "dataset_mapping = {\n",
    "    \"one\": lambda: one_Original(train_day7_dir, train_day10_dir),\n",
    "    \"two\": lambda: two_Ori_Hori_blur(train_day7_dir, train_day10_dir),\n",
    "    \"three\": lambda: three_Orig_Veri_sharp(train_day7_dir, train_day10_dir),\n",
    "    \"four\": lambda: four_Orig_verihori_sharp_blur(train_day7_dir, train_day10_dir),\n",
    "    \"five\": lambda: five_only_D10_Hori(train_day7_dir, train_day10_dir),\n",
    "    \"six\": lambda: six_only_D10_veri(train_day7_dir, train_day10_dir),\n",
    "    \"seven\": lambda: seven_D10_verihori(train_day7_dir, train_day10_dir),\n",
    "    \"eight\": lambda: ate_only_D7_Hori(train_day7_dir, train_day10_dir),\n",
    "    \"nine\": lambda: nine_only_D7_veri(train_day7_dir, train_day10_dir),\n",
    "    \"ten\": lambda: ten_D7_verihori(train_day7_dir, train_day10_dir),\n",
    "    \"eleven\": lambda: eleven_Orig_R90_sharp_blur(train_day7_dir, train_day10_dir),\n",
    "    \"twelve\": lambda: twelve_Orig_R270_sharp_blur(train_day7_dir, train_day10_dir),\n",
    "    \"thirteen\": lambda: thirteen_Orig_HoriR90_sharp_blur(train_day7_dir, train_day10_dir),\n",
    "    \"fourteen\": lambda: fourteen_Orig_HoriR270_sharp_blur(train_day7_dir, train_day10_dir),\n",
    "    \"fifteen\": lambda: fifteen_D7_R90(train_day7_dir, train_day10_dir),\n",
    "    \"sixteen\": lambda: sixteen_D7_R270(train_day7_dir, train_day10_dir),\n",
    "    \"seventeen\": lambda: seventeen_D7_HoriR90(train_day7_dir, train_day10_dir),\n",
    "    \"eighteen\": lambda: ateen_D7_HoriR270(train_day7_dir, train_day10_dir),\n",
    "    \"nineteen\": lambda: ninteen_D10_R90(train_day7_dir, train_day10_dir),\n",
    "    \"twenty\": lambda: twenty_D10_R270(train_day7_dir, train_day10_dir),\n",
    "    \"twentyone\": lambda: twentyone_D10_HoriR90(train_day7_dir, train_day10_dir),\n",
    "    \"twentytwo\": lambda: twentytwo_D10_HoriR270(train_day7_dir, train_day10_dir),\n",
    "}\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 16\n",
    "\n",
    "# Function to extract and concatenate features\n",
    "import os\n",
    "\n",
    "def extract_and_combine_features(simclr_model, dataset_mapping):\n",
    "    day7_features = []\n",
    "    day10_features = []\n",
    "\n",
    "    for key, dataset_func in dataset_mapping.items():\n",
    "        # Load dataset\n",
    "        train_dataset = dataset_func()\n",
    "\n",
    "        # Define DataLoader\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "        # Extract features\n",
    "        cond7_feats, cond10_feats = prepare_data_features(simclr_model, train_loader)\n",
    "\n",
    "        # Append to the list for concatenation\n",
    "        day7_features.append(cond7_feats)\n",
    "        day10_features.append(cond10_feats)\n",
    "\n",
    "    # Concatenate all day 7 and day 10 features\n",
    "    combined_cond7 = torch.cat(day7_features, dim=0)\n",
    "    combined_cond10 = torch.cat(day10_features, dim=0)\n",
    "\n",
    "    # Save combined features in the current directory\n",
    "    combined_cond7_path = \"combined_sd7.pt\"\n",
    "    combined_cond10_path = \"combined_sd10.pt\"\n",
    "\n",
    "    print(f\"Saving combined Day 7 features to: {combined_cond7_path}\")\n",
    "    print(f\"Saving combined Day 10 features to: {combined_cond10_path}\")\n",
    "    torch.save(combined_cond7, combined_cond7_path)\n",
    "    torch.save(combined_cond10, combined_cond10_path)\n",
    "\n",
    "    return combined_cond7, combined_cond10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.37s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.25s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.20s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.21s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.16s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.17s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.19s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.18s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 1/2 [00:01<00:01,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:02<00:00,  1.17s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([13, 512])\n",
      "Day 10 Batch features shape: torch.Size([13, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([29, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([29, 512])\n",
      "Saving combined Day 7 features to: combined_sd7.pt\n",
      "Saving combined Day 10 features to: combined_sd10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "combined_sd7, combined_sd10 = extract_and_combine_features(simclr_model, dataset_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([638, 512])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_sd7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explod\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# Define dataset mappings\n",
    "dataset_mapping = {\n",
    "    \"one\": lambda: one_Original(train_day7_dir, train_day10_dir),\n",
    "    \"two\": lambda: two_Ori_Hori_blur(train_day7_dir, train_day10_dir),\n",
    "    \"three\": lambda: three_Orig_Veri_sharp(train_day7_dir, train_day10_dir),\n",
    "    \"four\": lambda: four_Orig_verihori_sharp_blur(train_day7_dir, train_day10_dir),\n",
    "    \"five\": lambda: five_only_D10_Hori(train_day7_dir, train_day10_dir),\n",
    "    \"six\": lambda: six_only_D10_veri(train_day7_dir, train_day10_dir),\n",
    "    \"seven\": lambda: seven_D10_verihori(train_day7_dir, train_day10_dir),\n",
    "    \"eight\": lambda: ate_only_D7_Hori(train_day7_dir, train_day10_dir),\n",
    "    \"nine\": lambda: nine_only_D7_veri(train_day7_dir, train_day10_dir),\n",
    "    #\"ten\": lambda: ten_D7_verihori(train_day7_dir, train_day10_dir),\n",
    "    \"eleven\": lambda: eleven_Orig_R90_sharp_blur(train_day7_dir, train_day10_dir),\n",
    "    #\"twelve\": lambda: twelve_Orig_R270_sharp_blur(train_day7_dir, train_day10_dir),\n",
    "    \"thirteen\": lambda: thirteen_Orig_HoriR90_sharp_blur(train_day7_dir, train_day10_dir),\n",
    "    \"fourteen\": lambda: fourteen_Orig_HoriR270_sharp_blur(train_day7_dir, train_day10_dir),\n",
    "    \"fifteen\": lambda: fifteen_D7_R90(train_day7_dir, train_day10_dir),\n",
    "    \"sixteen\": lambda: sixteen_D7_R270(train_day7_dir, train_day10_dir),\n",
    "    \"seventeen\": lambda: seventeen_D7_HoriR90(train_day7_dir, train_day10_dir),\n",
    "    #\"eighteen\": lambda: ateen_D7_HoriR270(train_day7_dir, train_day10_dir),\n",
    "    \"nineteen\": lambda: ninteen_D10_R90(train_day7_dir, train_day10_dir),\n",
    "    #\"twenty\": lambda: twenty_D10_R270(train_day7_dir, train_day10_dir),\n",
    "    \"twentyone\": lambda: twentyone_D10_HoriR90(train_day7_dir, train_day10_dir),\n",
    "    #\"twentytwo\": lambda: twentytwo_D10_HoriR270(train_day7_dir, train_day10_dir),\n",
    "}\n",
    "\n",
    "# Define batch size\n",
    "batch_size = 16\n",
    "\n",
    "\n",
    "\n",
    "def extract_and_combine_features(simclr_model, dataset_mapping):\n",
    "    day7_features = []\n",
    "    day10_features = []\n",
    "\n",
    "    for key, dataset_func in dataset_mapping.items():\n",
    "        # Load dataset\n",
    "        train_dataset = dataset_func()\n",
    "\n",
    "        # Define DataLoader\n",
    "        train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "        # Extract features\n",
    "        cond7_feats, cond10_feats = prepare_data_features(simclr_model, train_loader)\n",
    "\n",
    "        # Append to the list for concatenation\n",
    "        day7_features.append(cond7_feats)\n",
    "        day10_features.append(cond10_feats)\n",
    "\n",
    "    # Concatenate all day 7 and day 10 features\n",
    "    combined_cond7 = torch.cat(day7_features, dim=0)\n",
    "    combined_cond10 = torch.cat(day10_features, dim=0)\n",
    "\n",
    "    # Save combined features in the current directory\n",
    "    combined_cond7_path = \"combined_ex7.pt\"\n",
    "    combined_cond10_path = \"combined_ex10.pt\"\n",
    "\n",
    "    print(f\"Saving combined Day 7 features to: {combined_cond7_path}\")\n",
    "    print(f\"Saving combined Day 10 features to: {combined_cond10_path}\")\n",
    "    torch.save(combined_cond7, combined_cond7_path)\n",
    "    torch.save(combined_cond10, combined_cond10_path)\n",
    "\n",
    "    return combined_cond7, combined_cond10\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([6, 512])\n",
      "Day 10 Batch features shape: torch.Size([6, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([38, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([38, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([6, 512])\n",
      "Day 10 Batch features shape: torch.Size([6, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([38, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([38, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.23s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.00s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([6, 512])\n",
      "Day 10 Batch features shape: torch.Size([6, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([38, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([38, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([6, 512])\n",
      "Day 10 Batch features shape: torch.Size([6, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([38, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([38, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([6, 512])\n",
      "Day 10 Batch features shape: torch.Size([6, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([38, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([38, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.26s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.29s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([6, 512])\n",
      "Day 10 Batch features shape: torch.Size([6, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([38, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([38, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.03s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([6, 512])\n",
      "Day 10 Batch features shape: torch.Size([6, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([38, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([38, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([6, 512])\n",
      "Day 10 Batch features shape: torch.Size([6, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([38, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([38, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([6, 512])\n",
      "Day 10 Batch features shape: torch.Size([6, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([38, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([38, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.38s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.09s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([6, 512])\n",
      "Day 10 Batch features shape: torch.Size([6, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([38, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([38, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([6, 512])\n",
      "Day 10 Batch features shape: torch.Size([6, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([38, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([38, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.36s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([6, 512])\n",
      "Day 10 Batch features shape: torch.Size([6, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([38, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([38, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.06s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([6, 512])\n",
      "Day 10 Batch features shape: torch.Size([6, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([38, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([38, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.04s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([6, 512])\n",
      "Day 10 Batch features shape: torch.Size([6, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([38, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([38, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([6, 512])\n",
      "Day 10 Batch features shape: torch.Size([6, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([38, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([38, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([6, 512])\n",
      "Day 10 Batch features shape: torch.Size([6, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([38, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([38, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 1/3 [00:01<00:02,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.31s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([16, 512])\n",
      "Day 10 Batch features shape: torch.Size([16, 512])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:03<00:00,  1.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Day 7 Batch features shape: torch.Size([6, 512])\n",
      "Day 10 Batch features shape: torch.Size([6, 512])\n",
      "Day 7 Features shape after concatenation: torch.Size([38, 512])\n",
      "Day 10 Features shape after concatenation: torch.Size([38, 512])\n",
      "Saving combined Day 7 features to: combined_ex7.pt\n",
      "Saving combined Day 10 features to: combined_ex10.pt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "combined_sd7, combined_sd10 = extract_and_combine_features(simclr_model, dataset_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([646, 512])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_sd7.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
