{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset\n",
    "import os\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from torchvision import transforms\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from collections import Counter\n",
    "\n",
    "from scipy.stats import mode\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Class Labels and Counts:\n",
      "Class 'cure_cond7_40' (Index 0): 40 images\n",
      "Class 'ex' (Index 1): 40 images\n",
      "Class 'sdonly_40' (Index 2): 40 images\n"
     ]
    }
   ],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = []\n",
    "        self.labels = []\n",
    "        self.class_names = []  # To store class (folder) names\n",
    "        self.class_to_idx = {}  # To map class names to indices\n",
    "        self.class_counts = {}  # To store count of images per class\n",
    "\n",
    "        # Define a transformation to resize the images\n",
    "        self.transform = transforms.Compose([transforms.Resize((96, 96))])\n",
    "\n",
    "        # Get all subdirectories (classes)\n",
    "        self.class_names = [d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))]\n",
    "        self.class_names.sort()  # Ensure consistent ordering\n",
    "        self.class_to_idx = {cls_name: idx for idx, cls_name in enumerate(self.class_names)}\n",
    "\n",
    "        # Load images and assign labels based on folder name\n",
    "        for class_name in self.class_names:\n",
    "            class_dir = os.path.join(image_dir, class_name)\n",
    "            class_images = [os.path.join(class_dir, file) for file in os.listdir(class_dir) if file.endswith(('.tiff', '.tif'))]\n",
    "            self.image_files.extend(class_images)\n",
    "            self.labels.extend([self.class_to_idx[class_name]] * len(class_images))  # Assign class index as label\n",
    "            \n",
    "            # Store the count of images per class\n",
    "            self.class_counts[class_name] = len(class_images)\n",
    "\n",
    "        # Print labels and counts\n",
    "        self.print_labels_and_counts()\n",
    "     \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "        \n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        original_image = image.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Convert to a torch tensor \n",
    "        image = torch.tensor(original_image, dtype=torch.float32)\n",
    "        #print(image.shape)\n",
    "        # Apply the resizing transform (resize)\n",
    "        image = self.transform(image)\n",
    "\n",
    "        flattened_image = image.view(-1).numpy()  # Reshape to (96*96*3, )\n",
    "        \n",
    "        return flattened_image, label\n",
    "\n",
    "    def print_labels_and_counts(self):\n",
    "        print(\"Class Labels and Counts:\")\n",
    "        for class_name, class_index in self.class_to_idx.items():\n",
    "            print(f\"Class '{class_name}' (Index {class_index}): {self.class_counts[class_name]} images\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "image_dir = r\"G:\\cluster_40\\cure\"\n",
    "#image_dir = r\"G:\\cluster_40\\uncure\"\n",
    "#image_dir=  r\"G:\\classification\\cond_all\"\n",
    "#image_dir=  r\"G:\\classification\\cure_cond\" \n",
    "\n",
    "\n",
    "dataset = ImageDataset(image_dir)  # Initialize dataset, it will automatically print labels and counts\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(27648,)\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(dataset)):\n",
    "    falttened_image,l = dataset[i]\n",
    "    print(falttened_image.shape)\n",
    "    print(l)  \n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(falttened_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(27648,)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "falttened_image.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all images into a single dataset for K-Means input\n",
    "def load_image_data(dataset):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        flattened_image, label = dataset[i]  # Unpack the image and label\n",
    "        all_images.append(flattened_image)\n",
    "        all_labels.append(label)\n",
    "    \n",
    "    # Stack all the flattened images to create a large dataset\n",
    "    # Convert to numpy arrays for K-Means input\n",
    "    return np.vstack(all_images), np.array(all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X, labels = load_image_data(dataset) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120, 27648)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(120,)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(type(labels))\n",
    "\n",
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/400, Accuracy: 0.5833\n",
      "Run 2/400, Accuracy: 0.7083\n",
      "Run 3/400, Accuracy: 0.7583\n",
      "Run 4/400, Accuracy: 0.6167\n",
      "Run 5/400, Accuracy: 0.7167\n",
      "Run 6/400, Accuracy: 0.7333\n",
      "Run 7/400, Accuracy: 0.7167\n",
      "Run 8/400, Accuracy: 0.7333\n",
      "Run 9/400, Accuracy: 0.7167\n",
      "Run 10/400, Accuracy: 0.7083\n",
      "Run 11/400, Accuracy: 0.7167\n",
      "Run 12/400, Accuracy: 0.7083\n",
      "Run 13/400, Accuracy: 0.5833\n",
      "Run 14/400, Accuracy: 0.5833\n",
      "Run 15/400, Accuracy: 0.7750\n",
      "Run 16/400, Accuracy: 0.7167\n",
      "Run 17/400, Accuracy: 0.7333\n",
      "Run 18/400, Accuracy: 0.6167\n",
      "Run 19/400, Accuracy: 0.5417\n",
      "Run 20/400, Accuracy: 0.5417\n",
      "Run 21/400, Accuracy: 0.5833\n",
      "Run 22/400, Accuracy: 0.5833\n",
      "Run 23/400, Accuracy: 0.7167\n",
      "Run 24/400, Accuracy: 0.7750\n",
      "Run 25/400, Accuracy: 0.5833\n",
      "Run 26/400, Accuracy: 0.6000\n",
      "Run 27/400, Accuracy: 0.7750\n",
      "Run 28/400, Accuracy: 0.5833\n",
      "Run 29/400, Accuracy: 0.7250\n",
      "Run 30/400, Accuracy: 0.6000\n",
      "Run 31/400, Accuracy: 0.6083\n",
      "Run 32/400, Accuracy: 0.7167\n",
      "Run 33/400, Accuracy: 0.6000\n",
      "Run 34/400, Accuracy: 0.6083\n",
      "Run 35/400, Accuracy: 0.7500\n",
      "Run 36/400, Accuracy: 0.7167\n",
      "Run 37/400, Accuracy: 0.7250\n",
      "Run 38/400, Accuracy: 0.5417\n",
      "Run 39/400, Accuracy: 0.5833\n",
      "Run 40/400, Accuracy: 0.5500\n",
      "Run 41/400, Accuracy: 0.5583\n",
      "Run 42/400, Accuracy: 0.7250\n",
      "Run 43/400, Accuracy: 0.5500\n",
      "Run 44/400, Accuracy: 0.7083\n",
      "Run 45/400, Accuracy: 0.7750\n",
      "Run 46/400, Accuracy: 0.7750\n",
      "Run 47/400, Accuracy: 0.5417\n",
      "Run 48/400, Accuracy: 0.7167\n",
      "Run 49/400, Accuracy: 0.6000\n",
      "Run 50/400, Accuracy: 0.7167\n",
      "Run 51/400, Accuracy: 0.6167\n",
      "Run 52/400, Accuracy: 0.6167\n",
      "Run 53/400, Accuracy: 0.6000\n",
      "Run 54/400, Accuracy: 0.6000\n",
      "Run 55/400, Accuracy: 0.7250\n",
      "Run 56/400, Accuracy: 0.7250\n",
      "Run 57/400, Accuracy: 0.7167\n",
      "Run 58/400, Accuracy: 0.7167\n",
      "Run 59/400, Accuracy: 0.5917\n",
      "Run 60/400, Accuracy: 0.7250\n",
      "Run 61/400, Accuracy: 0.7750\n",
      "Run 62/400, Accuracy: 0.7750\n",
      "Run 63/400, Accuracy: 0.7167\n",
      "Run 64/400, Accuracy: 0.7167\n",
      "Run 65/400, Accuracy: 0.7250\n",
      "Run 66/400, Accuracy: 0.7750\n",
      "Run 67/400, Accuracy: 0.7250\n",
      "Run 68/400, Accuracy: 0.7750\n",
      "Run 69/400, Accuracy: 0.5417\n",
      "Run 70/400, Accuracy: 0.7167\n",
      "Run 71/400, Accuracy: 0.7083\n",
      "Run 72/400, Accuracy: 0.7750\n",
      "Run 73/400, Accuracy: 0.6000\n",
      "Run 74/400, Accuracy: 0.7250\n",
      "Run 75/400, Accuracy: 0.7750\n",
      "Run 76/400, Accuracy: 0.7167\n",
      "Run 77/400, Accuracy: 0.5833\n",
      "Run 78/400, Accuracy: 0.7167\n",
      "Run 79/400, Accuracy: 0.7750\n",
      "Run 80/400, Accuracy: 0.7333\n",
      "Run 81/400, Accuracy: 0.7250\n",
      "Run 82/400, Accuracy: 0.5833\n",
      "Run 83/400, Accuracy: 0.7167\n",
      "Run 84/400, Accuracy: 0.5833\n",
      "Run 85/400, Accuracy: 0.7333\n",
      "Run 86/400, Accuracy: 0.7167\n",
      "Run 87/400, Accuracy: 0.7167\n",
      "Run 88/400, Accuracy: 0.7167\n",
      "Run 89/400, Accuracy: 0.7750\n",
      "Run 90/400, Accuracy: 0.7500\n",
      "Run 91/400, Accuracy: 0.5833\n",
      "Run 92/400, Accuracy: 0.7000\n",
      "Run 93/400, Accuracy: 0.7500\n",
      "Run 94/400, Accuracy: 0.7167\n",
      "Run 95/400, Accuracy: 0.7167\n",
      "Run 96/400, Accuracy: 0.6000\n",
      "Run 97/400, Accuracy: 0.5417\n",
      "Run 98/400, Accuracy: 0.7500\n",
      "Run 99/400, Accuracy: 0.6750\n",
      "Run 100/400, Accuracy: 0.7167\n",
      "Run 101/400, Accuracy: 0.7250\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 108\u001b[0m\n\u001b[0;32m    105\u001b[0m num_runs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m  \u001b[38;5;66;03m# Number of K-Means runs\u001b[39;00m\n\u001b[0;32m    106\u001b[0m max_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m  \u001b[38;5;66;03m# Maximum iterations per run\u001b[39;00m\n\u001b[1;32m--> 108\u001b[0m best_accuracy, best_centroids, best_idx, best_cluster_counts \u001b[38;5;241m=\u001b[39m \u001b[43mmain_kMeans_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_runs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 78\u001b[0m, in \u001b[0;36mmain_kMeans_experiment\u001b[1;34m(X, labels_np, K, num_runs, max_iters)\u001b[0m\n\u001b[0;32m     75\u001b[0m initial_centroids \u001b[38;5;241m=\u001b[39m kMeans_init_centroids(X, K)\n\u001b[0;32m     77\u001b[0m \u001b[38;5;66;03m# Run K-Means\u001b[39;00m\n\u001b[1;32m---> 78\u001b[0m centroids, idx \u001b[38;5;241m=\u001b[39m \u001b[43mrun_kMeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_centroids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     80\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[0;32m     81\u001b[0m accuracy, cluster_counts \u001b[38;5;241m=\u001b[39m calculate_accuracy(idx, labels_np, K)\n",
      "Cell \u001b[1;32mIn[11], line 31\u001b[0m, in \u001b[0;36mrun_kMeans\u001b[1;34m(X, initial_centroids, max_iters)\u001b[0m\n\u001b[0;32m     26\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[0;32m     29\u001b[0m     \n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Assign each data point to the closest centroid\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[43mfind_closest_centroids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentroids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Compute new centroids\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     centroids \u001b[38;5;241m=\u001b[39m compute_centroids(X, idx, K)\n",
      "Cell \u001b[1;32mIn[11], line 11\u001b[0m, in \u001b[0;36mfind_closest_centroids\u001b[1;34m(X, centroids)\u001b[0m\n\u001b[0;32m      9\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m---> 11\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcentroids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     idx[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(distances)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m idx\n",
      "File \u001b[1;32mc:\\Users\\k54739\\.conda\\envs\\master\\Lib\\site-packages\\numpy\\linalg\\linalg.py:2379\u001b[0m, in \u001b[0;36m_norm_dispatcher\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2375\u001b[0m     result \u001b[38;5;241m=\u001b[39m op(svd(y, compute_uv\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m   2376\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result\n\u001b[1;32m-> 2379\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_norm_dispatcher\u001b[39m(x, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   2380\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m (x,)\n\u001b[0;32m   2383\u001b[0m \u001b[38;5;129m@array_function_dispatch\u001b[39m(_norm_dispatcher)\n\u001b[0;32m   2384\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mnorm\u001b[39m(x, \u001b[38;5;28mord\u001b[39m\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, keepdims\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# K-Means initialization function\n",
    "def kMeans_init_centroids(X, K):\n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    centroids = X[randidx[:K]]\n",
    "    return centroids\n",
    "\n",
    "# Function to find the closest centroids\n",
    "def find_closest_centroids(X, centroids):\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        distances = np.linalg.norm(X[i] - centroids, axis=1)\n",
    "        idx[i] = np.argmin(distances)\n",
    "    return idx\n",
    "\n",
    "# Function to compute new centroids\n",
    "def compute_centroids(X, idx, K):\n",
    "    centroids = np.zeros((K, X.shape[1]))  # Use shape[1] for features\n",
    "    for k in range(K):\n",
    "        points = X[idx == k]\n",
    "        centroids[k] = np.mean(points, axis=0) if len(points) > 0 else centroids[k]\n",
    "    return centroids\n",
    "\n",
    "def run_kMeans(X, initial_centroids, max_iters=10):\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    idx = np.zeros(X.shape[0])\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        \n",
    "        # Assign each data point to the closest centroid\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        \n",
    "        # Compute new centroids\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "    return centroids,idx\n",
    "\n",
    "def calculate_accuracy(idx, labels_np, K=3):\n",
    "    \"\"\"Calculate accuracy for a given set of cluster assignments.\"\"\"\n",
    "    total_samples = len(labels_np)\n",
    "    cluster_label_counts = {}\n",
    "    label_to_cluster = {}\n",
    "    correctly_classified = 0\n",
    "\n",
    "    # Count true labels in each cluster\n",
    "    for cluster in range(K):\n",
    "        cluster_indices = np.where(idx == cluster)[0]\n",
    "        cluster_labels = labels_np[cluster_indices]\n",
    "        label_counts = Counter(cluster_labels)\n",
    "        cluster_label_counts[cluster] = label_counts\n",
    "    \n",
    "    # Assign each label to the cluster where it is most common\n",
    "    for label in range(3):  # Assuming 3 classes: 0, 1, 2\n",
    "        max_count = 0\n",
    "        assigned_cluster = None\n",
    "        for cluster, label_counts in cluster_label_counts.items():\n",
    "            if label_counts[label] > max_count:\n",
    "                max_count = label_counts[label]\n",
    "                assigned_cluster = cluster\n",
    "        if assigned_cluster is not None:\n",
    "            label_to_cluster[label] = assigned_cluster\n",
    "            correctly_classified += max_count\n",
    "\n",
    "    accuracy = correctly_classified / total_samples\n",
    "    return accuracy, cluster_label_counts \n",
    "\n",
    "def main_kMeans_experiment(X, labels_np, K=3, num_runs=100, max_iters=50):\n",
    "    accuracies = []\n",
    "    best_accuracy = 0\n",
    "    best_cluster_counts = None\n",
    "    best_centroids = None\n",
    "    best_idx = None\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        # Initialize centroids randomly\n",
    "        initial_centroids = kMeans_init_centroids(X, K)\n",
    "        \n",
    "        # Run K-Means\n",
    "        centroids, idx = run_kMeans(X, initial_centroids, max_iters)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy, cluster_counts = calculate_accuracy(idx, labels_np, K)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        # Track the best run\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_cluster_counts = cluster_counts\n",
    "            best_centroids = centroids\n",
    "            best_idx = idx\n",
    "        \n",
    "        print(f\"Run {run + 1}/{num_runs}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Print final results\n",
    "    print(\"\\n=== Final Results ===\")\n",
    "    print(f\"Max Accuracy: {best_accuracy:.4f}\")\n",
    "    print(\"Cluster Descriptions:\")\n",
    "    for cluster, counts in best_cluster_counts.items():\n",
    "        print(f\"Cluster {cluster} has true labels: {counts}\")\n",
    "    \n",
    "    # Return the best centroids and idx along with accuracy\n",
    "    return best_accuracy, best_centroids, best_idx, best_cluster_counts\n",
    "\n",
    "\n",
    "K = 3  # Number of clusters\n",
    "num_runs = 400  # Number of K-Means runs\n",
    "max_iters = 50  # Maximum iterations per run\n",
    "\n",
    "best_accuracy, best_centroids, best_idx, best_cluster_counts = main_kMeans_experiment(X, labels, K, num_runs, max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7666666666666667"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(33+22+37)/120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5366430260047281"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(101+126)/423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/400, Accuracy: 0.3688\n",
      "Run 2/400, Accuracy: 0.3688\n",
      "Run 3/400, Accuracy: 0.3688\n",
      "Run 4/400, Accuracy: 0.3688\n",
      "Run 5/400, Accuracy: 0.3688\n",
      "Run 6/400, Accuracy: 0.3688\n",
      "Run 7/400, Accuracy: 0.3688\n",
      "Run 8/400, Accuracy: 0.3688\n",
      "Run 9/400, Accuracy: 0.3688\n",
      "Run 10/400, Accuracy: 0.3688\n",
      "Run 11/400, Accuracy: 0.3688\n",
      "Run 12/400, Accuracy: 0.3688\n",
      "Run 13/400, Accuracy: 0.3688\n",
      "Run 14/400, Accuracy: 0.3688\n",
      "Run 15/400, Accuracy: 0.3688\n",
      "Run 16/400, Accuracy: 0.3688\n",
      "Run 17/400, Accuracy: 0.3688\n",
      "Run 18/400, Accuracy: 0.3688\n",
      "Run 19/400, Accuracy: 0.3688\n",
      "Run 20/400, Accuracy: 0.3688\n",
      "Run 21/400, Accuracy: 0.3688\n",
      "Run 22/400, Accuracy: 0.3688\n",
      "Run 23/400, Accuracy: 0.3688\n",
      "Run 24/400, Accuracy: 0.3688\n",
      "Run 25/400, Accuracy: 0.3688\n",
      "Run 26/400, Accuracy: 0.3688\n",
      "Run 27/400, Accuracy: 0.3688\n",
      "Run 28/400, Accuracy: 0.3688\n",
      "Run 29/400, Accuracy: 0.3688\n",
      "Run 30/400, Accuracy: 0.3688\n",
      "Run 31/400, Accuracy: 0.3688\n",
      "Run 32/400, Accuracy: 0.3688\n",
      "Run 33/400, Accuracy: 0.3688\n",
      "Run 34/400, Accuracy: 0.3688\n",
      "Run 35/400, Accuracy: 0.3688\n",
      "Run 36/400, Accuracy: 0.3688\n",
      "Run 37/400, Accuracy: 0.3688\n",
      "Run 38/400, Accuracy: 0.3688\n",
      "Run 39/400, Accuracy: 0.3688\n",
      "Run 40/400, Accuracy: 0.3688\n",
      "Run 41/400, Accuracy: 0.3688\n",
      "Run 42/400, Accuracy: 0.3688\n",
      "Run 43/400, Accuracy: 0.3688\n",
      "Run 44/400, Accuracy: 0.3688\n",
      "Run 45/400, Accuracy: 0.3688\n",
      "Run 46/400, Accuracy: 0.3688\n",
      "Run 47/400, Accuracy: 0.3688\n",
      "Run 48/400, Accuracy: 0.3688\n",
      "Run 49/400, Accuracy: 0.3688\n",
      "Run 50/400, Accuracy: 0.3688\n",
      "Run 51/400, Accuracy: 0.3688\n",
      "Run 52/400, Accuracy: 0.3688\n",
      "Run 53/400, Accuracy: 0.3688\n",
      "Run 54/400, Accuracy: 0.3688\n",
      "Run 55/400, Accuracy: 0.3688\n",
      "Run 56/400, Accuracy: 0.3688\n",
      "Run 57/400, Accuracy: 0.3688\n",
      "Run 58/400, Accuracy: 0.3688\n",
      "Run 59/400, Accuracy: 0.3688\n",
      "Run 60/400, Accuracy: 0.3688\n",
      "Run 61/400, Accuracy: 0.3688\n",
      "Run 62/400, Accuracy: 0.3688\n",
      "Run 63/400, Accuracy: 0.3688\n",
      "Run 64/400, Accuracy: 0.3688\n",
      "Run 65/400, Accuracy: 0.3688\n",
      "Run 66/400, Accuracy: 0.3688\n",
      "Run 67/400, Accuracy: 0.3688\n",
      "Run 68/400, Accuracy: 0.3688\n",
      "Run 69/400, Accuracy: 0.3688\n",
      "Run 70/400, Accuracy: 0.3688\n",
      "Run 71/400, Accuracy: 0.3688\n",
      "Run 72/400, Accuracy: 0.3688\n",
      "Run 73/400, Accuracy: 0.3688\n",
      "Run 74/400, Accuracy: 0.3688\n",
      "Run 75/400, Accuracy: 0.3688\n",
      "Run 76/400, Accuracy: 0.3688\n",
      "Run 77/400, Accuracy: 0.3688\n",
      "Run 78/400, Accuracy: 0.3688\n",
      "Run 79/400, Accuracy: 0.3688\n",
      "Run 80/400, Accuracy: 0.3688\n",
      "Run 81/400, Accuracy: 0.3688\n",
      "Run 82/400, Accuracy: 0.3688\n",
      "Run 83/400, Accuracy: 0.3688\n",
      "Run 84/400, Accuracy: 0.3688\n",
      "Run 85/400, Accuracy: 0.3688\n",
      "Run 86/400, Accuracy: 0.3688\n",
      "Run 87/400, Accuracy: 0.3688\n",
      "Run 88/400, Accuracy: 0.3688\n",
      "Run 89/400, Accuracy: 0.3688\n",
      "Run 90/400, Accuracy: 0.3688\n",
      "Run 91/400, Accuracy: 0.3688\n",
      "Run 92/400, Accuracy: 0.3688\n",
      "Run 93/400, Accuracy: 0.3688\n",
      "Run 94/400, Accuracy: 0.3688\n",
      "Run 95/400, Accuracy: 0.3688\n",
      "Run 96/400, Accuracy: 0.3688\n",
      "Run 97/400, Accuracy: 0.3688\n",
      "Run 98/400, Accuracy: 0.3688\n",
      "Run 99/400, Accuracy: 0.3688\n",
      "Run 100/400, Accuracy: 0.3688\n",
      "Run 101/400, Accuracy: 0.3688\n",
      "Run 102/400, Accuracy: 0.3688\n",
      "Run 103/400, Accuracy: 0.3688\n",
      "Run 104/400, Accuracy: 0.3688\n",
      "Run 105/400, Accuracy: 0.3688\n",
      "Run 106/400, Accuracy: 0.3688\n",
      "Run 107/400, Accuracy: 0.3688\n",
      "Run 108/400, Accuracy: 0.3688\n",
      "Run 109/400, Accuracy: 0.3688\n",
      "Run 110/400, Accuracy: 0.3688\n",
      "Run 111/400, Accuracy: 0.3688\n",
      "Run 112/400, Accuracy: 0.3688\n",
      "Run 113/400, Accuracy: 0.3688\n",
      "Run 114/400, Accuracy: 0.3688\n",
      "Run 115/400, Accuracy: 0.3688\n",
      "Run 116/400, Accuracy: 0.3688\n",
      "Run 117/400, Accuracy: 0.3688\n",
      "Run 118/400, Accuracy: 0.3688\n",
      "Run 119/400, Accuracy: 0.3688\n",
      "Run 120/400, Accuracy: 0.3688\n",
      "Run 121/400, Accuracy: 0.3688\n",
      "Run 122/400, Accuracy: 0.3688\n",
      "Run 123/400, Accuracy: 0.3688\n",
      "Run 124/400, Accuracy: 0.3688\n",
      "Run 125/400, Accuracy: 0.3688\n",
      "Run 126/400, Accuracy: 0.3688\n",
      "Run 127/400, Accuracy: 0.3688\n",
      "Run 128/400, Accuracy: 0.3688\n",
      "Run 129/400, Accuracy: 0.3688\n",
      "Run 130/400, Accuracy: 0.3688\n",
      "Run 131/400, Accuracy: 0.3688\n",
      "Run 132/400, Accuracy: 0.3688\n",
      "Run 133/400, Accuracy: 0.3688\n",
      "Run 134/400, Accuracy: 0.3688\n",
      "Run 135/400, Accuracy: 0.3688\n",
      "Run 136/400, Accuracy: 0.3688\n",
      "Run 137/400, Accuracy: 0.3688\n",
      "Run 138/400, Accuracy: 0.3688\n",
      "Run 139/400, Accuracy: 0.3688\n",
      "Run 140/400, Accuracy: 0.3688\n",
      "Run 141/400, Accuracy: 0.3688\n",
      "Run 142/400, Accuracy: 0.3688\n",
      "Run 143/400, Accuracy: 0.3688\n",
      "Run 144/400, Accuracy: 0.3688\n",
      "Run 145/400, Accuracy: 0.3688\n",
      "Run 146/400, Accuracy: 0.3688\n",
      "Run 147/400, Accuracy: 0.3688\n",
      "Run 148/400, Accuracy: 0.3688\n",
      "Run 149/400, Accuracy: 0.3688\n",
      "Run 150/400, Accuracy: 0.3688\n",
      "Run 151/400, Accuracy: 0.3688\n",
      "Run 152/400, Accuracy: 0.3688\n",
      "Run 153/400, Accuracy: 0.3688\n",
      "Run 154/400, Accuracy: 0.3688\n",
      "Run 155/400, Accuracy: 0.3688\n",
      "Run 156/400, Accuracy: 0.3688\n",
      "Run 157/400, Accuracy: 0.3688\n",
      "Run 158/400, Accuracy: 0.3688\n",
      "Run 159/400, Accuracy: 0.3688\n",
      "Run 160/400, Accuracy: 0.3688\n",
      "Run 161/400, Accuracy: 0.3688\n",
      "Run 162/400, Accuracy: 0.3688\n",
      "Run 163/400, Accuracy: 0.3688\n",
      "Run 164/400, Accuracy: 0.3688\n",
      "Run 165/400, Accuracy: 0.3688\n",
      "Run 166/400, Accuracy: 0.3688\n",
      "Run 167/400, Accuracy: 0.3688\n",
      "Run 168/400, Accuracy: 0.3688\n",
      "Run 169/400, Accuracy: 0.3688\n",
      "Run 170/400, Accuracy: 0.3688\n",
      "Run 171/400, Accuracy: 0.3688\n",
      "Run 172/400, Accuracy: 0.3688\n",
      "Run 173/400, Accuracy: 0.3688\n",
      "Run 174/400, Accuracy: 0.3688\n",
      "Run 175/400, Accuracy: 0.3688\n",
      "Run 176/400, Accuracy: 0.3688\n",
      "Run 177/400, Accuracy: 0.3688\n",
      "Run 178/400, Accuracy: 0.3688\n",
      "Run 179/400, Accuracy: 0.3688\n",
      "Run 180/400, Accuracy: 0.3688\n",
      "Run 181/400, Accuracy: 0.3688\n",
      "Run 182/400, Accuracy: 0.3688\n",
      "Run 183/400, Accuracy: 0.3688\n",
      "Run 184/400, Accuracy: 0.3688\n",
      "Run 185/400, Accuracy: 0.3688\n",
      "Run 186/400, Accuracy: 0.3688\n",
      "Run 187/400, Accuracy: 0.3688\n",
      "Run 188/400, Accuracy: 0.3688\n",
      "Run 189/400, Accuracy: 0.3688\n",
      "Run 190/400, Accuracy: 0.3688\n",
      "Run 191/400, Accuracy: 0.3688\n",
      "Run 192/400, Accuracy: 0.3688\n",
      "Run 193/400, Accuracy: 0.3688\n",
      "Run 194/400, Accuracy: 0.3688\n",
      "Run 195/400, Accuracy: 0.3688\n",
      "Run 196/400, Accuracy: 0.3688\n",
      "Run 197/400, Accuracy: 0.3688\n",
      "Run 198/400, Accuracy: 0.3688\n",
      "Run 199/400, Accuracy: 0.3688\n",
      "Run 200/400, Accuracy: 0.3688\n",
      "Run 201/400, Accuracy: 0.3688\n",
      "Run 202/400, Accuracy: 0.3688\n",
      "Run 203/400, Accuracy: 0.3688\n",
      "Run 204/400, Accuracy: 0.3688\n",
      "Run 205/400, Accuracy: 0.3688\n",
      "Run 206/400, Accuracy: 0.3688\n",
      "Run 207/400, Accuracy: 0.3688\n",
      "Run 208/400, Accuracy: 0.3688\n",
      "Run 209/400, Accuracy: 0.3688\n",
      "Run 210/400, Accuracy: 0.3688\n",
      "Run 211/400, Accuracy: 0.3688\n",
      "Run 212/400, Accuracy: 0.3688\n",
      "Run 213/400, Accuracy: 0.3688\n",
      "Run 214/400, Accuracy: 0.3688\n",
      "Run 215/400, Accuracy: 0.3688\n",
      "Run 216/400, Accuracy: 0.3688\n",
      "Run 217/400, Accuracy: 0.3688\n",
      "Run 218/400, Accuracy: 0.3688\n",
      "Run 219/400, Accuracy: 0.3688\n",
      "Run 220/400, Accuracy: 0.3688\n",
      "Run 221/400, Accuracy: 0.3688\n",
      "Run 222/400, Accuracy: 0.3688\n",
      "Run 223/400, Accuracy: 0.3688\n",
      "Run 224/400, Accuracy: 0.3688\n",
      "Run 225/400, Accuracy: 0.3688\n",
      "Run 226/400, Accuracy: 0.3688\n",
      "Run 227/400, Accuracy: 0.3688\n",
      "Run 228/400, Accuracy: 0.3688\n",
      "Run 229/400, Accuracy: 0.3688\n",
      "Run 230/400, Accuracy: 0.3688\n",
      "Run 231/400, Accuracy: 0.3688\n",
      "Run 232/400, Accuracy: 0.3688\n",
      "Run 233/400, Accuracy: 0.3688\n",
      "Run 234/400, Accuracy: 0.3688\n",
      "Run 235/400, Accuracy: 0.3688\n",
      "Run 236/400, Accuracy: 0.3688\n",
      "Run 237/400, Accuracy: 0.3688\n",
      "Run 238/400, Accuracy: 0.3688\n",
      "Run 239/400, Accuracy: 0.3688\n",
      "Run 240/400, Accuracy: 0.3688\n",
      "Run 241/400, Accuracy: 0.3688\n",
      "Run 242/400, Accuracy: 0.3688\n",
      "Run 243/400, Accuracy: 0.3688\n",
      "Run 244/400, Accuracy: 0.3688\n",
      "Run 245/400, Accuracy: 0.3688\n",
      "Run 246/400, Accuracy: 0.3688\n",
      "Run 247/400, Accuracy: 0.3688\n",
      "Run 248/400, Accuracy: 0.3688\n",
      "Run 249/400, Accuracy: 0.3688\n",
      "Run 250/400, Accuracy: 0.3688\n",
      "Run 251/400, Accuracy: 0.3688\n",
      "Run 252/400, Accuracy: 0.3688\n",
      "Run 253/400, Accuracy: 0.3688\n",
      "Run 254/400, Accuracy: 0.3688\n",
      "Run 255/400, Accuracy: 0.3688\n",
      "Run 256/400, Accuracy: 0.3688\n",
      "Run 257/400, Accuracy: 0.3688\n",
      "Run 258/400, Accuracy: 0.3688\n",
      "Run 259/400, Accuracy: 0.3688\n",
      "Run 260/400, Accuracy: 0.3688\n",
      "Run 261/400, Accuracy: 0.3688\n",
      "Run 262/400, Accuracy: 0.3688\n",
      "Run 263/400, Accuracy: 0.3688\n",
      "Run 264/400, Accuracy: 0.3688\n",
      "Run 265/400, Accuracy: 0.3688\n",
      "Run 266/400, Accuracy: 0.3688\n",
      "Run 267/400, Accuracy: 0.3688\n",
      "Run 268/400, Accuracy: 0.3688\n",
      "Run 269/400, Accuracy: 0.3688\n",
      "Run 270/400, Accuracy: 0.3688\n",
      "Run 271/400, Accuracy: 0.3688\n",
      "Run 272/400, Accuracy: 0.3688\n",
      "Run 273/400, Accuracy: 0.3688\n",
      "Run 274/400, Accuracy: 0.3688\n",
      "Run 275/400, Accuracy: 0.3688\n",
      "Run 276/400, Accuracy: 0.3688\n",
      "Run 277/400, Accuracy: 0.3688\n",
      "Run 278/400, Accuracy: 0.3688\n",
      "Run 279/400, Accuracy: 0.3688\n",
      "Run 280/400, Accuracy: 0.3688\n",
      "Run 281/400, Accuracy: 0.3688\n",
      "Run 282/400, Accuracy: 0.3688\n",
      "Run 283/400, Accuracy: 0.3688\n",
      "Run 284/400, Accuracy: 0.3688\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[12], line 116\u001b[0m\n\u001b[0;32m    113\u001b[0m num_runs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m400\u001b[39m  \u001b[38;5;66;03m# Number of K-Means runs\u001b[39;00m\n\u001b[0;32m    114\u001b[0m max_iters \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m50\u001b[39m  \u001b[38;5;66;03m# Maximum iterations per run\u001b[39;00m\n\u001b[1;32m--> 116\u001b[0m best_accuracy, best_centroids, best_idx, best_cluster_counts \u001b[38;5;241m=\u001b[39m \u001b[43mmain_kMeans_experiment\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mK\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_runs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[12], line 86\u001b[0m, in \u001b[0;36mmain_kMeans_experiment\u001b[1;34m(X, labels_np, K, num_runs, max_iters)\u001b[0m\n\u001b[0;32m     83\u001b[0m initial_centroids \u001b[38;5;241m=\u001b[39m kMeans_init_centroids(X, K)\n\u001b[0;32m     85\u001b[0m \u001b[38;5;66;03m# Run K-Means\u001b[39;00m\n\u001b[1;32m---> 86\u001b[0m centroids, idx \u001b[38;5;241m=\u001b[39m \u001b[43mrun_kMeans\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitial_centroids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmax_iters\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     88\u001b[0m \u001b[38;5;66;03m# Calculate accuracy\u001b[39;00m\n\u001b[0;32m     89\u001b[0m accuracy, cluster_counts \u001b[38;5;241m=\u001b[39m calculate_accuracy(idx, labels_np, K)\n",
      "Cell \u001b[1;32mIn[12], line 31\u001b[0m, in \u001b[0;36mrun_kMeans\u001b[1;34m(X, initial_centroids, max_iters)\u001b[0m\n\u001b[0;32m     26\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(max_iters):\n\u001b[0;32m     29\u001b[0m     \n\u001b[0;32m     30\u001b[0m     \u001b[38;5;66;03m# Assign each data point to the closest centroid\u001b[39;00m\n\u001b[1;32m---> 31\u001b[0m     idx \u001b[38;5;241m=\u001b[39m \u001b[43mfind_closest_centroids\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcentroids\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;66;03m# Compute new centroids\u001b[39;00m\n\u001b[0;32m     34\u001b[0m     centroids \u001b[38;5;241m=\u001b[39m compute_centroids(X, idx, K)\n",
      "Cell \u001b[1;32mIn[12], line 11\u001b[0m, in \u001b[0;36mfind_closest_centroids\u001b[1;34m(X, centroids)\u001b[0m\n\u001b[0;32m      9\u001b[0m idx \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mzeros(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]):\n\u001b[1;32m---> 11\u001b[0m     distances \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinalg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mcentroids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     12\u001b[0m     idx[i] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmin(distances)\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m idx\n",
      "File \u001b[1;32mc:\\Users\\k54739\\.conda\\envs\\master\\Lib\\site-packages\\numpy\\linalg\\linalg.py:2583\u001b[0m, in \u001b[0;36mnorm\u001b[1;34m(x, ord, axis, keepdims)\u001b[0m\n\u001b[0;32m   2580\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mord\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mord\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[0;32m   2581\u001b[0m     \u001b[38;5;66;03m# special case for speedup\u001b[39;00m\n\u001b[0;32m   2582\u001b[0m     s \u001b[38;5;241m=\u001b[39m (x\u001b[38;5;241m.\u001b[39mconj() \u001b[38;5;241m*\u001b[39m x)\u001b[38;5;241m.\u001b[39mreal\n\u001b[1;32m-> 2583\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m sqrt(\u001b[43madd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43ms\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkeepdims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkeepdims\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[0;32m   2584\u001b[0m \u001b[38;5;66;03m# None of the str-type keywords for ord ('fro', 'nuc')\u001b[39;00m\n\u001b[0;32m   2585\u001b[0m \u001b[38;5;66;03m# are valid for vectors\u001b[39;00m\n\u001b[0;32m   2586\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mord\u001b[39m, \u001b[38;5;28mstr\u001b[39m):\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "# K-Means initialization function\n",
    "def kMeans_init_centroids(X, K):\n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    centroids = X[randidx[:K]]\n",
    "    return centroids\n",
    "\n",
    "# Function to find the closest centroids\n",
    "def find_closest_centroids(X, centroids):\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        distances = np.linalg.norm(X[i] - centroids, axis=1)\n",
    "        idx[i] = np.argmin(distances)\n",
    "    return idx\n",
    "\n",
    "# Function to compute new centroids\n",
    "def compute_centroids(X, idx, K):\n",
    "    centroids = np.zeros((K, X.shape[1]))  # Use shape[1] for features\n",
    "    for k in range(K):\n",
    "        points = X[idx == k]\n",
    "        centroids[k] = np.mean(points, axis=0) if len(points) > 0 else centroids[k]\n",
    "    return centroids\n",
    "\n",
    "def run_kMeans(X, initial_centroids, max_iters=10):\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    idx = np.zeros(X.shape[0])\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        \n",
    "        # Assign each data point to the closest centroid\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        \n",
    "        # Compute new centroids\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "    return centroids,idx\n",
    "\n",
    "def calculate_accuracy(idx, labels_np, K=3):\n",
    "    \"\"\"Calculate accuracy for a given set of cluster assignments.\"\"\"\n",
    "    total_samples = len(labels_np)\n",
    "    cluster_label_counts = {}\n",
    "    label_to_cluster = {}\n",
    "    correctly_classified = 0\n",
    "\n",
    "    # Count true labels in each cluster\n",
    "    for cluster in range(K):\n",
    "        cluster_indices = np.where(idx == cluster)[0]\n",
    "        cluster_labels = labels_np[cluster_indices]\n",
    "        label_counts = Counter(cluster_labels)\n",
    "        cluster_label_counts[cluster] = label_counts\n",
    "    \n",
    "    # Track clusters already assigned to labels\n",
    "    assigned_clusters = set()\n",
    "\n",
    "    # Assign each label to the cluster where it is most common, respecting the rule\n",
    "    for label in range(3):  # Assuming 3 classes: 0, 1, 2\n",
    "        max_count = 0\n",
    "        assigned_cluster = None\n",
    "        for cluster, label_counts in cluster_label_counts.items():\n",
    "            # Skip clusters already assigned to another label\n",
    "            if cluster in assigned_clusters:\n",
    "                continue\n",
    "            if label_counts[label] > max_count:\n",
    "                max_count = label_counts[label]\n",
    "                assigned_cluster = cluster\n",
    "        # Assign this label to the cluster and mark the cluster as used\n",
    "        if assigned_cluster is not None:\n",
    "            label_to_cluster[label] = assigned_cluster\n",
    "            assigned_clusters.add(assigned_cluster)\n",
    "            correctly_classified += max_count\n",
    "\n",
    "    accuracy = correctly_classified / total_samples\n",
    "    return accuracy, cluster_label_counts \n",
    "\n",
    "def main_kMeans_experiment(X, labels_np, K=3, num_runs=100, max_iters=50):\n",
    "    accuracies = []\n",
    "    best_accuracy = 0\n",
    "    best_cluster_counts = None\n",
    "    best_centroids = None\n",
    "    best_idx = None\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        # Initialize centroids randomly\n",
    "        initial_centroids = kMeans_init_centroids(X, K)\n",
    "        \n",
    "        # Run K-Means\n",
    "        centroids, idx = run_kMeans(X, initial_centroids, max_iters)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy, cluster_counts = calculate_accuracy(idx, labels_np, K)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        # Track the best run\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_cluster_counts = cluster_counts\n",
    "            best_centroids = centroids\n",
    "            best_idx = idx\n",
    "        \n",
    "        print(f\"Run {run + 1}/{num_runs}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Print final results\n",
    "    print(\"\\n=== Final Results ===\")\n",
    "    print(f\"Max Accuracy: {best_accuracy:.4f}\")\n",
    "    print(\"Cluster Descriptions:\")\n",
    "    for cluster, counts in best_cluster_counts.items():\n",
    "        print(f\"Cluster {cluster} has true labels: {counts}\")\n",
    "    \n",
    "    # Return the best centroids and idx along with accuracy\n",
    "    return best_accuracy, best_centroids, best_idx, best_cluster_counts\n",
    "\n",
    "\n",
    "K = 3  # Number of clusters\n",
    "num_runs = 400  # Number of K-Means runs\n",
    "max_iters = 50  # Maximum iterations per run\n",
    "\n",
    "best_accuracy, best_centroids, best_idx, best_cluster_counts = main_kMeans_experiment(X, labels, K, num_runs, max_iters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(33+22+36)/120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(100+230+10)/615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "\n",
    "# Combine all images into a single dataset for K-Means input\n",
    "def load_image_data(dataset):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        flattened_image, label = dataset[i]  # Unpack the image and label\n",
    "        all_images.append(flattened_image)\n",
    "        all_labels.append(label)\n",
    "    \n",
    "    # Stack all the flattened images to create a large dataset\n",
    "    # Convert to numpy arrays for K-Means input\n",
    "    return np.vstack(all_images), np.array(all_labels)\n",
    "\n",
    "# K-Means initialization function\n",
    "def kMeans_init_centroids(X, K):\n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    centroids = X[randidx[:K]]\n",
    "    return centroids\n",
    "\n",
    "# Function to find the closest centroids\n",
    "def find_closest_centroids(X, centroids):\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        distances = np.linalg.norm(X[i] - centroids, axis=1)\n",
    "        idx[i] = np.argmin(distances)\n",
    "    return idx\n",
    "\n",
    "# Function to compute new centroids\n",
    "def compute_centroids(X, idx, K):\n",
    "    centroids = np.zeros((K, X.shape[1]))  # Use shape[1] for features\n",
    "    for k in range(K):\n",
    "        points = X[idx == k]\n",
    "        centroids[k] = np.mean(points, axis=0) if len(points) > 0 else centroids[k]\n",
    "    return centroids\n",
    "\n",
    "# Function to run K-Means algorithm with cost tracking\n",
    "def run_kMeans(X, initial_centroids, max_iters=10):\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    idx = np.zeros(X.shape[0])\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        #print(f\"K-Means iteration {i}/{max_iters - 1}\")\n",
    "        \n",
    "        # Assign each data point to the closest centroid\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        \n",
    "        # Compute new centroids\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "        \n",
    "    return centroids, idx\n",
    "\n",
    "# Function to reorder K-Means labels to match true labels\n",
    "def reorder_labels(true_labels, predicted_labels):\n",
    "    reordered_labels = np.zeros_like(predicted_labels)\n",
    "\n",
    "    for cluster in np.unique(predicted_labels):\n",
    "        mask = (predicted_labels == cluster)\n",
    "        # Use mode and handle cases where mode() returns a scalar\n",
    "        most_common_label = mode(true_labels[mask], axis=None).mode  # Get the mode for the current cluster\n",
    "        if isinstance(most_common_label, np.ndarray):\n",
    "            most_common_label = most_common_label[0]  # Safely extract the mode value if it's an array\n",
    "        \n",
    "        reordered_labels[mask] = most_common_label\n",
    "\n",
    "    return reordered_labels\n",
    "\n",
    "# Run the K-Means algorithm 100 times with different random initializations\n",
    "max_accuracy = 0\n",
    "num_runs = 40\n",
    "\n",
    "for run in range(num_runs):\n",
    "    print(f\"Run {run + 1}/{num_runs}\")\n",
    "    \n",
    "    # Load dataset (replace `dataset` with your actual dataset)\n",
    "    X, labels = load_image_data(dataset)\n",
    "    \n",
    "    K = 3  # Number of clusters\n",
    "    initial_centroids = kMeans_init_centroids(X, K)  # Initialize centroids\n",
    "    max_iters = 50  # Maximum iterations\n",
    "    \n",
    "    # Run K-Means\n",
    "    centroids, idx = run_kMeans(X, initial_centroids, max_iters)\n",
    "    \n",
    "    # Reorder labels and calculate accuracy\n",
    "    reordered_idx = reorder_labels(labels, idx)\n",
    "    accuracy = np.sum(reordered_idx == labels) / len(labels) * 100\n",
    "    \n",
    "    print(f\"Accuracy for run {run + 1}: {accuracy:.2f}%\")\n",
    "    max_accuracy = max(max_accuracy, accuracy)\n",
    "\n",
    "print(f\"Maximum accuracy achieved over {num_runs} runs: {max_accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combine all images into a single dataset for K-Means input\n",
    "def load_image_data(dataset):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        flattened_image, label = dataset[i]  # Unpack the image and label\n",
    "        all_images.append(flattened_image)\n",
    "        all_labels.append(label)\n",
    "    \n",
    "    # Stack all the flattened images to create a large dataset\n",
    "    # Convert to numpy arrays for K-Means input\n",
    "    return np.vstack(all_images), np.array(all_labels)\n",
    "\n",
    "# K-Means initialization function\n",
    "def kMeans_init_centroids(X, K):\n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    centroids = X[randidx[:K]]\n",
    "    return centroids\n",
    "\n",
    "# Function to find the closest centroids\n",
    "def find_closest_centroids(X, centroids):\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        distances = np.linalg.norm(X[i] - centroids, axis=1)\n",
    "        idx[i] = np.argmin(distances)\n",
    "    return idx\n",
    "\n",
    "# Function to compute new centroids\n",
    "def compute_centroids(X, idx, K):\n",
    "    centroids = np.zeros((K, X.shape[1]))  # Use shape[1] for features\n",
    "    for k in range(K):\n",
    "        points = X[idx == k]\n",
    "        centroids[k] = np.mean(points, axis=0) if len(points) > 0 else centroids[k]\n",
    "    return centroids\n",
    "\n",
    "# Function to run K-Means algorithm with cost tracking\n",
    "def run_kMeans(X, initial_centroids, max_iters=10):\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    idx = np.zeros(X.shape[0])\n",
    "    \n",
    "    #best_centroids = centroids\n",
    "    #lowest_cost = float('inf')\n",
    "    #final_iteration = 0  # To keep track of the iteration where the best centroids were found\n",
    "    #best_idx = idx\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        #print(f\"K-Means iteration {i}/{max_iters - 1}\")\n",
    "        \n",
    "        # Assign each data point to the closest centroid\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        \n",
    "        # Compute new centroids\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "\n",
    "        # Calculate cost function for the current centroids\n",
    "        cost = np.sum(np.linalg.norm(X - centroids[idx], axis=1)**2)\n",
    "        #print(f\"Cost function value: {cost:.4f}\")  # Print the cost function value\n",
    "\n",
    "        # Check if this is the best cost so far\n",
    "        #if cost < lowest_cost:\n",
    "            #lowest_cost = cost\n",
    "            #best_centroids = centroids\n",
    "            #best_idx = idx.copy()\n",
    "            #final_iteration = i  # Update the iteration where best centroids were found\n",
    "\n",
    "    #print(f\"Final centroids selected from iteration: {final_iteration}\")  # Indicate which iteration was chosen\n",
    "    return centroids,idx\n",
    "    #return best_centroids, best_idx, centroids,idx                                    # Return the best centroids\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to run the K-Means algorithm\n",
    "X, labels = load_image_data(dataset)  # Load data and labels \n",
    "\n",
    "# To check and print the dimensions:\n",
    "#print(\"Shape of stacked images (X):\", X.shape)\n",
    "#print(\"Shape of labels:\", labels.shape)  \n",
    "\n",
    "K = 3                          # Step 2: Set number of clusters\n",
    "initial_centroids = kMeans_init_centroids(X, K)  # Step 3: Initialize centroids \n",
    "max_iters = 50                # Step 4: Number of iterations\n",
    "\n",
    "centroids, idx = run_kMeans(X, initial_centroids, max_iters)\n",
    "#best_centroids, best_idx, centroids, idx = run_kMeans(X, initial_centroids, max_iters)  # Step 5: Run K-Means\n",
    "#print(\"Final centroids:\", best_centroids)  # Output the final centroids\n",
    "# `idx` contains the cluster assignments from KMeans\n",
    "#  `labels` contains the true labels\n",
    "\n",
    "K = len(np.unique(idx))  # Number of clusters\n",
    "\n",
    "# Iterate over each cluster and count the true labels in that cluster\n",
    "for cluster in range(K):\n",
    "    # Find the indices of images assigned to the current cluster\n",
    "    cluster_indices = np.where(idx == cluster)[0]\n",
    "    \n",
    "    # Get the true labels for the images in this cluster\n",
    "    cluster_labels = labels[cluster_indices]\n",
    "    \n",
    "    # Use Counter to count occurrences of each label in the cluster\n",
    "    label_counts = Counter(cluster_labels)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Cluster {cluster} has true labels: {label_counts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 126+101\n",
    "print(num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num/423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reorder K-Means labels to match true labels\n",
    "def reorder_labels(true_labels, predicted_labels):\n",
    "    reordered_labels = np.zeros_like(predicted_labels)\n",
    "\n",
    "    for cluster in np.unique(predicted_labels):\n",
    "        mask = (predicted_labels == cluster)\n",
    "        # Use mode and handle cases where mode() returns a scalar\n",
    "        most_common_label = mode(true_labels[mask], axis=None).mode  # Get the mode for the current cluster\n",
    "        if isinstance(most_common_label, np.ndarray):\n",
    "            most_common_label = most_common_label[0]  # Safely extract the mode value if it's an array\n",
    "        \n",
    "        reordered_labels[mask] = most_common_label\n",
    "\n",
    "    return reordered_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this after running K-Means\n",
    "reordered_idx = reorder_labels(labels, idx)\n",
    "\n",
    "# Now you can compare `reordered_idx` with `labels` to evaluate accuracy\n",
    "accuracy = np.sum(reordered_idx == labels) / len(labels) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Cluster assignments:\", idx)\n",
    "print(\"True labels:\", labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "print(\"Cluster assignments:\", best_idx)\n",
    "print(\"True labels:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_idx == idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "K = len(np.unique(best_idx))  # Number of clusters\n",
    "\n",
    "# Iterate over each cluster and count the true labels in that cluster\n",
    "for cluster in range(K):\n",
    "    # Find the indices of images assigned to the current cluster\n",
    "    cluster_indices = np.where(best_idx == cluster)[0]\n",
    "    \n",
    "    # Get the true labels for the images in this cluster\n",
    "    cluster_labels = labels[cluster_indices]\n",
    "    \n",
    "    # Use Counter to count occurrences of each label in the cluster\n",
    "    label_counts = Counter(cluster_labels)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Cluster {cluster} has true labels: {label_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply this after running K-Means\n",
    "reordered_idx = reorder_labels(labels, best_idx)\n",
    "\n",
    "# Now you can compare `reordered_idx` with `labels` to evaluate accuracy\n",
    "accuracy = np.sum(reordered_idx == labels) / len(labels) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reduce the dimensionality of data points and centroids to 2D using PCA\n",
    "def reduce_to_2D_pca(X, centroids):\n",
    "    # Initialize PCA with 2 components\n",
    "    pca = PCA(n_components=2)\n",
    "    \n",
    "    # Apply PCA to the data points (X) and centroids\n",
    "    X_2D = pca.fit_transform(X)  # Reducing original data points\n",
    "    centroids_2D = pca.transform(centroids)  # Reducing centroids\n",
    "\n",
    "    return X_2D, centroids_2D\n",
    "\n",
    "# Function to plot 2D visualization of clustered data points and centroids with true labels\n",
    "def plot_2D_clusters_with_labels(X_2D, centroids_2D, idx, labels, K):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    # Define color map for clusters\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, K))\n",
    "    \n",
    "    # Plot data points colored by their cluster assignment\n",
    "    for k in range(K):\n",
    "        cluster_points = X_2D[idx == k]\n",
    "        cluster_labels = labels[idx == k]  # Get true labels for the current cluster\n",
    "        \n",
    "        # Scatter plot for each cluster\n",
    "        plt.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "                    c=[colors[k]], label=f\"Cluster {k+1}\", alpha=0.6)\n",
    "        \n",
    "        # Annotate each point with its true label\n",
    "        for i in range(cluster_points.shape[0]):\n",
    "            plt.annotate(str(cluster_labels[i]), \n",
    "                         (cluster_points[i, 0], cluster_points[i, 1]), \n",
    "                         fontsize=8, alpha=0.75)\n",
    "\n",
    "    # Plot centroids as larger markers\n",
    "    plt.scatter(centroids_2D[:, 0], centroids_2D[:, 1], \n",
    "                c='k', marker='x', s=200, label='Centroids')\n",
    "\n",
    "    plt.title(\"2D Visualization of Clusters using PCA with True Labels\")\n",
    "    plt.xlabel(\"Component 1\")\n",
    "    plt.ylabel(\"Component 2\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA after K-Means clustering for 2D visualization\n",
    "X_2D_pca, centroids_2D_pca = reduce_to_2D_pca(X, centroids)\n",
    "\n",
    "# Plot the 2D clusters with centroids and true labels\n",
    "plot_2D_clusters_with_labels(X_2D_pca, centroids_2D_pca, idx, labels, K)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Apply PCA after K-Means clustering for 2D visualization\n",
    "X_2D_pca, centroids_2D_pca = reduce_to_2D_pca(X, best_centroids)\n",
    "\n",
    "# Plot the 2D clusters with centroids and true labels\n",
    "plot_2D_clusters_with_labels(X_2D_pca, centroids_2D_pca, best_idx, labels, K)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Combine all images into a single dataset for K-Means input\n",
    "def load_image_data(dataset):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        flattened_image, label = dataset[i]  # Unpack the image and label\n",
    "        all_images.append(flattened_image)\n",
    "        all_labels.append(label)\n",
    "    \n",
    "    # Stack all the flattened images to create a large dataset\n",
    "    # Convert to numpy arrays for K-Means input\n",
    "    return np.vstack(all_images), np.array(all_labels)\n",
    "\n",
    "# K-Means initialization function\n",
    "def kMeans_init_centroids(X, K):\n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    centroids = X[randidx[:K]]\n",
    "    return centroids\n",
    "\n",
    "# Function to find the closest centroids using Cosine Similarity\n",
    "def find_closest_centroids(X, centroids):\n",
    "    # Normalize both the data points and centroids to ensure we compute cosine similarity\n",
    "    X_norm = normalize(X, axis=1)\n",
    "    centroids_norm = normalize(centroids, axis=1)\n",
    "    #print(X_norm.shape)              #(60, 27648)\n",
    "    #print(centroids_norm.shape)  #(2, 27648)\n",
    "    #print(X_norm[0].shape) #(27648,)\n",
    "    \n",
    "    # Assign data points to closest centroids based on cosine similarity\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        # Compute cosine similarity\n",
    "        similarities = np.dot(centroids_norm, X_norm[i])  # Dot product gives cosine similarity\n",
    "        #print(similarities.shape)\n",
    "        idx[i] = np.argmax(similarities)  # We want the most similar (highest value)\n",
    "    return idx  #idx = [1, 0, 1, 1, 0,...]\n",
    "\n",
    "\n",
    "def compute_centroids(X, idx, K):\n",
    "    centroids = np.zeros((K, X.shape[1]))  # Use shape[1] for features\n",
    "    for k in range(K):\n",
    "        points = X[idx == k]\n",
    "        if len(points) > 0:\n",
    "            # Normalize the points within the cluster along each feature axis\n",
    "            normalized_points = normalize(points, axis=1)\n",
    "            # Compute the mean of the normalized points to get the new centroid\n",
    "            centroids[k] = np.mean(normalized_points, axis=0)\n",
    "    return centroids\n",
    "\n",
    "# Function to run K-Means algorithm with cost tracking (using Cosine Similarity)\n",
    "def run_kMeans(X, initial_centroids, max_iters=10):\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    idx = np.zeros(X.shape[0])\n",
    "    \n",
    "    best_centroids = centroids\n",
    "    lowest_cost = float('inf')\n",
    "    final_iteration = 0  # To keep track of the iteration where the best centroids were found\n",
    "    best_idx = idx  # Track the best index assignment\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        print(f\"K-Means iteration {i}/{max_iters - 1}\")\n",
    "        \n",
    "        # Assign each data point to the closest centroid using cosine similarity\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        \n",
    "        \n",
    "        # Compute new centroids\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "\n",
    "        #Range of cosine distance is from 0 to 2, 0 — identical vectors, 1 — no correlation, 2 — absolutely different.\n",
    "\n",
    "        # Calculate cost function for the current centroids using cosine distance\n",
    "        X_norm = normalize(X, axis=1)\n",
    "        centroids_norm = normalize(centroids, axis=1)\n",
    "\n",
    "        # 1. Compute cosine similarity\n",
    "        sim = np.dot(X_norm, centroids_norm.T)\n",
    "        #print(sim.shape)\n",
    "        #print(sim)\n",
    "        # 2. Calculate cosine distance\n",
    "        cosine_dist = 1 - sim\n",
    "        #print(cosine_dist.shape)\n",
    "        #print(cosine_dist)\n",
    "        # 3. Find maximum cosine distance for each data point\n",
    "        max_cosine_dist = cosine_dist.max(axis=1)\n",
    "        #print(max_cosine_dist.shape)\n",
    "        #print(max_cosine_dist)\n",
    "        \n",
    "\n",
    "        # 4. Sum of all maximum distances\n",
    "        cost = np.sum(max_cosine_dist)\n",
    "\n",
    "        #cost = np.sum(1 - np.dot(X_norm, centroids_norm.T).max(axis=1))  # Cosine distance = (1 - cosine similarity)  #this code calcs cosine sim to all images? wwhy max? inspect both code each value and then total value\n",
    "        print(f\"Cost function value: {cost:.4f}\")  # Print the cost function value\n",
    "\n",
    "        # Check if this is the best cost so far\n",
    "        if cost < lowest_cost:\n",
    "            lowest_cost = cost\n",
    "            best_centroids = centroids\n",
    "            best_idx = idx.copy()\n",
    "            final_iteration = i  # Update the iteration where best centroids were found\n",
    "\n",
    "    print(f\"Final centroids selected from iteration: {final_iteration}\")  # Indicate which iteration was chosen\n",
    "    return best_centroids, best_idx, idx  # Return the best centroids\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Combine all images into a single dataset for K-Means input\n",
    "def load_image_data(dataset):\n",
    "    all_images = []\n",
    "    all_labels = []\n",
    "    \n",
    "    for i in range(len(dataset)):\n",
    "        flattened_image, label = dataset[i]  # Unpack the image and label\n",
    "        all_images.append(flattened_image)\n",
    "        all_labels.append(label)\n",
    "    \n",
    "    # Stack all the flattened images to create a large dataset\n",
    "    X = np.vstack(all_images)  # Combine all images into a single dataset\n",
    "\n",
    "    # Normalize the combined dataset along the features axis (axis=1)\n",
    "    X_normalized = normalize(X, axis=1)\n",
    "    return X_normalized, np.array(all_labels)\n",
    "\n",
    "# K-Means initialization function\n",
    "def kMeans_init_centroids(X, K):\n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    centroids = X[randidx[:K]]  # Randomly select K centroids from normalized X\n",
    "    return centroids\n",
    "\n",
    "# Function to find the closest centroids using Cosine Similarity\n",
    "def find_closest_centroids(X, centroids):\n",
    "    # No need to normalize X and centroids here as they are already normalized\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        similarities = np.dot(centroids, X[i])  # Dot product gives cosine similarity\n",
    "        idx[i] = np.argmax(similarities)  # We want the most similar (highest value)\n",
    "    return idx\n",
    "\n",
    "# Function to compute new centroids\n",
    "def compute_centroids(X, idx, K):\n",
    "    centroids = np.zeros((K, X.shape[1]))\n",
    "    for k in range(K):\n",
    "        points = X[idx == k]\n",
    "        if len(points) > 0:\n",
    "            centroids[k] = np.mean(points, axis=0)  #why axs =0 ans:https://chatgpt.com/share/671b97a7-ec2c-8010-af33-af106df0a25c\n",
    "            centroids_norm = normalize(centroids, axis=1)\n",
    "    return centroids_norm\n",
    "\n",
    "# Function to run K-Means algorithm with cost tracking (using Cosine Similarity)\n",
    "def run_kMeans(X, initial_centroids, max_iters=10):\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    idx = np.zeros(X.shape[0])\n",
    "\n",
    "    best_centroids = centroids\n",
    "    lowest_cost = float('inf')\n",
    "    final_iteration = 0\n",
    "    best_idx = idx  # Track the best index assignment\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        print(f\"K-Means iteration {i}/{max_iters - 1}\")\n",
    "        \n",
    "        # Assign each data point to the closest centroid\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        \n",
    "        # Compute new centroids\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "\n",
    "        # Calculate cost function\n",
    "        sim = np.dot(X, centroids.T)\n",
    "        print(f\"sim:{sim}\")\n",
    "        cosine_dist = 1 - sim\n",
    "        #max_cosine_dist = cosine_dist.max(axis=1)\n",
    "        #cost = np.sum(max_cosine_dist)\n",
    "\n",
    "        cost = np.sum(cosine_dist)\n",
    "        \n",
    "\n",
    "        print(f\"Cost function value: {cost}\")\n",
    "\n",
    "        if cost < lowest_cost:\n",
    "            lowest_cost = cost\n",
    "            best_centroids = centroids\n",
    "            best_idx = idx.copy()\n",
    "            final_iteration = i\n",
    "\n",
    "    print(f\"Final centroids selected from iteration: {final_iteration}\")\n",
    "    return best_centroids, best_idx, centroids, idx  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to run the K-Means algorithm\n",
    "X, labels = load_image_data(dataset)  # Load data and labels \n",
    "\n",
    "# To check and print the dimensions:\n",
    "print(\"Shape of stacked images (X):\", X.shape)\n",
    "print(\"Shape of labels:\", labels.shape)       \n",
    "\n",
    "K = 2                          # Step 2: Set number of clusters\n",
    "initial_centroids = kMeans_init_centroids(X, K)  # Step 3: Initialize centroids \n",
    "max_iters = 50                # Step 4: Number of iterations\n",
    "\n",
    "best_centroids, best_idx, centroids, idx = run_kMeans(X, initial_centroids, max_iters)  # Step 5: Run K-Means\n",
    "print(\"Final centroids:\", best_centroids)  # Output the final centroids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cluster assignments:\", idx)\n",
    "print(\"True labels:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Cluster assignments:\", best_idx)\n",
    "print(\"True labels:\", labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `idx` contains the cluster assignments from KMeans\n",
    "#  `labels` contains the true labels\n",
    "\n",
    "K = len(np.unique(idx))  # Number of clusters\n",
    "\n",
    "# Iterate over each cluster and count the true labels in that cluster\n",
    "for cluster in range(K):\n",
    "    # Find the indices of images assigned to the current cluster\n",
    "    cluster_indices = np.where(idx == cluster)[0]\n",
    "    \n",
    "    # Get the true labels for the images in this cluster\n",
    "    cluster_labels = labels[cluster_indices]\n",
    "    \n",
    "    # Use Counter to count occurrences of each label in the cluster\n",
    "    label_counts = Counter(cluster_labels)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Cluster {cluster} has true labels: {label_counts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = len(np.unique(best_idx))  # Number of clusters\n",
    "\n",
    "# Iterate over each cluster and count the true labels in that cluster\n",
    "for cluster in range(K):\n",
    "    # Find the indices of images assigned to the current cluster\n",
    "    cluster_indices = np.where(best_idx == cluster)[0]\n",
    "    \n",
    "    # Get the true labels for the images in this cluster\n",
    "    cluster_labels = labels[cluster_indices]\n",
    "    \n",
    "    # Use Counter to count occurrences of each label in the cluster\n",
    "    label_counts = Counter(cluster_labels)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Cluster {cluster} has true labels: {label_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reorder K-Means labels to match true labels\n",
    "def reorder_labels(true_labels, predicted_labels):\n",
    "    reordered_labels = np.zeros_like(predicted_labels)\n",
    "\n",
    "    for cluster in np.unique(predicted_labels):\n",
    "        mask = (predicted_labels == cluster)\n",
    "        # Use mode and handle cases where mode() returns a scalar\n",
    "        most_common_label = mode(true_labels[mask], axis=None).mode  # Get the mode for the current cluster\n",
    "        if isinstance(most_common_label, np.ndarray):\n",
    "            most_common_label = most_common_label[0]  # Safely extract the mode value if it's an array\n",
    "        \n",
    "        reordered_labels[mask] = most_common_label\n",
    "\n",
    "    return reordered_labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this after running K-Means\n",
    "reordered_idx = reorder_labels(labels, idx)\n",
    "\n",
    "# Now you can compare `reordered_idx` with `labels` to evaluate accuracy\n",
    "accuracy = np.sum(reordered_idx == labels) / len(labels) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this after running K-Means\n",
    "reordered_idx = reorder_labels(labels, best_idx)\n",
    "\n",
    "# Now you can compare `reordered_idx` with `labels` to evaluate accuracy\n",
    "accuracy = np.sum(reordered_idx == labels) / len(labels) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reduce the dimensionality of data points and centroids to 2D using PCA\n",
    "def reduce_to_2D_pca(X, centroids):\n",
    "    # Initialize PCA with 2 components\n",
    "    pca = PCA(n_components=2)\n",
    "    \n",
    "    # Apply PCA to the data points (X) and centroids\n",
    "    X_2D = pca.fit_transform(X)  # Reducing original data points\n",
    "    centroids_2D = pca.transform(centroids)  # Reducing centroids\n",
    "\n",
    "    return X_2D, centroids_2D\n",
    "\n",
    "# Function to plot 2D visualization of clustered data points and centroids with true labels\n",
    "def plot_2D_clusters_with_labels(X_2D, centroids_2D, idx, labels, K):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    # Define color map for clusters\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, K))\n",
    "    \n",
    "    # Plot data points colored by their cluster assignment\n",
    "    for k in range(K):\n",
    "        cluster_points = X_2D[idx == k]\n",
    "        cluster_labels = labels[idx == k]  # Get true labels for the current cluster\n",
    "        \n",
    "        # Scatter plot for each cluster\n",
    "        plt.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "                    c=[colors[k]], label=f\"Cluster {k+1}\", alpha=0.6)\n",
    "        \n",
    "        # Annotate each point with its true label\n",
    "        for i in range(cluster_points.shape[0]):\n",
    "            plt.annotate(str(cluster_labels[i]), \n",
    "                         (cluster_points[i, 0], cluster_points[i, 1]), \n",
    "                         fontsize=8, alpha=0.75)\n",
    "\n",
    "    # Plot centroids as larger markers\n",
    "    plt.scatter(centroids_2D[:, 0], centroids_2D[:, 1], \n",
    "                c='k', marker='x', s=200, label='Centroids')\n",
    "\n",
    "    plt.title(\"2D Visualization of Clusters using PCA with True Labels\")\n",
    "    plt.xlabel(\"Component 1\")\n",
    "    plt.ylabel(\"Component 2\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA after K-Means clustering for 2D visualization\n",
    "X_2D_pca, centroids_2D_pca = reduce_to_2D_pca(X, centroids)\n",
    "\n",
    "# Plot the 2D clusters with centroids and true labels\n",
    "plot_2D_clusters_with_labels(X_2D_pca, centroids_2D_pca, idx, labels, K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA after K-Means clustering for 2D visualization\n",
    "X_2D_pca, centroids_2D_pca = reduce_to_2D_pca(X, best_centroids)\n",
    "\n",
    "# Plot the 2D clusters with centroids and true labels\n",
    "plot_2D_clusters_with_labels(X_2D_pca, centroids_2D_pca, best_idx, labels, K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_data_points = 30+30+12\n",
    "wrong = 3 \n",
    "predicted_corrected = total_data_points - wrong\n",
    "accuracy = (predicted_corrected/total_data_points)*100\n",
    "print(accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibi = np.array([\n",
    "    [0.6394, 0.64353806, 0.64770716, 0.68035775, 0.68076485, 0.68122697],\n",
    "    [0.6434593, 0.64427465, 0.6459859, 0.6629785, 0.6606025, 0.65433437],\n",
    "    [0.6341258, 0.63328487, 0.62688166, 0.6681404, 0.66825783, 0.6676554],\n",
    "    [0.627638, 0.6284246, 0.6292516, 0.61081785, 0.6114242, 0.6106233],\n",
    "    [0.63396144, 0.63511825, 0.6288564, 0.6226765, 0.6219877, 0.62269145],\n",
    "    [0.6106442, 0.61703616, 0.6183802, 0.616232, 0.6164079, 0.6152731],\n",
    "    [0.6106442, 0.61703616, 0.6183802, 0.616232, 0.6164079, 0.6152731]\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bibi.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.tiff')] \n",
    "        \n",
    "        # Define a transformation to resize the images\n",
    "        self.transform = transforms.Compose([transforms.Resize((256, 256))])\n",
    "     \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "        \n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        original_image = image.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Convert to a torch tensor \n",
    "        image = torch.tensor(original_image, dtype=torch.float32)\n",
    "\n",
    "        # Apply the resizing transform\n",
    "        image = self.transform(image)\n",
    "\n",
    "        image_numpy = image.numpy()\n",
    "\n",
    "        return image_numpy, original_image\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset and visualize images\n",
    "dataset = ImageDataset(r\"../../tiff_experiment_unsupervised_data/combined\")\n",
    "for i in range(len(dataset)):\n",
    "    image_numpy, original_image = dataset[i]  # This will get the resized and original images\n",
    "\n",
    "    # Plot the original and resized images side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Display original image\n",
    "    axes[0].imshow(original_image.transpose(1, 2, 0))  # Change shape for imshow (H, W, C)\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')  # Turn off axis\n",
    "\n",
    "    # Display resized image\n",
    "    axes[1].imshow(image_numpy.transpose(1, 2, 0))  # Change shape for imshow (H, W, C)\n",
    "    axes[1].set_title('Resized Image')\n",
    "    axes[1].axis('off')  # Turn off axis\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class ImageData(Dataset):\n",
    "    def __init__(self, image_dir):\n",
    "        self.image_dir = image_dir\n",
    "        self.image_files = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.tiff')] \n",
    "        \n",
    "        # Define a transformation to resize the images (Note: Resize expects a PIL image or torchvision tensor)\n",
    "        self.transform = transforms.Resize((256, 256))\n",
    "     \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Print the shape of the loaded image\n",
    "        print(f\"Image {img_path} loaded with shape: {image.shape}\")\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "        \n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        original_image = image.astype(np.float32) / 65535.0\n",
    "        print(original_image.shape)\n",
    "        # Convert to a torch tensor \n",
    "        image = torch.tensor(original_image, dtype=torch.float32)\n",
    "        print(f\"tensor image {image.shape}\")\n",
    "        # Apply resizing using torch.nn.functional.interpolate\n",
    "        image = F.interpolate(image.unsqueeze(0), size=(256, 256), mode='bilinear', align_corners=False).squeeze(0)\n",
    "\n",
    "        image_numpy = image.numpy()\n",
    "\n",
    "        # Flatten the resized image for K-Means input (reshape into (3, 256*256))\n",
    "        #reshaped_image = image.view(3, -1).T  # Reshape to (256*256, 3)\n",
    "        #print(f\"Reshaped image shape: {reshaped_image.shape}\")\n",
    "\n",
    "        return original_image, image_numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Create dataset and visualize images\n",
    "dataset = ImageData(r\"../../tiff_experiment_unsupervised_data/combined\")\n",
    "for i in range(len(dataset)):\n",
    "    orig_image, image_np = dataset[i]  # This will get the resized and original images\n",
    "\n",
    "    # Plot the original and resized images side by side\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(10, 5))\n",
    "\n",
    "    # Display original image\n",
    "    axes[0].imshow(orig_image.transpose(1, 2, 0))  # Change shape for imshow (H, W, C)\n",
    "    axes[0].set_title('Original Image')\n",
    "    axes[0].axis('off')  # Turn off axis\n",
    "\n",
    "    # Display resized image\n",
    "    axes[1].imshow(image_np.transpose(1, 2, 0))  # Change shape for imshow (H, W, C)\n",
    "    axes[1].set_title('Resized Image')\n",
    "    axes[1].axis('off')  # Turn off axis\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    break  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "image = tiff.imread(r'C:\\Users\\k54739\\Bibin Babu\\thesis\\Data_supervised\\drug_screened\\B02-T01.tiff')\n",
    "\n",
    "# Print the shape of the loaded image\n",
    "print(f\"Image shape {image.shape}\")\n",
    "\n",
    "# Ensure the image has 3 layers (channels)\n",
    "if image.shape[0] != 3:\n",
    "    raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "        \n",
    "# Normalize the 16-bit image to [0, 1]\n",
    "original_image = image.astype(np.float32) / 65535.0\n",
    "print(original_image.shape)\n",
    "# Convert to a torch tensor \n",
    "image = torch.tensor(original_image, dtype=torch.float32)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "def resize_with_aspect_ratio(image, target_size):\n",
    "    # Calculate the target size maintaining aspect ratio\n",
    "    h, w = image.shape[1], image.shape[2]\n",
    "    aspect_ratio = w / h\n",
    "    \n",
    "    if aspect_ratio > 1:  # Wider than tall\n",
    "        new_width = target_size\n",
    "        new_height = int(target_size / aspect_ratio)\n",
    "    else:  # Taller than wide\n",
    "        new_height = target_size\n",
    "        new_width = int(target_size * aspect_ratio)\n",
    "\n",
    "    resized_image = F.interpolate(image.unsqueeze(0), size=(new_height, new_width), mode='bilinear', align_corners=False).squeeze(0)\n",
    "    \n",
    "    # Pad to the target size if necessary\n",
    "    padded_image = F.pad(resized_image, (0, target_size - new_width, 0, target_size - new_height), mode='constant', value=0)\n",
    "    return padded_image\n",
    "padded_image = resize_with_aspect_ratio(image,256)\n",
    "print(padded_image.shape)\n",
    "np_image = padded_image.numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import tifffile as tiff  # Import tifffile for reading TIFF images\n",
    "\n",
    "# Function to resize with aspect ratio while padding\n",
    "def resize_with_aspect_ratio(image, target_size):\n",
    "    # Get original dimensions\n",
    "    h, w = image.shape[1], image.shape[2]  # Assuming image shape is (C, H, W)\n",
    "    aspect_ratio = w / h\n",
    "    \n",
    "    if aspect_ratio > 1:  # Wider than tall\n",
    "        new_w = target_size\n",
    "        new_h = int(target_size / aspect_ratio)\n",
    "    else:  # Taller than wide or square\n",
    "        new_h = target_size\n",
    "        new_w = int(target_size * aspect_ratio)\n",
    "\n",
    "    # Resize using F.interpolate\n",
    "    resized_image = torch.nn.functional.interpolate(\n",
    "        image.unsqueeze(0), size=(new_h, new_w), mode='bilinear', align_corners=False\n",
    "    ).squeeze(0)\n",
    "\n",
    "    # Create a padded image\n",
    "    padded_image = torch.zeros((3, target_size, target_size))  # Create an empty image of target size\n",
    "    padded_image[:, :new_h, :new_w] = resized_image  # Place resized image in the top-left corner\n",
    "\n",
    "    return padded_image\n",
    "\n",
    "# Load the image\n",
    "img_path = r'C:\\Users\\k54739\\Bibin Babu\\thesis\\Data_supervised\\drug_screened\\B02-T01.tiff'\n",
    "image = tiff.imread(img_path)\n",
    "\n",
    "# Print the shape of the loaded image\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "\n",
    "# Ensure the image has 3 layers (channels)\n",
    "if image.shape[0] != 3:\n",
    "    raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "        \n",
    "# Normalize the 16-bit image to [0, 1]\n",
    "original_image = image.astype(np.float32) / 65535.0\n",
    "print(f\"Normalized image shape: {original_image.shape}\")\n",
    "\n",
    "# Convert to a torch tensor \n",
    "image_tensor = torch.tensor(original_image, dtype=torch.float32)\n",
    "\n",
    "# Resize with aspect ratio and pad\n",
    "padded_image = resize_with_aspect_ratio(image_tensor, 256)\n",
    "print(f\"Padded image shape: {padded_image.shape}\")\n",
    "\n",
    "# Convert padded tensor back to numpy array for visualization\n",
    "np_image = padded_image.numpy()\n",
    "\n",
    "# Plot the original and padded images side by side\n",
    "fig, axes = plt.subplots(1, 2, figsize=(12, 6))\n",
    "\n",
    "# Display original image\n",
    "axes[0].imshow(np.transpose(original_image, (1, 2, 0)))  # Transpose for matplotlib\n",
    "axes[0].set_title('Original Image')\n",
    "axes[0].axis('off')\n",
    "\n",
    "# Display padded image\n",
    "axes[1].imshow(np.transpose(np_image, (1, 2, 0)))  # Transpose for matplotlib\n",
    "axes[1].set_title('Padded Image')\n",
    "axes[1].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dataset = ImageDataset(r\"../../tiff_experiment_unsupervised_data/combined\")\n",
    "for i in range(len(dataset)):\n",
    "    falttened_image = dataset[i]  # This will print the shape of each image\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Load an example dataset that we will be using\n",
    "def load_data():\n",
    "    return np.random.rand(300, 2) * 10  # 300 data points with 2 features\n",
    "\n",
    "# Function for random initialization of centroids\n",
    "def kMeans_init_centroids(X, K):\n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    centroids = X[randidx[:K]]\n",
    "    return centroids\n",
    "\n",
    "# Function to find the closest centroids\n",
    "def find_closest_centroids(X, centroids):\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        distances = np.linalg.norm(X[i] - centroids, axis=1)\n",
    "        idx[i] = np.argmin(distances)\n",
    "    return idx\n",
    "\n",
    "# Function to compute new centroids\n",
    "def compute_centroids(X, idx, K):\n",
    "    centroids = np.zeros((K, X.shape[1]))  # Use shape[1] for features\n",
    "    for k in range(K):\n",
    "        points = X[idx == k]\n",
    "        centroids[k] = np.mean(points, axis=0) if len(points) > 0 else centroids[k]\n",
    "    return centroids\n",
    "\n",
    "# Function to run K-Means algorithm\n",
    "def run_kMeans(X, initial_centroids, max_iters=10):\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    idx = np.zeros(X.shape[0])\n",
    "    centroids_history = []\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        print(f\"K-Means iteration {i}/{max_iters - 1}\")\n",
    "        # Assign each data point to the closest centroid\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        # Store the current centroids\n",
    "        centroids_history.append(centroids.copy())\n",
    "        # Compute new centroids\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "\n",
    "    # Final plot after all iterations\n",
    "    plot_progress_kMeans(X, centroids_history, idx, K)\n",
    "    return centroids, idx\n",
    "\n",
    "# Updated plotting function\n",
    "def plot_progress_kMeans(X, centroids_history, idx, K):\n",
    "    plt.figure(figsize=(8, 6))\n",
    "    \n",
    "    # Get colors for each cluster\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, K))\n",
    "    \n",
    "    # Plot data points with colors based on their final assignments\n",
    "    plt.scatter(X[:, 0], X[:, 1], c=colors[idx], alpha=0.6)\n",
    "\n",
    "    # Plot all centroid movements\n",
    "    for k in range(K):\n",
    "        for i in range(len(centroids_history) - 1):\n",
    "            plt.plot([centroids_history[i][k, 0], centroids_history[i + 1][k, 0]], \n",
    "                     [centroids_history[i][k, 1], centroids_history[i + 1][k, 1]], \n",
    "                     'k--')  # Draw dashed lines\n",
    "\n",
    "        # Plot the last centroid position\n",
    "        plt.scatter(centroids_history[-1][k, 0], centroids_history[-1][k, 1], marker='x', s=200, c='k', label='Final Centroids' if k == 0 else \"\")\n",
    "\n",
    "    plt.title(\"K-Means Clustering Progress\")\n",
    "    plt.xlabel(\"Feature 1\")\n",
    "    plt.ylabel(\"Feature 2\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.xlim(X[:, 0].min() - 1, X[:, 0].max() + 1)\n",
    "    plt.ylim(X[:, 1].min() - 1, X[:, 1].max() + 1)\n",
    "    plt.show()\n",
    "\n",
    "# Main function to run the K-Means algorithm\n",
    "X = load_data()                 # Step 1: Load dataset\n",
    "K = 3                           # Step 2: Set number of clusters\n",
    "initial_centroids = kMeans_init_centroids(X, K)  # Step 3: Initialize centroids\n",
    "max_iters = 10                  # Step 4: Number of iterations\n",
    "centroids, idx = run_kMeans(X, initial_centroids, max_iters)  # Step 5: Run K-Means\n",
    "print(\"Final centroids:\", centroids)  # Output the final centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "centroids.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx.shape"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
