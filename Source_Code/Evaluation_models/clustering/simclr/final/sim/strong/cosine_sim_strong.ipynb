{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy\n",
    "import random\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "from collections import Counter\n",
    "from scipy.stats import mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set seed for reproducibility\n",
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Set seed\n",
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimCLR(nn.Module):\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay,max_epochs):\n",
    "        super().__init__()\n",
    "        self.temperature = temperature\n",
    "        \n",
    "        # Load the pretrained ResNet-18 model\n",
    "        self.convnet = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "        \n",
    "        # Modify the fully connected layer\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4 * hidden_dim),  # Linear layer with 4*hidden_dim output\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * hidden_dim, 20)  # Output layer with hidden_dim output\n",
    "        )\n",
    "\n",
    "        self.optimizer = optim.AdamW(self.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "        self.lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(self.optimizer, T_max=max_epochs, eta_min=lr / 50)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convnet(x)\n",
    "\n",
    "    def info_nce_loss(self, imgs1, imgs2, device):\n",
    "\n",
    "        imgs = torch.cat((imgs1, imgs2), dim=0)  # Concatenate along the batch dimension\n",
    "        imgs = imgs.to(device)  # Move images to the device\n",
    "\n",
    "        # Encode all images\n",
    "        feats = self.forward(imgs)\n",
    "    \n",
    "        # Calculate cosine similarity\n",
    "        cos_sim = nn.functional.cosine_similarity(feats[:, None, :], feats[None, :, :], dim=-1)\n",
    "    \n",
    "        # Mask out cosine similarity to itself\n",
    "        self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "        cos_sim.masked_fill_(self_mask, -9e15)\n",
    "    \n",
    "        # Find positive example -> batch_size//2 away from the original example\n",
    "        pos_mask = self_mask.roll(shifts=cos_sim.shape[0] // 2, dims=0)\n",
    "    \n",
    "        # Normalize similarity scores by temperature\n",
    "        cos_sim = cos_sim / self.temperature\n",
    "\n",
    "        # InfoNCE loss\n",
    "        nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "        nll = nll.mean()\n",
    "\n",
    "        # Accuracy calculations\n",
    "        # Create a combination of positive and negative similarities for ranking\n",
    "        comb_sim = torch.cat([cos_sim[pos_mask][:, None],  # Positive example in first position\n",
    "                          cos_sim.masked_fill(pos_mask, -9e15)], dim=-1)\n",
    "    \n",
    "        # Sort and get the ranking position of the positive example\n",
    "        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
    "    \n",
    "        # Compute accuracy metrics\n",
    "        top1_acc = (sim_argsort == 0).float().mean()  # Top-1 accuracy\n",
    "        top5_acc = (sim_argsort < 5).float().mean()   # Top-5 accuracy\n",
    "        mean_pos = 1 + sim_argsort.float().mean()     # Mean position of the positive example\n",
    "\n",
    "        return nll, top1_acc, top5_acc, mean_pos\n",
    "\n",
    "    def train_epoch(self, train_loader, device):\n",
    "        self.train()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        for batch in tqdm(train_loader, desc=\"Training\", leave=False):\n",
    "            imgs1, imgs2, _ = batch\n",
    "            imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "        \n",
    "            self.optimizer.zero_grad()\n",
    "\n",
    "            # Calculate loss and accuracy metrics\n",
    "            loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "            loss.backward()\n",
    "            self.optimizer.step()\n",
    "            #self.lr_scheduler.step()\n",
    "\n",
    "            # Accumulate metrics\n",
    "            total_loss += loss.item()\n",
    "            total_top1_acc += top1_acc.item()\n",
    "            total_top5_acc += top5_acc.item()\n",
    "            total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(train_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(train_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(train_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos\n",
    "\n",
    "    def validate_epoch(self, val_loader, device):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(val_loader, desc=\"Validating\", leave=False):\n",
    "                imgs1, imgs2, _ = batch\n",
    "                imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "\n",
    "                # Calculate loss and accuracy metrics\n",
    "                loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "                # Accumulate metrics\n",
    "                total_loss += loss.item()\n",
    "                total_top1_acc += top1_acc.item()\n",
    "                total_top5_acc += top5_acc.item()\n",
    "                total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(val_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(val_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(val_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(val_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos\n",
    "    \n",
    "\n",
    "    def inference_epoch(self, inference_loader, device):\n",
    "        self.eval()\n",
    "        total_loss = 0.0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        with torch.no_grad():\n",
    "            for batch in tqdm(inference_loader, desc=\"Inferencing\", leave=False):\n",
    "                imgs1, imgs2, _ = batch\n",
    "                imgs1, imgs2 = imgs1.to(device), imgs2.to(device)  # Move data to device\n",
    "\n",
    "                # Calculate loss and accuracy metrics\n",
    "                loss, top1_acc, top5_acc, mean_pos = self.info_nce_loss(imgs1, imgs2, device)\n",
    "\n",
    "                # Accumulate metrics\n",
    "                total_loss += loss.item()\n",
    "                total_top1_acc += top1_acc.item()\n",
    "                total_top5_acc += top5_acc.item()\n",
    "                total_mean_pos += mean_pos.item()\n",
    "\n",
    "        avg_loss = total_loss / len(inference_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(inference_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(inference_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(inference_loader)\n",
    "\n",
    "        return avg_loss, avg_top1_acc, avg_top5_acc, avg_mean_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\k54739\\AppData\\Local\\Temp\\ipykernel_18000\\2656644616.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  simclr_model.load_state_dict(torch.load(full_model_path))\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "SimCLR(\n",
       "  (convnet): ResNet(\n",
       "    (conv1): Conv2d(3, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
       "    (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (relu): ReLU(inplace=True)\n",
       "    (maxpool): MaxPool2d(kernel_size=3, stride=2, padding=1, dilation=1, ceil_mode=False)\n",
       "    (layer1): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer2): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer3): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (layer4): Sequential(\n",
       "      (0): BasicBlock(\n",
       "        (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (downsample): Sequential(\n",
       "          (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
       "          (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        )\n",
       "      )\n",
       "      (1): BasicBlock(\n",
       "        (conv1): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "        (relu): ReLU(inplace=True)\n",
       "        (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "        (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
       "    (fc): Sequential(\n",
       "      (0): Linear(in_features=512, out_features=512, bias=True)\n",
       "      (1): ReLU(inplace=True)\n",
       "      (2): Linear(in_features=512, out_features=20, bias=True)\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_model_path =  r'C:\\Users\\k54739\\saved_model\\simclr_strongcrop_245.pth' \n",
    "simclr_model = SimCLR(hidden_dim=128, lr=5e-4, temperature=0.07, weight_decay=1e-4,max_epochs=245)\n",
    "simclr_model.load_state_dict(torch.load(full_model_path))\n",
    "simclr_model.to(device)\n",
    "simclr_model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label distribution: {'cond7_all': 472, 'sd_only': 103, 'ex': 40}\n"
     ]
    }
   ],
   "source": [
    "class LabeledImageDataset(Dataset):\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        #self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "\n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Convert to a torch tensor and add channel dimension\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        \n",
    "        # Apply resize transform\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def load_data(root_dir):\n",
    "\n",
    "    classes = ['cond7_all', 'sd_only','ex'] #full dataset\n",
    "    #classes = ['cond7_curated', 'sd_only','ex'] # curated full dataset\n",
    "\n",
    "\n",
    "    #classes = ['uncure_cond7_40', 'sdonly_40','ex'] # 40 subset # 97.5\n",
    "    #classes = ['cure_cond7_40', 'sdonly_40','ex'] # curated 40 subset\n",
    "\n",
    "    #inference\n",
    "    #classes = ['cond7_all', 'sd_plus_dsclose','ex'] #full dataset\n",
    "    #classes = ['cond7_curated', 'sd_plus_dsclose','ex'] # curated full dataset\n",
    "\n",
    "\n",
    "\n",
    "    #classes = ['uncure_cond7_40', 'sd_plus_dsclose_40','ex'] # curated 40 subset inference\n",
    "    #classes = ['cure_cond7_40', 'sd_plus_dsclose_40','ex'] # curated 40 subset inference\n",
    "\n",
    "    image_files = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(root_dir, class_name)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir) if file.endswith(('.tiff', '.tif'))]\n",
    "        image_files.extend(files)\n",
    "        labels.extend([idx] * len(files))\n",
    "    \n",
    "    # Check if the labels correctly reflect the classes\n",
    "    print(\"Label distribution:\", {classes[i]: labels.count(i) for i in range(len(classes))})\n",
    "\n",
    "    return image_files, labels\n",
    "\n",
    "\n",
    "# Directories for labeled data\n",
    "image_dir = r\"C:\\Users\\k54739\\Bibi_new_thesis\\thesis\\classification\"\n",
    "\n",
    "# Load data\n",
    "image_files, labels = load_data(image_dir)\n",
    "\n",
    "# Create the labeled datasets\n",
    "labeled_dataset = LabeledImageDataset(image_files, labels)\n",
    "\n",
    "# Define DataLoaders\n",
    "batch_size = 16\n",
    "loader_labeled = DataLoader(labeled_dataset, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 96, 96]) torch.Size([16]) torch.float32\n",
      "tensor([0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 2, 0, 2, 0, 2])\n"
     ]
    }
   ],
   "source": [
    "for anchor,label in loader_labeled:\n",
    "    print(anchor.shape, label.shape, anchor.dtype)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_data_features(model, dataloader):\n",
    "    # Prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    #network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    # Encode all images\n",
    "    feats, labels = [], []\n",
    "    for batch_imgs, batch_labels in tqdm(dataloader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        print(f\"Batch features shape: {batch_feats.shape}\")\n",
    "        print(f\"Batch labels shape: {batch_labels.shape}\")\n",
    "        \n",
    "        feats.append(batch_feats.detach().cpu())\n",
    "        labels.append(batch_labels)\n",
    "\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    \n",
    "    print(f\"Features shape after concatenation: {feats.shape}\")\n",
    "    print(f\"Labels shape after concatenation: {labels.shape}\")\n",
    "\n",
    "    return torch.utils.data.TensorDataset(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 1/39 [00:00<00:34,  1.11it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  5%|▌         | 2/39 [00:01<00:30,  1.22it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  8%|▊         | 3/39 [00:02<00:28,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 10%|█         | 4/39 [00:03<00:27,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 13%|█▎        | 5/39 [00:03<00:26,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 15%|█▌        | 6/39 [00:04<00:24,  1.33it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 18%|█▊        | 7/39 [00:05<00:23,  1.34it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 21%|██        | 8/39 [00:06<00:23,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 23%|██▎       | 9/39 [00:06<00:22,  1.32it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 26%|██▌       | 10/39 [00:07<00:22,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 28%|██▊       | 11/39 [00:08<00:22,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 31%|███       | 12/39 [00:09<00:21,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 33%|███▎      | 13/39 [00:10<00:21,  1.20it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 36%|███▌      | 14/39 [00:11<00:20,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 38%|███▊      | 15/39 [00:11<00:19,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 41%|████      | 16/39 [00:12<00:17,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 44%|████▎     | 17/39 [00:13<00:17,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 46%|████▌     | 18/39 [00:14<00:16,  1.30it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 49%|████▊     | 19/39 [00:14<00:15,  1.29it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 51%|█████▏    | 20/39 [00:15<00:14,  1.31it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 21/39 [00:16<00:14,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 56%|█████▋    | 22/39 [00:17<00:13,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 59%|█████▉    | 23/39 [00:18<00:12,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 62%|██████▏   | 24/39 [00:18<00:12,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 64%|██████▍   | 25/39 [00:19<00:11,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 67%|██████▋   | 26/39 [00:20<00:10,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 69%|██████▉   | 27/39 [00:21<00:09,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 72%|███████▏  | 28/39 [00:22<00:08,  1.23it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 74%|███████▍  | 29/39 [00:22<00:08,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 77%|███████▋  | 30/39 [00:23<00:07,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 79%|███████▉  | 31/39 [00:24<00:06,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 82%|████████▏ | 32/39 [00:25<00:05,  1.24it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 85%|████████▍ | 33/39 [00:26<00:04,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 87%|████████▋ | 34/39 [00:26<00:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 90%|████████▉ | 35/39 [00:27<00:03,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 92%|█████████▏| 36/39 [00:28<00:02,  1.25it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 95%|█████████▍| 37/39 [00:29<00:01,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 97%|█████████▋| 38/39 [00:30<00:00,  1.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 20])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 39/39 [00:30<00:00,  1.28it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([7, 20])\n",
      "Batch labels shape: torch.Size([7])\n",
      "Features shape after concatenation: torch.Size([615, 20])\n",
      "Labels shape after concatenation: torch.Size([615])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract features for train and test datasets\n",
    "feats_simclr = prepare_data_features(simclr_model, loader_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of features (for K-Means): (615, 20)\n",
      "Shape of labels: (615,)\n"
     ]
    }
   ],
   "source": [
    "# Convert features and labels to NumPy arrays\n",
    "feats_np = feats_simclr.tensors[0].numpy()  # Features in shape (60, 512)\n",
    "feats_np_norm = normalize(feats_np, axis=1)\n",
    "labels_np = feats_simclr.tensors[1].numpy()  # Corresponding labels\n",
    "\n",
    "# Check the shapes\n",
    "print(\"Shape of features (for K-Means):\", feats_np.shape)\n",
    "print(\"Shape of labels:\", labels_np.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/400, Accuracy: 0.7073\n",
      "Run 2/400, Accuracy: 0.7171\n",
      "Run 3/400, Accuracy: 0.6211\n",
      "Run 4/400, Accuracy: 0.6033\n",
      "Run 5/400, Accuracy: 0.6423\n",
      "Run 6/400, Accuracy: 0.6211\n",
      "Run 7/400, Accuracy: 0.6179\n",
      "Run 8/400, Accuracy: 0.6423\n",
      "Run 9/400, Accuracy: 0.6455\n",
      "Run 10/400, Accuracy: 0.6244\n",
      "Run 11/400, Accuracy: 0.6407\n",
      "Run 12/400, Accuracy: 0.5854\n",
      "Run 13/400, Accuracy: 0.6520\n",
      "Run 14/400, Accuracy: 0.6016\n",
      "Run 15/400, Accuracy: 0.5984\n",
      "Run 16/400, Accuracy: 0.5854\n",
      "Run 17/400, Accuracy: 0.6423\n",
      "Run 18/400, Accuracy: 0.5447\n",
      "Run 19/400, Accuracy: 0.6049\n",
      "Run 20/400, Accuracy: 0.6439\n",
      "Run 21/400, Accuracy: 0.5447\n",
      "Run 22/400, Accuracy: 0.7187\n",
      "Run 23/400, Accuracy: 0.4407\n",
      "Run 24/400, Accuracy: 0.6472\n",
      "Run 25/400, Accuracy: 0.5919\n",
      "Run 26/400, Accuracy: 0.6423\n",
      "Run 27/400, Accuracy: 0.7252\n",
      "Run 28/400, Accuracy: 0.5967\n",
      "Run 29/400, Accuracy: 0.5447\n",
      "Run 30/400, Accuracy: 0.4667\n",
      "Run 31/400, Accuracy: 0.6244\n",
      "Run 32/400, Accuracy: 0.5854\n",
      "Run 33/400, Accuracy: 0.5382\n",
      "Run 34/400, Accuracy: 0.5447\n",
      "Run 35/400, Accuracy: 0.6016\n",
      "Run 36/400, Accuracy: 0.5057\n",
      "Run 37/400, Accuracy: 0.5902\n",
      "Run 38/400, Accuracy: 0.7171\n",
      "Run 39/400, Accuracy: 0.4780\n",
      "Run 40/400, Accuracy: 0.6228\n",
      "Run 41/400, Accuracy: 0.5285\n",
      "Run 42/400, Accuracy: 0.7268\n",
      "Run 43/400, Accuracy: 0.5902\n",
      "Run 44/400, Accuracy: 0.6423\n",
      "Run 45/400, Accuracy: 0.5415\n",
      "Run 46/400, Accuracy: 0.6276\n",
      "Run 47/400, Accuracy: 0.5447\n",
      "Run 48/400, Accuracy: 0.6000\n",
      "Run 49/400, Accuracy: 0.6504\n",
      "Run 50/400, Accuracy: 0.5171\n",
      "Run 51/400, Accuracy: 0.5854\n",
      "Run 52/400, Accuracy: 0.6423\n",
      "Run 53/400, Accuracy: 0.5122\n",
      "Run 54/400, Accuracy: 0.7252\n",
      "Run 55/400, Accuracy: 0.7268\n",
      "Run 56/400, Accuracy: 0.6098\n",
      "Run 57/400, Accuracy: 0.4943\n",
      "Run 58/400, Accuracy: 0.6472\n",
      "Run 59/400, Accuracy: 0.5805\n",
      "Run 60/400, Accuracy: 0.5398\n",
      "Run 61/400, Accuracy: 0.5057\n",
      "Run 62/400, Accuracy: 0.5854\n",
      "Run 63/400, Accuracy: 0.5447\n",
      "Run 64/400, Accuracy: 0.5398\n",
      "Run 65/400, Accuracy: 0.6000\n",
      "Run 66/400, Accuracy: 0.6000\n",
      "Run 67/400, Accuracy: 0.5447\n",
      "Run 68/400, Accuracy: 0.6049\n",
      "Run 69/400, Accuracy: 0.5447\n",
      "Run 70/400, Accuracy: 0.6098\n",
      "Run 71/400, Accuracy: 0.6423\n",
      "Run 72/400, Accuracy: 0.6602\n",
      "Run 73/400, Accuracy: 0.5496\n",
      "Run 74/400, Accuracy: 0.6455\n",
      "Run 75/400, Accuracy: 0.7073\n",
      "Run 76/400, Accuracy: 0.6000\n",
      "Run 77/400, Accuracy: 0.5122\n",
      "Run 78/400, Accuracy: 0.6423\n",
      "Run 79/400, Accuracy: 0.5496\n",
      "Run 80/400, Accuracy: 0.4114\n",
      "Run 81/400, Accuracy: 0.5902\n",
      "Run 82/400, Accuracy: 0.5252\n",
      "Run 83/400, Accuracy: 0.5902\n",
      "Run 84/400, Accuracy: 0.6439\n",
      "Run 85/400, Accuracy: 0.6146\n",
      "Run 86/400, Accuracy: 0.5285\n",
      "Run 87/400, Accuracy: 0.6033\n",
      "Run 88/400, Accuracy: 0.6423\n",
      "Run 89/400, Accuracy: 0.6228\n",
      "Run 90/400, Accuracy: 0.7236\n",
      "Run 91/400, Accuracy: 0.5447\n",
      "Run 92/400, Accuracy: 0.5626\n",
      "Run 93/400, Accuracy: 0.6797\n",
      "Run 94/400, Accuracy: 0.5902\n",
      "Run 95/400, Accuracy: 0.6098\n",
      "Run 96/400, Accuracy: 0.5447\n",
      "Run 97/400, Accuracy: 0.6016\n",
      "Run 98/400, Accuracy: 0.6504\n",
      "Run 99/400, Accuracy: 0.5268\n",
      "Run 100/400, Accuracy: 0.6488\n",
      "Run 101/400, Accuracy: 0.5463\n",
      "Run 102/400, Accuracy: 0.4764\n",
      "Run 103/400, Accuracy: 0.6423\n",
      "Run 104/400, Accuracy: 0.5398\n",
      "Run 105/400, Accuracy: 0.5398\n",
      "Run 106/400, Accuracy: 0.6423\n",
      "Run 107/400, Accuracy: 0.4748\n",
      "Run 108/400, Accuracy: 0.5854\n",
      "Run 109/400, Accuracy: 0.5805\n",
      "Run 110/400, Accuracy: 0.6488\n",
      "Run 111/400, Accuracy: 0.5366\n",
      "Run 112/400, Accuracy: 0.6829\n",
      "Run 113/400, Accuracy: 0.5252\n",
      "Run 114/400, Accuracy: 0.5447\n",
      "Run 115/400, Accuracy: 0.6211\n",
      "Run 116/400, Accuracy: 0.6423\n",
      "Run 117/400, Accuracy: 0.4862\n",
      "Run 118/400, Accuracy: 0.5252\n",
      "Run 119/400, Accuracy: 0.6016\n",
      "Run 120/400, Accuracy: 0.6325\n",
      "Run 121/400, Accuracy: 0.6000\n",
      "Run 122/400, Accuracy: 0.6211\n",
      "Run 123/400, Accuracy: 0.5984\n",
      "Run 124/400, Accuracy: 0.6634\n",
      "Run 125/400, Accuracy: 0.6130\n",
      "Run 126/400, Accuracy: 0.6211\n",
      "Run 127/400, Accuracy: 0.6098\n",
      "Run 128/400, Accuracy: 0.7171\n",
      "Run 129/400, Accuracy: 0.5463\n",
      "Run 130/400, Accuracy: 0.6423\n",
      "Run 131/400, Accuracy: 0.5317\n",
      "Run 132/400, Accuracy: 0.6179\n",
      "Run 133/400, Accuracy: 0.6911\n",
      "Run 134/400, Accuracy: 0.5984\n",
      "Run 135/400, Accuracy: 0.6504\n",
      "Run 136/400, Accuracy: 0.6423\n",
      "Run 137/400, Accuracy: 0.6423\n",
      "Run 138/400, Accuracy: 0.6423\n",
      "Run 139/400, Accuracy: 0.5301\n",
      "Run 140/400, Accuracy: 0.6000\n",
      "Run 141/400, Accuracy: 0.5463\n",
      "Run 142/400, Accuracy: 0.5902\n",
      "Run 143/400, Accuracy: 0.6065\n",
      "Run 144/400, Accuracy: 0.4650\n",
      "Run 145/400, Accuracy: 0.6146\n",
      "Run 146/400, Accuracy: 0.6016\n",
      "Run 147/400, Accuracy: 0.5447\n",
      "Run 148/400, Accuracy: 0.4927\n",
      "Run 149/400, Accuracy: 0.6423\n",
      "Run 150/400, Accuracy: 0.6000\n",
      "Run 151/400, Accuracy: 0.5154\n",
      "Run 152/400, Accuracy: 0.6423\n",
      "Run 153/400, Accuracy: 0.6602\n",
      "Run 154/400, Accuracy: 0.6423\n",
      "Run 155/400, Accuracy: 0.7106\n",
      "Run 156/400, Accuracy: 0.5382\n",
      "Run 157/400, Accuracy: 0.6423\n",
      "Run 158/400, Accuracy: 0.7268\n",
      "Run 159/400, Accuracy: 0.7187\n",
      "Run 160/400, Accuracy: 0.4748\n",
      "Run 161/400, Accuracy: 0.5301\n",
      "Run 162/400, Accuracy: 0.6163\n",
      "Run 163/400, Accuracy: 0.5154\n",
      "Run 164/400, Accuracy: 0.6455\n",
      "Run 165/400, Accuracy: 0.5463\n",
      "Run 166/400, Accuracy: 0.6455\n",
      "Run 167/400, Accuracy: 0.6228\n",
      "Run 168/400, Accuracy: 0.5870\n",
      "Run 169/400, Accuracy: 0.6423\n",
      "Run 170/400, Accuracy: 0.4748\n",
      "Run 171/400, Accuracy: 0.6423\n",
      "Run 172/400, Accuracy: 0.5447\n",
      "Run 173/400, Accuracy: 0.5854\n",
      "Run 174/400, Accuracy: 0.5447\n",
      "Run 175/400, Accuracy: 0.6423\n",
      "Run 176/400, Accuracy: 0.6000\n",
      "Run 177/400, Accuracy: 0.7268\n",
      "Run 178/400, Accuracy: 0.5447\n",
      "Run 179/400, Accuracy: 0.6423\n",
      "Run 180/400, Accuracy: 0.6423\n",
      "Run 181/400, Accuracy: 0.5854\n",
      "Run 182/400, Accuracy: 0.5967\n",
      "Run 183/400, Accuracy: 0.5447\n",
      "Run 184/400, Accuracy: 0.5870\n",
      "Run 185/400, Accuracy: 0.5870\n",
      "Run 186/400, Accuracy: 0.6423\n",
      "Run 187/400, Accuracy: 0.6049\n",
      "Run 188/400, Accuracy: 0.5447\n",
      "Run 189/400, Accuracy: 0.5984\n",
      "Run 190/400, Accuracy: 0.6423\n",
      "Run 191/400, Accuracy: 0.5854\n",
      "Run 192/400, Accuracy: 0.5431\n",
      "Run 193/400, Accuracy: 0.7252\n",
      "Run 194/400, Accuracy: 0.6894\n",
      "Run 195/400, Accuracy: 0.7268\n",
      "Run 196/400, Accuracy: 0.6423\n",
      "Run 197/400, Accuracy: 0.6423\n",
      "Run 198/400, Accuracy: 0.5496\n",
      "Run 199/400, Accuracy: 0.5577\n",
      "Run 200/400, Accuracy: 0.6211\n",
      "Run 201/400, Accuracy: 0.5854\n",
      "Run 202/400, Accuracy: 0.6423\n",
      "Run 203/400, Accuracy: 0.6894\n",
      "Run 204/400, Accuracy: 0.6423\n",
      "Run 205/400, Accuracy: 0.5902\n",
      "Run 206/400, Accuracy: 0.4715\n",
      "Run 207/400, Accuracy: 0.6211\n",
      "Run 208/400, Accuracy: 0.6000\n",
      "Run 209/400, Accuracy: 0.6016\n",
      "Run 210/400, Accuracy: 0.5447\n",
      "Run 211/400, Accuracy: 0.5984\n",
      "Run 212/400, Accuracy: 0.5415\n",
      "Run 213/400, Accuracy: 0.6098\n",
      "Run 214/400, Accuracy: 0.6033\n",
      "Run 215/400, Accuracy: 0.5854\n",
      "Run 216/400, Accuracy: 0.5463\n",
      "Run 217/400, Accuracy: 0.6423\n",
      "Run 218/400, Accuracy: 0.6504\n",
      "Run 219/400, Accuracy: 0.7187\n",
      "Run 220/400, Accuracy: 0.6325\n",
      "Run 221/400, Accuracy: 0.6602\n",
      "Run 222/400, Accuracy: 0.5902\n",
      "Run 223/400, Accuracy: 0.6130\n",
      "Run 224/400, Accuracy: 0.5447\n",
      "Run 225/400, Accuracy: 0.7187\n",
      "Run 226/400, Accuracy: 0.5447\n",
      "Run 227/400, Accuracy: 0.5447\n",
      "Run 228/400, Accuracy: 0.5463\n",
      "Run 229/400, Accuracy: 0.5935\n",
      "Run 230/400, Accuracy: 0.6244\n",
      "Run 231/400, Accuracy: 0.6114\n",
      "Run 232/400, Accuracy: 0.7252\n",
      "Run 233/400, Accuracy: 0.6260\n",
      "Run 234/400, Accuracy: 0.5447\n",
      "Run 235/400, Accuracy: 0.6862\n",
      "Run 236/400, Accuracy: 0.7268\n",
      "Run 237/400, Accuracy: 0.5398\n",
      "Run 238/400, Accuracy: 0.6423\n",
      "Run 239/400, Accuracy: 0.5463\n",
      "Run 240/400, Accuracy: 0.6423\n",
      "Run 241/400, Accuracy: 0.7268\n",
      "Run 242/400, Accuracy: 0.7268\n",
      "Run 243/400, Accuracy: 0.6423\n",
      "Run 244/400, Accuracy: 0.6423\n",
      "Run 245/400, Accuracy: 0.6439\n",
      "Run 246/400, Accuracy: 0.5902\n",
      "Run 247/400, Accuracy: 0.5447\n",
      "Run 248/400, Accuracy: 0.6455\n",
      "Run 249/400, Accuracy: 0.5984\n",
      "Run 250/400, Accuracy: 0.6423\n",
      "Run 251/400, Accuracy: 0.5854\n",
      "Run 252/400, Accuracy: 0.5301\n",
      "Run 253/400, Accuracy: 0.7252\n",
      "Run 254/400, Accuracy: 0.5447\n",
      "Run 255/400, Accuracy: 0.5463\n",
      "Run 256/400, Accuracy: 0.5854\n",
      "Run 257/400, Accuracy: 0.6114\n",
      "Run 258/400, Accuracy: 0.6130\n",
      "Run 259/400, Accuracy: 0.6602\n",
      "Run 260/400, Accuracy: 0.5854\n",
      "Run 261/400, Accuracy: 0.5415\n",
      "Run 262/400, Accuracy: 0.6179\n",
      "Run 263/400, Accuracy: 0.5854\n",
      "Run 264/400, Accuracy: 0.4569\n",
      "Run 265/400, Accuracy: 0.5772\n",
      "Run 266/400, Accuracy: 0.6423\n",
      "Run 267/400, Accuracy: 0.6114\n",
      "Run 268/400, Accuracy: 0.5301\n",
      "Run 269/400, Accuracy: 0.5382\n",
      "Run 270/400, Accuracy: 0.6016\n",
      "Run 271/400, Accuracy: 0.6000\n",
      "Run 272/400, Accuracy: 0.6423\n",
      "Run 273/400, Accuracy: 0.5447\n",
      "Run 274/400, Accuracy: 0.7252\n",
      "Run 275/400, Accuracy: 0.6423\n",
      "Run 276/400, Accuracy: 0.6439\n",
      "Run 277/400, Accuracy: 0.7252\n",
      "Run 278/400, Accuracy: 0.5902\n",
      "Run 279/400, Accuracy: 0.6163\n",
      "Run 280/400, Accuracy: 0.6033\n",
      "Run 281/400, Accuracy: 0.5610\n",
      "Run 282/400, Accuracy: 0.5821\n",
      "Run 283/400, Accuracy: 0.6098\n",
      "Run 284/400, Accuracy: 0.6439\n",
      "Run 285/400, Accuracy: 0.4878\n",
      "Run 286/400, Accuracy: 0.6439\n",
      "Run 287/400, Accuracy: 0.6829\n",
      "Run 288/400, Accuracy: 0.5415\n",
      "Run 289/400, Accuracy: 0.6423\n",
      "Run 290/400, Accuracy: 0.6423\n",
      "Run 291/400, Accuracy: 0.5447\n",
      "Run 292/400, Accuracy: 0.6894\n",
      "Run 293/400, Accuracy: 0.6309\n",
      "Run 294/400, Accuracy: 0.6423\n",
      "Run 295/400, Accuracy: 0.5252\n",
      "Run 296/400, Accuracy: 0.4553\n",
      "Run 297/400, Accuracy: 0.5447\n",
      "Run 298/400, Accuracy: 0.5902\n",
      "Run 299/400, Accuracy: 0.4748\n",
      "Run 300/400, Accuracy: 0.5854\n",
      "Run 301/400, Accuracy: 0.6927\n",
      "Run 302/400, Accuracy: 0.6423\n",
      "Run 303/400, Accuracy: 0.6000\n",
      "Run 304/400, Accuracy: 0.6098\n",
      "Run 305/400, Accuracy: 0.5984\n",
      "Run 306/400, Accuracy: 0.5415\n",
      "Run 307/400, Accuracy: 0.7252\n",
      "Run 308/400, Accuracy: 0.5333\n",
      "Run 309/400, Accuracy: 0.5902\n",
      "Run 310/400, Accuracy: 0.6423\n",
      "Run 311/400, Accuracy: 0.6000\n",
      "Run 312/400, Accuracy: 0.5301\n",
      "Run 313/400, Accuracy: 0.6423\n",
      "Run 314/400, Accuracy: 0.6260\n",
      "Run 315/400, Accuracy: 0.5902\n",
      "Run 316/400, Accuracy: 0.5447\n",
      "Run 317/400, Accuracy: 0.6455\n",
      "Run 318/400, Accuracy: 0.5902\n",
      "Run 319/400, Accuracy: 0.6098\n",
      "Run 320/400, Accuracy: 0.6098\n",
      "Run 321/400, Accuracy: 0.5854\n",
      "Run 322/400, Accuracy: 0.6260\n",
      "Run 323/400, Accuracy: 0.5398\n",
      "Run 324/400, Accuracy: 0.6033\n",
      "Run 325/400, Accuracy: 0.6033\n",
      "Run 326/400, Accuracy: 0.5252\n",
      "Run 327/400, Accuracy: 0.5545\n",
      "Run 328/400, Accuracy: 0.4862\n",
      "Run 329/400, Accuracy: 0.5463\n",
      "Run 330/400, Accuracy: 0.6748\n",
      "Run 331/400, Accuracy: 0.6423\n",
      "Run 332/400, Accuracy: 0.6358\n",
      "Run 333/400, Accuracy: 0.5984\n",
      "Run 334/400, Accuracy: 0.5463\n",
      "Run 335/400, Accuracy: 0.5902\n",
      "Run 336/400, Accuracy: 0.6179\n",
      "Run 337/400, Accuracy: 0.5447\n",
      "Run 338/400, Accuracy: 0.6228\n",
      "Run 339/400, Accuracy: 0.5740\n",
      "Run 340/400, Accuracy: 0.6000\n",
      "Run 341/400, Accuracy: 0.5854\n",
      "Run 342/400, Accuracy: 0.5252\n",
      "Run 343/400, Accuracy: 0.6423\n",
      "Run 344/400, Accuracy: 0.6423\n",
      "Run 345/400, Accuracy: 0.5902\n",
      "Run 346/400, Accuracy: 0.6846\n",
      "Run 347/400, Accuracy: 0.5772\n",
      "Run 348/400, Accuracy: 0.6423\n",
      "Run 349/400, Accuracy: 0.7252\n",
      "Run 350/400, Accuracy: 0.5854\n",
      "Run 351/400, Accuracy: 0.6049\n",
      "Run 352/400, Accuracy: 0.6488\n",
      "Run 353/400, Accuracy: 0.6423\n",
      "Run 354/400, Accuracy: 0.5447\n",
      "Run 355/400, Accuracy: 0.6423\n",
      "Run 356/400, Accuracy: 0.5415\n",
      "Run 357/400, Accuracy: 0.5902\n",
      "Run 358/400, Accuracy: 0.6244\n",
      "Run 359/400, Accuracy: 0.5902\n",
      "Run 360/400, Accuracy: 0.6423\n",
      "Run 361/400, Accuracy: 0.5854\n",
      "Run 362/400, Accuracy: 0.7187\n",
      "Run 363/400, Accuracy: 0.5951\n",
      "Run 364/400, Accuracy: 0.5870\n",
      "Run 365/400, Accuracy: 0.5415\n",
      "Run 366/400, Accuracy: 0.5902\n",
      "Run 367/400, Accuracy: 0.6033\n",
      "Run 368/400, Accuracy: 0.6000\n",
      "Run 369/400, Accuracy: 0.5740\n",
      "Run 370/400, Accuracy: 0.6016\n",
      "Run 371/400, Accuracy: 0.6049\n",
      "Run 372/400, Accuracy: 0.6000\n",
      "Run 373/400, Accuracy: 0.5902\n",
      "Run 374/400, Accuracy: 0.6016\n",
      "Run 375/400, Accuracy: 0.6098\n",
      "Run 376/400, Accuracy: 0.4732\n",
      "Run 377/400, Accuracy: 0.6260\n",
      "Run 378/400, Accuracy: 0.5854\n",
      "Run 379/400, Accuracy: 0.5951\n",
      "Run 380/400, Accuracy: 0.5463\n",
      "Run 381/400, Accuracy: 0.6000\n",
      "Run 382/400, Accuracy: 0.5447\n",
      "Run 383/400, Accuracy: 0.7187\n",
      "Run 384/400, Accuracy: 0.6504\n",
      "Run 385/400, Accuracy: 0.5106\n",
      "Run 386/400, Accuracy: 0.6000\n",
      "Run 387/400, Accuracy: 0.6016\n",
      "Run 388/400, Accuracy: 0.5837\n",
      "Run 389/400, Accuracy: 0.4618\n",
      "Run 390/400, Accuracy: 0.6585\n",
      "Run 391/400, Accuracy: 0.5447\n",
      "Run 392/400, Accuracy: 0.5447\n",
      "Run 393/400, Accuracy: 0.5333\n",
      "Run 394/400, Accuracy: 0.6423\n",
      "Run 395/400, Accuracy: 0.6407\n",
      "Run 396/400, Accuracy: 0.6244\n",
      "Run 397/400, Accuracy: 0.5675\n",
      "Run 398/400, Accuracy: 0.6049\n",
      "Run 399/400, Accuracy: 0.5854\n",
      "Run 400/400, Accuracy: 0.5984\n",
      "\n",
      "=== Final Results ===\n",
      "Max Accuracy: 0.7268\n",
      "Cluster Descriptions:\n",
      "Cluster 0 has true labels: Counter({0: 97, 2: 38, 1: 1})\n",
      "Cluster 1 has true labels: Counter({0: 307, 2: 1})\n",
      "Cluster 2 has true labels: Counter({1: 102, 0: 68, 2: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Functions: K-Means initialization, assignment, and computation\n",
    "def kMeans_init_centroids(X, K):\n",
    "    \"\"\"Initialize centroids randomly from the dataset.\"\"\"\n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    centroids = X[randidx[:K]]\n",
    "    return centroids\n",
    "\n",
    "def find_closest_centroids(X, centroids):\n",
    "    \"\"\"Assign data points to closest centroids using cosine similarity.\"\"\"\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        similarities = np.dot(centroids, X[i])  # Cosine similarity\n",
    "        idx[i] = np.argmax(similarities)  # Assign to the most similar centroid\n",
    "    return idx\n",
    "\n",
    "def compute_centroids(X, idx, K):\n",
    "    \"\"\"Compute new centroids based on assigned clusters.\"\"\"\n",
    "    centroids = np.zeros((K, X.shape[1]))\n",
    "    for k in range(K):\n",
    "        points = X[idx == k]\n",
    "        if len(points) > 0:\n",
    "            centroids[k] = np.mean(points, axis=0)\n",
    "    centroids = normalize(centroids, axis=1)  # Normalize centroids\n",
    "    return centroids\n",
    "\n",
    "def run_kMeans(X, initial_centroids, max_iters=10):\n",
    "    \"\"\"Run the K-Means algorithm.\"\"\"\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for _ in range(max_iters):\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "    return centroids, idx\n",
    "\n",
    "# Accuracy calculation and main experiment loop\n",
    "def calculate_accuracy(idx, labels_np, K=3):\n",
    "    \"\"\"Calculate accuracy for a given set of cluster assignments.\"\"\"\n",
    "    total_samples = len(labels_np)\n",
    "    cluster_label_counts = {}\n",
    "    label_to_cluster = {}\n",
    "    correctly_classified = 0\n",
    "\n",
    "    # Count true labels in each cluster\n",
    "    for cluster in range(K):\n",
    "        cluster_indices = np.where(idx == cluster)[0]\n",
    "        cluster_labels = labels_np[cluster_indices]\n",
    "        label_counts = Counter(cluster_labels)\n",
    "        cluster_label_counts[cluster] = label_counts\n",
    "    \n",
    "    # Assign each label to the cluster where it is most common\n",
    "    for label in range(3):  # Assuming 3 classes: 0, 1, 2\n",
    "        max_count = 0\n",
    "        assigned_cluster = None\n",
    "        for cluster, label_counts in cluster_label_counts.items():\n",
    "            if label_counts[label] > max_count:\n",
    "                max_count = label_counts[label]\n",
    "                assigned_cluster = cluster\n",
    "        if assigned_cluster is not None:\n",
    "            label_to_cluster[label] = assigned_cluster\n",
    "            correctly_classified += max_count\n",
    "\n",
    "    accuracy = correctly_classified / total_samples\n",
    "    return accuracy, cluster_label_counts \n",
    "\n",
    "'''# Accuracy calculation and main experiment loop\n",
    "def calculate_accuracy(idx, labels_np, K=3):\n",
    "    \"\"\"Calculate accuracy for a given set of cluster assignments.\"\"\"\n",
    "    total_samples = len(labels_np)\n",
    "    cluster_label_counts = {}\n",
    "    label_to_cluster = {}\n",
    "    correctly_classified = 0\n",
    "\n",
    "    # Count true labels in each cluster\n",
    "    for cluster in range(K):\n",
    "        cluster_indices = np.where(idx == cluster)[0]\n",
    "        cluster_labels = labels_np[cluster_indices]\n",
    "        label_counts = Counter(cluster_labels)\n",
    "        cluster_label_counts[cluster] = label_counts\n",
    "    \n",
    "    # Track clusters already assigned to labels\n",
    "    assigned_clusters = set()\n",
    "\n",
    "    # Assign each label to the cluster where it is most common, respecting the rule\n",
    "    for label in range(3):  # Assuming 3 classes: 0, 1, 2\n",
    "        max_count = 0\n",
    "        assigned_cluster = None\n",
    "        for cluster, label_counts in cluster_label_counts.items():\n",
    "            # Skip clusters already assigned to another label\n",
    "            if cluster in assigned_clusters:\n",
    "                #continue\n",
    "            if label_counts[label] > max_count:\n",
    "                max_count = label_counts[label]\n",
    "                assigned_cluster = cluster\n",
    "        # Assign this label to the cluster and mark the cluster as used\n",
    "        if assigned_cluster is not None:\n",
    "            label_to_cluster[label] = assigned_cluster\n",
    "            assigned_clusters.add(assigned_cluster)\n",
    "            correctly_classified += max_count\n",
    "\n",
    "    accuracy = correctly_classified / total_samples\n",
    "    return accuracy, cluster_label_counts'''\n",
    "\n",
    "def main_kMeans_experiment(X, labels_np, K=3, num_runs=100, max_iters=50):\n",
    "    accuracies = []\n",
    "    best_accuracy = 0\n",
    "    best_cluster_counts = None\n",
    "    best_centroids = None\n",
    "    best_idx = None\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        # Initialize centroids randomly\n",
    "        initial_centroids = kMeans_init_centroids(X, K)\n",
    "        \n",
    "        # Run K-Means\n",
    "        centroids, idx = run_kMeans(X, initial_centroids, max_iters)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy, cluster_counts = calculate_accuracy(idx, labels_np, K)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        # Track the best run\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_cluster_counts = cluster_counts\n",
    "            best_centroids = centroids\n",
    "            best_idx = idx\n",
    "        \n",
    "        print(f\"Run {run + 1}/{num_runs}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Print final results\n",
    "    print(\"\\n=== Final Results ===\")\n",
    "    print(f\"Max Accuracy: {best_accuracy:.4f}\")\n",
    "    print(\"Cluster Descriptions:\")\n",
    "    for cluster, counts in best_cluster_counts.items():\n",
    "        print(f\"Cluster {cluster} has true labels: {counts}\")\n",
    "    \n",
    "    # Return the best centroids and idx along with accuracy\n",
    "    return best_accuracy, best_centroids, best_idx, best_cluster_counts\n",
    "\n",
    "\n",
    "'''\n",
    "# Main loop for running K-Means multiple times\n",
    "def main_kMeans_experiment(X, labels_np, K=3, num_runs=100, max_iters=50):\n",
    "    accuracies = []\n",
    "    best_accuracy = 0\n",
    "    best_cluster_counts = None\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        # Initialize centroids randomly\n",
    "        initial_centroids = kMeans_init_centroids(X, K)\n",
    "        \n",
    "        # Run K-Means\n",
    "        centroids, idx = run_kMeans(X, initial_centroids, max_iters)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy, cluster_counts = calculate_accuracy(idx, labels_np, K)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        # Track the best run\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_cluster_counts = cluster_counts\n",
    "        \n",
    "        print(f\"Run {run + 1}/{num_runs}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Print final results\n",
    "    print(\"\\n=== Final Results ===\")\n",
    "    print(f\"Max Accuracy: {best_accuracy:.4f}\")\n",
    "    print(\"Cluster Descriptions:\")\n",
    "    for cluster, counts in best_cluster_counts.items():\n",
    "        print(f\"Cluster {cluster} has true labels: {counts}\")'''\n",
    "\n",
    "    \n",
    "\n",
    "# Example usage\n",
    "# Assuming `feats_np_norm` is your normalized feature matrix and `labels_np` contains true labels\n",
    "K = 3  # Number of clusters\n",
    "num_runs = 400  # Number of K-Means runs\n",
    "max_iters = 50  # Maximum iterations per run\n",
    "\n",
    "best_accuracy, best_centroids, best_idx, best_cluster_counts = main_kMeans_experiment(feats_np_norm, labels_np, K, num_runs, max_iters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "414"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "374+40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6731707317073171"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "414/615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7268292682926829"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "447/615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "89"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "21+31+37"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7416666666666667"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "89/120"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "285"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "216+69"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "93+104+33"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "93+132+6"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "231/423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run 1/400, Accuracy: 0.6423\n",
      "Run 2/400, Accuracy: 0.5919\n",
      "Run 3/400, Accuracy: 0.6244\n",
      "Run 4/400, Accuracy: 0.5886\n",
      "Run 5/400, Accuracy: 0.6098\n",
      "Run 6/400, Accuracy: 0.6098\n",
      "Run 7/400, Accuracy: 0.6000\n",
      "Run 8/400, Accuracy: 0.7252\n",
      "Run 9/400, Accuracy: 0.3837\n",
      "Run 10/400, Accuracy: 0.5171\n",
      "Run 11/400, Accuracy: 0.6423\n",
      "Run 12/400, Accuracy: 0.6602\n",
      "Run 13/400, Accuracy: 0.5317\n",
      "Run 14/400, Accuracy: 0.5171\n",
      "Run 15/400, Accuracy: 0.5122\n",
      "Run 16/400, Accuracy: 0.6098\n",
      "Run 17/400, Accuracy: 0.5854\n",
      "Run 18/400, Accuracy: 0.4602\n",
      "Run 19/400, Accuracy: 0.6423\n",
      "Run 20/400, Accuracy: 0.5268\n",
      "Run 21/400, Accuracy: 0.5171\n",
      "Run 22/400, Accuracy: 0.5902\n",
      "Run 23/400, Accuracy: 0.5854\n",
      "Run 24/400, Accuracy: 0.5935\n",
      "Run 25/400, Accuracy: 0.5967\n",
      "Run 26/400, Accuracy: 0.6423\n",
      "Run 27/400, Accuracy: 0.6033\n",
      "Run 28/400, Accuracy: 0.7089\n",
      "Run 29/400, Accuracy: 0.6000\n",
      "Run 30/400, Accuracy: 0.5187\n",
      "Run 31/400, Accuracy: 0.5919\n",
      "Run 32/400, Accuracy: 0.5122\n",
      "Run 33/400, Accuracy: 0.5854\n",
      "Run 34/400, Accuracy: 0.6016\n",
      "Run 35/400, Accuracy: 0.4098\n",
      "Run 36/400, Accuracy: 0.4195\n",
      "Run 37/400, Accuracy: 0.7171\n",
      "Run 38/400, Accuracy: 0.5447\n",
      "Run 39/400, Accuracy: 0.5854\n",
      "Run 40/400, Accuracy: 0.6000\n",
      "Run 41/400, Accuracy: 0.5171\n",
      "Run 42/400, Accuracy: 0.6016\n",
      "Run 43/400, Accuracy: 0.5854\n",
      "Run 44/400, Accuracy: 0.6000\n",
      "Run 45/400, Accuracy: 0.5138\n",
      "Run 46/400, Accuracy: 0.6423\n",
      "Run 47/400, Accuracy: 0.5171\n",
      "Run 48/400, Accuracy: 0.4585\n",
      "Run 49/400, Accuracy: 0.6260\n",
      "Run 50/400, Accuracy: 0.5772\n",
      "Run 51/400, Accuracy: 0.5854\n",
      "Run 52/400, Accuracy: 0.6504\n",
      "Run 53/400, Accuracy: 0.6033\n",
      "Run 54/400, Accuracy: 0.6000\n",
      "Run 55/400, Accuracy: 0.5984\n",
      "Run 56/400, Accuracy: 0.5902\n",
      "Run 57/400, Accuracy: 0.4114\n",
      "Run 58/400, Accuracy: 0.4650\n",
      "Run 59/400, Accuracy: 0.5854\n",
      "Run 60/400, Accuracy: 0.6423\n",
      "Run 61/400, Accuracy: 0.5951\n",
      "Run 62/400, Accuracy: 0.5171\n",
      "Run 63/400, Accuracy: 0.6000\n",
      "Run 64/400, Accuracy: 0.5122\n",
      "Run 65/400, Accuracy: 0.5171\n",
      "Run 66/400, Accuracy: 0.5203\n",
      "Run 67/400, Accuracy: 0.6602\n",
      "Run 68/400, Accuracy: 0.5984\n",
      "Run 69/400, Accuracy: 0.6423\n",
      "Run 70/400, Accuracy: 0.4098\n",
      "Run 71/400, Accuracy: 0.6065\n",
      "Run 72/400, Accuracy: 0.6049\n",
      "Run 73/400, Accuracy: 0.4602\n",
      "Run 74/400, Accuracy: 0.5220\n",
      "Run 75/400, Accuracy: 0.5854\n",
      "Run 76/400, Accuracy: 0.6179\n",
      "Run 77/400, Accuracy: 0.3984\n",
      "Run 78/400, Accuracy: 0.5398\n",
      "Run 79/400, Accuracy: 0.5463\n",
      "Run 80/400, Accuracy: 0.6000\n",
      "Run 81/400, Accuracy: 0.7187\n",
      "Run 82/400, Accuracy: 0.6488\n",
      "Run 83/400, Accuracy: 0.5187\n",
      "Run 84/400, Accuracy: 0.6455\n",
      "Run 85/400, Accuracy: 0.6423\n",
      "Run 86/400, Accuracy: 0.5528\n",
      "Run 87/400, Accuracy: 0.7252\n",
      "Run 88/400, Accuracy: 0.6423\n",
      "Run 89/400, Accuracy: 0.5220\n",
      "Run 90/400, Accuracy: 0.6423\n",
      "Run 91/400, Accuracy: 0.6098\n",
      "Run 92/400, Accuracy: 0.6488\n",
      "Run 93/400, Accuracy: 0.5187\n",
      "Run 94/400, Accuracy: 0.5220\n",
      "Run 95/400, Accuracy: 0.6098\n",
      "Run 96/400, Accuracy: 0.5935\n",
      "Run 97/400, Accuracy: 0.6276\n",
      "Run 98/400, Accuracy: 0.6179\n",
      "Run 99/400, Accuracy: 0.6488\n",
      "Run 100/400, Accuracy: 0.6407\n",
      "Run 101/400, Accuracy: 0.6000\n",
      "Run 102/400, Accuracy: 0.6000\n",
      "Run 103/400, Accuracy: 0.6000\n",
      "Run 104/400, Accuracy: 0.6504\n",
      "Run 105/400, Accuracy: 0.6423\n",
      "Run 106/400, Accuracy: 0.4098\n",
      "Run 107/400, Accuracy: 0.5902\n",
      "Run 108/400, Accuracy: 0.5398\n",
      "Run 109/400, Accuracy: 0.5902\n",
      "Run 110/400, Accuracy: 0.4650\n",
      "Run 111/400, Accuracy: 0.6504\n",
      "Run 112/400, Accuracy: 0.7268\n",
      "Run 113/400, Accuracy: 0.5577\n",
      "Run 114/400, Accuracy: 0.6423\n",
      "Run 115/400, Accuracy: 0.6016\n",
      "Run 116/400, Accuracy: 0.6439\n",
      "Run 117/400, Accuracy: 0.5886\n",
      "Run 118/400, Accuracy: 0.5122\n",
      "Run 119/400, Accuracy: 0.6033\n",
      "Run 120/400, Accuracy: 0.5854\n",
      "Run 121/400, Accuracy: 0.6439\n",
      "Run 122/400, Accuracy: 0.6423\n",
      "Run 123/400, Accuracy: 0.6423\n",
      "Run 124/400, Accuracy: 0.5984\n",
      "Run 125/400, Accuracy: 0.6000\n",
      "Run 126/400, Accuracy: 0.6423\n",
      "Run 127/400, Accuracy: 0.7171\n",
      "Run 128/400, Accuracy: 0.5610\n",
      "Run 129/400, Accuracy: 0.4146\n",
      "Run 130/400, Accuracy: 0.6000\n",
      "Run 131/400, Accuracy: 0.5187\n",
      "Run 132/400, Accuracy: 0.6894\n",
      "Run 133/400, Accuracy: 0.5089\n",
      "Run 134/400, Accuracy: 0.5203\n",
      "Run 135/400, Accuracy: 0.4569\n",
      "Run 136/400, Accuracy: 0.6407\n",
      "Run 137/400, Accuracy: 0.5187\n",
      "Run 138/400, Accuracy: 0.5902\n",
      "Run 139/400, Accuracy: 0.4618\n",
      "Run 140/400, Accuracy: 0.6423\n",
      "Run 141/400, Accuracy: 0.5577\n",
      "Run 142/400, Accuracy: 0.5854\n",
      "Run 143/400, Accuracy: 0.6000\n",
      "Run 144/400, Accuracy: 0.4764\n",
      "Run 145/400, Accuracy: 0.5171\n",
      "Run 146/400, Accuracy: 0.6016\n",
      "Run 147/400, Accuracy: 0.6455\n",
      "Run 148/400, Accuracy: 0.5187\n",
      "Run 149/400, Accuracy: 0.6423\n",
      "Run 150/400, Accuracy: 0.6423\n",
      "Run 151/400, Accuracy: 0.6423\n",
      "Run 152/400, Accuracy: 0.6098\n",
      "Run 153/400, Accuracy: 0.5187\n",
      "Run 154/400, Accuracy: 0.6163\n",
      "Run 155/400, Accuracy: 0.5268\n",
      "Run 156/400, Accuracy: 0.5171\n",
      "Run 157/400, Accuracy: 0.6423\n",
      "Run 158/400, Accuracy: 0.5854\n",
      "Run 159/400, Accuracy: 0.6098\n",
      "Run 160/400, Accuracy: 0.5333\n",
      "Run 161/400, Accuracy: 0.5984\n",
      "Run 162/400, Accuracy: 0.6098\n",
      "Run 163/400, Accuracy: 0.5610\n",
      "Run 164/400, Accuracy: 0.5187\n",
      "Run 165/400, Accuracy: 0.5171\n",
      "Run 166/400, Accuracy: 0.5236\n",
      "Run 167/400, Accuracy: 0.6016\n",
      "Run 168/400, Accuracy: 0.5236\n",
      "Run 169/400, Accuracy: 0.6098\n",
      "Run 170/400, Accuracy: 0.5203\n",
      "Run 171/400, Accuracy: 0.5902\n",
      "Run 172/400, Accuracy: 0.5187\n",
      "Run 173/400, Accuracy: 0.5171\n",
      "Run 174/400, Accuracy: 0.6130\n",
      "Run 175/400, Accuracy: 0.5902\n",
      "Run 176/400, Accuracy: 0.6000\n",
      "Run 177/400, Accuracy: 0.5805\n",
      "Run 178/400, Accuracy: 0.4585\n",
      "Run 179/400, Accuracy: 0.6423\n",
      "Run 180/400, Accuracy: 0.6504\n",
      "Run 181/400, Accuracy: 0.6439\n",
      "Run 182/400, Accuracy: 0.7268\n",
      "Run 183/400, Accuracy: 0.6049\n",
      "Run 184/400, Accuracy: 0.5902\n",
      "Run 185/400, Accuracy: 0.6423\n",
      "Run 186/400, Accuracy: 0.6423\n",
      "Run 187/400, Accuracy: 0.6000\n",
      "Run 188/400, Accuracy: 0.5187\n",
      "Run 189/400, Accuracy: 0.6065\n",
      "Run 190/400, Accuracy: 0.6488\n",
      "Run 191/400, Accuracy: 0.6065\n",
      "Run 192/400, Accuracy: 0.5171\n",
      "Run 193/400, Accuracy: 0.6423\n",
      "Run 194/400, Accuracy: 0.5870\n",
      "Run 195/400, Accuracy: 0.6098\n",
      "Run 196/400, Accuracy: 0.6081\n",
      "Run 197/400, Accuracy: 0.5203\n",
      "Run 198/400, Accuracy: 0.6455\n",
      "Run 199/400, Accuracy: 0.5187\n",
      "Run 200/400, Accuracy: 0.5171\n",
      "Run 201/400, Accuracy: 0.6033\n",
      "Run 202/400, Accuracy: 0.5171\n",
      "Run 203/400, Accuracy: 0.4976\n",
      "Run 204/400, Accuracy: 0.7187\n",
      "Run 205/400, Accuracy: 0.6016\n",
      "Run 206/400, Accuracy: 0.6423\n",
      "Run 207/400, Accuracy: 0.5171\n",
      "Run 208/400, Accuracy: 0.6195\n",
      "Run 209/400, Accuracy: 0.4098\n",
      "Run 210/400, Accuracy: 0.7187\n",
      "Run 211/400, Accuracy: 0.5187\n",
      "Run 212/400, Accuracy: 0.5902\n",
      "Run 213/400, Accuracy: 0.6423\n",
      "Run 214/400, Accuracy: 0.7252\n",
      "Run 215/400, Accuracy: 0.7187\n",
      "Run 216/400, Accuracy: 0.5854\n",
      "Run 217/400, Accuracy: 0.6423\n",
      "Run 218/400, Accuracy: 0.6439\n",
      "Run 219/400, Accuracy: 0.4098\n",
      "Run 220/400, Accuracy: 0.5236\n",
      "Run 221/400, Accuracy: 0.5236\n",
      "Run 222/400, Accuracy: 0.7171\n",
      "Run 223/400, Accuracy: 0.5902\n",
      "Run 224/400, Accuracy: 0.5854\n",
      "Run 225/400, Accuracy: 0.6423\n",
      "Run 226/400, Accuracy: 0.5854\n",
      "Run 227/400, Accuracy: 0.5187\n",
      "Run 228/400, Accuracy: 0.5301\n",
      "Run 229/400, Accuracy: 0.6244\n",
      "Run 230/400, Accuracy: 0.6065\n",
      "Run 231/400, Accuracy: 0.6016\n",
      "Run 232/400, Accuracy: 0.6423\n",
      "Run 233/400, Accuracy: 0.6098\n",
      "Run 234/400, Accuracy: 0.6423\n",
      "Run 235/400, Accuracy: 0.6602\n",
      "Run 236/400, Accuracy: 0.5935\n",
      "Run 237/400, Accuracy: 0.6000\n",
      "Run 238/400, Accuracy: 0.6423\n",
      "Run 239/400, Accuracy: 0.5301\n",
      "Run 240/400, Accuracy: 0.5203\n",
      "Run 241/400, Accuracy: 0.5854\n",
      "Run 242/400, Accuracy: 0.6146\n",
      "Run 243/400, Accuracy: 0.5171\n",
      "Run 244/400, Accuracy: 0.6033\n",
      "Run 245/400, Accuracy: 0.4569\n",
      "Run 246/400, Accuracy: 0.6260\n",
      "Run 247/400, Accuracy: 0.6016\n",
      "Run 248/400, Accuracy: 0.5854\n",
      "Run 249/400, Accuracy: 0.6228\n",
      "Run 250/400, Accuracy: 0.7171\n",
      "Run 251/400, Accuracy: 0.6098\n",
      "Run 252/400, Accuracy: 0.6423\n",
      "Run 253/400, Accuracy: 0.7073\n",
      "Run 254/400, Accuracy: 0.5902\n",
      "Run 255/400, Accuracy: 0.6049\n",
      "Run 256/400, Accuracy: 0.5187\n",
      "Run 257/400, Accuracy: 0.6000\n",
      "Run 258/400, Accuracy: 0.7187\n",
      "Run 259/400, Accuracy: 0.6423\n",
      "Run 260/400, Accuracy: 0.5203\n",
      "Run 261/400, Accuracy: 0.6423\n",
      "Run 262/400, Accuracy: 0.5902\n",
      "Run 263/400, Accuracy: 0.5171\n",
      "Run 264/400, Accuracy: 0.6325\n",
      "Run 265/400, Accuracy: 0.6000\n",
      "Run 266/400, Accuracy: 0.7122\n",
      "Run 267/400, Accuracy: 0.5220\n",
      "Run 268/400, Accuracy: 0.5854\n",
      "Run 269/400, Accuracy: 0.6455\n",
      "Run 270/400, Accuracy: 0.6423\n",
      "Run 271/400, Accuracy: 0.6033\n",
      "Run 272/400, Accuracy: 0.5870\n",
      "Run 273/400, Accuracy: 0.5984\n",
      "Run 274/400, Accuracy: 0.5854\n",
      "Run 275/400, Accuracy: 0.5171\n",
      "Run 276/400, Accuracy: 0.6423\n",
      "Run 277/400, Accuracy: 0.5252\n",
      "Run 278/400, Accuracy: 0.6033\n",
      "Run 279/400, Accuracy: 0.6033\n",
      "Run 280/400, Accuracy: 0.6049\n",
      "Run 281/400, Accuracy: 0.5854\n",
      "Run 282/400, Accuracy: 0.6033\n",
      "Run 283/400, Accuracy: 0.7106\n",
      "Run 284/400, Accuracy: 0.5268\n",
      "Run 285/400, Accuracy: 0.7268\n",
      "Run 286/400, Accuracy: 0.4569\n",
      "Run 287/400, Accuracy: 0.6439\n",
      "Run 288/400, Accuracy: 0.5171\n",
      "Run 289/400, Accuracy: 0.5886\n",
      "Run 290/400, Accuracy: 0.4146\n",
      "Run 291/400, Accuracy: 0.6423\n",
      "Run 292/400, Accuracy: 0.6114\n",
      "Run 293/400, Accuracy: 0.5122\n",
      "Run 294/400, Accuracy: 0.5220\n",
      "Run 295/400, Accuracy: 0.5919\n",
      "Run 296/400, Accuracy: 0.6049\n",
      "Run 297/400, Accuracy: 0.6065\n",
      "Run 298/400, Accuracy: 0.6016\n",
      "Run 299/400, Accuracy: 0.6423\n",
      "Run 300/400, Accuracy: 0.5626\n",
      "Run 301/400, Accuracy: 0.6065\n",
      "Run 302/400, Accuracy: 0.5187\n",
      "Run 303/400, Accuracy: 0.5122\n",
      "Run 304/400, Accuracy: 0.4098\n",
      "Run 305/400, Accuracy: 0.6016\n",
      "Run 306/400, Accuracy: 0.6000\n",
      "Run 307/400, Accuracy: 0.5984\n",
      "Run 308/400, Accuracy: 0.5577\n",
      "Run 309/400, Accuracy: 0.5902\n",
      "Run 310/400, Accuracy: 0.4634\n",
      "Run 311/400, Accuracy: 0.5463\n",
      "Run 312/400, Accuracy: 0.5870\n",
      "Run 313/400, Accuracy: 0.7268\n",
      "Run 314/400, Accuracy: 0.6000\n",
      "Run 315/400, Accuracy: 0.6423\n",
      "Run 316/400, Accuracy: 0.5935\n",
      "Run 317/400, Accuracy: 0.6033\n",
      "Run 318/400, Accuracy: 0.5902\n",
      "Run 319/400, Accuracy: 0.6211\n",
      "Run 320/400, Accuracy: 0.6049\n",
      "Run 321/400, Accuracy: 0.5902\n",
      "Run 322/400, Accuracy: 0.5171\n",
      "Run 323/400, Accuracy: 0.6602\n",
      "Run 324/400, Accuracy: 0.6504\n",
      "Run 325/400, Accuracy: 0.5902\n",
      "Run 326/400, Accuracy: 0.5171\n",
      "Run 327/400, Accuracy: 0.6098\n",
      "Run 328/400, Accuracy: 0.5870\n",
      "Run 329/400, Accuracy: 0.4585\n",
      "Run 330/400, Accuracy: 0.5171\n",
      "Run 331/400, Accuracy: 0.5122\n",
      "Run 332/400, Accuracy: 0.5171\n",
      "Run 333/400, Accuracy: 0.7187\n",
      "Run 334/400, Accuracy: 0.7187\n",
      "Run 335/400, Accuracy: 0.4650\n",
      "Run 336/400, Accuracy: 0.4780\n",
      "Run 337/400, Accuracy: 0.6423\n",
      "Run 338/400, Accuracy: 0.5854\n",
      "Run 339/400, Accuracy: 0.6423\n",
      "Run 340/400, Accuracy: 0.5122\n",
      "Run 341/400, Accuracy: 0.6098\n",
      "Run 342/400, Accuracy: 0.5854\n",
      "Run 343/400, Accuracy: 0.6797\n",
      "Run 344/400, Accuracy: 0.5463\n",
      "Run 345/400, Accuracy: 0.6423\n",
      "Run 346/400, Accuracy: 0.7089\n",
      "Run 347/400, Accuracy: 0.5252\n",
      "Run 348/400, Accuracy: 0.6423\n",
      "Run 349/400, Accuracy: 0.5187\n",
      "Run 350/400, Accuracy: 0.6423\n",
      "Run 351/400, Accuracy: 0.5236\n",
      "Run 352/400, Accuracy: 0.5187\n",
      "Run 353/400, Accuracy: 0.6439\n",
      "Run 354/400, Accuracy: 0.6065\n",
      "Run 355/400, Accuracy: 0.6016\n",
      "Run 356/400, Accuracy: 0.6797\n",
      "Run 357/400, Accuracy: 0.5122\n",
      "Run 358/400, Accuracy: 0.4390\n",
      "Run 359/400, Accuracy: 0.4618\n",
      "Run 360/400, Accuracy: 0.6211\n",
      "Run 361/400, Accuracy: 0.6455\n",
      "Run 362/400, Accuracy: 0.5642\n",
      "Run 363/400, Accuracy: 0.4390\n",
      "Run 364/400, Accuracy: 0.5187\n",
      "Run 365/400, Accuracy: 0.6423\n",
      "Run 366/400, Accuracy: 0.6423\n",
      "Run 367/400, Accuracy: 0.5187\n",
      "Run 368/400, Accuracy: 0.6423\n",
      "Run 369/400, Accuracy: 0.6000\n",
      "Run 370/400, Accuracy: 0.6179\n",
      "Run 371/400, Accuracy: 0.5187\n",
      "Run 372/400, Accuracy: 0.6618\n",
      "Run 373/400, Accuracy: 0.6033\n",
      "Run 374/400, Accuracy: 0.4699\n",
      "Run 375/400, Accuracy: 0.5171\n",
      "Run 376/400, Accuracy: 0.5350\n",
      "Run 377/400, Accuracy: 0.5171\n",
      "Run 378/400, Accuracy: 0.5902\n",
      "Run 379/400, Accuracy: 0.6049\n",
      "Run 380/400, Accuracy: 0.5919\n",
      "Run 381/400, Accuracy: 0.5854\n",
      "Run 382/400, Accuracy: 0.5854\n",
      "Run 383/400, Accuracy: 0.5268\n",
      "Run 384/400, Accuracy: 0.6081\n",
      "Run 385/400, Accuracy: 0.6423\n",
      "Run 386/400, Accuracy: 0.6098\n",
      "Run 387/400, Accuracy: 0.7106\n",
      "Run 388/400, Accuracy: 0.4764\n",
      "Run 389/400, Accuracy: 0.5171\n",
      "Run 390/400, Accuracy: 0.6033\n",
      "Run 391/400, Accuracy: 0.5252\n",
      "Run 392/400, Accuracy: 0.6423\n",
      "Run 393/400, Accuracy: 0.5171\n",
      "Run 394/400, Accuracy: 0.6065\n",
      "Run 395/400, Accuracy: 0.5171\n",
      "Run 396/400, Accuracy: 0.5301\n",
      "Run 397/400, Accuracy: 0.5187\n",
      "Run 398/400, Accuracy: 0.6423\n",
      "Run 399/400, Accuracy: 0.5220\n",
      "Run 400/400, Accuracy: 0.6000\n",
      "\n",
      "=== Final Results ===\n",
      "Max Accuracy: 0.7268\n",
      "Cluster Descriptions:\n",
      "Cluster 0 has true labels: Counter({1: 102, 0: 68, 2: 1})\n",
      "Cluster 1 has true labels: Counter({0: 307, 2: 1})\n",
      "Cluster 2 has true labels: Counter({0: 97, 2: 38, 1: 1})\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import normalize\n",
    "\n",
    "# Functions: K-Means initialization, assignment, and computation\n",
    "def kMeans_init_centroids(X, K):\n",
    "    \"\"\"Initialize centroids randomly from the dataset.\"\"\"\n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    centroids = X[randidx[:K]]\n",
    "    return centroids\n",
    "\n",
    "def find_closest_centroids(X, centroids):\n",
    "    \"\"\"Assign data points to closest centroids using cosine similarity.\"\"\"\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        similarities = np.dot(centroids, X[i])  # Cosine similarity\n",
    "        idx[i] = np.argmax(similarities)  # Assign to the most similar centroid\n",
    "    return idx\n",
    "\n",
    "def compute_centroids(X, idx, K):\n",
    "    \"\"\"Compute new centroids based on assigned clusters.\"\"\"\n",
    "    centroids = np.zeros((K, X.shape[1]))\n",
    "    for k in range(K):\n",
    "        points = X[idx == k]\n",
    "        if len(points) > 0:\n",
    "            centroids[k] = np.mean(points, axis=0)\n",
    "    centroids = normalize(centroids, axis=1)  # Normalize centroids\n",
    "    return centroids\n",
    "\n",
    "def run_kMeans(X, initial_centroids, max_iters=10):\n",
    "    \"\"\"Run the K-Means algorithm.\"\"\"\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for _ in range(max_iters):\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "    return centroids, idx\n",
    "\n",
    "'''# Accuracy calculation and main experiment loop\n",
    "def calculate_accuracy(idx, labels_np, K=3):\n",
    "    \"\"\"Calculate accuracy for a given set of cluster assignments.\"\"\"\n",
    "    total_samples = len(labels_np)\n",
    "    cluster_label_counts = {}\n",
    "    label_to_cluster = {}\n",
    "    correctly_classified = 0\n",
    "\n",
    "    # Count true labels in each cluster\n",
    "    for cluster in range(K):\n",
    "        cluster_indices = np.where(idx == cluster)[0]\n",
    "        cluster_labels = labels_np[cluster_indices]\n",
    "        label_counts = Counter(cluster_labels)\n",
    "        cluster_label_counts[cluster] = label_counts\n",
    "    \n",
    "    # Assign each label to the cluster where it is most common\n",
    "    for label in range(3):  # Assuming 3 classes: 0, 1, 2\n",
    "        max_count = 0\n",
    "        assigned_cluster = None\n",
    "        for cluster, label_counts in cluster_label_counts.items():\n",
    "            if label_counts[label] > max_count:\n",
    "                max_count = label_counts[label]\n",
    "                assigned_cluster = cluster\n",
    "        if assigned_cluster is not None:\n",
    "            label_to_cluster[label] = assigned_cluster\n",
    "            correctly_classified += max_count\n",
    "\n",
    "    accuracy = correctly_classified / total_samples\n",
    "    return accuracy, cluster_label_counts '''\n",
    "\n",
    "# Accuracy calculation and main experiment loop\n",
    "def calculate_accuracy(idx, labels_np, K=3):\n",
    "    \"\"\"Calculate accuracy for a given set of cluster assignments.\"\"\"\n",
    "    total_samples = len(labels_np)\n",
    "    cluster_label_counts = {}\n",
    "    label_to_cluster = {}\n",
    "    correctly_classified = 0\n",
    "\n",
    "    # Count true labels in each cluster\n",
    "    for cluster in range(K):\n",
    "        cluster_indices = np.where(idx == cluster)[0]\n",
    "        cluster_labels = labels_np[cluster_indices]\n",
    "        label_counts = Counter(cluster_labels)\n",
    "        cluster_label_counts[cluster] = label_counts\n",
    "    \n",
    "    # Track clusters already assigned to labels\n",
    "    assigned_clusters = set()\n",
    "\n",
    "    # Assign each label to the cluster where it is most common, respecting the rule\n",
    "    for label in range(3):  # Assuming 3 classes: 0, 1, 2\n",
    "        max_count = 0\n",
    "        assigned_cluster = None\n",
    "        for cluster, label_counts in cluster_label_counts.items():\n",
    "            # Skip clusters already assigned to another label\n",
    "            if cluster in assigned_clusters:\n",
    "                continue\n",
    "            if label_counts[label] > max_count:\n",
    "                max_count = label_counts[label]\n",
    "                assigned_cluster = cluster\n",
    "        # Assign this label to the cluster and mark the cluster as used\n",
    "        if assigned_cluster is not None:\n",
    "            label_to_cluster[label] = assigned_cluster\n",
    "            assigned_clusters.add(assigned_cluster)\n",
    "            correctly_classified += max_count\n",
    "\n",
    "    accuracy = correctly_classified / total_samples\n",
    "    return accuracy, cluster_label_counts\n",
    "\n",
    "def main_kMeans_experiment(X, labels_np, K=3, num_runs=100, max_iters=50):\n",
    "    accuracies = []\n",
    "    best_accuracy = 0\n",
    "    best_cluster_counts = None\n",
    "    best_centroids = None\n",
    "    best_idx = None\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        # Initialize centroids randomly\n",
    "        initial_centroids = kMeans_init_centroids(X, K)\n",
    "        \n",
    "        # Run K-Means\n",
    "        centroids, idx = run_kMeans(X, initial_centroids, max_iters)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy, cluster_counts = calculate_accuracy(idx, labels_np, K)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        # Track the best run\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_cluster_counts = cluster_counts\n",
    "            best_centroids = centroids\n",
    "            best_idx = idx\n",
    "        \n",
    "        print(f\"Run {run + 1}/{num_runs}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Print final results\n",
    "    print(\"\\n=== Final Results ===\")\n",
    "    print(f\"Max Accuracy: {best_accuracy:.4f}\")\n",
    "    print(\"Cluster Descriptions:\")\n",
    "    for cluster, counts in best_cluster_counts.items():\n",
    "        print(f\"Cluster {cluster} has true labels: {counts}\")\n",
    "    \n",
    "    # Return the best centroids and idx along with accuracy\n",
    "    return best_accuracy, best_centroids, best_idx, best_cluster_counts\n",
    "\n",
    "\n",
    "'''\n",
    "# Main loop for running K-Means multiple times\n",
    "def main_kMeans_experiment(X, labels_np, K=3, num_runs=100, max_iters=50):\n",
    "    accuracies = []\n",
    "    best_accuracy = 0\n",
    "    best_cluster_counts = None\n",
    "\n",
    "    for run in range(num_runs):\n",
    "        # Initialize centroids randomly\n",
    "        initial_centroids = kMeans_init_centroids(X, K)\n",
    "        \n",
    "        # Run K-Means\n",
    "        centroids, idx = run_kMeans(X, initial_centroids, max_iters)\n",
    "        \n",
    "        # Calculate accuracy\n",
    "        accuracy, cluster_counts = calculate_accuracy(idx, labels_np, K)\n",
    "        accuracies.append(accuracy)\n",
    "        \n",
    "        # Track the best run\n",
    "        if accuracy > best_accuracy:\n",
    "            best_accuracy = accuracy\n",
    "            best_cluster_counts = cluster_counts\n",
    "        \n",
    "        print(f\"Run {run + 1}/{num_runs}, Accuracy: {accuracy:.4f}\")\n",
    "\n",
    "    # Print final results\n",
    "    print(\"\\n=== Final Results ===\")\n",
    "    print(f\"Max Accuracy: {best_accuracy:.4f}\")\n",
    "    print(\"Cluster Descriptions:\")\n",
    "    for cluster, counts in best_cluster_counts.items():\n",
    "        print(f\"Cluster {cluster} has true labels: {counts}\")'''\n",
    "\n",
    "    \n",
    "\n",
    "# Example usage\n",
    "# Assuming `feats_np_norm` is your normalized feature matrix and `labels_np` contains true labels\n",
    "K = 3  # Number of clusters\n",
    "num_runs = 400  # Number of K-Means runs\n",
    "max_iters = 50  # Maximum iterations per run\n",
    "\n",
    "best_accuracy, best_centroids, best_idx, best_cluster_counts = main_kMeans_experiment(feats_np_norm, labels_np, K, num_runs, max_iters)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "516"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "103+373+40\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8390243902439024"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "516/615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.4845528455284553"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "298/615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'ss' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[22], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mss\u001b[49m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'ss' is not defined"
     ]
    }
   ],
   "source": [
    "ss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "85+137+11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "233/423"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "284/615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "425+125+40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "590/637"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "124+406+40"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "570/637"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Number of clusters\n",
    "K = len(np.unique(best_idx))\n",
    "\n",
    "# Total number of samples\n",
    "total_samples = len(labels_np)\n",
    "\n",
    "# Dictionary to track the cluster assigned to each label\n",
    "label_to_cluster = {}\n",
    "\n",
    "# Variable to count correctly classified samples\n",
    "correctly_classified = 0\n",
    "\n",
    "# Iterate over each cluster and count the true labels in that cluster\n",
    "cluster_label_counts = {}  # To store the counts for each cluster\n",
    "for cluster in range(K):\n",
    "    # Find the indices of images assigned to the current cluster\n",
    "    cluster_indices = np.where(best_idx == cluster)[0]\n",
    "    \n",
    "    # Get the true labels for the images in this cluster\n",
    "    cluster_labels = labels_np[cluster_indices]\n",
    "    \n",
    "    # Use Counter to count occurrences of each label in the cluster\n",
    "    label_counts = Counter(cluster_labels)\n",
    "    \n",
    "    # Save label counts for this cluster\n",
    "    cluster_label_counts[cluster] = label_counts\n",
    "\n",
    "# Track clusters already assigned to labels\n",
    "assigned_clusters = set()\n",
    "\n",
    "# Assign each label to the cluster where it is most common, respecting the rule\n",
    "for label in range(3):  # Assuming 3 classes: 0, 1, 2\n",
    "    max_count = 0\n",
    "    assigned_cluster = None\n",
    "    for cluster, label_counts in cluster_label_counts.items():\n",
    "        # Skip clusters already assigned to another label\n",
    "        if cluster in assigned_clusters:\n",
    "            continue\n",
    "        if label_counts[label] > max_count:\n",
    "            max_count = label_counts[label]\n",
    "            assigned_cluster = cluster\n",
    "    # Assign this label to the cluster and mark the cluster as used\n",
    "    if assigned_cluster is not None:\n",
    "        label_to_cluster[label] = assigned_cluster\n",
    "        assigned_clusters.add(assigned_cluster)\n",
    "        correctly_classified += max_count\n",
    "\n",
    "# Calculate accuracy\n",
    "accuracy = correctly_classified / total_samples\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Track clusters already assigned to labels\n",
    "assigned_clusters = set()\n",
    "\n",
    "if cluster in assigned_clusters:\n",
    "            continue\n",
    "\n",
    "assigned_clusters.add(assigned_cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "SKLEARN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define KMeansCosine class\n",
    "class KMeansCosine:\n",
    "    def __init__(self, n_clusters=2, max_iter=300, random_state=None):\n",
    "        self.n_clusters = n_clusters\n",
    "        self.max_iter = max_iter\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def fit(self, X):\n",
    "        # Normalize the data to unit vectors\n",
    "        X_normalized = X / np.linalg.norm(X, axis=1)[:, np.newaxis]\n",
    "\n",
    "        # Initialize centroids randomly from the data points\n",
    "        np.random.seed(self.random_state)\n",
    "        initial_indices = np.random.choice(X_normalized.shape[0], self.n_clusters, replace=False)\n",
    "        centroids = X_normalized[initial_indices]\n",
    "\n",
    "        # Track the minimum cost and corresponding labels/centroids\n",
    "        best_cost = float('inf')\n",
    "        best_labels = None\n",
    "        best_centroids = None\n",
    "\n",
    "\n",
    "        for _ in range(self.max_iter):\n",
    "            # Compute the cosine similarity and distance\n",
    "            similarities = cosine_similarity(X_normalized, centroids)\n",
    "            cosine_dist = 1 - similarities\n",
    "            cost = np.sum(cosine_dist)\n",
    "            #print(f\"Iteration cost: {cost}\")\n",
    "\n",
    "            # Update best cost and corresponding labels/centroids if the current cost is lower\n",
    "            if cost < best_cost:\n",
    "                best_cost = cost\n",
    "                best_labels = np.argmax(similarities, axis=1)\n",
    "                best_centroids = centroids.copy()\n",
    "\n",
    "            # Assign clusters based on the highest similarity (lowest distance)\n",
    "            labels = np.argmax(similarities, axis=1)\n",
    "\n",
    "            # Update centroids by taking the mean of the points in each cluster\n",
    "            new_centroids = np.array([X_normalized[labels == i].mean(axis=0) for i in range(self.n_clusters)])\n",
    "            new_centroids /= np.linalg.norm(new_centroids, axis=1)[:, np.newaxis]\n",
    "\n",
    "            # Check for convergence (if centroids do not change)\n",
    "            if np.allclose(centroids, new_centroids, atol=1e-6):  # Use np.allclose for numerical stability\n",
    "                break\n",
    "\n",
    "            centroids = new_centroids\n",
    "\n",
    "        # Store final centroids and labels\n",
    "        self.labels_ = labels\n",
    "        self.centroids_ = centroids\n",
    "        self.best_labels_ = best_labels\n",
    "        self.best_centroids_ = best_centroids\n",
    "        self.best_cost_ = best_cost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans_cosine = KMeansCosine(n_clusters=3, max_iter=100, random_state=11)\n",
    "kmeans_cosine.fit(feats_np)\n",
    "\n",
    "#print(\"Final Cluster Labels:\", kmeans_cosine.labels_)\n",
    "#print(\"Final Centroids:\", kmeans_cosine.centroids_)\n",
    "#print(\"Best Cluster Labels with Lowest Cost:\", kmeans_cosine.best_labels_)\n",
    "#print(\"Best Centroids with Lowest Cost:\", kmeans_cosine.best_centroids_)\n",
    "#print(\"Lowest Cost:\", kmeans_cosine.best_cost_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = kmeans_cosine.labels_\n",
    "idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# `idx` contains the cluster assignments from KMeans\n",
    "#  `labels` contains the true labels\n",
    "\n",
    "K = len(np.unique(idx))  # Number of clusters\n",
    "\n",
    "# Iterate over each cluster and count the true labels in that cluster\n",
    "for cluster in range(K):\n",
    "    # Find the indices of images assigned to the current cluster\n",
    "    cluster_indices = np.where(idx == cluster)[0]\n",
    "    \n",
    "    # Get the true labels for the images in this cluster\n",
    "    cluster_labels = labels_np[cluster_indices]\n",
    "    \n",
    "    # Use Counter to count occurrences of each label in the cluster\n",
    "    label_counts = Counter(cluster_labels)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Cluster {cluster} has true labels: {label_counts}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 49+ 164"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num/615"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "full Dataset\n",
    "1 = 58.7\n",
    "2 = 55.60\n",
    "3 = "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reorder K-Means labels to match true labels\n",
    "def reorder_labels(true_labels, predicted_labels):\n",
    "    reordered_labels = np.zeros_like(predicted_labels)\n",
    "\n",
    "    for cluster in np.unique(predicted_labels):\n",
    "        mask = (predicted_labels == cluster)\n",
    "        # Use mode and handle cases where mode() returns a scalar\n",
    "        most_common_label = mode(true_labels[mask], axis=None).mode  # Get the mode for the current cluster\n",
    "        if isinstance(most_common_label, np.ndarray):\n",
    "            most_common_label = most_common_label[0]  # Safely extract the mode value if it's an array\n",
    "        \n",
    "        reordered_labels[mask] = most_common_label\n",
    "\n",
    "    return reordered_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this after running K-Means\n",
    "reordered_idx = reorder_labels(labels_np, idx)\n",
    "\n",
    "# Now you can compare `reordered_idx` with `labels` to evaluate accuracy\n",
    "accuracy = np.sum(reordered_idx == labels_np) / len(labels_np) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From scratch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K-Means initialization function\n",
    "def kMeans_init_centroids(X, K):\n",
    "    randidx = np.random.permutation(X.shape[0])\n",
    "    centroids = X[randidx[:K]]\n",
    "    return centroids\n",
    "\n",
    "# Function to find the closest centroids using Cosine Similarity\n",
    "def find_closest_centroids(X, centroids):\n",
    "    # Normalize both the data points and centroids to ensure we compute cosine similarity\n",
    "    #X_norm = normalize(X, axis=1)\n",
    "    #centroids_norm = normalize(centroids, axis=1)\n",
    "    \n",
    "    # Assign data points to closest centroids based on cosine similarity\n",
    "    idx = np.zeros(X.shape[0], dtype=int)\n",
    "    for i in range(X.shape[0]):\n",
    "        # Compute cosine similarity\n",
    "        similarities = np.dot(centroids, X[i])  # Dot product gives cosine similarity\n",
    "        idx[i] = np.argmax(similarities)  # We want the most similar (highest value)\n",
    "    return idx\n",
    "\n",
    "# Function to compute new centroids\n",
    "def compute_centroids(X, idx, K):\n",
    "    centroids = np.zeros((K, X.shape[1]))  # Use shape[1] for features\n",
    "    for k in range(K):\n",
    "        points = X[idx == k]\n",
    "        if len(points) > 0:\n",
    "            centroids[k] = np.mean(points, axis=0)   # noralised vectors mean maynot be normalised. hence we normalise before calculating mean.https://chatgpt.com/share/671b97a7-ec2c-8010-af33-af106df0a25c\n",
    "            centroids_norm = normalize(centroids, axis=1)\n",
    "    return centroids_norm\n",
    "\n",
    "# Function to run K-Means algorithm with cost tracking (using Cosine Similarity)\n",
    "def run_kMeans(X, initial_centroids, max_iters=10):\n",
    "    K = initial_centroids.shape[0]\n",
    "    centroids = initial_centroids\n",
    "    idx = np.zeros(X.shape[0])\n",
    "    \n",
    "\n",
    "\n",
    "    for i in range(max_iters):\n",
    "        #print(f\"K-Means iteration {i}/{max_iters - 1}\")\n",
    "        \n",
    "        # Assign each data point to the closest centroid using cosine similarity\n",
    "        idx = find_closest_centroids(X, centroids)\n",
    "        \n",
    "        # Compute new centroids\n",
    "        centroids = compute_centroids(X, idx, K)\n",
    "\n",
    "        # Calculate cost function for the current centroids using cosine distance\n",
    "\n",
    "        # 1. Compute cosine similarity\n",
    "        sim = np.dot(X, centroids.T)\n",
    "        #print(sim.shape)\n",
    "        #print(sim)\n",
    "        # 2. Calculate cosine distance\n",
    "        cosine_dist = 1 - sim\n",
    "        #print(cosine_dist.shape)\n",
    "        #print(cosine_dist)\n",
    "        # 3. Find maximum cosine distance for each data point\n",
    "        #max_cosine_dist = cosine_dist.max(axis=1)\n",
    "        #print(max_cosine_dist.shape)\n",
    "        #print(max_cosine_dist)\n",
    "        cost = np.sum(cosine_dist)\n",
    "\n",
    "        # 4. Sum of all maximum distances\n",
    "        #cost = np.sum(max_cosine_dist)\n",
    "\n",
    "        #cost = np.sum(1 - np.dot(X_norm, centroids_norm.T).max(axis=1))  # Cosine distance = 1 - cosine similarity  \n",
    "        #print(f\"Cost function value: {cost}\")  # Print the cost function value\n",
    "\n",
    "        \n",
    "\n",
    "   # Indicate which iteration was chosen\n",
    "    return centroids,idx  # Return the best centroids\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main function to run the K-Means algorithm\n",
    "\n",
    "K = 3                     # Set number of clusters\n",
    "initial_centroids = kMeans_init_centroids(feats_np_norm, K)  # Step 3: Initialize centroids\n",
    "max_iters = 50                # Step 4: Number of iterations\n",
    "centroids, idx = run_kMeans(feats_np_norm, initial_centroids, max_iters)  # Step 5: Run K-Means\n",
    "#print(\"Final centroids:\", centroids)  # Output the final centroids\n",
    "\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "# Assuming `idx` contains the cluster assignments from KMeans\n",
    "# and `labels` contains the true labels\n",
    "\n",
    "K = len(np.unique(idx))  # Number of clusters\n",
    "\n",
    "# Iterate over each cluster and count the true labels in that cluster\n",
    "for cluster in range(K):\n",
    "    # Find the indices of images assigned to the current cluster\n",
    "    cluster_indices = np.where(idx == cluster)[0]\n",
    "    \n",
    "    # Get the true labels for the images in this cluster\n",
    "    cluster_labels = labels_np[cluster_indices]\n",
    "    \n",
    "    # Use Counter to count occurrences of each label in the cluster\n",
    "    label_counts = Counter(cluster_labels)\n",
    "    \n",
    "    # Print the result\n",
    "    print(f\"Cluster {cluster} has true labels: {label_counts}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 63+191\n",
    "num/(280+40+103)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after full \n",
    "56.26\n",
    "60.04"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after curated full \n",
    "48.22\n",
    "46.80\n",
    "49.17\n",
    "53.12\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this after running K-Means\n",
    "reordered_idx = reorder_labels(labels_np, idx)\n",
    "\n",
    "# Now you can compare `reordered_idx` with `labels` to evaluate accuracy\n",
    "accuracy = np.sum(reordered_idx == labels_np) / len(labels_np) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after uncure 40\n",
    "75.83"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num = 103 + 413 + 40\n",
    "num/615"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full Dataset\n",
    "1 = 50.57\n",
    "2= 55.\n",
    "3. 58\n",
    "4= 51.86\n",
    "5 = 54.95\n",
    "6 = 53.33\n",
    "7 = 90.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "strong curated full\n",
    "\n",
    "one = 62.41,\n",
    "two = 62.41,\n",
    "three = 68.08,\n",
    "four= 85.58,\n",
    "5 = 62.17,\n",
    "6 = 68.08,\n",
    "7 = 62.88,\n",
    "8 = 68.08\n",
    "9 = 62.17\n",
    "10 = 62.17\n",
    "11 = 100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import mode\n",
    "import numpy as np\n",
    "\n",
    "# Function to reorder K-Means labels to match true labels\n",
    "def reorder_labels(true_labels, predicted_labels):\n",
    "    reordered_labels = np.zeros_like(predicted_labels)\n",
    "\n",
    "    for cluster in np.unique(predicted_labels):\n",
    "        mask = (predicted_labels == cluster)\n",
    "        # Use mode and handle cases where mode() returns a scalar\n",
    "        most_common_label = mode(true_labels[mask], axis=None).mode  # Get the mode for the current cluster\n",
    "        if isinstance(most_common_label, np.ndarray):\n",
    "            most_common_label = most_common_label[0]  # Safely extract the mode value if it's an array\n",
    "        \n",
    "        reordered_labels[mask] = most_common_label\n",
    "\n",
    "    return reordered_labels\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply this after running K-Means\n",
    "reordered_idx = reorder_labels(labels_np, idx)\n",
    "\n",
    "# Now you can compare `reordered_idx` with `labels` to evaluate accuracy\n",
    "accuracy = np.sum(reordered_idx == labels_np) / len(labels_np) * 100\n",
    "print(f\"Accuracy: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "after strong cure 40\n",
    "3 = 70.83\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 347,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to reduce the dimensionality of data points and centroids to 2D using PCA\n",
    "def reduce_to_2D_pca(X, centroids):\n",
    "    # Initialize PCA with 2 components\n",
    "    pca = PCA(n_components=2)\n",
    "    \n",
    "    # Apply PCA to the data points (X) and centroids\n",
    "    X_2D = pca.fit_transform(X)  # Reducing original data points\n",
    "    centroids_2D = pca.transform(centroids)  # Reducing centroids\n",
    "\n",
    "    return X_2D, centroids_2D\n",
    "\n",
    "# Function to plot 2D visualization of clustered data points and centroids with true labels\n",
    "def plot_2D_clusters_with_labels(X_2D, centroids_2D, idx, labels, K):\n",
    "    plt.figure(figsize=(10, 7))\n",
    "    \n",
    "    # Define color map for clusters\n",
    "    colors = plt.cm.rainbow(np.linspace(0, 1, K))\n",
    "    \n",
    "    # Plot data points colored by their cluster assignment\n",
    "    for k in range(K):\n",
    "        cluster_points = X_2D[idx == k]\n",
    "        cluster_labels = labels[idx == k]  # Get true labels for the current cluster\n",
    "        \n",
    "        # Scatter plot for each cluster\n",
    "        plt.scatter(cluster_points[:, 0], cluster_points[:, 1], \n",
    "                    c=[colors[k]], label=f\"Cluster {k+1}\", alpha=0.6)\n",
    "        \n",
    "        # Annotate each point with its true label\n",
    "        for i in range(cluster_points.shape[0]):\n",
    "            plt.annotate(str(cluster_labels[i]), \n",
    "                         (cluster_points[i, 0], cluster_points[i, 1]), \n",
    "                         fontsize=8, alpha=0.75)\n",
    "\n",
    "    # Plot centroids as larger markers\n",
    "    plt.scatter(centroids_2D[:, 0], centroids_2D[:, 1], \n",
    "                c='k', marker='x', s=200, label='Centroids')\n",
    "\n",
    "    plt.title(\"Strong before full dataset\")\n",
    "    plt.xlabel(\"Component 1\")\n",
    "    plt.ylabel(\"Component 2\")\n",
    "    plt.legend()\n",
    "    plt.grid()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA after K-Means clustering for 2D visualization\n",
    "X_2D_pca, centroids_2D_pca = reduce_to_2D_pca(feats_np_norm, centroids)\n",
    "\n",
    "# Plot the 2D clusters with centroids and true labels\n",
    "plot_2D_clusters_with_labels(X_2D_pca, centroids_2D_pca, idx, labels_np, K)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
