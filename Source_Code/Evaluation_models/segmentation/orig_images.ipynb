{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import skimage.io\n",
    "import cv2\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import skimage.filters\n",
    "import skimage.morphology\n",
    "\n",
    "# Paths\n",
    "image_dir = r'C:\\Users\\k54739\\Today_data\\segmentation\\test_img'  # Input image directory\n",
    "mask_dir = r'C:\\Users\\k54739\\Today_data\\segmentation\\test_mask'  # Output mask directory\n",
    "\n",
    "os.makedirs(mask_dir, exist_ok=True)  # Ensure mask directory exists\n",
    "\n",
    "def process_image(image_path):\n",
    "    # Load the image\n",
    "    image = skimage.io.imread(image_path)\n",
    "\n",
    "    # Convert to grayscale if necessary\n",
    "    if len(image.shape) == 3:\n",
    "        img_gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    else:\n",
    "        img_gray = image\n",
    "\n",
    "    # Convert to 8-bit format\n",
    "    img_gray_8bit = cv2.normalize(img_gray, None, 0, 255, cv2.NORM_MINMAX).astype('uint8')\n",
    "\n",
    "    # Blur using bilateral filter\n",
    "    blur = cv2.bilateralFilter(img_gray_8bit, 50, 40, 40)\n",
    "\n",
    "    # Apply Otsu thresholding\n",
    "    t = skimage.filters.threshold_otsu(blur)\n",
    "    binary_mask = blur > t\n",
    "\n",
    "    # Remove small objects\n",
    "    filtered_mask = skimage.morphology.remove_small_objects(binary_mask, 10000)\n",
    "\n",
    "    return img_gray_8bit, filtered_mask\n",
    "\n",
    "def save_mask_as_16bit_tiff(mask, save_path):\n",
    "    \"\"\"\n",
    "    Save the binary mask as a 16-bit TIFF file with background as black (0)\n",
    "    and segmented object as white (65535).\n",
    "    \"\"\"\n",
    "    # Invert mask: Background (False) -> 0, Object (True) -> 65535\n",
    "    mask_16bit = mask.astype(np.uint16) * 65535\n",
    "    skimage.io.imsave(save_path, mask_16bit, check_contrast=False)  # Save as 16-bit TIFF\n",
    "\n",
    "# Process all images\n",
    "for image_name in os.listdir(image_dir):\n",
    "    image_path = os.path.join(image_dir, image_name)\n",
    "    \n",
    "    # Skip non-image files\n",
    "    if not image_name.lower().endswith(('.tiff', '.tif')):\n",
    "        continue\n",
    "\n",
    "    # Process image\n",
    "    img_gray_8bit, mask = process_image(image_path)\n",
    "\n",
    "    # Save the mask\n",
    "    mask_path = os.path.join(mask_dir, os.path.splitext(image_name)[0] + '_mask.tiff')  # Save as .tiff\n",
    "    save_mask_as_16bit_tiff(mask, mask_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Pixel Values: [    0 65535]\n",
      "Number of Unique Pixel Values: 2\n",
      "Counts of Each Pixel Value: [1416998 2801918]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import skimage.io\n",
    "\n",
    "# Load the TIFF mask image\n",
    "mask_path = r'C:\\Users\\k54739\\Today_data\\segmentation\\test_mask\\cond10_ds_41_E10-T01_mask.tiff'  # Replace with your mask path\n",
    "mask = skimage.io.imread(mask_path)\n",
    "\n",
    "# Get unique pixel values and their counts\n",
    "unique_values, counts = np.unique(mask, return_counts=True)\n",
    "\n",
    "# Print unique pixel values and their count\n",
    "print(\"Unique Pixel Values:\", unique_values)\n",
    "print(\"Number of Unique Pixel Values:\", len(unique_values))\n",
    "print(\"Counts of Each Pixel Value:\", counts)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\k54739/.cache\\torch\\hub\\mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    }
   ],
   "source": [
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "    in_channels=3, out_channels=1, init_features=32, pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "UNet(\n",
      "  (encoder1): Sequential(\n",
      "    (enc1conv1): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc1norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc1relu1): ReLU(inplace=True)\n",
      "    (enc1conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc1norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc1relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (encoder2): Sequential(\n",
      "    (enc2conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc2norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc2relu1): ReLU(inplace=True)\n",
      "    (enc2conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc2norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc2relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (encoder3): Sequential(\n",
      "    (enc3conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc3norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc3relu1): ReLU(inplace=True)\n",
      "    (enc3conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc3norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc3relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (encoder4): Sequential(\n",
      "    (enc4conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc4norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc4relu1): ReLU(inplace=True)\n",
      "    (enc4conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc4norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc4relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bottleneck): Sequential(\n",
      "    (bottleneckconv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bottlenecknorm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bottleneckrelu1): ReLU(inplace=True)\n",
      "    (bottleneckconv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bottlenecknorm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bottleneckrelu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (upconv4): ConvTranspose2d(512, 256, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (decoder4): Sequential(\n",
      "    (dec4conv1): Conv2d(512, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (dec4norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec4relu1): ReLU(inplace=True)\n",
      "    (dec4conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (dec4norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec4relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (upconv3): ConvTranspose2d(256, 128, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (decoder3): Sequential(\n",
      "    (dec3conv1): Conv2d(256, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (dec3norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec3relu1): ReLU(inplace=True)\n",
      "    (dec3conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (dec3norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec3relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (upconv2): ConvTranspose2d(128, 64, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (decoder2): Sequential(\n",
      "    (dec2conv1): Conv2d(128, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (dec2norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec2relu1): ReLU(inplace=True)\n",
      "    (dec2conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (dec2norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec2relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (upconv1): ConvTranspose2d(64, 32, kernel_size=(2, 2), stride=(2, 2))\n",
      "  (decoder1): Sequential(\n",
      "    (dec1conv1): Conv2d(64, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (dec1norm1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec1relu1): ReLU(inplace=True)\n",
      "    (dec1conv2): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (dec1norm2): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (dec1relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (conv): Conv2d(32, 1, kernel_size=(1, 1), stride=(1, 1))\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset\n",
    "class SegmentationDataset(Dataset):\n",
    "    def __init__(self, image_dir, mask_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.mask_dir = mask_dir\n",
    "        self.image_names = [f for f in os.listdir(image_dir) if f.endswith(('.tiff', '.tif'))]\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_names)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_name = self.image_names[idx]\n",
    "        image_path = os.path.join(self.image_dir, image_name)\n",
    "        mask_path = os.path.join(self.mask_dir, os.path.splitext(image_name)[0] + '_mask.tiff')  # Match naming\n",
    "\n",
    "        # Load image and mask\n",
    "        image = skimage.io.imread(image_path).astype(np.float32)\n",
    "        mask = skimage.io.imread(mask_path).astype(np.float32)\n",
    "\n",
    "        # Normalize image and mask\n",
    "        image = image / 65535.0  # Normalize to [0, 1]\n",
    "        mask = mask / 65535.0    # Normalize mask to [0, 1]\n",
    "\n",
    "        # Add channel dimension for grayscale images\n",
    "        if len(image.shape) == 2:\n",
    "            image = np.expand_dims(image, axis=0)\n",
    "        else:\n",
    "            image = np.transpose(image, (2, 0, 1))  # For 3-channel images\n",
    "\n",
    "        mask = np.expand_dims(mask, axis=0)  # Add channel dimension to mask\n",
    "\n",
    "        # Apply transformations if any\n",
    "        if self.transform:\n",
    "            image = self.transform(torch.tensor(image))\n",
    "            mask = torch.tensor(mask)\n",
    "\n",
    "        return torch.tensor(image, dtype=torch.float32), torch.tensor(mask, dtype=torch.float32)\n",
    "    \n",
    "    # Define transformations (if needed)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Normalize(mean=[0.5], std=[0.5])  # Normalize values\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Paths\n",
    "image_dir = r'C:\\path\\to\\images'\n",
    "mask_dir = r'C:\\path\\to\\masks'\n",
    "\n",
    "# Split dataset into train and validation\n",
    "all_images = os.listdir(image_dir)\n",
    "train_images, val_images = train_test_split(all_images, test_size=0.2, random_state=42)\n",
    "\n",
    "# Train and validation datasets\n",
    "train_dataset = SegmentationDataset(image_dir, mask_dir, transform=transform)\n",
    "val_dataset = SegmentationDataset(image_dir, mask_dir, transform=transform)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=4, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=4, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Load pretrained U-Net model\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet',\n",
    "                       in_channels=3, out_channels=1, init_features=32, pretrained=True)\n",
    "\n",
    "# Define loss and optimizer\n",
    "criterion = nn.BCEWithLogitsLoss()  # Use Binary Cross-Entropy Loss with logits\n",
    "optimizer = optim.Adam(model.parameters(), lr=1e-4)\n",
    "\n",
    "# Move model to GPU if available\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop\n",
    "num_epochs = 25\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    train_loss = 0.0\n",
    "\n",
    "    for images, masks in train_loader:\n",
    "        images, masks = images.to(device), masks.to(device)\n",
    "\n",
    "        # Forward pass\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, masks)\n",
    "\n",
    "        # Backpropagation and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for images, masks in val_loader:\n",
    "            images, masks = images.to(device), masks.to(device)\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, masks)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "    # Print epoch summary\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Val Loss: {val_loss/len(val_loader):.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save model\n",
    "torch.save(model.state_dict(), 'unet_segmentation_model.pth')\n",
    "\n",
    "# Visualize results\n",
    "model.eval()\n",
    "images, masks = next(iter(val_loader))\n",
    "images, masks = images.to(device), masks.to(device)\n",
    "outputs = model(images)\n",
    "predicted_masks = (torch.sigmoid(outputs) > 0.5).float()\n",
    "\n",
    "for i in range(len(images)):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    plt.subplot(1, 3, 1)\n",
    "    plt.title(\"Input Image\")\n",
    "    plt.imshow(images[i].cpu().permute(1, 2, 0).numpy(), cmap='gray')\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.title(\"Ground Truth Mask\")\n",
    "    plt.imshow(masks[i].cpu().squeeze(0).numpy(), cmap='gray')\n",
    "    plt.subplot(1, 3, 3)\n",
    "    plt.title(\"Predicted Mask\")\n",
    "    plt.imshow(predicted_masks[i].cpu().squeeze(0).numpy(), cmap='gray')\n",
    "    plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
