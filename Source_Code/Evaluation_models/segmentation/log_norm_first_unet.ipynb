{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "import tifffile as tiff\n",
    "import numpy as np\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import time\n",
    "from copy import deepcopy\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the output of projection head because output of botteleneck is 1834 which is greater than 96 input image size. and we can't change the size because then we have to change the model weights then its no meaning to use pretrained model.\n",
    "strange: i got acc:40% with projection head and without:100% for one epoch for logistic regression (downstream task)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    if torch.cuda.is_available():\n",
    "        torch.cuda.manual_seed(seed)\n",
    "        torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Custom Dataset class for 3 channel/image\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir,size):\n",
    "        self.image_dir = image_dir\n",
    "        #self.transform = transform\n",
    "        self.image_files = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.tiff')]\n",
    "        #we don't need to resize into 96*96 because we are doing that in below contrastive transform (self.resize_transform = transforms.resize((96,96)))\n",
    "        self.transform = transforms.Compose([\n",
    "            #transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomResizedCrop(size=size),\n",
    "            transforms.RandomApply([transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.1)], p=0.8),\n",
    "            #transforms.RandomGrayscale(p=0.2),\n",
    "            #transforms.GaussianBlur(kernel_size=9),\n",
    "        ])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "        \n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        \n",
    "        # Convert to a torch tensor\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        \n",
    "        if self.transform:\n",
    "            image1 = self.transform(image)\n",
    "            image2 = self.transform(image)\n",
    "        return image1, image2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 channel\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, size, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.tiff')]\n",
    "        self.resize_transform = transforms.Resize((size,size))\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "        \n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "        \n",
    "        # Calculate sharpness for each layer\n",
    "        sharpness_scores = []\n",
    "        for i in range(3):\n",
    "            layer = image[i]\n",
    "            gy, gx = np.gradient(layer)\n",
    "            gnorm = np.sqrt(gx**2 + gy**2)\n",
    "            sharpness = np.average(gnorm)\n",
    "            sharpness_scores.append(sharpness)\n",
    "        \n",
    "\n",
    "        # Find the index of the sharpest layer\n",
    "        sharpest_layer_index = np.argmax(sharpness_scores)\n",
    "        \n",
    "        # Determine the anchor (sharpest layer) and the other two layers (augmentations)\n",
    "        anchor = image[sharpest_layer_index]\n",
    "        other_indices = [i for i in range(3) if i != sharpest_layer_index]\n",
    "        augmentation1 = image[other_indices[0]]\n",
    "        augmentation2 = image[other_indices[1]]\n",
    "\n",
    "        # Convert to a torch tensor and add channel dimension\n",
    "        anchor = torch.tensor(anchor, dtype=torch.float32).unsqueeze(0)\n",
    "        img1 = torch.tensor(augmentation1, dtype=torch.float32).unsqueeze(0)\n",
    "        img2 = torch.tensor(augmentation2, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        # Apply resize transform\n",
    "        #anchor = self.resize_transform(anchor)\n",
    "        img1 = self.resize_transform(img1)\n",
    "        img2 = self.resize_transform(img2)\n",
    "        \n",
    "        return img1, img2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_curves(train_losses, val_losses, train_top1_accs, val_top1_accs, train_top5_accs, val_top5_accs, train_mean_pos, val_mean_pos):\n",
    "    epochs = range(1, len(train_losses) + 1)\n",
    "\n",
    "    # Plot loss\n",
    "    plt.figure(figsize=(12, 4))\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(epochs, train_losses, 'bo-', label='Training Loss')\n",
    "    plt.plot(epochs, val_losses, 'ro-', label='Validation Loss')\n",
    "    plt.title('Training and Validation Loss')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Top-1 accuracy\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(epochs, train_top1_accs, 'bo-', label='Training Top-1 Accuracy')\n",
    "    plt.plot(epochs, val_top1_accs, 'ro-', label='Validation Top-1 Accuracy')\n",
    "    plt.title('Training and Validation Top-1 Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Top-1 Accuracy (%)')\n",
    "    plt.legend()\n",
    "\n",
    "    # Show the plots\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    # Plot Top-5 accuracy\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(epochs, train_top5_accs, 'bo-', label='Training Top-5 Accuracy')\n",
    "    plt.plot(epochs, val_top5_accs, 'ro-', label='Validation Top-5 Accuracy')\n",
    "    plt.title('Training and Validation Top-5 Accuracy')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Top-5 Accuracy (%)')\n",
    "    plt.legend()\n",
    "\n",
    "    # Plot Mean Position of Positive Example\n",
    "    plt.figure(figsize=(6, 4))\n",
    "    plt.plot(epochs, train_mean_pos, 'bo-', label='Training Mean Position')\n",
    "    plt.plot(epochs, val_mean_pos, 'ro-', label='Validation Mean Position')\n",
    "    plt.title('Training and Validation Mean Position of Positive Example')\n",
    "    plt.xlabel('Epochs')\n",
    "    plt.ylabel('Mean Position')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "# Function to split dataset with explicit percentage\n",
    "def split_dataset(dataset, val_percentage):\n",
    "    val_size = int(len(dataset) * val_percentage)\n",
    "    train_size = len(dataset) - val_size\n",
    "    return random_split(dataset, [train_size, val_size])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 channel\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Resnet, self).__init__()\n",
    "        \n",
    "        # Load the pretrained ResNet-18 model\n",
    "        self.convnet = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "        \n",
    "        # Modify the first convolutional layer to accept single-channel images\n",
    "        self.convnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        \n",
    "        # Modify the fully connected layer\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4 * hidden_dim),  # Linear layer with 4*hidden_dim output\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * hidden_dim, hidden_dim)  # Output layer with hidden_dim output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convnet(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 channel\n",
    "\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Resnet, self).__init__()\n",
    "        \n",
    "        # Load the pretrained ResNet-18 model\n",
    "        self.convnet = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "        \n",
    "        # Modify the first convolutional layer to accept single-channel images\n",
    "        self.convnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        \n",
    "        # Modify the fully connected layer\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4 * hidden_dim),  # Linear layer with 4*hidden_dim output\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * hidden_dim, hidden_dim)  # Output layer with hidden_dim output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Forward pass through the ResNet layers\n",
    "        x = self.convnet.conv1(x)\n",
    "        x = self.convnet.bn1(x)\n",
    "        x = self.convnet.relu(x)\n",
    "        x = self.convnet.maxpool(x)\n",
    "        print(f\"Shape after conv1: {x.shape}\")\n",
    "\n",
    "        x = self.convnet.layer1(x)\n",
    "        print(f\"Shape after layer1: {x.shape}\")\n",
    "\n",
    "        x = self.convnet.layer2(x)\n",
    "        print(f\"Shape after layer2: {x.shape}\")\n",
    "\n",
    "        x = self.convnet.layer3(x)\n",
    "        print(f\"Shape after layer3: {x.shape}\")\n",
    "\n",
    "        x = self.convnet.layer4(x)\n",
    "        print(f\"Shape after layer4: {x.shape}\")\n",
    "\n",
    "        # Global average pooling\n",
    "        x = self.convnet.avgpool(x)\n",
    "        print(f\"Shape after avgpool: {x.shape}\")\n",
    "\n",
    "        # Flatten the tensor\n",
    "        x = torch.flatten(x, 1)\n",
    "        print(f\"Shape after flatten: {x.shape}\")\n",
    "\n",
    "        # Pass through the projection head\n",
    "        x = self.convnet.fc(x)\n",
    "        print(f\"Shape after projection head: {x.shape}\")\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model for 3 channel/image\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.convnet = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4 * hidden_dim),  # Linear layer with 4*hidden_dim output\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * hidden_dim, hidden_dim)  # Output layer with hidden_dim output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Pass through the convolutional layers\n",
    "        x = self.convnet.conv1(x)\n",
    "        x = self.convnet.bn1(x)\n",
    "        x = self.convnet.relu(x)\n",
    "        x = self.convnet.maxpool(x)\n",
    "\n",
    "        x = self.convnet.layer1(x)\n",
    "        x = self.convnet.layer2(x)\n",
    "        x = self.convnet.layer3(x)\n",
    "        x = self.convnet.layer4(x)\n",
    "\n",
    "        # Print the shape after each layer\n",
    "        print(f\"Shape after conv1: {x.shape}\")\n",
    "        print(f\"Shape after layer1: {x.shape}\")\n",
    "        print(f\"Shape after layer2: {x.shape}\")\n",
    "        print(f\"Shape after layer3: {x.shape}\")\n",
    "        print(f\"Shape after layer4: {x.shape}\")\n",
    "\n",
    "        # Global average pooling\n",
    "        x = self.convnet.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        print(f\"Shape after avgpool: {x.shape}\")\n",
    "\n",
    "        # Pass through the projection head\n",
    "        x = self.convnet.fc(x)\n",
    "        print(f\"Shape after projection head: {x.shape}\")\n",
    "\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 channel\n",
    "class Resnet(nn.Module):\n",
    "    def __init__(self, hidden_dim):\n",
    "        super(Resnet, self).__init__()\n",
    "        self.convnet = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')   #weights='ResNet18_Weights.DEFAULT' or weights=None\n",
    "\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4 * hidden_dim),  # Linear layer with 4*hidden_dim output\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * hidden_dim, hidden_dim)  # Output layer with hidden_dim output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.convnet(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\k54739/.cache\\torch\\hub\\mateuszbuda_brain-segmentation-pytorch_master\n"
     ]
    }
   ],
   "source": [
    "# Load the pretrained UNet model\n",
    "model = torch.hub.load('mateuszbuda/brain-segmentation-pytorch', 'unet', \n",
    "                       in_channels=3, out_channels=1, init_features=32, pretrained=True)\n",
    "\n",
    "class UNetEncoder(nn.Module):\n",
    "    def __init__(self, unet_model, image_size=96, in_channel=3,hidden_dim=128):\n",
    "        super(UNetEncoder, self).__init__()\n",
    "        self.image_size = image_size\n",
    "        self.in_channel = in_channel\n",
    "        self.hidden_dim = hidden_dim\n",
    "        \n",
    "        original_encoder1 = unet_model.encoder1\n",
    "        \n",
    "        # Create a new encoder1 layer with variable input channels, keeping the same output channels and kernel size\n",
    "        self.encoder1 = nn.Sequential(\n",
    "            nn.Conv2d(self.in_channel, original_encoder1[0].out_channels, \n",
    "                      kernel_size=original_encoder1[0].kernel_size, \n",
    "                      stride=original_encoder1[0].stride, \n",
    "                      padding=original_encoder1[0].padding),\n",
    "            original_encoder1[1]  # Keep the rest of the layers (e.g., BatchNorm, ReLU) intact\n",
    "        )\n",
    "        \n",
    "        self.pool1 = unet_model.pool1\n",
    "        self.encoder2 = unet_model.encoder2\n",
    "        self.pool2 = unet_model.pool2\n",
    "        self.encoder3 = unet_model.encoder3\n",
    "        self.pool3 = unet_model.pool3\n",
    "        self.encoder4 = unet_model.encoder4\n",
    "        self.pool4 = unet_model.pool4\n",
    "        self.bottleneck = unet_model.bottleneck\n",
    "        dummy = torch.zeros((1, self.in_channel, image_size, image_size))\n",
    "        out = self.bottleneck(self.pool4(self.encoder4(self.pool3(self.encoder3(self.pool2(self.encoder2(self.pool1(self.encoder1(dummy)))))))))\n",
    "        shape= torch.flatten(out, start_dim=1).shape[1]\n",
    "        \n",
    "        # Define the fully connected layers after the bottleneck\n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(shape, 4 * self.hidden_dim),  # Adjust input size based on bottleneck output\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4 * self.hidden_dim, 20)  # Output layer with hidden_dim output\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder1(x)\n",
    "        x = self.pool1(x)\n",
    "        x = self.encoder2(x)\n",
    "        x = self.pool2(x)\n",
    "        x = self.encoder3(x)\n",
    "        x = self.pool3(x)\n",
    "        x = self.encoder4(x)\n",
    "        x = self.pool4(x)\n",
    "        bottleneck = self.bottleneck(x)\n",
    "        \n",
    "        # Flatten the bottleneck output for the fully connected layer\n",
    "        bottleneck_flat = torch.flatten(bottleneck, start_dim=1)\n",
    "        \n",
    "        # Pass through the fully connected layers\n",
    "        output = self.fc(bottleneck_flat)\n",
    "        \n",
    "        # Return all encoder outputs or just bottleneck, depending on your needs\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SimCLR_loss(feats, temperature):\n",
    "    # Calculate cosine similarity\n",
    "    cos_sim = nn.functional.cosine_similarity(feats[:, None, :], feats[None, :, :], dim=-1)\n",
    "    \n",
    "    # Mask out cosine similarity to itself\n",
    "    self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "    cos_sim.masked_fill_(self_mask, -9e15)\n",
    "    \n",
    "    # Find positive example -> batch_size//2 away from the original example\n",
    "    pos_mask = self_mask.roll(shifts=cos_sim.shape[0] // 2, dims=0)\n",
    "    \n",
    "    # InfoNCE loss\n",
    "    cos_sim = cos_sim / temperature\n",
    "    nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "    nll = nll.mean()\n",
    "\n",
    "    # Accuracy calculations\n",
    "    comb_sim = torch.cat([cos_sim[pos_mask][:, None],  # First position positive example\n",
    "                          cos_sim.masked_fill(pos_mask, -9e15)],\n",
    "                         dim=-1)\n",
    "    sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
    "\n",
    "    # Calculate accuracy metrics\n",
    "    acc_top1 = (sim_argsort == 0).float().mean()\n",
    "    acc_top5 = (sim_argsort < 5).float().mean()\n",
    "    mean_pos = 1 + sim_argsort.float().mean()\n",
    "\n",
    "    return nll, acc_top1.item(), acc_top5.item(), mean_pos.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(train_loader, model, epochs, lr=5e-4, temperature=0.07, weight_decay=1e-4, device='cuda', validate=False):\n",
    "    if not validate:\n",
    "        model = model.train().to(device)\n",
    "    else:\n",
    "        model = model.eval().to(device)\n",
    "    \n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=50, eta_min=lr / 50)\n",
    "\n",
    "    train_losses = []\n",
    "    train_top1_accs = []\n",
    "    train_top5_accs = []\n",
    "    mean_positions = []\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        total_loss = 0\n",
    "        total_top1_acc = 0.0\n",
    "        total_top5_acc = 0.0\n",
    "        total_mean_pos = 0.0\n",
    "\n",
    "        for imgs1, imgs2 in train_loader:\n",
    "            imgs1, imgs2 = imgs1.to(device), imgs2.to(device)\n",
    "            imgs = torch.cat((imgs1, imgs2), dim=0)\n",
    "            feats = model(imgs)\n",
    "\n",
    "            # Compute the loss and accuracy\n",
    "            loss, acc_top1, acc_top5, mean_pos = SimCLR_loss(feats, temperature)\n",
    "\n",
    "            if not validate:\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                lr_scheduler.step()\n",
    "\n",
    "            total_loss += loss.item()\n",
    "            total_top1_acc += acc_top1\n",
    "            total_top5_acc += acc_top5\n",
    "            total_mean_pos += mean_pos\n",
    "\n",
    "        avg_loss = total_loss / len(train_loader)\n",
    "        avg_top1_acc = total_top1_acc / len(train_loader)\n",
    "        avg_top5_acc = total_top5_acc / len(train_loader)\n",
    "        avg_mean_pos = total_mean_pos / len(train_loader)\n",
    "\n",
    "        train_losses.append(avg_loss)\n",
    "        train_top1_accs.append(avg_top1_acc)\n",
    "        train_top5_accs.append(avg_top5_acc)\n",
    "        mean_positions.append(avg_mean_pos)\n",
    "\n",
    "        print(f\"Epoch {epoch + 1}/{epochs} | \"\n",
    "              f\"Loss: {avg_loss:.4f} | \"\n",
    "              f\"Top-1 Acc: {avg_top1_acc:.2f}% | \"\n",
    "              f\"Top-5 Acc: {avg_top5_acc:.2f}% | \"\n",
    "              f\"Mean Position: {avg_mean_pos:.2f}\")\n",
    "\n",
    "    return model, (train_losses, train_top1_accs, train_top5_accs, mean_positions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch 0:\n",
      "  Image1: torch.Size([16, 3, 96, 96])\n",
      "  Image2: torch.Size([16, 3, 96, 96])\n",
      "UNetEncoder(\n",
      "  (encoder1): Sequential(\n",
      "    (0): Conv2d(3, 32, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "  )\n",
      "  (pool1): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (encoder2): Sequential(\n",
      "    (enc2conv1): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc2norm1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc2relu1): ReLU(inplace=True)\n",
      "    (enc2conv2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc2norm2): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc2relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (encoder3): Sequential(\n",
      "    (enc3conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc3norm1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc3relu1): ReLU(inplace=True)\n",
      "    (enc3conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc3norm2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc3relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool3): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (encoder4): Sequential(\n",
      "    (enc4conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc4norm1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc4relu1): ReLU(inplace=True)\n",
      "    (enc4conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (enc4norm2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (enc4relu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (pool4): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "  (bottleneck): Sequential(\n",
      "    (bottleneckconv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bottlenecknorm1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bottleneckrelu1): ReLU(inplace=True)\n",
      "    (bottleneckconv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "    (bottlenecknorm2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (bottleneckrelu2): ReLU(inplace=True)\n",
      "  )\n",
      "  (fc): Sequential(\n",
      "    (0): Linear(in_features=18432, out_features=512, bias=True)\n",
      "    (1): ReLU(inplace=True)\n",
      "    (2): Linear(in_features=512, out_features=20, bias=True)\n",
      "  )\n",
      ")\n",
      "training\n"
     ]
    }
   ],
   "source": [
    "batch_size = 16\n",
    "size = 96\n",
    "\n",
    "image_dir = r\"C:\\Users\\k54739\\Today_data\\combined_1259\\crop_simclr\\train\"\n",
    "dataset = ImageDataset(image_dir=image_dir,size=size)\n",
    "\n",
    "\n",
    "# Split the dataset with 20% for validation\n",
    "val_percentage = 0.2\n",
    "train_dataset, val_dataset = split_dataset(dataset, val_percentage)\n",
    "\n",
    "# Define DataLoaders\n",
    "train_loader = DataLoader(train_dataset, \n",
    "                          batch_size=batch_size, \n",
    "                          shuffle=True, \n",
    "                          drop_last=False, \n",
    "                          pin_memory=True, \n",
    "                          num_workers=0) #num_workers=os.cpu count() using cluster gpu\n",
    "val_loader = DataLoader(val_dataset, \n",
    "                        batch_size=batch_size, \n",
    "                        shuffle=False, \n",
    "                        drop_last=False, \n",
    "                        pin_memory=True, \n",
    "                        num_workers=0)\n",
    "\n",
    "for i, (image1, image2) in enumerate(train_loader):\n",
    "    print(f\"Batch {i}:\")\n",
    "    print(f\"  Image1: {image1.shape}\")\n",
    "    print(f\"  Image2: {image2.shape}\")\n",
    "    plt.imshow(image1[0,0])\n",
    "    break\n",
    "\n",
    "unet_encoder = UNetEncoder(model,image_size=96,in_channel=3,hidden_dim=128)\n",
    "#model = Resnet(size)\n",
    "#print(model)\n",
    "print(unet_encoder)\n",
    "print('training')\n",
    "unet_model, train_results = train(train_loader, unet_encoder, epochs=100, device='cuda')\n",
    "print('validating')\n",
    "unet_model, val_results = train(val_loader, unet_encoder, epochs=100, device='cuda', validate=True)\n",
    "\n",
    "train_losses, train_top1_accs, train_top5_accs, train_mean_pos = train_results\n",
    "val_losses, val_top1_accs, val_top5_accs, val_mean_pos = val_results\n",
    "\n",
    "plot_curves(train_losses, val_losses, train_top1_accs, val_top1_accs, train_top5_accs, val_top5_accs, train_mean_pos, val_mean_pos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledImageDataset(Dataset):\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "\n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Convert to a torch tensor and add channel dimension\n",
    "        image = torch.tensor(image, dtype=torch.float32)\n",
    "        \n",
    "        # Apply resize transform\n",
    "        image = self.resize_transform(image)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return image, label\n",
    "\n",
    "def load_and_split_data(root_dir, test_size=0.2):\n",
    "    classes = ['untreated', 'single_dose', 'drug_screened']\n",
    "    image_files = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(root_dir, class_name)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir) if file.endswith('.tiff')]\n",
    "        image_files.extend(files)\n",
    "        labels.extend([idx] * len(files))\n",
    "    \n",
    "    # Check if the labels correctly reflect the classes\n",
    "    #print(\"Label distribution:\", {classes[i]: labels.count(i) for i in range(len(classes))})\n",
    "    \n",
    "    # Split data into training and test sets\n",
    "    train_files, test_files, train_labels, test_labels = train_test_split(\n",
    "        image_files, labels, test_size=test_size, stratify=labels, random_state=42)\n",
    "\n",
    "    return train_files, test_files, train_labels, test_labels\n",
    "\n",
    "\n",
    "# Directories for labeled data\n",
    "image_dir = r\"../../Data_supervised\"\n",
    "\n",
    "# Load and split the data\n",
    "train_files, test_files, train_labels, test_labels = load_and_split_data(image_dir, test_size=0.2)\n",
    "\n",
    "# Create the labeled datasets\n",
    "train_labeled_dataset = LabeledImageDataset(train_files, train_labels)\n",
    "test_labeled_dataset = LabeledImageDataset(test_files, test_labels)\n",
    "\n",
    "# Define DataLoaders\n",
    "batch_size = 16\n",
    "train_loader_labeled = DataLoader(train_labeled_dataset, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=0)\n",
    "test_loader_labeled = DataLoader(test_labeled_dataset, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True, num_workers=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 3, 96, 96]) torch.Size([16]) torch.float32\n",
      "tensor([0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 2, 1, 0, 1, 1, 0])\n"
     ]
    }
   ],
   "source": [
    "for anchor,label in train_loader_labeled:\n",
    "    print(anchor.shape, label.shape, anchor.dtype)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_data_features(model, dataloader):\n",
    "    # Prepare model\n",
    "    network = deepcopy(model)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    # Encode all images\n",
    "    feats, labels = [], []\n",
    "    for batch_imgs, batch_labels in tqdm(dataloader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        print(f\"Batch features shape: {batch_feats.shape}\")\n",
    "        print(f\"Batch labels shape: {batch_labels.shape}\")\n",
    "        \n",
    "        feats.append(batch_feats.detach().cpu())\n",
    "        labels.append(batch_labels)\n",
    "\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    \n",
    "    print(f\"Features shape after concatenation: {feats.shape}\")\n",
    "    print(f\"Labels shape after concatenation: {labels.shape}\")\n",
    "\n",
    "    return torch.utils.data.TensorDataset(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 25%|██▌       | 1/4 [00:01<00:03,  1.01s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 18432])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 50%|█████     | 2/4 [00:02<00:02,  1.03s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 18432])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.02s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([16, 18432])\n",
      "Batch labels shape: torch.Size([16])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:03<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([9, 18432])\n",
      "Batch labels shape: torch.Size([9])\n",
      "Features shape after concatenation: torch.Size([57, 18432])\n",
      "Labels shape after concatenation: torch.Size([57])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.03it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch features shape: torch.Size([15, 18432])\n",
      "Batch labels shape: torch.Size([15])\n",
      "Features shape after concatenation: torch.Size([15, 18432])\n",
      "Labels shape after concatenation: torch.Size([15])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Extract features for train and test datasets\n",
    "train_feats_unet = prepare_data_features(unet_model, train_loader_labeled)\n",
    "test_feats_unet = prepare_data_features(unet_model, test_loader_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Logistic Regression model definition\n",
    "class LogisticRegression(nn.Module):\n",
    "    def __init__(self, feature_dim, num_classes):\n",
    "        super(LogisticRegression, self).__init__()\n",
    "        self.linear = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training function\n",
    "def train_logistic_regression(model, train_loader, optimizer, scheduler, device):\n",
    "    model.train()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    for batch_feats, batch_labels in tqdm(train_loader, desc=\"Training\"):\n",
    "        batch_feats, batch_labels = batch_feats.to(device), batch_labels.to(device)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(batch_feats)\n",
    "        loss = nn.functional.cross_entropy(outputs, batch_labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        # Update learning rate scheduler\n",
    "        scheduler.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        preds = outputs.argmax(dim=1)\n",
    "        all_preds.extend(preds.cpu().numpy())\n",
    "        all_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(train_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluation function\n",
    "def evaluate_logistic_regression(model, test_loader, criterion, device):\n",
    "    model.eval()\n",
    "    total_loss = 0.0\n",
    "    all_preds = []\n",
    "    all_labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_feats, batch_labels in tqdm(test_loader, desc=\"Evaluating\"):\n",
    "            batch_feats, batch_labels = batch_feats.to(device), batch_labels.to(device)\n",
    "            \n",
    "            outputs = model(batch_feats)\n",
    "            loss = nn.functional.cross_entropy(outputs, batch_labels)\n",
    "            total_loss += loss.item()\n",
    "\n",
    "            preds = outputs.argmax(dim=1)\n",
    "            all_preds.extend(preds.cpu().numpy())\n",
    "            all_labels.extend(batch_labels.cpu().numpy())\n",
    "\n",
    "    avg_loss = total_loss / len(test_loader)\n",
    "    accuracy = accuracy_score(all_labels, all_preds)\n",
    "    return avg_loss, accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main training loop\n",
    "def train_logreg_simplified(batch_size, train_feats_data, test_feats_data, feature_dim, num_classes, lr=5e-4, weight_decay=1e-4, max_epochs=50):\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_feats_data, batch_size=batch_size, shuffle=True,\n",
    "                                   drop_last=False, pin_memory=True, num_workers=0) #num_workers =os.cpu_count()\n",
    "    test_loader = DataLoader(test_feats_data, batch_size=batch_size, shuffle=False,\n",
    "                                  drop_last=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "    # Model, loss, and optimizer\n",
    "    model = LogisticRegression(feature_dim, num_classes).to(device)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.AdamW(model.parameters(), lr=lr, weight_decay=weight_decay)\n",
    "    scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                               milestones=[int(max_epochs * 0.6), int(max_epochs * 0.8)],\n",
    "                                               gamma=0.1)\n",
    "\n",
    "    # Store metrics for plotting\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "\n",
    "    best_test_acc = 0.0\n",
    "    for epoch in range(max_epochs):\n",
    "        print(f\"Epoch {epoch+1}/{max_epochs}\")\n",
    "\n",
    "        train_loss, train_acc = train_logistic_regression(model, train_loader, optimizer, scheduler, device)\n",
    "        test_loss, test_acc = evaluate_logistic_regression(model, test_loader, criterion, device)\n",
    "        \n",
    "        print(f\"Training loss: {train_loss:.4f}, Training accuracy: {train_acc:.4f}\")\n",
    "        print(f\"Test loss: {test_loss:.4f}, Test accuracy: {test_acc:.4f}\")\n",
    "\n",
    "        train_losses.append(train_loss)\n",
    "        test_losses.append(test_loss)\n",
    "        train_accuracies.append(train_acc)\n",
    "        test_accuracies.append(test_acc)\n",
    "\n",
    "        if test_acc > best_test_acc:\n",
    "            best_test_acc = test_acc\n",
    "            best_model_state = model.state_dict()\n",
    "\n",
    "    # Load best model state\n",
    "    model.load_state_dict(best_model_state)\n",
    "\n",
    "    # Plot results\n",
    "    plt.figure(figsize=(15, 5))\n",
    "\n",
    "    # Loss curve\n",
    "    plt.subplot(1, 2, 1)\n",
    "    plt.plot(range(max_epochs), train_losses, label='Train Loss')\n",
    "    plt.plot(range(max_epochs), test_losses, label='Test Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.title('Loss Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    # Accuracy curve\n",
    "    plt.subplot(1, 2, 2)\n",
    "    plt.plot(range(max_epochs), train_accuracies, label='Train Accuracy')\n",
    "    plt.plot(range(max_epochs), test_accuracies, label='Test Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Accuracy Curve')\n",
    "    plt.legend()\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "    return model, {\"train_acc\": train_acc, \"test_acc\": test_acc}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 84.63it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1100.29it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.6280, Training accuracy: 0.7193\n",
      "Test loss: 0.0082, Test accuracy: 1.0000\n",
      "Epoch 2/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 97.44it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 75.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0882, Training accuracy: 0.9649\n",
      "Test loss: 0.0018, Test accuracy: 1.0000\n",
      "Epoch 3/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 90.66it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0054, Training accuracy: 1.0000\n",
      "Test loss: 0.0015, Test accuracy: 1.0000\n",
      "Epoch 4/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 154.99it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 118.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0033, Training accuracy: 1.0000\n",
      "Test loss: 0.0012, Test accuracy: 1.0000\n",
      "Epoch 5/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 162.14it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 115.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0030, Training accuracy: 1.0000\n",
      "Test loss: 0.0011, Test accuracy: 1.0000\n",
      "Epoch 6/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 161.18it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 116.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0032, Training accuracy: 1.0000\n",
      "Test loss: 0.0011, Test accuracy: 1.0000\n",
      "Epoch 7/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 122.00it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0034, Training accuracy: 1.0000\n",
      "Test loss: 0.0011, Test accuracy: 1.0000\n",
      "Epoch 8/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 118.80it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0029, Training accuracy: 1.0000\n",
      "Test loss: 0.0011, Test accuracy: 1.0000\n",
      "Epoch 9/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 160.40it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 119.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0028, Training accuracy: 1.0000\n",
      "Test loss: 0.0011, Test accuracy: 1.0000\n",
      "Epoch 10/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 160.16it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 120.07it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0028, Training accuracy: 1.0000\n",
      "Test loss: 0.0011, Test accuracy: 1.0000\n",
      "Epoch 11/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 161.57it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 1044.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0028, Training accuracy: 1.0000\n",
      "Test loss: 0.0011, Test accuracy: 1.0000\n",
      "Epoch 12/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 120.64it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 116.68it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0027, Training accuracy: 1.0000\n",
      "Test loss: 0.0011, Test accuracy: 1.0000\n",
      "Epoch 13/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 161.43it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0027, Training accuracy: 1.0000\n",
      "Test loss: 0.0011, Test accuracy: 1.0000\n",
      "Epoch 14/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 95.98it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0028, Training accuracy: 1.0000\n",
      "Test loss: 0.0010, Test accuracy: 1.0000\n",
      "Epoch 15/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 154.25it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 135.94it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0029, Training accuracy: 1.0000\n",
      "Test loss: 0.0010, Test accuracy: 1.0000\n",
      "Epoch 16/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 118.96it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 122.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0026, Training accuracy: 1.0000\n",
      "Test loss: 0.0010, Test accuracy: 1.0000\n",
      "Epoch 17/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 113.21it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 124.45it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0026, Training accuracy: 1.0000\n",
      "Test loss: 0.0010, Test accuracy: 1.0000\n",
      "Epoch 18/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 176.12it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 112.54it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0010, Test accuracy: 1.0000\n",
      "Epoch 19/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 164.29it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 115.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0027, Training accuracy: 1.0000\n",
      "Test loss: 0.0010, Test accuracy: 1.0000\n",
      "Epoch 20/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 121.31it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 127.92it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0010, Test accuracy: 1.0000\n",
      "Epoch 21/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 161.28it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0024, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 22/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 119.39it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 121.27it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0024, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 23/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 120.26it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 127.24it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0024, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 24/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 162.88it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0024, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 25/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 119.13it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 26/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 159.04it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 118.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0033, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 27/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 121.32it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 117.11it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0022, Training accuracy: 1.0000\n",
      "Test loss: 0.0009, Test accuracy: 1.0000\n",
      "Epoch 28/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 161.27it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 117.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0022, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 29/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 158.23it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 121.20it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0022, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 30/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 159.83it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 120.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0022, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 31/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 159.77it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 120.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0022, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 32/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 161.92it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 117.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 33/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 156.15it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 119.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 34/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 161.16it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 35/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 119.44it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 127.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0023, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 36/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 161.39it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 116.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0071, Training accuracy: 1.0000\n",
      "Test loss: 0.0008, Test accuracy: 1.0000\n",
      "Epoch 37/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 160.95it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 121.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 38/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 157.67it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 4228.13it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 155.61it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0021, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 40/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 120.79it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 119.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 41/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 119.36it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 118.74it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0019, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 42/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 119.64it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 124.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 43/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 158.89it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<?, ?it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0007, Test accuracy: 1.0000\n",
      "Epoch 44/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 159.22it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 117.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0018, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 45/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 158.68it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 120.58it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0025, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 46/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 158.44it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 126.46it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 120.58it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 127.21it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0017, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 48/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 157.33it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 124.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0016, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 49/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 158.23it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 121.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0015, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n",
      "Epoch 50/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training: 100%|██████████| 8/8 [00:00<00:00, 160.80it/s]\n",
      "Evaluating: 100%|██████████| 2/2 [00:00<00:00, 119.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training loss: 0.0053, Training accuracy: 1.0000\n",
      "Test loss: 0.0006, Test accuracy: 1.0000\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1500x500 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Train the logistic regression model\n",
    "logreg_model, results = train_logreg_simplified(\n",
    "    batch_size=8,\n",
    "    train_feats_data=train_feats_unet,\n",
    "    test_feats_data=test_feats_unet,\n",
    "    feature_dim=train_feats_unet.tensors[0].shape[1],\n",
    "    num_classes=3,\n",
    "    lr=5e-4,\n",
    "    weight_decay=1e-4,\n",
    "    max_epochs=50\n",
    ")\n",
    "\n",
    "#print(f\"Final Train Accuracy: {results['train_acc']:.4f}, Final Test Accuracy: {results['test_acc']:.4f}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
