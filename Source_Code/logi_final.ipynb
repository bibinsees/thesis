{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from torchvision import transforms\n",
    "import torchvision\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "import tifffile as tiff\n",
    "import matplotlib.pyplot as plt\n",
    "import time\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pytorch_lightning.loggers import CSVLogger\n",
    "from tqdm import tqdm\n",
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "CHECKPOINT_PATH = \"./saved_models/simclr\"  # Change this to your desired checkpoint path\n",
    "\n",
    "# Custom Dataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.tiff')]\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "\n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Calculate sharpness for each layer\n",
    "        sharpness_scores = []\n",
    "        for i in range(3):\n",
    "            layer = image[i]\n",
    "            gy, gx = np.gradient(layer)\n",
    "            gnorm = np.sqrt(gx**2 + gy**2)\n",
    "            sharpness = np.average(gnorm)\n",
    "            sharpness_scores.append(sharpness)\n",
    "\n",
    "        # Find the index of the sharpest layer\n",
    "        sharpest_layer_index = np.argmax(sharpness_scores)\n",
    "        \n",
    "        # Determine the anchor (sharpest layer) and the other two layers (augmentations)\n",
    "        anchor = image[sharpest_layer_index]\n",
    "        other_indices = [i for i in range(3) if i != sharpest_layer_index]\n",
    "        augmentation1 = image[other_indices[0]]\n",
    "        augmentation2 = image[other_indices[1]]\n",
    "\n",
    "        # Convert to a torch tensor and add channel dimension\n",
    "        anchor = torch.tensor(anchor, dtype=torch.float32).unsqueeze(0)\n",
    "        aug1 = torch.tensor(augmentation1, dtype=torch.float32).unsqueeze(0)\n",
    "        aug2 = torch.tensor(augmentation2, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        # Apply resize transform\n",
    "        anchor = self.resize_transform(anchor)\n",
    "        aug1 = self.resize_transform(aug1)\n",
    "        aug2 = self.resize_transform(aug2)\n",
    "\n",
    "        return aug1, aug2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the dataset\n",
    "image_dir = \"../.tiff_experiment_unsupervised_data/combined\"\n",
    "dataset = ImageDataset(image_dir=image_dir)\n",
    "batch_size = 16\n",
    "\n",
    "# Function to split dataset with explicit percentage\n",
    "def split_dataset(dataset, val_percentage):\n",
    "    val_size = int(len(dataset) * val_percentage)\n",
    "    train_size = len(dataset) - val_size\n",
    "    return random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Split the dataset with 20% for validation\n",
    "val_percentage = 0.2\n",
    "train_dataset, val_dataset = split_dataset(dataset, val_percentage)\n",
    "\n",
    "# Define DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=os.cpu_count())\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True, num_workers=os.cpu_count())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 96, 96]) torch.Size([16, 1, 96, 96]) torch.float32\n"
     ]
    }
   ],
   "source": [
    "# Check an example to ensure correct conversion\n",
    "for (aug1, aug2) in train_loader:\n",
    "    print(aug1.shape, aug2.shape, aug1.dtype)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Seed set to 42\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type   | Params | Mode \n",
      "-------------------------------------------\n",
      "0 | convnet | ResNet | 11.5 M | train\n",
      "-------------------------------------------\n",
      "11.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.5 M    Total params\n",
      "45.994    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14:   0%|          | 0/19 [00:00<?, ?it/s, v_num=52, train_loss_step=3.69e-5, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.271, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0485, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]          "
     ]
    }
   ],
   "source": [
    "# Define the SimCLR model class (same as in the tutorial)\n",
    "class SimCLR(pl.LightningModule):\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay, max_epochs=50):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        assert self.hparams.temperature > 0.0, 'The temperature must be a positive float!'\n",
    "\n",
    "        # Load the pretrained ResNet-18 model\n",
    "        self.convnet = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "        \n",
    "        # Modify the first convolutional layer to accept single-channel input\n",
    "        # Replace the existing convolutional layer with one that accepts a single channel\n",
    "        #in_channels = 1\n",
    "        '''self.convnet.conv1 = nn.Conv2d(in_channels, self.convnet.conv1.out_channels, \n",
    "                                        kernel_size=self.convnet.conv1.kernel_size, \n",
    "                                        stride=self.convnet.conv1.stride, \n",
    "                                        padding=self.convnet.conv1.padding, \n",
    "                                        bias=self.convnet.conv1.bias)'''\n",
    "                                        \n",
    "        weight = self.convnet.conv1.weight.clone()\n",
    "        self.convnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.convnet.conv1.weight.data = weight.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        # Modify the fully connected layer\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4*hidden_dim),  # Linear layer with 4*hidden_dim output\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4*hidden_dim, hidden_dim)  # Output layer with hidden_dim output\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.hparams.max_epochs, eta_min=self.hparams.lr/50)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def info_nce_loss(self, batch, mode='train'):\n",
    "        aug1, aug2 = batch\n",
    "        imgs = torch.cat((aug1, aug2), dim=0).to(self.device)  # Concatenate along the batch dimension\n",
    "\n",
    "        # Encode all images\n",
    "        feats = self.convnet(imgs).to(self.device)\n",
    "        # Calculate cosine similarity\n",
    "        cos_sim = nn.functional.cosine_similarity(feats[:, None, :], feats[None, :, :], dim=-1)\n",
    "        # Mask out cosine similarity to itself\n",
    "        self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "        cos_sim.masked_fill_(self_mask, -9e15)\n",
    "        # Find positive example -> batch_size//2 away from the original example\n",
    "        pos_mask = self_mask.roll(shifts=cos_sim.shape[0] // 2, dims=0)\n",
    "        # InfoNCE loss\n",
    "        cos_sim = cos_sim / self.hparams.temperature\n",
    "        nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "        nll = nll.mean()\n",
    "\n",
    "        # Logging loss\n",
    "        self.log(mode + '_loss', nll, on_epoch=True, prog_bar=True)\n",
    "        # Get ranking position of positive example\n",
    "        comb_sim = torch.cat([cos_sim[pos_mask][:, None],  # First position positive example\n",
    "                              cos_sim.masked_fill(pos_mask, -9e15)], dim=-1)\n",
    "        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
    "        # Logging ranking metrics\n",
    "        self.log(mode + '_acc_top1', (sim_argsort == 0).float().mean(), on_epoch=True, prog_bar=True)\n",
    "        self.log(mode + '_acc_top5', (sim_argsort < 5).float().mean(), on_epoch=True, prog_bar=True)\n",
    "        self.log(mode + '_acc_mean_pos', 1 + sim_argsort.float().mean(), on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return nll\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.info_nce_loss(batch, mode='train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.info_nce_loss(batch, mode='val')\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Define a callback to plot the training/validation loss and accuracy\n",
    "class PlotLossAccuracyCallback(pl.Callback):\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_acc_top1 = []\n",
    "        self.val_acc_top1 = []\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        if 'train_loss' in trainer.callback_metrics:\n",
    "            self.train_losses.append(trainer.callback_metrics['train_loss'].item())\n",
    "        if 'train_acc_top1' in trainer.callback_metrics:\n",
    "            self.train_acc_top1.append(trainer.callback_metrics['train_acc_top1'].item())\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        if 'val_loss' in trainer.callback_metrics:\n",
    "            self.val_losses.append(trainer.callback_metrics['val_loss'].item())\n",
    "        if 'val_acc_top1' in trainer.callback_metrics:\n",
    "            self.val_acc_top1.append(trainer.callback_metrics['val_acc_top1'].item())\n",
    "\n",
    "    def on_train_end(self, trainer, pl_module):\n",
    "        # Ensure the lists are the same length\n",
    "        min_len = min(len(self.train_losses), len(self.val_losses), len(self.train_acc_top1), len(self.val_acc_top1))\n",
    "        self.train_losses = self.train_losses[:min_len]\n",
    "        self.val_losses = self.val_losses[:min_len]\n",
    "        self.train_acc_top1 = self.train_acc_top1[:min_len]\n",
    "        self.val_acc_top1 = self.val_acc_top1[:min_len]\n",
    "\n",
    "        # Plotting the loss curves\n",
    "        epochs = range(1, min_len + 1)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, self.train_losses, label='Training Loss')\n",
    "        plt.plot(epochs, self.val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Training and Validation Loss')\n",
    "\n",
    "        # Plotting the accuracy curves\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, self.train_acc_top1, label='Training Accuracy Top-1')\n",
    "        plt.plot(epochs, self.val_acc_top1, label='Validation Accuracy Top-1')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Accuracy')\n",
    "        plt.legend()\n",
    "        plt.title('Training and Validation Accuracy Top-1')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "# Function to train the model\n",
    "def train_simclr(batch_size, max_epochs=50, **kwargs):\n",
    "    plot_callback = PlotLossAccuracyCallback()\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, 'SimCLR'),\n",
    "                         accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "                         devices= 'auto',\n",
    "                         max_epochs=max_epochs,\n",
    "                         log_every_n_steps=10,  # Set this value to a lower number to see logs more frequently\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode='max', monitor='val_acc_top5'),\n",
    "                                    LearningRateMonitor('epoch'), plot_callback])\n",
    "\n",
    "    trainer.logger._default_hp_metric = None  # Optional logging argument we don't need\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, 'SimCLR.ckpt')\n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f'Found pretrained model at {pretrained_filename}, loading...')\n",
    "        model = SimCLR.load_from_checkpoint(pretrained_filename)  # Automatically loads the model with the saved hyperparameters\n",
    "    else:\n",
    "        pl.seed_everything(42)  # To be reproducible\n",
    "        model = SimCLR(max_epochs=max_epochs, **kwargs)\n",
    "        trainer.fit(model, train_loader, val_loader)\n",
    "        model = SimCLR.load_from_checkpoint(trainer.checkpoint_callback.best_model_path)  # Load best checkpoint after training\n",
    "\n",
    "    return model\n",
    "\n",
    "# Train the SimCLR model\n",
    "simclr_model = train_simclr(batch_size=32, hidden_dim=128, lr=5e-4, temperature=0.07, weight_decay=1e-4, max_epochs=50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LabeledImageDataset(Dataset):\n",
    "    def __init__(self, image_files, labels, transform=None):\n",
    "        self.image_files = image_files\n",
    "        self.labels = labels\n",
    "        self.transform = transform\n",
    "        self.resize_transform = transforms.Resize((96, 96))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "\n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Calculate sharpness for each layer\n",
    "        sharpness_scores = []\n",
    "        for i in range(3):\n",
    "            layer = image[i]\n",
    "            gy, gx = np.gradient(layer)\n",
    "            gnorm = np.sqrt(gx**2 + gy**2)\n",
    "            sharpness = np.average(gnorm)\n",
    "            sharpness_scores.append(sharpness)\n",
    "\n",
    "        # Find the index of the sharpest layer\n",
    "        sharpest_layer_index = np.argmax(sharpness_scores)\n",
    "        \n",
    "        # Determine the anchor (sharpest layer)\n",
    "        anchor = image[sharpest_layer_index]\n",
    "\n",
    "        # Convert to a torch tensor and add channel dimension\n",
    "        anchor = torch.tensor(anchor, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        # Apply resize transform\n",
    "        anchor = self.resize_transform(anchor)\n",
    "\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        return anchor, label\n",
    "\n",
    "def load_and_split_data(root_dir, test_size=0.2):\n",
    "    classes = ['untreated', 'single_dose', 'drug_screened']\n",
    "    image_files = []\n",
    "    labels = []\n",
    "\n",
    "    for idx, class_name in enumerate(classes):\n",
    "        class_dir = os.path.join(root_dir, class_name)\n",
    "        files = [os.path.join(class_dir, file) for file in os.listdir(class_dir) if file.endswith('.tiff')]\n",
    "        image_files.extend(files)\n",
    "        labels.extend([idx] * len(files))\n",
    "    \n",
    "    # Split data into training and test sets\n",
    "    train_files, test_files, train_labels, test_labels = train_test_split(\n",
    "        image_files, labels, test_size=test_size, stratify=labels, random_state=42)\n",
    "\n",
    "    return train_files, test_files, train_labels, test_labels\n",
    "\n",
    "# Directories for labeled data\n",
    "image_dir = \"/home/k54739/Data_supervised\"\n",
    "\n",
    "# Load and split the data\n",
    "train_files, test_files, train_labels, test_labels = load_and_split_data(image_dir, test_size=0.2)\n",
    "\n",
    "# Create the labeled datasets\n",
    "train_labeled_dataset = LabeledImageDataset(train_files, train_labels)\n",
    "test_labeled_dataset = LabeledImageDataset(test_files, test_labels)\n",
    "\n",
    "# Define DataLoaders\n",
    "batch_size = 16\n",
    "train_loader_labeled = DataLoader(train_labeled_dataset, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=os.cpu_count())\n",
    "test_loader_labeled = DataLoader(test_labeled_dataset, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True, num_workers=os.cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([16, 1, 96, 96]) torch.Size([16]) torch.float32\n",
      "tensor([0, 0, 1, 0, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1])\n"
     ]
    }
   ],
   "source": [
    "for anchor,label in train_loader_labeled:\n",
    "    print(anchor.shape, label.shape, anchor.dtype)\n",
    "    print(label)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def prepare_data_features(model, dataloader):\n",
    "    # Prepare model\n",
    "    network = deepcopy(model.convnet)\n",
    "    network.fc = nn.Identity()  # Removing projection head g(.)\n",
    "    network.eval()\n",
    "    network.to(device)\n",
    "\n",
    "    # Encode all images\n",
    "    feats, labels = [], []\n",
    "    for batch_imgs, batch_labels in tqdm(dataloader):\n",
    "        batch_imgs = batch_imgs.to(device)\n",
    "        batch_feats = network(batch_imgs)\n",
    "        \n",
    "        #print(f\"Batch features shape: {batch_feats.shape}\")\n",
    "        #print(f\"Batch labels shape: {batch_labels.shape}\")\n",
    "        \n",
    "        feats.append(batch_feats.detach().cpu())\n",
    "        labels.append(batch_labels)\n",
    "\n",
    "    feats = torch.cat(feats, dim=0)\n",
    "    labels = torch.cat(labels, dim=0)\n",
    "    \n",
    "    #print(f\"Features shape after concatenation: {feats.shape}\")\n",
    "    #print(f\"Labels shape after concatenation: {labels.shape}\")\n",
    "\n",
    "    return torch.utils.data.TensorDataset(feats, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:10<00:00,  3.52s/it]\n",
      "100%|██████████| 1/1 [00:07<00:00,  7.96s/it]\n"
     ]
    }
   ],
   "source": [
    "# Extract features for train and test datasets\n",
    "train_feats_simclr = prepare_data_features(simclr_model, train_loader_labeled)\n",
    "test_feats_simclr = prepare_data_features(simclr_model, test_loader_labeled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LogisticRegression(pl.LightningModule):\n",
    "    def __init__(self, feature_dim, num_classes, lr, weight_decay, max_epochs=5):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        # Mapping from representation h to classes\n",
    "        self.model = nn.Linear(feature_dim, num_classes)\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(),\n",
    "                                lr=self.hparams.lr,\n",
    "                                weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = optim.lr_scheduler.MultiStepLR(optimizer,\n",
    "                                                      milestones=[int(self.hparams.max_epochs * 0.6),\n",
    "                                                                  int(self.hparams.max_epochs * 0.8)],\n",
    "                                                      gamma=0.1)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def _calculate_loss(self, batch, mode='train'):\n",
    "        feats, labels = batch\n",
    "        preds = self.model(feats)\n",
    "        loss = nn.functional.cross_entropy(preds, labels)\n",
    "        acc = (preds.argmax(dim=-1) == labels).float().mean()\n",
    "\n",
    "        self.log(mode + '_loss', loss)\n",
    "        self.log(mode + '_acc', acc)\n",
    "        return loss\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self._calculate_loss(batch, mode='train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self._calculate_loss(batch, mode='val')\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        self._calculate_loss(batch, mode='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_logreg(batch_size, train_feats_data, test_feats_data, model_suffix, max_epochs=100, **kwargs):\n",
    "    trainer = pl.Trainer(default_root_dir=os.path.join(CHECKPOINT_PATH, \"LogisticRegression\"),\n",
    "                         accelerator=\"gpu\" if torch.cuda.is_available() else \"cpu\",\n",
    "                         devices=1,\n",
    "                         max_epochs=max_epochs,\n",
    "                         callbacks=[ModelCheckpoint(save_weights_only=True, mode='max', monitor='val_acc'),\n",
    "                                    LearningRateMonitor(\"epoch\")],\n",
    "                         enable_progress_bar=True,\n",
    "                         check_val_every_n_epoch=10)\n",
    "    trainer.logger._default_hp_metric = None\n",
    "\n",
    "    # Data loaders\n",
    "    train_loader = DataLoader(train_feats_data, batch_size=batch_size, shuffle=True,\n",
    "                                   drop_last=False, pin_memory=True, num_workers=0)\n",
    "    test_loader = DataLoader(test_feats_data, batch_size=batch_size, shuffle=False,\n",
    "                                  drop_last=False, pin_memory=True, num_workers=0)\n",
    "\n",
    "    # Check whether pretrained model exists. If yes, load it and skip training\n",
    "    pretrained_filename = os.path.join(CHECKPOINT_PATH, f\"LogisticRegression_{model_suffix}.ckpt\")\n",
    "    \n",
    "    if os.path.isfile(pretrained_filename):\n",
    "        print(f\"Found pretrained model at {pretrained_filename}, loading...\")\n",
    "        model = LogisticRegression.load_from_checkpoint(pretrained_filename)\n",
    "    else:\n",
    "        pl.seed_everything(42)  # To be reproducible\n",
    "        model = LogisticRegression(**kwargs)\n",
    "        trainer.fit(model, train_loader, test_loader)\n",
    "        best_model_path = trainer.checkpoint_callback.best_model_path\n",
    "        \n",
    "        if best_model_path:\n",
    "            print(f\"Saving best model to {best_model_path}\")\n",
    "            model = LogisticRegression.load_from_checkpoint(best_model_path)\n",
    "        else:\n",
    "            print(\"No checkpoint found. Training completed without saving a checkpoint.\")\n",
    "            model = LogisticRegression(**kwargs)  # Reinitialize if no checkpoint saved\n",
    "\n",
    "    # Test best model on train and validation set\n",
    "    train_result = trainer.test(model, train_loader, verbose=False)\n",
    "    test_result = trainer.test(model, test_loader, verbose=False)\n",
    "    result = {\"train\": train_result[0][\"test_acc\"], \"test\": test_result[0][\"test_acc\"]}\n",
    "\n",
    "    return model, result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Seed set to 42\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name  | Type   | Params | Mode \n",
      "-----------------------------------------\n",
      "0 | model | Linear | 1.5 K  | train\n",
      "-----------------------------------------\n",
      "1.5 K     Trainable params\n",
      "0         Non-trainable params\n",
      "1.5 K     Total params\n",
      "0.006     Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                            "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 63.35it/s, v_num=17] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "`Trainer.fit` stopped: `max_epochs=50` reached.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 49: 100%|██████████| 3/3 [00:00<00:00, 59.92it/s, v_num=17]\n",
      "Saving best model to saved_models/simclr/LogisticRegression/lightning_logs/version_17/checkpoints/epoch=9-step=30.ckpt\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 3/3 [00:00<00:00, 74.22it/s] \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 1/1 [00:00<00:00, 31.81it/s] \n",
      "Train Accuracy: 0.75, Test Accuracy: 0.75\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "# Train the logistic regression model\n",
    "logreg_model, results = train_logreg(batch_size=16, train_feats_data=train_feats_simclr, test_feats_data=test_feats_simclr, \n",
    "                                     model_suffix=\"SimCLR\", feature_dim=train_feats_simclr.tensors[0].shape[1], num_classes=3, lr=5e-4, weight_decay=1e-4, max_epochs=50)\n",
    "\n",
    "print(f\"Train Accuracy: {results['train']}, Test Accuracy: {results['test']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Simclr just another way used (not important)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "Missing logger folder: /home/k54739/lightning_logs\n",
      "/home/k54739/miniconda3/envs/thesis/lib/python3.12/site-packages/pytorch_lightning/callbacks/model_checkpoint.py:652: Checkpoint directory /home/k54739/saved_models/simclr exists and is not empty.\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n",
      "\n",
      "  | Name    | Type   | Params | Mode \n",
      "-------------------------------------------\n",
      "0 | convnet | ResNet | 11.5 M | train\n",
      "-------------------------------------------\n",
      "11.5 M    Trainable params\n",
      "0         Non-trainable params\n",
      "11.5 M    Total params\n",
      "45.994    Total estimated model params size (MB)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                                           \r"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/k54739/miniconda3/envs/thesis/lib/python3.12/site-packages/pytorch_lightning/loops/fit_loop.py:298: The number of training batches (19) is smaller than the logging interval Trainer(log_every_n_steps=50). Set a lower value for log_every_n_steps if you want to see logs for the training epoch.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0: 100%|██████████| 19/19 [00:26<00:00,  0.73it/s, v_num=0, train_loss_step=0.00136, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=1.430, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.399, train_acc_top1_epoch=0.998, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 0, global step 19: 'val_loss' reached 1.42672 (best 1.42672), saving model to '/home/k54739/saved_models/simclr/best_model.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1: 100%|██████████| 19/19 [00:30<00:00,  0.63it/s, v_num=0, train_loss_step=0.0704, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=2.280, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.212, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 1, global step 38: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2: 100%|██████████| 19/19 [00:28<00:00,  0.67it/s, v_num=0, train_loss_step=0.00146, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=1.560, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.179, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 2, global step 57: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3: 100%|██████████| 19/19 [00:28<00:00,  0.66it/s, v_num=0, train_loss_step=0.000935, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.324, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.117, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 3, global step 76: 'val_loss' reached 0.32446 (best 0.32446), saving model to '/home/k54739/saved_models/simclr/best_model.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4: 100%|██████████| 19/19 [00:28<00:00,  0.67it/s, v_num=0, train_loss_step=0.000764, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.101, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0894, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 4, global step 95: 'val_loss' reached 0.10053 (best 0.10053), saving model to '/home/k54739/saved_models/simclr/best_model.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5: 100%|██████████| 19/19 [00:30<00:00,  0.62it/s, v_num=0, train_loss_step=0.000277, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.0887, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0499, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 5, global step 114: 'val_loss' reached 0.08870 (best 0.08870), saving model to '/home/k54739/saved_models/simclr/best_model.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6: 100%|██████████| 19/19 [00:31<00:00,  0.60it/s, v_num=0, train_loss_step=0.000283, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.0729, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0491, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 6, global step 133: 'val_loss' reached 0.07294 (best 0.07294), saving model to '/home/k54739/saved_models/simclr/best_model.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7: 100%|██████████| 19/19 [00:32<00:00,  0.59it/s, v_num=0, train_loss_step=0.00102, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.188, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0451, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 7, global step 152: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8: 100%|██████████| 19/19 [00:29<00:00,  0.63it/s, v_num=0, train_loss_step=0.000299, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.310, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0476, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 8, global step 171: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9: 100%|██████████| 19/19 [00:29<00:00,  0.64it/s, v_num=0, train_loss_step=0.00184, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.157, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0586, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 9, global step 190: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10: 100%|██████████| 19/19 [00:29<00:00,  0.65it/s, v_num=0, train_loss_step=0.000687, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.401, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0842, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 10, global step 209: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11: 100%|██████████| 19/19 [00:28<00:00,  0.67it/s, v_num=0, train_loss_step=0.0469, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=1.350, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0897, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 11, global step 228: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12: 100%|██████████| 19/19 [00:29<00:00,  0.63it/s, v_num=0, train_loss_step=0.00543, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.293, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0709, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 12, global step 247: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13: 100%|██████████| 19/19 [00:30<00:00,  0.63it/s, v_num=0, train_loss_step=0.000951, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.355, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.080, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 13, global step 266: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14: 100%|██████████| 19/19 [00:30<00:00,  0.61it/s, v_num=0, train_loss_step=0.00158, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.109, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.065, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 14, global step 285: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15: 100%|██████████| 19/19 [00:29<00:00,  0.65it/s, v_num=0, train_loss_step=0.000742, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.114, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0531, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 15, global step 304: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16: 100%|██████████| 19/19 [00:30<00:00,  0.61it/s, v_num=0, train_loss_step=0.000428, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.0801, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0371, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 16, global step 323: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17: 100%|██████████| 19/19 [00:30<00:00,  0.62it/s, v_num=0, train_loss_step=0.00012, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.123, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0362, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]  "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 17, global step 342: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18: 100%|██████████| 19/19 [00:30<00:00,  0.62it/s, v_num=0, train_loss_step=0.000743, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.234, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0382, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 18, global step 361: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19: 100%|██████████| 19/19 [00:29<00:00,  0.64it/s, v_num=0, train_loss_step=0.000576, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.697, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0506, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 19, global step 380: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20: 100%|██████████| 19/19 [00:28<00:00,  0.66it/s, v_num=0, train_loss_step=0.000765, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.331, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.056, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 20, global step 399: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21: 100%|██████████| 19/19 [00:28<00:00,  0.66it/s, v_num=0, train_loss_step=0.0441, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.183, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0469, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 21, global step 418: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22: 100%|██████████| 19/19 [00:28<00:00,  0.67it/s, v_num=0, train_loss_step=0.0101, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.211, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0773, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 22, global step 437: 'val_loss' was not in top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23: 100%|██████████| 19/19 [00:28<00:00,  0.67it/s, v_num=0, train_loss_step=0.000409, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.048, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.0609, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 23, global step 456: 'val_loss' reached 0.04796 (best 0.04796), saving model to '/home/k54739/saved_models/simclr/best_model.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24: 100%|██████████| 19/19 [00:28<00:00,  0.66it/s, v_num=0, train_loss_step=0.000209, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.038, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.050, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000] "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Epoch 24, global step 475: 'val_loss' reached 0.03798 (best 0.03798), saving model to '/home/k54739/saved_models/simclr/best_model.ckpt' as top 1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25:   0%|          | 0/19 [00:00<?, ?it/s, v_num=0, train_loss_step=0.000209, train_acc_top1_step=1.000, train_acc_top5_step=1.000, train_acc_mean_pos_step=1.000, val_loss=0.038, val_acc_top1=1.000, val_acc_top5=1.000, val_acc_mean_pos=1.000, train_loss_epoch=0.050, train_acc_top1_epoch=1.000, train_acc_top5_epoch=1.000, train_acc_mean_pos_epoch=1.000]         "
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception ignored in: <function _MultiProcessingDataLoaderIter.__del__ at 0x7f73ea854ae0>\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/k54739/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1477, in __del__\n",
      "    self._shutdown_workers()\n",
      "  File \"/home/k54739/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1436, in _shutdown_workers\n",
      "    self._mark_worker_as_unavailable(worker_id, shutdown=True)\n",
      "  File \"/home/k54739/miniconda3/envs/thesis/lib/python3.12/site-packages/torch/utils/data/dataloader.py\", line 1384, in _mark_worker_as_unavailable\n",
      "    q.put(None)\n",
      "  File \"/home/k54739/miniconda3/envs/thesis/lib/python3.12/multiprocessing/queues.py\", line 94, in put\n",
      "    self._start_thread()\n",
      "  File \"/home/k54739/miniconda3/envs/thesis/lib/python3.12/multiprocessing/queues.py\", line 192, in _start_thread\n",
      "    self._thread.start()\n",
      "  File \"/home/k54739/miniconda3/envs/thesis/lib/python3.12/threading.py\", line 997, in start\n",
      "    self._started.wait()\n",
      "  File \"/home/k54739/miniconda3/envs/thesis/lib/python3.12/threading.py\", line 655, in wait\n",
      "    signaled = self._cond.wait(timeout)\n",
      "               ^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"/home/k54739/miniconda3/envs/thesis/lib/python3.12/threading.py\", line 355, in wait\n",
      "    waiter.acquire()\n",
      "KeyboardInterrupt: \n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import pytorch_lightning as pl\n",
    "from torch import nn, optim\n",
    "from torch.utils.data import DataLoader, Dataset, random_split\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import tifffile as tiff\n",
    "from sklearn.model_selection import train_test_split\n",
    "from copy import deepcopy\n",
    "from tqdm import tqdm\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint, LearningRateMonitor\n",
    "\n",
    "# Set the device\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "CHECKPOINT_PATH = \"./saved_models/simclr\"  # Change this to your desired checkpoint path\n",
    "\n",
    "# Custom Dataset class\n",
    "class ImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.image_files = [os.path.join(image_dir, file) for file in os.listdir(image_dir) if file.endswith('.tiff')]\n",
    "        self.resize_transform = transforms.Resize((256, 256))\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_files[idx]\n",
    "        image = tiff.imread(img_path)\n",
    "\n",
    "        # Ensure the image has 3 layers (channels)\n",
    "        if image.shape[0] != 3:\n",
    "            raise ValueError(f\"Image {img_path} does not have exactly 3 layers.\")\n",
    "\n",
    "        # Normalize the 16-bit image to [0, 1]\n",
    "        image = image.astype(np.float32) / 65535.0\n",
    "\n",
    "        # Calculate sharpness for each layer\n",
    "        sharpness_scores = []\n",
    "        for i in range(3):\n",
    "            layer = image[i]\n",
    "            gy, gx = np.gradient(layer)\n",
    "            gnorm = np.sqrt(gx**2 + gy**2)\n",
    "            sharpness = np.average(gnorm)\n",
    "            sharpness_scores.append(sharpness)\n",
    "\n",
    "        # Find the index of the sharpest layer\n",
    "        sharpest_layer_index = np.argmax(sharpness_scores)\n",
    "        \n",
    "        # Determine the anchor (sharpest layer) and the other two layers (augmentations)\n",
    "        anchor = image[sharpest_layer_index]\n",
    "        other_indices = [i for i in range(3) if i != sharpest_layer_index]\n",
    "        augmentation1 = image[other_indices[0]]\n",
    "        augmentation2 = image[other_indices[1]]\n",
    "\n",
    "        # Convert to a torch tensor and add channel dimension\n",
    "        anchor = torch.tensor(anchor, dtype=torch.float32).unsqueeze(0)\n",
    "        aug1 = torch.tensor(augmentation1, dtype=torch.float32).unsqueeze(0)\n",
    "        aug2 = torch.tensor(augmentation2, dtype=torch.float32).unsqueeze(0)\n",
    "        \n",
    "        # Apply resize transform\n",
    "        anchor = self.resize_transform(anchor)\n",
    "        aug1 = self.resize_transform(aug1)\n",
    "        aug2 = self.resize_transform(aug2)\n",
    "\n",
    "        return aug1, aug2\n",
    "\n",
    "# Create the dataset\n",
    "image_dir = \"/home/k54739/.tiff_experiment_unsupervised_data/combined\"\n",
    "dataset = ImageDataset(image_dir=image_dir)\n",
    "batch_size = 16\n",
    "\n",
    "# Function to split dataset with explicit percentage\n",
    "def split_dataset(dataset, val_percentage):\n",
    "    val_size = int(len(dataset) * val_percentage)\n",
    "    train_size = len(dataset) - val_size\n",
    "    return random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Split the dataset with 20% for validation\n",
    "val_percentage = 0.2\n",
    "train_dataset, val_dataset = split_dataset(dataset, val_percentage)\n",
    "\n",
    "# Define DataLoaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, drop_last=False, pin_memory=True, num_workers=os.cpu_count())\n",
    "val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False, drop_last=False, pin_memory=True, num_workers=os.cpu_count())\n",
    "\n",
    "# Define the SimCLR model class (same as in the tutorial)\n",
    "class SimCLR(pl.LightningModule):\n",
    "    def __init__(self, hidden_dim, lr, temperature, weight_decay, max_epochs=50):\n",
    "        super().__init__()\n",
    "        self.save_hyperparameters()\n",
    "        assert self.hparams.temperature > 0.0, 'The temperature must be a positive float!'\n",
    "\n",
    "        # Load the pretrained ResNet-18 model\n",
    "        self.convnet = torchvision.models.resnet18(weights='ResNet18_Weights.DEFAULT')\n",
    "        \n",
    "        # Modify the first convolutional layer to accept single-channel input\n",
    "        # Replace the existing convolutional layer with one that accepts a single channel\n",
    "        #in_channels = 1\n",
    "        '''self.convnet.conv1 = nn.Conv2d(in_channels, self.convnet.conv1.out_channels, \n",
    "                                        kernel_size=self.convnet.conv1.kernel_size, \n",
    "                                        stride=self.convnet.conv1.stride, \n",
    "                                        padding=self.convnet.conv1.padding, \n",
    "                                        bias=self.convnet.conv1.bias)'''\n",
    "                                        \n",
    "        weight = self.convnet.conv1.weight.clone()\n",
    "        self.convnet.conv1 = nn.Conv2d(1, 64, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
    "        self.convnet.conv1.weight.data = weight.sum(dim=1, keepdim=True)\n",
    "        \n",
    "        # Modify the fully connected layer\n",
    "        self.convnet.fc = nn.Sequential(\n",
    "            nn.Linear(self.convnet.fc.in_features, 4*hidden_dim),  # Linear layer with 4*hidden_dim output\n",
    "            nn.ReLU(inplace=True),\n",
    "            nn.Linear(4*hidden_dim, hidden_dim)  # Output layer with hidden_dim output\n",
    "        )\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        optimizer = optim.AdamW(self.parameters(), lr=self.hparams.lr, weight_decay=self.hparams.weight_decay)\n",
    "        lr_scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=self.hparams.max_epochs, eta_min=self.hparams.lr/50)\n",
    "        return [optimizer], [lr_scheduler]\n",
    "\n",
    "    def info_nce_loss(self, batch, mode='train'):\n",
    "        aug1, aug2 = batch\n",
    "        imgs = torch.cat((aug1, aug2), dim=0).to(self.device)  # Concatenate along the batch dimension\n",
    "\n",
    "        # Encode all images\n",
    "        feats = self.convnet(imgs).to(self.device)\n",
    "        # Calculate cosine similarity\n",
    "        cos_sim = nn.functional.cosine_similarity(feats[:, None, :], feats[None, :, :], dim=-1)\n",
    "        # Mask out cosine similarity to itself\n",
    "        self_mask = torch.eye(cos_sim.shape[0], dtype=torch.bool, device=cos_sim.device)\n",
    "        cos_sim.masked_fill_(self_mask, -9e15)\n",
    "        # Find positive example -> batch_size//2 away from the original example\n",
    "        pos_mask = self_mask.roll(shifts=cos_sim.shape[0] // 2, dims=0)\n",
    "        # InfoNCE loss\n",
    "        cos_sim = cos_sim / self.hparams.temperature\n",
    "        nll = -cos_sim[pos_mask] + torch.logsumexp(cos_sim, dim=-1)\n",
    "        nll = nll.mean()\n",
    "\n",
    "        # Logging loss\n",
    "        self.log(mode + '_loss', nll, on_epoch=True, prog_bar=True)\n",
    "        # Get ranking position of positive example\n",
    "        comb_sim = torch.cat([cos_sim[pos_mask][:, None],  # First position positive example\n",
    "                              cos_sim.masked_fill(pos_mask, -9e15)], dim=-1)\n",
    "        sim_argsort = comb_sim.argsort(dim=-1, descending=True).argmin(dim=-1)\n",
    "        # Logging ranking metrics\n",
    "        self.log(mode + '_acc_top1', (sim_argsort == 0).float().mean(), on_epoch=True, prog_bar=True)\n",
    "        self.log(mode + '_acc_top5', (sim_argsort < 5).float().mean(), on_epoch=True, prog_bar=True)\n",
    "        self.log(mode + '_acc_mean_pos', 1 + sim_argsort.float().mean(), on_epoch=True, prog_bar=True)\n",
    "\n",
    "        return nll\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        return self.info_nce_loss(batch, mode='train')\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        self.info_nce_loss(batch, mode='val')\n",
    "\n",
    "# Define a callback to plot the training/validation loss and accuracy\n",
    "class PlotLossAccuracyCallback(pl.Callback):\n",
    "    def __init__(self):\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.train_acc_top1 = []\n",
    "        self.val_acc_top1 = []\n",
    "\n",
    "    def on_train_epoch_end(self, trainer, pl_module):\n",
    "        if 'train_loss' in trainer.callback_metrics:\n",
    "            self.train_losses.append(trainer.callback_metrics['train_loss'].item())\n",
    "        if 'train_acc_top1' in trainer.callback_metrics:\n",
    "            self.train_acc_top1.append(trainer.callback_metrics['train_acc_top1'].item())\n",
    "\n",
    "    def on_validation_epoch_end(self, trainer, pl_module):\n",
    "        if 'val_loss' in trainer.callback_metrics:\n",
    "            self.val_losses.append(trainer.callback_metrics['val_loss'].item())\n",
    "        if 'val_acc_top1' in trainer.callback_metrics:\n",
    "            self.val_acc_top1.append(trainer.callback_metrics['val_acc_top1'].item())\n",
    "\n",
    "    def plot_metrics(self):\n",
    "        epochs = range(1, len(self.train_losses) + 1)\n",
    "        plt.figure(figsize=(12, 4))\n",
    "        \n",
    "        plt.subplot(1, 2, 1)\n",
    "        plt.plot(epochs, self.train_losses, label='Train Loss')\n",
    "        plt.plot(epochs, self.val_losses, label='Validation Loss')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Loss')\n",
    "        plt.legend()\n",
    "        plt.title('Training and Validation Loss')\n",
    "\n",
    "        plt.subplot(1, 2, 2)\n",
    "        plt.plot(epochs, self.train_acc_top1, label='Train Accuracy')\n",
    "        plt.plot(epochs, self.val_acc_top1, label='Validation Accuracy')\n",
    "        plt.xlabel('Epochs')\n",
    "        plt.ylabel('Top-1 Accuracy')\n",
    "        plt.legend()\n",
    "        plt.title('Training and Validation Accuracy')\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "# Define the model and trainer\n",
    "model = SimCLR(hidden_dim=128, lr=1e-3, temperature=0.1, weight_decay=1e-4, max_epochs=5)\n",
    "\n",
    "# Callbacks\n",
    "checkpoint_callback = ModelCheckpoint(\n",
    "    dirpath=CHECKPOINT_PATH,\n",
    "    filename='best_model',\n",
    "    save_top_k=1,\n",
    "    verbose=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min'\n",
    ")\n",
    "\n",
    "lr_monitor = LearningRateMonitor(logging_interval='epoch')\n",
    "plot_callback = PlotLossAccuracyCallback()\n",
    "\n",
    "# Train the model\n",
    "trainer = pl.Trainer(\n",
    "    max_epochs=50,\n",
    "    callbacks=[checkpoint_callback, lr_monitor, plot_callback],\n",
    "    accelerator = 'gpu' if torch.cuda.is_available() else cpu\n",
    ")\n",
    "\n",
    "# Fit the model\n",
    "trainer.fit(model, train_loader, val_loader)\n",
    "\n",
    "# Plot the metrics\n",
    "plot_callback.plot_metrics()\n",
    "\n",
    "# Load the best checkpoint after training\n",
    "best_model_path = checkpoint_callback.best_model_path\n",
    "print(f\"Best model path: {best_model_path}\")\n",
    "\n",
    "# Ensure the best model is loaded for further use\n",
    "model = SimCLR.load_from_checkpoint(best_model_path)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "thesis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
